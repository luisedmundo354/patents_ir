<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07297862-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07297862</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10234677</doc-number>
<date>20020904</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2001-267951</doc-number>
<date>20010904</date>
</priority-claim>
</priority-claims>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>10</class>
<subclass>H</subclass>
<main-group>3</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification> 84723</main-classification>
<further-classification> 84609</further-classification>
<further-classification> 84615</further-classification>
<further-classification> 84622</further-classification>
<further-classification> 84735</further-classification>
</classification-national>
<invention-title id="d0e61">Musical tone control apparatus and method</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5027688</doc-number>
<kind>A</kind>
<name>Suzuki et al.</name>
<date>19910700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5046394</doc-number>
<kind>A</kind>
<name>Suzuki et al.</name>
<date>19910900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5058480</doc-number>
<kind>A</kind>
<name>Suzuki et al.</name>
<date>19911000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5177311</doc-number>
<kind>A</kind>
<name>Suzuki et al.</name>
<date>19930100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5192823</doc-number>
<kind>A</kind>
<name>Suzuki et al.</name>
<date>19930300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 84600</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5278346</doc-number>
<kind>A</kind>
<name>Yamaguchi</name>
<date>19940100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>5290964</doc-number>
<kind>A</kind>
<name>Hiyoshi et al.</name>
<date>19940300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5313010</doc-number>
<kind>A</kind>
<name>Matsushima et al.</name>
<date>19940500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5338891</doc-number>
<kind>A</kind>
<name>Masubuchi et al.</name>
<date>19940800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 84600</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>5373096</doc-number>
<kind>A</kind>
<name>Suzuki et al.</name>
<date>19941200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 84600</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>5396025</doc-number>
<kind>A</kind>
<name>Tamura</name>
<date>19950300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 84736</main-classification></classification-national>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>5422956</doc-number>
<kind>A</kind>
<name>Wheaton</name>
<date>19950600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>381122</main-classification></classification-national>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>5512703</doc-number>
<kind>A</kind>
<name>Usa</name>
<date>19960400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>5585584</doc-number>
<kind>A</kind>
<name>Usa</name>
<date>19961200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>5648627</doc-number>
<kind>A</kind>
<name>Usa</name>
<date>19970700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>5663514</doc-number>
<kind>A</kind>
<name>Usa</name>
<date>19970900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>6297438</doc-number>
<kind>B1</kind>
<name>Por Paul</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 84600</main-classification></classification-national>
</citation>
<citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>6861582</doc-number>
<kind>B2</kind>
<name>Street</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 84600</main-classification></classification-national>
</citation>
<citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>6969795</doc-number>
<kind>B2</kind>
<name>Hofmeister et al.</name>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 84600</main-classification></classification-national>
</citation>
<citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>2001/0015123</doc-number>
<kind>A1</kind>
<name>Nishitani et al.</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>2002/0088335</doc-number>
<kind>A1</kind>
<name>Nishitani et al.</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 84600</main-classification></classification-national>
</citation>
<citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2003/0041721</doc-number>
<kind>A1</kind>
<name>Nishitani et al.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 84609</main-classification></classification-national>
</citation>
<citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2003/0101863</doc-number>
<kind>A1</kind>
<name>Street</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 84723</main-classification></classification-national>
</citation>
<citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2003/0196542</doc-number>
<kind>A1</kind>
<name>Harrison, Jr.</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 84737</main-classification></classification-national>
</citation>
<citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2005/0013662</doc-number>
<kind>A1</kind>
<name>Provenzano, III</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>404 75</main-classification></classification-national>
</citation>
<citation>
<patcit num="00026">
<document-id>
<country>JP</country>
<doc-number>54-118223</doc-number>
<date>19790900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00027">
<document-id>
<country>JP</country>
<doc-number>01-243096</doc-number>
<date>19890900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00028">
<document-id>
<country>JP</country>
<doc-number>02-19197</doc-number>
<date>19900200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00029">
<document-id>
<country>JP</country>
<doc-number>04-33912</doc-number>
<date>19900300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00030">
<document-id>
<country>JP</country>
<doc-number>04-085598</doc-number>
<date>19920300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00031">
<document-id>
<country>JP</country>
<doc-number>4257920</doc-number>
<date>19920900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00032">
<document-id>
<country>JP</country>
<doc-number>04-294394</doc-number>
<date>19921000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00033">
<document-id>
<country>JP</country>
<doc-number>06-035466</doc-number>
<date>19940200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00034">
<document-id>
<country>JP</country>
<doc-number>09-127937</doc-number>
<date>19970500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00035">
<document-id>
<country>JP</country>
<doc-number>11-85153</doc-number>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00036">
<othercit>Japanese Office Action dated Nov. 16, 2005 and translation.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00037">
<othercit>Submission of Publication filed in the basic Japanese patent application No. 2001-267961 and English translations thereof.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00038">
<othercit>Japanese Office Action dated Feb. 14, 2006 issued on Japanese Patent Application No. 2001-267951.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>17</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification> 84600-604</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84609-612</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84615</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84622-626</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84633-636</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84649-653</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84659-662</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84665</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84723</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84725-726</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84730-731</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84735-737</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84741</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>8</number-of-drawing-sheets>
<number-of-figures>13</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20030041721</doc-number>
<kind>A1</kind>
<date>20030306</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Nishitani</last-name>
<first-name>Yoshiki</first-name>
<address>
<city>Hamakita</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Miyazawa</last-name>
<first-name>Kenichi</first-name>
<address>
<city>Iwata-gun</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Ono</last-name>
<first-name>Masaharu</first-name>
<address>
<city>Hamamatsu</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="004" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Kato</last-name>
<first-name>Nagayuki</first-name>
<address>
<city>Hamamatsu</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Harness, Dickey &amp; Pierce, PLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Yamaha Corporation</orgname>
<role>03</role>
<address>
<city>Shizuoka-Ken</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Fletcher</last-name>
<first-name>Marlon</first-name>
<department>2837</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">There is provided a musical tone control apparatus that enables a user to easily play a musical instrument without spoiling the user's feeling that he is actually playing a musical instrument. A storage device stores musical piece data containing interval data indicative of intervals of musical tones constituting a musical piece. A motion of an operator is detected. A controller provides control so as to instruct a musical tone output device capable of outputting musical tones to adopt the intervals as one of characteristic amounts relating to musical tones to be output from the musical tone output device, according to the interval data, and instruct the musical tone output device to adopt at least one of the characteristic amounts other than the intervals according to the detected motion of the operator.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="151.38mm" wi="176.36mm" file="US07297862-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="203.88mm" wi="182.37mm" file="US07297862-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="180.42mm" wi="144.19mm" file="US07297862-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="229.95mm" wi="177.80mm" file="US07297862-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="204.55mm" wi="161.80mm" file="US07297862-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="143.09mm" wi="131.15mm" file="US07297862-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="192.45mm" wi="81.11mm" file="US07297862-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="200.15mm" wi="95.42mm" file="US07297862-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="240.96mm" wi="179.07mm" file="US07297862-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">1. Field of the invention</p>
<p id="p-0003" num="0002">The present invention relates to a musical tone control apparatus and method for controlling generation of musical tones.</p>
<p id="p-0004" num="0003">2. Description of the Related Art</p>
<p id="p-0005" num="0004">As is well known, various musical expressions can be provided using various natural instruments including keyboard instruments such as piano and organ, string instruments such as violin and guitar, and wind instruments such as trumpet and flute. Further, electronic instruments such as electronic piano and organ can be used to provide musical expressions as rich as those of the natural instruments.</p>
<p id="p-0006" num="0005">The manner of playing a musical piece is characterized by controlled amounts of various characteristics (such as rhythm, volume, and interval (hereinafter referred to as “characteristic amounts”). Therefore, in order for a player to provide a desired musical expression using a musical instrument, he or she must select and output specific musical tones with appropriate rhythm and volume. However, it is very difficult for a beginner, who is not accustomed to playing a musical instrument, to properly select all these characteristic amounts for performance.</p>
<p id="p-0007" num="0006">On the other hand, what is called Desk Top Music enables the user to play a desired musical piece by using a personal computer to input various characteristic amounts for musical tones to the computer. Thus, even a beginner can relatively easily provide various performances. However, with this method, the user cannot have a feeling that he is actually playing a musical instrument. Therefore, those who desire to enjoy actual operations of playing a musical instrument are not always satisfied with this method.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INNOVATION</heading>
<p id="p-0008" num="0007">It is an object of the present invention to provide a musical tone control apparatus and method that enable a user to easily play a musical instrument without spoiling the user's feeling that he is actually playing a musical instrument.</p>
<p id="p-0009" num="0008">To attain the above object, in a first aspect of the present invention, there is provided a musical tone control apparatus comprising a storage device that stores musical piece data containing interval data indicative of intervals of musical tones constituting a musical piece, a detecting device that detects a motion of an operator, and a controller that provides control so as to instruct a musical tone output device capable of outputting musical tones to adopt the intervals as one of characteristic amounts relating to musical tones to be output from the musical tone output device, according to the interval data, and instruct the musical tone output device to adopt at least one of the characteristic amounts other than the intervals according to the motion of the operator detected by the detecting device.</p>
<p id="p-0010" num="0009">In a preferred form of the present invention, the controller instructs the musical tone output device to adopt timing corresponding to the motion of the operator as timing in which each of the musical tones constituting the musical piece is to be output.</p>
<p id="p-0011" num="0010">In a more preferred form of the present invention, the musical tone control apparatus according to the present invention further comprises an operating element operated by the operator, and wherein the detecting device detects an operation made on the operating element, and the controller instructs the musical tone output device to adopt timing corresponding to the operation made on the operating element as timing in which at least one associated musical tone of the musical tones constituting the musical tone is to be output.</p>
<p id="p-0012" num="0011">Preferably, the operating element is disposed to reciprocate along a particular direction according to the motion of the operator, and the controller is responsive to the operating element being moved, for instructing the musical tone output device to output at least one associated musical tone of the musical tones constituting the musical piece.</p>
<p id="p-0013" num="0012">More preferably, the controller is responsive to the operating means being moved in one direction along the particular direction, for instructing the musical tone output device to output at least one associated musical tone of the musical tones constituting the musical piece.</p>
<p id="p-0014" num="0013">Also preferably, the operating element comprises a pair of members joined together via a telescopic joining member, and the controller is responsive to at least one of the pair of members being moved away from each other and the pair of members being moved toward each other according to the motion of the operator, for instructing the musical tone controller to output at least one associated musical tone of the musical tones constituting the musical piece.</p>
<p id="p-0015" num="0014">In a preferred example, the operating element comprises strings that are vibrated in response to the motion of the operator, and the controller is responsive to the strings being vibrated, for instructing the musical tone output device to output at least one associated musical tone of the musical tones constituting the musical piece.</p>
<p id="p-0016" num="0015">In a preferred form of the present invention, the controller instructs the musical tone output device to adopt volume corresponding to the motion of the operator as the volume of the musical tones to be output from the musical tone output device.</p>
<p id="p-0017" num="0016">Preferably, the detecting device detects a posture of the musical tone control apparatus which changes depending on the motion of the operator, and the controller instructs the musical tone output device to adopt a volume corresponding to the posture of the musical tone control apparatus, as a volume with which the musical tones to be output from the musical tone output device.</p>
<p id="p-0018" num="0017">In a more preferred form of the present invention, the musical tone control apparatus according to the present invention further comprises an operating element operated by the operator, and wherein the detecting device detects an motion made on the operating element, and the controller instructs the musical tone output device to carry out or stop output of the musical tones based on the musical piece data, depending on the operation detected by the detecting device.</p>
<p id="p-0019" num="0018">In this case, it is preferable that the controller is responsive to the operating element being operated, for instructing the musical tone output device to carry out the output of the musical tones and responsive to the operating element not being operated, for instructing the musical tone output device to stop the output of the musical tones.</p>
<p id="p-0020" num="0019">It is also preferable that the controller instructs the musical tone output device to adopt a tempo corresponding to the motion of the operator, as a tempo at which the output of the musical tones is carried out.</p>
<p id="p-0021" num="0020">It is preferable that the musical tone output device is provided in one body with the musical tone controller.</p>
<p id="p-0022" num="0021">To attain the above object, in a second aspect of the present invention, there is provided a musical tone control method comprising the steps of causing a storage device to store musical piece data containing interval data indicative of intervals of musical tones constituting a musical piece, detecting a motion of an operator, and instructing a musical tone output device capable of outputting musical tones to adopt the intervals as one of characteristic amounts relating to musical tones to be output from the musical tone output device, according to the interval data, and instructing the musical tone output device to adopt at least one of the characteristic amounts other than the intervals according to the detected motion of the operator.</p>
<p id="p-0023" num="0022">According to the present invention, the intervals of musical tones constituting a musical piece are determined based on interval data stored in advance, whereas the characteristic amounts relating to musical tones other than the intervals are determined according to the operator's motion detected by the detecting device. As a result, the operator, who plays the musical piece, need not pay special attention to the intervals of musical tones and can thus easily play the musical piece. On the other hand, the characteristic amounts relating to the musical tones other than the intervals are adjusted according to the operator's motion, thereby avoiding spoilage of the operator's feeling that he is actually playing musical instrument.</p>
<p id="p-0024" num="0023">The above and other objects, features and advantages of the Invention will become more apparent from the following detailed description taken in conjunction with the accompanying drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing the functional construction of a musical tone control apparatus according to a first embodiment of the present invention;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 2</figref> is a view showing an example of the contents of musical piece data for use in the musical tone control apparatus in <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 3A</figref> is a plan view showing the appearance of an first example of the musical tone control apparatus in <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 3B</figref> is a side view of the musical tone control apparatus in <figref idref="DRAWINGS">FIG. 3A</figref>;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram showing the functional construction of the musical tone control apparatus in <figref idref="DRAWINGS">FIGS. 3A and 3B</figref>;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 5</figref> is a view useful in explaining the operation of the musical tone control apparatus in <figref idref="DRAWINGS">FIGS. 3A and 3B</figref>;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 6</figref> is a view showing an example of operation of the musical tone control apparatus in <figref idref="DRAWINGS">FIGS. 3A and 3B</figref>;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 7</figref> is a view showing an example of operation of the musical tone control apparatus in <figref idref="DRAWINGS">FIGS. 3A and 3B</figref>;</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 8</figref> is a perspective view showing the appearance of a second example of the musical tone control apparatus in <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 9</figref> is a perspective view showing the appearance of a third example of the musical tone control apparatus in <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 10</figref> is a perspective view showing the appearance of a variation of the third example of the musical tone control apparatus in <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 11</figref> is a perspective view showing the appearance of a fourth example of the musical tone control apparatus in <figref idref="DRAWINGS">FIG. 1</figref>; and</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 12</figref> is a view useful in explaining the operation of a musical tone control apparatus according to a second embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0038" num="0037">The present invention will be now described with reference to the drawings showing preferred embodiments thereof. The embodiments shown below illustrate preferred embodiments of the present invention and do not limit the present invention. The embodiments can be arbitrarily changed within the scope of the present invention.</p>
<p id="p-0039" num="0038">First, the construction of a musical tone control apparatus according to a first embodiment of the present invention will be described with reference to <figref idref="DRAWINGS">FIG. 1</figref>. As shown in <figref idref="DRAWINGS">FIG. 1</figref>, the musical tone control apparatus <b>1</b> according to the present embodiment is comprised of a motion sensor <b>11</b>, a storage device <b>12</b>, a tone generator device <b>13</b>, a sound speaker system <b>14</b>, and a controller <b>15</b>.</p>
<p id="p-0040" num="0039">The motion sensor <b>11</b> is means for detecting the motion of an operator of the musical tone control apparatus <b>1</b>. Specifically, the motion sensor <b>11</b> may be an acceleration sensor, a speed sensor, and a tilt sensor, and is disposed to output a signal corresponding to the operator's motion (hereinafter referred to as the “motion signal”), to the controller <b>15</b>. Motions to be detected by the motion sensor <b>11</b> include, for example, a motion of the operator operating a predetermined operating element, and a motion of the operator tilting the musical tone control apparatus <b>1</b>. The specific contents of the motions will be described later in detail.</p>
<p id="p-0041" num="0040">The storage device <b>12</b> stores musical piece data corresponding to a musical piece to be played, and is comprised of a storage medium such as a floppy disk (registered trade name) or a CD-ROM, and a readout device that reads out data stored in the storage medium. The storage device <b>12</b> (more specifically, the storage medium constituting the storage device <b>12</b>) stores musical piece data of a plurality of musical pieces. Here, <figref idref="DRAWINGS">FIG. 2</figref> is a view showing an example of the contents of the musical piece data. As shown in the figure, the musical piece data are stored in correspondence to the respective musical pieces. Musical piece data corresponding to one musical piece contains interval data (in <figref idref="DRAWINGS">FIG. 2</figref>, “do (C)”, “mi (E)”, and others) indicative of the intervals of a plurality of musical tones constituting the musical piece, the interval data being arranged in the order corresponding to the arrangement of the musical tones constituting the musical piece.</p>
<p id="p-0042" num="0041">The tone generator device <b>13</b>, shown in <figref idref="DRAWINGS">FIG. 1</figref>, is means for generating musical tone signals corresponding to musical tones to be output and outputting the musical tone signals to the sound speaker system <b>14</b>. More specifically, when the controller <b>15</b> designates characteristic amounts for musical tones, the tone generator device <b>13</b> generates musical tone signals corresponding to the musical tones specified by these characteristic amounts, and outputs the musical tone signals to the sound speaker system. The sound speaker system <b>14</b> is comprised of, for example, an amplifier, and a speaker, and outputs via the speaker musical tones corresponding to the musical tone signal supplied from the tone generator device <b>13</b>.</p>
<p id="p-0043" num="0042">The controller <b>15</b> is comprised of a CPU (Central Processing Unit), and functions as a control center of the musical tone control apparatus such that it transmits and receives various kinds of information to and from the storage device <b>12</b> and the tone generator device <b>13</b>. More specifically, the controller <b>15</b> instructs the tone generator device <b>13</b> to adopt characteristic amounts for musical tones for which musical tone signals are to be generated, based on interval data stored in the storage device <b>12</b> and the motion signal supplied from the motion sensor <b>11</b>. Here, the characteristic amounts for musical tones are parameters that characterize the musical tones, for example, interval, tone generation timing, volume, and tone color. However, in the present embodiment, it is assumed that the controller <b>15</b> instructs the tone generator device <b>13</b> to adopt interval, tone generation timing, and volume as characteristic amounts for musical tones for which musical tone signals are to be generated.</p>
<p id="p-0044" num="0043">More specifically, the controller <b>15</b> instructs or designates an interval indicated by interval data in the musical piece data stored in the storage device <b>12</b>, as the interval of a musical tone for which a musical tone signal is to be generated by the tone generator device <b>13</b>. Thus, the interval of musical tones output from the sound speaker system <b>14</b> is determined based on the contents of the musical piece data irrespective of the operator's intention. On the other hand, the controller <b>15</b> instructs the tone generator device <b>13</b> to adopt characteristic amounts for musical tones other than the interval, i.e. tone generation timing and volume, based on the motion signal output from the motion sensor <b>11</b>. Thus, the characteristic amounts other than the interval for musical tones output from the sound speaker system <b>14</b> reflect the motion signal output from the motion sensor <b>11</b>, i.e. the contents of the operator's motion. For example, upon recognizing a specific motion made by the operator based on the motion signal supplied from the motion sensor <b>11</b>, the controller <b>15</b> outputs interval data in the musical piece data to the tone generator device <b>13</b> in timing in which the above motion is made. As a result, whenever the operator makes a specific motion, musical tones constituting the musical piece are sequentially output. On the other hand, when the operator makes another motion, the controller <b>15</b> instructs the tone generator device <b>13</b> to adopt a volume corresponding to this motion.</p>
<p id="p-0045" num="0044">The musical tone control apparatus according to the present embodiment is basically constructed as described above. Specific examples of the musical tone control apparatus according to the present embodiment will be described hereinbelow.</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 3A</figref> is a plan view showing the appearance of a musical tone control apparatus according to a first example of the present embodiment. <figref idref="DRAWINGS">FIG. 3B</figref> is a side view corresponding to <figref idref="DRAWINGS">FIG. 3A</figref>. As shown in these figures, the musical tone control apparatus <b>1</b><i>a </i>according to the first example is comprised of a support section <b>21</b>, a slider <b>22</b>, and a main body section <b>23</b>. The support section <b>21</b> is a tubular member bent in a U form. The slider <b>22</b> is a tubular member bent in a U form similarly to the support section <b>21</b>, with the opposite ends of the slider <b>22</b> being inserted into the corresponding ends of the support section <b>21</b>. With this construction, the operator can repeatedly move the slider <b>22</b> into an arbitrary position between a position in which the slider <b>22</b> is fully drawn out from the support section <b>21</b> (the position shown by the solid lines in <figref idref="DRAWINGS">FIG. 3A</figref>) and a position in which the slider <b>22</b> is deeply inserted into the support section <b>21</b> (the position shown by the dotted lines in <figref idref="DRAWINGS">FIG. 3A</figref>).</p>
<p id="p-0047" num="0046">The main body section <b>23</b> is comprised of the elements shown in <figref idref="DRAWINGS">FIG. 1</figref>, described previously, and a housing <b>23</b> that accommodates these elements. The housing <b>231</b> is shaped generally like a disk. A peripheral edge of the housing <b>231</b> is partially fixed to a pair of straight portions of the support section <b>21</b> which extend parallel with each other. Further, a speaker <b>141</b> constituting the sound speaker system <b>14</b> is provided on one of opposite circular side surfaces of the housing <b>23</b>.</p>
<p id="p-0048" num="0047">Furthermore, as shown in <figref idref="DRAWINGS">FIG. 4</figref>, the musical tone control apparatus <b>1</b><i>a </i>according to the present example includes a displacement sensor <b>111</b> and a tilt sensor <b>112</b> as the motion sensor <b>11</b>, shown in <figref idref="DRAWINGS">FIG. 1</figref> and described previously. The displacement sensor <b>111</b> outputs a signal corresponding to a position of the slider <b>22</b> with respect to the support section <b>21</b> (hereinafter referred to as the “displacement signal”), to the controller <b>15</b>. On the other hand, the tilt sensor <b>112</b> outputs a signal corresponding to a tilt (i.e. posture) of the musical tone control apparatus <b>1</b><i>a </i>(hereinafter referred to as the “tilt signal”), to the controller <b>15</b>. That is, the displacement signal reflecting the operator's motion of moving the slider <b>22</b> (hereinafter referred to as the “slide motion”) and the tilt signal reflecting the operator's motion of tilting the musical tone control apparatus <b>1</b><i>a </i>are output to the controller <b>15</b> as the above described motion signal. Then, the controller <b>15</b> controls tone generation timing for musical tones according to the contents of the displacement signal. That is, the controller <b>15</b> gives an instruction to the tone generator device <b>13</b> such that musical tones are output while the operator is making a slide motion and the output of musical tones is stopped when the operator does not make a slide motion. Furthermore, the controller <b>15</b> controls the volume of musical tones to be output, according to the contents of the tilt signal.</p>
<p id="p-0049" num="0048">Now, a description will be given of the operation of the musical tone control apparatus <b>1</b><i>a </i>according to the present example.</p>
<p id="p-0050" num="0049">First, the operator performs predetermined operations on keys, not shown, provided on the main body section <b>23</b> to instruct the musical tone control apparatus <b>1</b><i>a </i>to select a musical piece to be played and to start playing the musical piece. Upon receiving the instruction, the controller <b>15</b> instructs the tone generator device <b>13</b> to generate musical tone signals based on the contents of the musical piece data stored in the storage device <b>12</b> and according to the motion signal (displacement signal and tilt signal) supplied from the motion sensor <b>11</b>. The details of this process will now be described below with reference to <figref idref="DRAWINGS">FIG. 5</figref>. In the graph shown in <figref idref="DRAWINGS">FIG. 5</figref>, the ordinate represents the position x of the slider <b>22</b>, which varies with the operator's slide motion, while the abscissa indicates time t. The position x indicates the position of the slider <b>22</b> with respect to the support section <b>21</b>, the position x being set to “0” when the slider <b>22</b> is at a particular position. Further, it is assumed here that a musical piece A, shown in <figref idref="DRAWINGS">FIG. 2</figref>, is selected, i.e. a musical piece in which musical tones “do (C)”, “mi (E)”, “so (G)”, . . . are arranged in this order is played.</p>
<p id="p-0051" num="0050">First, let it assumed that the operator holds the musical tone control apparatus <b>1</b><i>a </i>in his or her hands as shown in <figref idref="DRAWINGS">FIG. 6</figref>, and moves the slider <b>22</b> away from the support section <b>21</b> (the direction indicated by the arrow in the figure) at a time point t<b>0</b>. Upon recognizing the start of this slide motion based on the displacement signal supplied from the displacement sensor <b>111</b>, the controller <b>15</b> outputs, to the tone generator device <b>13</b>, interval data indicative of the interval of the first musical tone “do” and contained in musical piece data corresponding to the musical piece A which is stored in the storage device <b>12</b>. Upon receiving this interval data, the tone generator device <b>13</b> generates a musical tone signal corresponding to the interval data indicative of the interval of the musical tone “do” and outputs it to the sound speaker system <b>14</b>. As a result, as shown in <figref idref="DRAWINGS">FIG. 5</figref>, the speaker <b>141</b> outputs the musical tone “do”. Then, at a time point t<b>1</b>, upon recognizing the stoppage of the slide motion (i.e. the stoppage of a change in the position x) from the displacement signal, the controller <b>15</b> instructs the tone generator device <b>13</b> to stop the musical tone “do” from being output. As a result, the output of the musical tone signal from the tone generator device <b>13</b> and the output of the musical tone “do” from the speaker <b>141</b> are stopped. In this way, the musical tone “do” is continuously output throughout the time period during which the slide motion is made.</p>
<p id="p-0052" num="0051">Then, when a slide motion is started again at a time point t<b>2</b>, the controller <b>15</b> outputs interval data indicative the interval of the next musical tone “mi” in the musical piece data to the tone generator device <b>13</b>. As a result, the tone generator device <b>13</b> generates a musical tone signal corresponding to the interval data indicative of the interval of the musical tone “mi” and the speaker <b>141</b> outputs the musical tone “mi”. Similar operations are subsequently carried out. As a result, during each time period when the operator makes a slide motion, the speaker <b>141</b> outputs a musical tone or musical tones (in the present embodiment, one musical tone), and thus musical tones constituting the musical piece are output from the speaker <b>141</b> in the order in which the musical tones constitute the musical piece.</p>
<p id="p-0053" num="0052">On the other hand, as shown in <figref idref="DRAWINGS">FIG. 7</figref>, when the operator tilts the musical tone controller <b>1</b><i>a, </i>the tilt sensor <b>112</b> outputs a tilt signal corresponding to this tilt. Upon receiving the tilt signal, the controller <b>15</b> instructs the tone generator device <b>13</b> to adopt a volume corresponding to the degree of tilt indicated by the tilt signal. Upon receiving the instruction via the tone generator device <b>13</b>, the sound speaker system <b>14</b> adjusts the volume of musical tones to be output, to the value of the instructed volume.</p>
<p id="p-0054" num="0053">In this way, according to the present example, each of musical tones constituting a musical piece is output in timing according to a slide motion and with a volume according to a tilt of the musical tone control apparatus <b>1</b><i>a</i>. As a result, the operator can very easily play a musical piece without paying special attention to musical tones. On the other hand, the operator can adjust the tone generation timing and volume as desired according to his own motion. This avoids spoilage of the operator's feeling that he is actually playing, as well as significant limitation of his or her musical expressions.</p>
<p id="p-0055" num="0054">In the present example, the output of musical tones is switched depending on whether or not the operator is making a slide motion. However, the output and/or stoppage of musical tones may be switched depending on the direction of a slide motion. For example, musical tones may be output when the operator makes a slide motion so as to move the slider <b>22</b> away from the support section <b>21</b>. On the other hand, the output of musical tones may be stopped when the operator makes a slide motion in the opposite direction, i.e. so as to move the slider <b>22</b> toward the support section <b>21</b>, or stops the slide motion. In this case, in place of the displacement sensor <b>111</b>, shown in <figref idref="DRAWINGS">FIG. 4</figref>, a pressure sensor may be used which detects pressure in the tube formed by the slider <b>22</b> and support section <b>21</b>, to output a pressure signal corresponding to the pressure. That is, it may be arranged such that when the pressure signal indicates negative pressure, the controller <b>15</b> determines that the slider <b>22</b> is moving away from the support section <b>21</b> and instructs the tone generator device <b>13</b> to output musical tones, whereas, when the pressure signal indicates positive pressure, the controller <b>15</b> determines that the slider <b>22</b> is moving toward the support section <b>21</b> and instructs the tone generator device <b>13</b> to stop musical tones from being output.</p>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. 8</figref> is a perspective view showing the appearance of a musical tone control apparatus according to a second example of the present embodiment. As shown in <figref idref="DRAWINGS">FIG. 8</figref>, the musical tone control apparatus <b>1</b><i>b </i>according to the second example is comprised of telescopic bellows <b>31</b>, and a first body portion <b>32</b> and a second body portion <b>33</b> connected together via the bellows <b>31</b>, and thus the apparatus <b>1</b><i>b </i>is generally shaped like an accordion (concertina). The first body portion <b>32</b> and the second body portion <b>33</b> are each provided with a belt <b>34</b> to fix the operator's hand. With this construction, the operator, with the right and left hands fixed to the first and second body portions <b>32</b> and <b>33</b>, respectively, using the belts <b>34</b>, moves the body portions toward or away from each other.</p>
<p id="p-0057" num="0056">The first body portion <b>32</b> accommodates the elements shown in <figref idref="DRAWINGS">FIG. 1</figref>. However, the musical tone control apparatus <b>1</b><i>b </i>according to the present example is provided, as the motion sensor <b>11</b>, with a pressure sensor that outputs a pressure signal corresponding to wind pressure inside the bellows <b>31</b> and a tilt sensor that outputs a tilt signal corresponding to the tilt of the musical tone control apparatus <b>1</b><i>b </i>(more specifically, the first body portion <b>32</b>). With this arrangement, the controller <b>15</b> receives the pressure signal from the pressure sensor and the tilt signal from the tilt sensor as the motion signal according to the operator's motion, to control the tone generation timing and volume of musical tones based on these motion signals, as in the case of the above described first example.</p>
<p id="p-0058" num="0057">That is, when the operator moves the first and second body portions <b>32</b> and <b>33</b> toward each other or away from each other (hereinafter referred to as an “opening and closing motion”), the pressure sensor outputs a pressure signal corresponding to a change in the pressure inside the bellows <b>31</b> associated with this opening or closing motion. Upon receiving the pressure signal to recognize the start of the opening and closing motion, the controller <b>15</b> outputs, to the tone generator device <b>13</b>, interval data corresponding to the first musical tone of the musical piece and contained in the musical piece data stored in the storage device <b>12</b>. As a result, the tone generator device <b>13</b> generates a musical tone signal corresponding to the interval data. Then, the speaker system <b>14</b> outputs a musical tone corresponding to the musical tone signal. On the other hand, when the operator stops the opening or closing motion, the controller <b>15</b> recognizes the stoppage of the motion based on a change in the pressure signal, to instruct the tone generator device <b>13</b> to stop the musical tone from being output. As a result, the output of the musical tone from the sound speaker system <b>14</b> is stopped. Thereafter, similar operations are executed according to the operator's motion. As a result, during each time period when the operator makes an opening or closing motion, a musical tone is output, and thus musical tones constituting the musical piece are sequentially output.</p>
<p id="p-0059" num="0058">On the other hand, when the operator <b>32</b> tilts the first body portion <b>32</b>, the tilt sensor outputs a tilt signal corresponding to the tilt motion. Upon receiving the tilt signal, the controller <b>15</b> instructs the sound speaker system <b>14</b> to adopt a volume corresponding to the degree of tilt indicated by the tilt signal. Upon receiving the instruction, the sound speaker system <b>14</b> adjusts the volume of musical tones to be output, to the value of the instructed volume.</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 9</figref> is a perspective view showing the appearance of a musical tone control apparatus according to a third example of the present embodiment. As shown in <figref idref="DRAWINGS">FIG. 9</figref>, the musical tone control apparatus <b>1</b><i>c </i>according to the present example is comprised of a body portion (resonating body portion) <b>41</b>, a neck <b>42</b> projecting from the body portion <b>41</b>, and strings <b>43</b> extended from the body portion <b>41</b> to the neighborhood of one end of the neck <b>42</b>, and the apparatus <b>1</b>C is generally shaped like an ordinary violin. However, the musical tone control apparatus <b>1</b><i>c </i>differs from ordinary violins, which are typically four-stringed, in that it has only two strings <b>43</b>. With this construction, the operator can vibrate the strings <b>43</b> by picking the strings <b>43</b> with fingers or rubbing the strings <b>43</b> using a bow.</p>
<p id="p-0061" num="0060">The body portion <b>41</b> accommodates the elements shown in <figref idref="DRAWINGS">FIG. 1</figref>. However, the musical tone control apparatus <b>1</b><i>c </i>according to the present example is provided, as the motion sensor <b>11</b>, with a vibration sensor that outputs a signal corresponding to vibration imparted to the strings <b>43</b> (hereinafter referred to as the “vibration signal”) and a tilt sensor that outputs a tilt signal corresponding to the tilt of the musical tone control apparatus <b>1</b><i>c</i>. With this arrangement, the controller <b>15</b> receives the motion signal (vibration signal and tilt signal) from the motion sensor <b>11</b> having the vibration sensor and tilt sensor, to control the tone generation timing and volume of musical tones to be output based on the motion signal, as in the case of the above described first and second examples.</p>
<p id="p-0062" num="0061">That is, when the operator <b>43</b> vibrates the strings <b>43</b>, the vibration sensor outputs a vibration signal corresponding to the vibration. Upon receiving the vibration signal to recognize the vibration of the string <b>43</b>, the controller <b>15</b> outputs, to the tone generator device <b>13</b>, interval data indicative of the interval of the first musical tone of the musical piece and contained in the musical piece data stored in the storage device <b>12</b>. Then, the tone generator device <b>13</b> generates a musical tone signal corresponding to the interval data. Thereafter, the speaker system <b>14</b> outputs a musical tone corresponding to the musical tone signal. On the other hand, when the amplitude of the vibration imparted to the string <b>43</b> attenuates to or below a predetermined threshold, the controller <b>15</b> recognizes the attenuation of the vibration from the vibration signal output from the vibration sensor, to instruct the tone generator device <b>13</b> to stop the musical tone from being output. As a result, the output of the musical tone is stopped as the vibration attenuates. Thereafter, similar operations are carried out whenever the operator vibrates the strings by picking them or rubbing them using a bow. As a result, during each time period when the strings <b>43</b> are vibrated, a musical tone is output, and thus musical tones constituting the musical piece are sequentially output.</p>
<p id="p-0063" num="0062">On the other hand, when the operator tilts the musical tone control apparatus <b>1</b><i>c, </i>a process similar to that executed in the first and second examples is executed to adjust the volume of musical tones to be output, to a value corresponding to the tilt of the musical tone control apparatus <b>1</b><i>c. </i></p>
<p id="p-0064" num="0063">In the present example, the violin-type musical tone control apparatus <b>1</b><i>c </i>is illustrated. However, the technical concept of the present example is applicable to a musical tone control apparatus <b>1</b><i>d </i>which is shaped like an acoustic guitar, as illustrated in <figref idref="DRAWINGS">FIG. 10</figref>. That is, also the musical tone control apparatus <b>1</b><i>d </i>may be constructed such that during each time period when the strings <b>43</b> are vibrated, one of musical tones constituting a musical piece is output so that the musical tones are sequentially output, while the volume of the musical tones is adjusted to a value corresponding to the tilt of the musical tone control apparatus <b>1</b><i>d. </i></p>
<p id="p-0065" num="0064">In the above examples, the illustrated musical tone control apparatuses are each shaped like a certain musical instrument (or a part thereof). However, as a simpler construction, for example, a construction as shown in <figref idref="DRAWINGS">FIG. 11</figref> may be employed. That is, this musical tone control apparatus <b>1</b><i>e</i>is comprised of the elements shown in <figref idref="DRAWINGS">FIG. 1</figref>, described previously, and a housing <b>51</b> having a rectangular parallelepiped configuration and accommodating these elements. The housing <b>51</b> is provided, on one side surface thereof, with a speaker <b>141</b> constituting the sound speaker system <b>14</b>, an operating switch <b>52</b> for instructing the apparatus to start and stop playing a musical piece, a performance operating switch <b>54</b> for instructing, for the tone generator device, tone generation timing for musical tones to be output, and a volume control knob <b>53</b> for adjusting the volume of musical tones to be output. Furthermore, the musical tone control apparatus <b>1</b><i>e </i>according to the present manner is provided, as the motion sensor <b>11</b> shown in <figref idref="DRAWINGS">FIG. 11</figref>, described previously, a sensor that outputs a signal corresponding to an operation of depressing the performance operating switch <b>54</b>, and a sensor that outputs a signal corresponding to an operation given to the volume control knob <b>53</b>.</p>
<p id="p-0066" num="0065">With this construction, when the operating switch <b>52</b> has been depressed to designate the start of a performance, and then the controller <b>15</b> recognizes the depression of the performance operating switch <b>54</b> from an output signal from the motion sensor <b>11</b>, the controller <b>15</b> outputs interval data indicative of the interval of the first musical tone of a musical piece contained in the musical piece data stored in the storage device <b>12</b>. As a result, the speaker <b>141</b> outputs the musical tone. On the other hand, upon recognizing depression release of the performance operating switch <b>54</b> from an output signal from the motion sensor <b>11</b>, the controller <b>15</b> gives the tone generator device <b>13</b> an instruction for stopping a musical tone from being output. Thus, the output of musical tones is stopped. Thereafter, whenever the performance operating switch <b>54</b> is depressed or released, similar operations are carried out, and thus, during each time period when the performance operating switch <b>54</b> is depressed, each of the musical tones constituting the musical piece is output, so that the musical tones are sequentially output.</p>
<p id="p-0067" num="0066">On the other hand, upon recognizing an operation (rotation) of the volume control knob <b>53</b> from an output signal from the motion sensor <b>11</b>, the controller <b>15</b> instructs the sound speaker system <b>14</b> to adopt a volume corresponding to the rotational angle of the volume control knob <b>53</b>. As a result, the volume of musical tones output from the speaker <b>141</b> is adjusted according to the operator's operation of the volume control knob <b>53</b> (i.e. motion of operating the knob <b>53</b>).</p>
<p id="p-0068" num="0067">As described above, according to the present embodiment, out of the characteristic amounts for each of musical tones constituting a musical piece, the interval is determined based on the already stored interval data. Therefore, the operator can easily play the musical piece without paying special attention to the interval. Further, according to the present embodiment, the characteristic amounts for musical tones other than the interval (tone generation timing and volume) are determined according to the operator's motion, whereby the motion of the operator can be reflected upon the performance of a musical piece, making it possible to avoid spoilage of the operator's feeling that he is actually playing the musical piece.</p>
<p id="p-0069" num="0068">Now, a musical tone control apparatus according to a second embodiment of the present invention will be described. In the above described first embodiment, musical tones constituting a musical piece are sequentially output according to the operator's motions. In contrast, in the musical tone control apparatus according to the present embodiment, the progress and stoppage of performance of a musical piece are switched depending on the operator's motions. Further, in the present embodiment, the performance tempo of a musical piece can be changed according to the operator's motion as desired. This will be described below in detail.</p>
<p id="p-0070" num="0069">The functional construction of the musical tone control apparatus according to the present embodiment is similar to that shown in <figref idref="DRAWINGS">FIG. 1</figref>, described previously. However, in the present embodiment, musical piece data corresponding to each musical piece conforms to, for example, the MIDI (Musical Instrument Digital Interface) Standard, and contains data indicative of the contents of performance of a plurality of parts (a plurality of musical instruments having different tone colors).</p>
<p id="p-0071" num="0070">The controller <b>15</b> instructs the tone generator device <b>13</b> to play a musical piece based on musical piece data. Then, a musical tone signal is generated based on the musical piece data, and the sound speaker system <b>14</b> outputs performance sound. However, the controller <b>15</b> in the present embodiment instructs the tone generator device <b>13</b> to progress or stop performance of a musical piece according to a motion detected by the motion sensor <b>11</b>. More specifically, the controller <b>15</b> determines whether or not the operator is making a specific motion, based on the motion signal from the motion sensor <b>11</b>. If the tone generator device <b>13</b> to play the musical piece. On the other hand, if the specific motion is not being made, the controller <b>15</b> instructs the tone generator device <b>13</b> to stop playing the musical piece. Furthermore, the controller <b>15</b> provides such control that the performance tempo of the musical piece matches the operator's motion. For example, if the operator quickly makes a specific motion, the musical piece is played with a fast tempo, whereas, if the operator slowly makes the specific motion, the musical piece is played with a slow tempo.</p>
<p id="p-0072" num="0071">Then, the details of operation of the musical tone control apparatus according to the present embodiment will be described. The musical tone control apparatus according to the present embodiment may employ any of the forms shown in <figref idref="DRAWINGS">FIG. 3</figref> or <figref idref="DRAWINGS">FIGS. 8 to 11</figref>, described previously. In the following description, the slider-type musical tone control apparatus <b>1</b><i>a, </i>given as the first example, will be taken by way of example. That is, in this case, musical tone performance is carried out when the operator is making a slide motion, while the musical tone performance is stopped when the operator stops the slide motion. Further, the tempo of the performance is determined based on the speed of the slide motion. A specific example of the motion will be described below with reference to <figref idref="DRAWINGS">FIG. 12</figref>. The volume of a musical piece is properly adjusted to a value corresponding to the tilt of the musical tone control apparatus detected by the tilt sensor, as in the case of the first embodiment.</p>
<p id="p-0073" num="0072">First, the operator designates a musical piece to be played and moves the slider <b>22</b> as desired. In <figref idref="DRAWINGS">FIG. 12</figref>, the slider <b>22</b> is seen to be moved from an initial position x<b>0</b> to a position x<b>1</b> from a time point t<b>0</b> at which the slide motion is started to a time point t<b>1</b> at which a predetermined time period has elapsed. Upon detecting that the slider <b>22</b> is being moved, from the displacement signal output from the displacement sensor <b>111</b>, the controller <b>15</b> reads musical piece data from the storage device <b>12</b> and then sequentially outputs, to the tone generator device <b>13</b>, various data contained in the musical piece data, such as interval data (note number) designating the interval, note-on events designating generation of musical tones, and note-off events designating the stoppage of the musical tones (these data will be collectively referred to as “performance data”). The controller <b>15</b> sequentially outputs these performance data until the slider <b>22</b> is stopped at the time point t<b>1</b>. On this occasion, the controller <b>15</b> outputs the performance data at time intervals based on a tempo Te<b>0</b> (initial value) preset to an initial value. On the other hand, the tone generator device <b>13</b> generates musical tone signals based on these performance data and outputs them to the sound speaker system <b>14</b>. As a result, the speaker <b>141</b> of the sound speaker system <b>14</b> sequentially outputs musical tones based on the musical piece data, according to the tempo Te<b>0</b>.</p>
<p id="p-0074" num="0073">On the other hand, upon detecting that the slide motion of the slider is stopped (time point t<b>1</b>), from the displacement signal output from the displacement sensor <b>11</b>, the controller <b>15</b> stops outputting performance data to the tone generator device <b>13</b>. As a result, the output of musical tones from the speaker <b>141</b> is also stopped. Furthermore, the controller <b>15</b> calculates the average speed of the slide motion so far made and stores it in the storage device <b>12</b>. For example, if the slider moves from position x<b>0</b> to position x<b>1</b> during the period from time point t<b>0</b> to time point t<b>1</b> as described above, the average speed v<b>1</b> of this slide motion is determined by dividing the displacement (x<b>1</b>−x<b>0</b>) of the slider <b>22</b> by the time period (t<b>1</b>−t<b>0</b>) required for the slide motion.</p>
<p id="p-0075" num="0074">On the other hand, when the slider <b>22</b>, which has been stopped, starts to be moved again at a time point t<b>2</b>, the controller <b>15</b> sequentially outputs performance data contained in the musical piece data to the tone generator device <b>13</b>. On this occasion, the controller <b>15</b> outputs the performance data so that the musical piece is played at a tempo Te<b>1</b> corresponding to the average speed v<b>1</b> stored previously in the storage device <b>12</b> (i.e. the average speed of the preceding slide motion). For example, if the average speed v<b>1</b> is relatively high, the controller <b>15</b> outputs the performance data so that the musical piece is played at a fast tempo. In contrast, if the average speed v<b>1</b> is relatively low, the controller <b>15</b> outputs the performance data so that the musical piece is played at a slow tempo. Such change of the tempo can be effected using various well-known techniques. For example, one possible method is to divide the frequency of a reference clock signal according to the average speed v<b>1</b> so that the performance data is output in synchronism with the thus obtained clock signal. Thus, the performance data is output at time intervals corresponding to the average speed v<b>1</b>. Consequently, the musical piece is played based on the musical piece data, at the tempo Te<b>1</b> corresponding to the average speed v<b>1</b>.</p>
<p id="p-0076" num="0075">Then, when at a time point t<b>3</b>, the moving direction of the slider <b>22</b> is reversed, i.e. the slider <b>22</b> is switched from movement in a direction in which the slider <b>22</b> is drawn out from the support section <b>21</b> to movement in a direction in which the slider <b>22</b> is inserted into the support section <b>21</b>, the controller <b>15</b> calculates the average speed v<b>2</b> of the preceding slide motion made from time point t<b>2</b> to time point t<b>3</b>. For example, in <figref idref="DRAWINGS">FIG. 12</figref>, the average speed v<b>2</b> is (x<b>2</b>−x<b>1</b>)/(t<b>3</b>−t<b>2</b>). In response to a slide motion after the time point t<b>3</b>, the controller <b>15</b> outputs performance data so that the musical piece is played at a tempo Te<b>2</b> corresponding to the average speed v<b>2</b>. As a result, in response to the slide motion from time point t<b>3</b> to time point t<b>4</b>, the musical piece is played at the tempo Te<b>2</b>. Thereafter, the above described operation is repeated until the operator completes playing the musical piece.</p>
<p id="p-0077" num="0076">In this way, according to the present embodiment, while a slide motion is being made, a musical piece is played based on musical piece data, whereas, while no sliding motion is being made, the performance of the musical piece is stopped. As a result, even beginners, who are unaccustomed to playing a musical instrument, can easily play a musical piece. On the other hand, the operator's motion can be reflected in the performance, thereby avoiding spoilage of the operator's feeling that he is actually playing the musical piece. Further, according to the present embodiment, the performance tempo of the musical piece corresponding to a slide motion made during a certain time period is properly varied depending on the contents of the preceding slide motion (average speed of the motion). Therefore, the operator can very easily reflect his own expressions in performance of the musical piece.</p>
<p id="p-0078" num="0077">In the above description, the slider-type musical tone control apparatus is illustrated. However, a similar construction can be employed for the musical tone control apparatuses of the other types shown in <figref idref="DRAWINGS">FIGS. 8 to 11</figref>. For example, with the accordion-type musical tone control apparatus <b>1</b><i>b </i>shown in <figref idref="DRAWINGS">FIG. 8</figref>, it may be so arranged that a musical piece is played while the pair of body portions <b>32</b> and <b>33</b> are being opened or closed, and in response to an opening or closing motion made during a certain time period, the musical piece is played at a tempo corresponding to the average speed of the preceding motion. Furthermore, with a string instrument—type musical tone control apparatus which is shaped like a violin as shown in <figref idref="DRAWINGS">FIG. 9</figref> or like an acoustic guitar as shown in <figref idref="DRAWINGS">FIG. 10</figref>, it may be so arranged that a musical piece is played during a certain time period when the string <b>43</b> is being vibrated, and in response to a picking motion made at a certain time point, the musical piece is played at a tempo corresponding to the contents of the preceding picking motion (for example, the intensity of the picking).</p>
<p id="p-0079" num="0078">Further, in the above embodiments, the unit time period after which the performance tempo of the musical piece is changed is a time period in which a certain motion has been continuously made (for example, the slider <b>22</b> has been continuously moved in one direction). However, the unit time period may be set as follows: that is, the average speed of a motion made during each time period is calculated, and the average speed calculated for each time period can be reflected in the performance tempo of the musical piece executed during the next time period. Thus, the operator's motion can be more minutely reflected in the performance tempo of the musical piece.</p>
<p id="p-0080" num="0079">The above described embodiments are only illustrative, and variations may be made thereto without deviating from the spirits of the present invention. For example, the following variations are possible:</p>
<p id="p-0081" num="0080">The types of motions to be detected such as a slide motion or a picking motion are not limited to those shown in the above embodiments. That is, in the above embodiments, with the slider-type musical tone control apparatus shown in <figref idref="DRAWINGS">FIG. 3</figref>, a slide motion made on the slider is detected. With the accordion-type musical tone control apparatus shown in <figref idref="DRAWINGS">FIG. 8</figref>, an opening or closing motion made on the opposite body portions is detected. With the string instrument-type musical tone control apparatus shown in <figref idref="DRAWINGS">FIG. 9</figref> or <b>10</b>, a picking motion or a string rubbing motion made on the strings is detected. However, motions to be detected are not limited to these types. Accordingly, the type of the operating element operated by the operator is not limited to the slider <b>22</b>, the first and second body portions, and the strings <b>43</b>, but other types of operating element may be employed.</p>
<p id="p-0082" num="0081">Further, characteristics of musical tones to be controlled in amount (characteristic amounts) according to the operator's motion are not limited to those shown in the above described embodiments. That is, although in the above described first embodiment, tone generation timing and volume are controlled according to the motion, and in the second embodiment, tempo and volume are controlled according to the motion, in addition to these characteristics, the tone color of musical tones, effects applied to the musical tones, and the like may be controlled. For example, it is possible that the tone color of musical tones is changed and/or effects (for example, reverberation) are applied to musical tones to be output, according to the operator's motion. That is, of the characteristics relating to musical tones, at least the interval may be determined in amount to be controlled, based on the musical piece data, whereas at least one of the other characteristics may be determined in amount to be controlled, according to the operator's motion (i.e. according to the contents of the motion signal output from the motion sensor <b>11</b>).</p>
<p id="p-0083" num="0082">Furthermore, the manner of determining the contents of control of the characteristic amounts is not limited to those shown in the above described embodiments. For example, in the above described embodiments, the volume of musical tones is controlled according to the posture of the musical tone control apparatus. However, with the string instrument-type musical tone control apparatus shown in <figref idref="DRAWINGS">FIG. 9</figref> or <b>10</b>, the volume may be controlled according to the amplitude of vibration applied to the strings <b>43</b>.</p>
<p id="p-0084" num="0083">In the above described embodiments, musical tone output devices such as the tone generator device <b>13</b> and the sound speaker system <b>14</b> are provided in one body with the musical tone control apparatus. However, these devices may be provided in separate bodies from the musical tone control apparatus. Specifically, data output from the controller <b>15</b> of the musical tone control apparatus may be supplied via a signal line to the tone generator device <b>13</b> and sound speaker system <b>14</b> which are provided at a distance from the musical tone control apparatus. The forms shown in <figref idref="DRAWINGS">FIGS. 3 and 8</figref> to <b>11</b> are only examples of the musical tone control apparatus according to the present invention. The scope of the present invention is not limited to these forms.</p>
<p id="p-0085" num="0084">The above described first embodiment employs a playing method in which musical tones are sequentially output whenever the operator makes a specific motion. The above described second embodiment employs a playing method in which performance of musical tones is progressed while the operator is making a specific motion. However, a single musical tone control apparatus may be provided, that can realize both the playing methods so that the operator can select one of the methods as desired.</p>
<p id="p-0086" num="0085">In the first embodiment, when the operator stops a specific motion, the output of a musical tone is immediately stopped. However, the musical tone control apparatus according to the present invention may be so configured that after the operator has stopped a specific motion, reverberation is added to the musical tone to be stopped for a predetermined time period. This avoids the musical tone from being suddenly stopped, thereby enabling more natural performance.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A musical tone control apparatus comprising:
<claim-text>a storage device that stores musical piece data containing interval data indicative of intervals of musical tones constituting a musical piece;</claim-text>
<claim-text>an operating element comprising a pair of members joined together via a telescopic joining member,</claim-text>
<claim-text>a detecting device that detects a start and stop motion of the operating element;</claim-text>
<claim-text>a controller that provides control so as to instruct a musical tone output device capable of outputting musical tones to adopt the intervals as one of characteristic amounts relating to musical tones to be output from the musical tone output device, according to the input interval data, and instruct the musical tone output device to adopt at least one of the characteristic amounts relating to musical tones other than the intervals, including note duration, to be output from the musical tone output device, according to the musical piece data, according to the start motion of the operator detected by said detecting device, and to quit output from the musical tone output device, according to the musical piece data, according to the stop motion of the operator detected by said detecting device;</claim-text>
<claim-text>wherein said controller is responsive to at least one of said pair of members being moved away from each other and said pair of members being moved toward each other according to the start of motion of the operator detected by said detecting device, for instructing the musical tone output device to output at least one associated musical tone of the musical tones constituting the musical piece; and</claim-text>
<claim-text>wherein said musical tone output device outputs the musical tones according to the musical interval data when the musical interval data are inputted, and maintains the outout of musical tones until it receive a stop instruction for outout based on the stop motion of the operator detected by said detecting device, whereupon the musical tone outout device puts an end to output the musical tones according to the stop instruction from said controller.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. A musical tone control apparatus comprising:
<claim-text>a storage device that stores musical piece data containing interval data indicative of intervals of musical tones constituting a musical piece;</claim-text>
<claim-text>said operating element comprising strings that are vibrated in response to the motion of the operator,</claim-text>
<claim-text>a detecting device that detects a start and stop motion of the operating element;</claim-text>
<claim-text>a controller that provides control so as to instruct a musical tone output device capable of outputting musical tones to adopt the intervals as one of characteristic amounts relating to musical tones to be output from the musical tone output device, according to the input interval data, and instruct the musical tone output device to adopt at least one of the characteristic amounts relating to musical tones other than the intervals, including note duration, to be output from the musical tone output device, according to the musical piece data, according to the start motion of the operator detected by said detecting device, to quit output from the musical tone output device, according to the musical piece data, according to the stop motion of the operator detected by said detecting device;</claim-text>
<claim-text>wherein said controller is responsive to the strings being vibrated, for instructing the musical tone output device to output at least one associated musical tone of the musical tones constituting the musical piece.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. A musical tone control apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said controller instructs the musical tone output device to adopt volume corresponding to the motion of the operator as the volume of the musical tones to be output from the musical tone output device.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A musical tone control apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said detecting device detects a posture of the musical tone control apparatus which changes depending on the motion of the operator, and said controller instructs the musical tone output device to adopt volume corresponding to the posture of the musical tone control apparatus, as the volume of the musical tones to be output from the musical tone output device.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A musical tone control apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said detecting device detects a motion made on said operating element, and said controller instructs the musical tone output device to carry out or stop output of the musical tones based on the musical piece data, depending on the operation detected by said detecting device.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A musical tone control apparatus according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein said controller is responsive to said operating element being operated, for instructing the musical tone output device to carry out the output of the musical tones and responsive to said operating element not being operated, for instructing the musical tone output device to stop the output of the musical tones.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A musical tone control apparatus according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein said controller instructs said musical tone output device to adopt a tempo corresponding to the motion of the operator, as a tempo at which the output of the musical tones is carried out.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A musical tone control apparatus according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein said controller instructs the musical tone output device to adopt a tempo corresponding to the motion of the operator, as a tempo at which the output of the musical tones is carried out.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A musical tone control apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the musical tone output device is provided in one body with the musical tone controller.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A musical tone control method comprising the steps of:
<claim-text>causing a storage device to store musical piece data containing interval data indicative of intervals of musical tones constituting a musical piece;</claim-text>
<claim-text>detecting a start and stop motion of the operating element; and</claim-text>
<claim-text>instructing a musical tone output device capable of outputting musical tones to adopt the intervals as one of characteristic amounts relating to musical tones to be output from the musical tone output device, according to the interval data, and instructing the musical tone output device to adopt at least one of the characteristic amounts other than the intervals, including note duration, according to the detected motion of the operator,</claim-text>
<claim-text>wherein the musical tone output device is instructed to output at least one associated musical tone of the musical tones constituting the musical piece when at least one of a pair of members joined together via a telescopic joining member being moved away from each other and said pair of members being moved toward each other according to the start of motion of the operator is occurred; and</claim-text>
<claim-text>wherein said musical tone output device outputs the musical tones according to the musical interval data when the musical interval data are inputted, and maintains the output of musical tones until it receive a stop instruction for output based on the stop motion of the operator detected by said detecting device, whereupon the musical tone output device puts an end to output the musical tones according to the stop instruction from said controller.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A musical tone control apparatus comprising:
<claim-text>a storage device that stores data corresponding to a musical piece comprised of musical tones;</claim-text>
<claim-text>a detecting device that detects a start and stop motion of the operating element; and</claim-text>
<claim-text>a controller that provides control so as to instruct a musical tone output device capable of outputting musical tones to output musical tones based at least in part upon the motion of the operator detected by said detecting device,</claim-text>
<claim-text>wherein said controller includes a pair of members joined together via a telescopic joining member, and said controller is responsive to at least one of said pair of members being moved away from each other and said pair of members being moved toward each other according to the start of motion of the operator detected by said detecting device, for instructing the musical tone controller to output at least one associated musical tone of the musical tones constituting the musical piece, and being further responsive according to the stop of motion of the operator detected by said detecting device for instructing the musical tone controller not to output musical tones.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. A musical tone control apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein said controller instructs the musical tone output device to adopt volume corresponding to the motion of the operator as the volume of the musical tones to be output from the musical tone output device.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. A musical tone control apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein said controller detects a posture of the musical tone control apparatus which changes depending on the motion of the operator, and said controller instructs the musical tone output device to adopt volume corresponding to the posture of the musical tone control apparatus, as the volume of the musical tones to be output from the musical tone output device.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A musical tone control apparatus for use with a musical instrument comprising:
<claim-text>a storage device that stores data corresponding to a musical piece comprised of musical tones;</claim-text>
<claim-text>a detecting device employing at least one displacement sensor that detects a start and stop of motion of an operator in manipulating the musical instrument, where displacement is measured in reference to a predetermined position on said musical instrument; and</claim-text>
<claim-text>a controller that provides control so as to instruct a musical tone output device capable of outputting musical tones to output musical tones based at least in part upon the start motion of the operator detected by said detecting device,</claim-text>
<claim-text>wherein said detecting device is operative to cause said controller to instruct the musical tone output device to carry out output of the musical tones only during the time motion is detected by analyzing the output of said displacement sensor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. A musical tone control apparatus according to <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein said detecting device is operative to cause said controller to instruct the musical tone output device to stop the output of musical tones during the time motion is not detected by analyzing the output of said displacement sensor.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The apparatus of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein said musical instrument includes a slider and the displacement is measured in reference to a predetermined position on said slider.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. A musical tone control apparatus comprising:
<claim-text>a storage device that stores musical piece data containing interval data indicative of intervals of musical tones constituting a musical piece;</claim-text>
<claim-text>an operating element comprising a pair of members joined together via a bellows joining member,</claim-text>
<claim-text>a detecting device that detects a start and stop motion of the operating element;</claim-text>
<claim-text>a controller that provides control so as to instruct a musical tone output device capable of outputting musical tones to adopt the intervals as one of characteristic amounts relating to musical tones to be output from the musical tone output device, according to the input interval data, and instruct the musical tone output device to adopt at least one of the characteristic amounts relating to musical tones other than the intervals, including note duration, to be output from the musical tone ouput device, according to the musical piece data, according to the start motion of the operator detected by said detecting device, to quit output from the musical tone output device, according to the musical piece data, according to the stop motion of the operator detected by said detecting device;</claim-text>
<claim-text>wherein said controller is responsive to at least one of said pair of members being moved away from each other and said pair of members being moved toward each other according to the start of motion of the operator detected by said detecting device, for instructing the musical tone controller to output at least one associated musical tone of the musical tones constituting the musical piece,</claim-text>
<claim-text>wherein said musical tone output device outputs the musical tones according to the musical interval data when the musical interval data are inputted, and maintains the output of musical tones until it receive a stop instruction for output based on the stop motion of the operator detected by said detecting device, whereupon the musical tone output device puts an end to output the musical tones according to the stop instruction from said controller.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
