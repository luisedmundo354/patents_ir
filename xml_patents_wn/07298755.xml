<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298755-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298755</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10361747</doc-number>
<date>20030208</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1040</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>12</main-group>
<subgroup>28</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>12</main-group>
<subgroup>56</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>12</main-group>
<subgroup>26</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>370414</main-classification>
<further-classification>370217</further-classification>
<further-classification>370418</further-classification>
</classification-national>
<invention-title id="d0e53">Apparatus and method for communicating with a network and for monitoring operational performance of the apparatus</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4475192</doc-number>
<kind>A</kind>
<name>Fernow et al.</name>
<date>19841000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>4933932</doc-number>
<kind>A</kind>
<name>Quinquis et al.</name>
<date>19900600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>4964119</doc-number>
<kind>A</kind>
<name>Endo et al.</name>
<date>19901000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370237</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5016248</doc-number>
<kind>A</kind>
<name>Kudoh</name>
<date>19910500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5291482</doc-number>
<kind>A</kind>
<name>McHarg et al.</name>
<date>19940300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5303302</doc-number>
<kind>A</kind>
<name>Burrows</name>
<date>19940400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>5610914</doc-number>
<kind>A</kind>
<name>Yamada</name>
<date>19970300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5701427</doc-number>
<kind>A</kind>
<name>Lathrop</name>
<date>19971200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5802058</doc-number>
<kind>A</kind>
<name>Harris et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6128295</doc-number>
<kind>A</kind>
<name>Larsson et al.</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6212165</doc-number>
<kind>B1</kind>
<name>Mann et al.</name>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>6215763</doc-number>
<kind>B1</kind>
<name>Doshi et al.</name>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370216</main-classification></classification-national>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>6266701</doc-number>
<kind>B1</kind>
<name>Sridhar et al.</name>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>6327677</doc-number>
<kind>B1</kind>
<name>Garg et al.</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>6400695</doc-number>
<kind>B1</kind>
<name>Chuah et al.</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>6408005</doc-number>
<kind>B1</kind>
<name>Fan et al.</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370412</main-classification></classification-national>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>6445717</doc-number>
<kind>B1</kind>
<name>Gibson et al.</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>6446028</doc-number>
<kind>B1</kind>
<name>Wang</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>6539431</doc-number>
<kind>B1</kind>
<name>Sitaraman et al.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00020">
<othercit>Adamson, et al.,NACK-Oriented Reliable Multicast (NORM) Protocol Building Blocks, Proceedings of the Fourty-Ninth Internet Engineering Task Force (Jul. 2000) &lt; http://www.ietf.org/proceedings/00dec/1-D/draft-ietf-rmt-morm-bb-00.txt.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00021">
<othercit>Adamson, et al.,NACK-Oriented Reliable Multicast Protocol (NORM), Proceedings of the Fourty-Ninth Internet Engineering Task Force (Nov. 2000) &lt; http://www.ietf.org/proceedings/00dec/l-D/draft-letf-rmt-morm-00.txt.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>30</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>8</number-of-drawing-sheets>
<number-of-figures>11</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20040156363</doc-number>
<kind>A1</kind>
<date>20040812</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Walls</last-name>
<first-name>Jeffrey Joel</first-name>
<address>
<city>Fort Collins</city>
<state>CO</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Hamilton</last-name>
<first-name>Michael T</first-name>
<address>
<city>Fort Collins</city>
<state>CO</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Hewlett-Packard Development Company, L.P.</orgname>
<role>02</role>
<address>
<city>Houston</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Abelson</last-name>
<first-name>Ron</first-name>
<department>2616</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An apparatus for communicating with a network comprises a data packet pipeline and a monitoring element. The data packet pipeline is configured to transfer data between a buffer and a network socket. The monitoring element is configured to provide an indication of an operational performance parameter for at least one component of the data packet pipeline thereby enabling an operational problem within the pipeline may be isolated based on the indication.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="139.28mm" wi="219.03mm" file="US07298755-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="231.82mm" wi="142.92mm" file="US07298755-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="244.77mm" wi="172.89mm" orientation="landscape" file="US07298755-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="224.79mm" wi="152.40mm" orientation="landscape" file="US07298755-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="259.42mm" wi="157.56mm" orientation="landscape" file="US07298755-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="222.50mm" wi="162.14mm" orientation="landscape" file="US07298755-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="144.70mm" wi="57.66mm" file="US07298755-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="232.66mm" wi="101.09mm" file="US07298755-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="226.48mm" wi="105.75mm" file="US07298755-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">RELATED ART</heading>
<p id="p-0002" num="0001">In some communication systems, such as networked graphical rendering systems, for example, large amounts of data are transmitted from a transmitting unit through a network to at least one receiving unit. For example, a graphics application at a transmitting unit may transmit graphical data to at least one remote receiving unit that renders the graphical data to form a rendered image. In such a system, communication of large amounts of graphical data at a relatively high transmission rate may be needed in order to provide a suitable frame rate for the rendered image.</p>
<p id="p-0003" num="0002">Performance of a system's transmitting and receiving units in transmitting data to and receiving data from a network is typically an important factor in whether graphical data can be successfully rendered via a remote receiving unit at suitable frame rates. Unfortunately, achieving a suitable transmission rate for the data communicated from the transmitting unit to the receiving unit or units can sometimes be problematic, particularly in instances where a large number of receiving units are to receive the graphical data. In such situations, the transmitting unit may be configured to transmit each graphics command multiple times through the network (e.g., once for each destination receiving unit that is to receive the command). The multiple transmissions of the graphics commands can significantly increase the amount of data that is to be communicated through the network.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0004" num="0003">Thus, techniques for enhancing the performance and ensuring adequate performance of the transmitting and receiving units are generally desirable. Generally, embodiments of the present invention provide an apparatus and method for communicating with a network and for monitoring operational performance of the apparatus.</p>
<p id="p-0005" num="0004">An exemplary apparatus in accordance with one embodiment of the present invention comprises a data packet pipeline and a monitoring element. The data packet pipeline is configured to transfer data between a buffer and a, network socket. The monitoring element is configured to provide an indication of an operational performance parameter for at least one component of the data packet pipeline thereby enabling an operational problem within the pipeline may be isolated based on the indication.</p>
<p id="p-0006" num="0005">An exemplary apparatus in accordance with another embodiment of the present invention comprises a data packet pipeline and a monitoring element. The data packet pipeline is configured to transfer data between a buffer and a network socket. The monitoring element is configured to disable a first portion of the pipeline from processing a plurality of data packets flowing through the pipeline. The monitoring element is configured to monitor a second portion of the pipeline that is processing the plurality of data packets while the first portion is disabled, wherein the monitoring element is configured to determine whether disabling of the first portion by the monitoring element affects a data throughput of the second portion.</p>
<p id="p-0007" num="0006">An exemplary apparatus in accordance with yet another embodiment of the present invention comprises a data packet pipeline and a monitoring element. The data packet pipeline is configured to transfer data between a buffer and a network socket. The monitoring element is configured to cause the data packet pipeline to discard a plurality of data packets flowing through the pipeline, and the monitoring element is further configured to determine a value indicative of an operational performance of the pipeline in processing the plurality of packets.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0008" num="0007">The invention can be better understood with reference to the following drawings. The elements of the drawings are not necessarily to scale relative to each other, emphasis instead being placed upon clearly illustrating the principles of the invention. Furthermore, like reference numerals designate corresponding parts throughout the several views.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram illustrating an exemplary communication system in accordance with the present invention.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram illustrating an exemplary transmitting unit, such as is depicted in <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram illustrating an exemplary buffer within a shared resource, such as is depicted in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram illustrating an exemplary entry in an entry queue of a shared resource, such as is depicted in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 5</figref> is a block diagram illustrating an exemplary communication session, such as is depicted in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 6</figref> is a block diagram illustrating an exemplary receiving unit, such as is depicted in <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 7</figref> is a block diagram illustrating an exemplary receiver, such as is depicted in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 8</figref> is a block diagram illustrating an exemplary entry in an entry queue of a shared resource, such as is depicted in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 9</figref> is a block diagram illustrating an exemplary buffer within a shared resource, such as is depicted in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 10</figref> is a flow chart illustrating an exemplary architecture and functionality of a monitoring element, such as is depicted in <figref idref="DRAWINGS">FIGS. 2 and 6</figref>.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 11</figref> is a flow chart illustrating another exemplary architecture and functionality of a monitoring element, such as is depicted in <figref idref="DRAWINGS">FIGS. 2 and 6</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 1</figref> depicts a communication system <b>20</b> in accordance with an exemplary embodiment of the present invention. As shown by <figref idref="DRAWINGS">FIG. 1</figref>, a transmitting apparatus or unit <b>21</b> transmits graphical data through a network <b>22</b> to at least one receiving apparatus or unit <b>24</b>. For illustrative purposes, the transmitting unit <b>21</b> will be described hereafter as transmitting graphical data to a plurality of receiving units <b>24</b>, which render the graphical data via known or future-developed techniques. However, it should be noted that the transmitting unit <b>21</b> may be configured, in other embodiments, to communicate other types of data, and the transmitting unit <b>21</b> may be configured to transmit such data with any number of receiving units <b>24</b>.</p>
<p id="p-0021" num="0020">As shown by <figref idref="DRAWINGS">FIG. 2</figref>, the transmitting unit <b>21</b> preferably comprises at least one graphics application <b>25</b> that produces graphical data for transmission through the network <b>22</b>. In the embodiment shown by <figref idref="DRAWINGS">FIG. 2</figref>, each graphics application <b>25</b> communicates with a corresponding set of buffer logic <b>33</b>. When a graphics application <b>25</b> is invoked for communicating graphical data to at least one receiving unit <b>24</b>, the graphics application <b>25</b> notifies its corresponding buffer logic <b>33</b>, and this buffer logic <b>33</b> preferably submits a request, referred to hereafter as a “session request,” to a transport manager <b>36</b>. In response, the transport manager <b>36</b>, as will be described in more detail hereinafter, associates the graphics application <b>25</b> with at least one of a plurality processes <b>39</b>, referred to herein as “communication sessions.” As will be described in more detail below, each session <b>39</b> is responsible for interfacing, with the network <b>22</b>, graphical data produced by its associated graphics applications <b>25</b>.</p>
<p id="p-0022" num="0021">In this regard, each graphics application <b>25</b> produces graphical data via known or future-developed techniques, and its corresponding buffer logic <b>33</b> stores the graphical data within a shared resource <b>45</b> that is accessible by each buffer logic <b>33</b>, as well as each communication session <b>39</b> shown in <figref idref="DRAWINGS">FIG. 2</figref>. Session logic <b>49</b> within each communication session <b>39</b> searches the shared resource <b>45</b> for data that its communication session <b>39</b> is responsible for interfacing with the network <b>22</b>. When the session logic <b>49</b> within a particular communication session <b>39</b> finds, in the shared resource <b>45</b>, graphical data from a graphics application <b>25</b> associated with the particular communication session <b>39</b>, the session logic <b>49</b> retrieves such graphical data from the shared resource <b>45</b>. The particular communication session <b>39</b> writes the graphical data to a socket <b>50</b> of a network interface <b>101</b>, which interfaces the retrieved graphical data with the network <b>22</b> such that the data is communicated to the appropriate receiving units <b>24</b>.</p>
<p id="p-0023" num="0022">Since communication of the graphical data with the network <b>22</b> is handled by associated communication sessions <b>39</b>, a graphics application <b>25</b> and/or its corresponding set of buffer logic <b>33</b> may begin performing other tasks once the graphical data has been written to the shared resource <b>45</b>. In this regard, it may be assumed, by the graphics application <b>25</b> and/or its corresponding set of buffer logic <b>33</b>, that the graphical data will be successfully transmitted to the appropriate receiving units <b>24</b> once the graphical data has been stored in the shared resource <b>45</b>. Thus, after the graphical data has, in fact, been stored in the shared resource <b>45</b>, the graphics application <b>25</b> may begin to immediately process the next set of graphical data. As a result, delays introduced by the communication of graphical data through the network <b>22</b> preferably do not significantly impact the performance of the graphics application <b>25</b>.</p>
<p id="p-0024" num="0023">Furthermore, each communication session <b>39</b> preferably runs on a separate thread of execution as compared to the graphics application <b>25</b> and the other communication sessions <b>39</b>. As a result, the consumption of processing resources by each communication session <b>39</b> preferably does not significantly reduce the processing speed of the graphics application <b>25</b> and to the other communication sessions <b>39</b>. However, it should be noted that, in other embodiments, it is possible for multiple ones of the communication sessions <b>39</b> to be implemented on the same thread of execution as another communication session <b>39</b> or as a graphics application <b>25</b>.</p>
<p id="p-0025" num="0024">It should be further noted that there are various techniques and protocols that may be employed to buffer data in the shared resource <b>45</b>. Exemplary techniques for achieving this functionality will now be described in more detail below.</p>
<p id="p-0026" num="0025">When a graphics application <b>25</b> is ready to initiate communication with at least one receiving unit <b>24</b>, this graphics application <b>25</b>, referred to hereafter as the “transmitting application <b>25</b>,” notifies its corresponding set of buffer logic <b>33</b>, referred to hereafter as the “transmitting buffer logic <b>33</b>.” In response to such notification, the transmitting buffer logic <b>33</b> is configured to submit a session request to the transport manager <b>36</b>. This session request may identify (e.g., include the address of) each receiving unit <b>24</b> to which graphical data from the transmitting graphics application <b>25</b> is to be communicated, and the session request also may identify the type of transport protocol that is to be used to communicate such graphical data.</p>
<p id="p-0027" num="0026">In a preferred embodiment, the network <b>22</b> is an internet protocol (IP) network, and the session request comprises the IP address of each receiving unit <b>24</b> that is to receive graphical data from the transmitting application <b>25</b>. Further, the communication sessions <b>39</b> may be configured to enable various types of protocols for communication across the network <b>22</b>. As an example, the communication sessions <b>39</b> may selectively enable communication via transmission control protocol (TCP), user datagram protocol (UDP), UDP-multicast (UDPM), and/or any other type of known or future-developed protocol.</p>
<p id="p-0028" num="0027">In response to the session request, the transport manager <b>36</b> selects a set of communication sessions <b>39</b> to service the transmitting graphics application <b>25</b> (i.e., to handle the communication of the transmitting graphics application's data with the network <b>22</b>). In this regard, the transport manager <b>36</b> preferably analyzes each active communication session <b>39</b> to determine whether any of the active sessions <b>39</b> are currently communicating data to the same set of receiving units <b>24</b> via the same protocol identified by the session request. Note that a communication session <b>39</b> is “active” when it is currently handling the communication of at least one graphics application <b>25</b>, and a communication session <b>39</b> is “inactive” when it is not presently handling the communication of any of the graphics applications <b>25</b>. Further note that while in an inactive state, a communication session <b>39</b> is preferably not running (e.g., is asleep) and, therefore, does not significantly consume processing resources.</p>
<p id="p-0029" num="0028">Moreover, if the transport manager <b>36</b> identifies any communication sessions <b>39</b> that are communicating to the same set of receiving units <b>24</b> via the same protocol identified by the session request, the transport manager <b>36</b> may be configured to select such identified communication sessions <b>39</b>, if any, to service the transmitting graphics application <b>25</b>. Note that such communication sessions <b>39</b> may exist when another graphics application <b>25</b> has previously initiated communication, via the same protocol requested via the session request, with the same set of receiving units <b>24</b> identified by the session request.</p>
<p id="p-0030" num="0029">If none or an insufficient number of the active communication sessions <b>39</b> are presently communicating with the same set of receiving units <b>24</b> and with the same transport protocol, then the transport manager <b>36</b> preferably also selects at least one of the inactive communication sessions <b>39</b> to service the graphics application <b>25</b>. For each selected inactive session <b>39</b>, the transport manager <b>36</b> activates (e.g., awakens) the selected session <b>39</b> and configures the session <b>39</b> to communicate, via the transport protocol identified by the session request, with the set of receiving units <b>24</b> also identified by the session request.</p>
<p id="p-0031" num="0030">In this regard, the transport manager <b>36</b> preferably stores or maintains sufficient information for enabling the manager <b>36</b> to find and initiate communication with each of the receiving units <b>24</b>. Moreover, when the transport manager <b>36</b> receives a session request from the transmitting buffer logic <b>33</b>, the manager <b>36</b> establishes a network socket (not specifically shown in <figref idref="DRAWINGS">FIG. 2</figref>) configured to interface data with the network <b>22</b> via the transport protocol identified by the session request. Using this socket, the transport manager <b>36</b> establishes communication with each receiving unit identified by the session request. Once such communication is established, the transport manager <b>36</b> hands-off or, in other words, allocates the foregoing socket to at least one session <b>39</b> activated for servicing the requesting application <b>25</b>. The activated session <b>39</b> may utilize such socket for communicating with the identified receiving units <b>24</b> according to techniques that will be described in more detail hereinbelow.</p>
<p id="p-0032" num="0031">Note that the number of sessions <b>39</b> selected to service a particular application <b>25</b> may vary depending on various factors and/or the configuration of the system <b>20</b>. For example, the graphics application <b>25</b> or the buffer logic <b>33</b> that initiated the session request may be configured to request that a particular number of sessions <b>39</b> be utilized for communicating the graphical data produced by the graphics application <b>25</b>. The transport manager <b>36</b> may be configured to select such a number of sessions <b>39</b> for servicing the graphics application <b>25</b> to the extent that such a number of sessions <b>39</b> is available.</p>
<p id="p-0033" num="0032">The transport manager <b>36</b> preferably assigns, to each set of communication sessions <b>39</b> configured to transmit to the same receiving units <b>24</b> via the same protocol, an identifier that uniquely identifies such sessions <b>39</b> from the other sessions <b>39</b> that also may retrieve data from the shared resource <b>45</b>. The transport manager <b>36</b>, after selecting a set of the communication sessions <b>39</b> for servicing the transmitting graphics application <b>25</b>, as described above, provides the session identifier of the selected set to the transmitting buffer logic <b>33</b>. As will be described in more detail hereinbelow, the transmitting buffer logic <b>33</b> uses this session identifier when storing, to the shared resource <b>45</b>, graphical data that is to be communicated to the receiving units <b>24</b>.</p>
<p id="p-0034" num="0033">As shown by <figref idref="DRAWINGS">FIG. 2</figref>, the shared resource <b>45</b> preferably comprises an entry queue <b>52</b> and shared memory <b>55</b> accessible by each of the sets of buffer logic <b>33</b> and the communication sessions <b>39</b>. The shared memory <b>55</b> is preferably partitioned into multiple segments or blocks <b>82</b>, referred to as “buffers.” As shown by <figref idref="DRAWINGS">FIG. 3</figref>, each buffer <b>82</b> comprises a header <b>85</b>, where various control information may be stored, and a data portion <b>88</b>, where data (e.g., graphical data from one of the graphics applications <b>25</b>) to be communicated over the network <b>22</b> may be stored. Techniques for storing and retrieving data to and from the buffers <b>82</b> will be described in more detail hereinbelow.</p>
<p id="p-0035" num="0034">The entry queue <b>52</b> of <figref idref="DRAWINGS">FIG. 2</figref> preferably stores a plurality of queued entries <b>91</b>, and each entry <b>91</b> has a session identifier (ID) <b>94</b> and a pointer <b>96</b>, as shown by <figref idref="DRAWINGS">FIG. 4</figref>. Initially, the number of entries <b>91</b> corresponds to the number of buffers <b>82</b>. More specifically, in the exemplary embodiment shown by <figref idref="DRAWINGS">FIG. 2</figref>, there is initially one entry <b>91</b> for each buffer <b>82</b>. Further, each entry <b>91</b> preferably corresponds to a different buffer <b>82</b>, and the pointer <b>96</b> of an entry <b>91</b> corresponding to a particular buffer <b>82</b> preferably points to (i.e., identifies) the particular buffer <b>82</b>. Thus, initially, each entry <b>91</b> corresponds to and points to a different buffer <b>82</b>.</p>
<p id="p-0036" num="0035">Initially, the session identifier <b>94</b> of each entry <b>91</b> comprises a value, referred to hereafter as an “empty buffer value,” which indicates that the buffer <b>82</b> identified by the entry's pointer <b>96</b> is empty (i.e., may be written to without corrupting or losing data). Note that once operation of the system <b>20</b> is begun, new entries <b>91</b> having other values stored as the session identifier <b>94</b> are preferably pushed into the queue <b>52</b> as will be described in more detail hereafter. Thus, after operation of the system <b>20</b> is initiated, some of the entries <b>91</b> may have the empty buffer value stored as their session identifiers <b>94</b>, and some of the entries <b>91</b> may other values stored as their session identifiers <b>94</b>.</p>
<p id="p-0037" num="0036">Moreover, when the transmitting application <b>25</b> is ready to transmit a set of graphical data to a set of receiving units <b>24</b>, its corresponding set of buffer logic <b>33</b> (i.e., the transmitting buffer logic <b>33</b>) searches the queue <b>52</b> for an entry <b>91</b> having the empty buffer value stored as the entry's session identifier <b>94</b>. Such an entry <b>91</b> is referred to herein as an “empty buffer entry <b>91</b>.” When the transmitting buffer logic <b>33</b> locates such an empty buffer entry <b>91</b>, it pulls the entry <b>91</b> from the queue <b>52</b> or, in other words, “pops” the entry <b>91</b> such that the entry <b>91</b> is no longer stored in the queue <b>52</b>, thereby disabling other components of the transmitting unit <b>21</b> from accessing the popped entry <b>91</b>. The transmitting buffer logic <b>33</b> writes the aforementioned set of graphical data to the buffer <b>82</b> pointed to or, in other words, identified by the pointer <b>96</b> of the popped entry <b>91</b>. For illustrative purposes, the foregoing buffer <b>82</b> will be referred to hereafter as the “used buffer <b>82</b>.”</p>
<p id="p-0038" num="0037">After popping, from the queue <b>52</b>, an empty buffer entry <b>91</b> identifying the used buffer <b>82</b> and then writing to the used buffer <b>82</b>, the transmitting buffer logic <b>33</b> pushes, into the queue <b>52</b>, an entry <b>91</b> having the same pointer <b>96</b> as the popped entry <b>91</b> (i.e., having a pointer <b>96</b> identifying the used buffer <b>82</b>). However, the transmitting buffer logic <b>33</b> assigns the session identifier <b>94</b> of the pushed entry <b>91</b> the value of the session identifier previously provided to it by the transport manager <b>36</b>. In other words, the session identifier <b>94</b> of the pushed entry <b>91</b> is associated with or identifies the set of communication sessions <b>39</b> that have been selected, by the transport manager <b>36</b>, to service the transmitting application <b>25</b>.</p>
<p id="p-0039" num="0038">Note that, in one exemplary embodiment, each set of buffer logic <b>33</b> is configured to write data to a buffer <b>82</b> only when the set of buffer logic <b>33</b> is able to locate, in the queue <b>52</b>, an empty buffer entry <b>91</b> that points to the particular buffer <b>82</b>, as described above. Thus, by popping, from the queue <b>52</b>, an empty buffer entry <b>91</b> identifying the used buffer <b>82</b>, the transmitting buffer logic <b>33</b> temporarily prevents or disables other sets of buffer logic <b>33</b> from writing to the used buffer <b>82</b>, thereby preventing corruption of the graphical data written to the used buffer <b>82</b> by the transmitting buffer logic <b>33</b>.</p>
<p id="p-0040" num="0039">After writing graphical data to the buffer <b>82</b>, buffer logic <b>33</b> also stores, in the header <b>85</b>, a value uniquely identifying the graphics application <b>25</b> that produced the data written to the buffer <b>55</b>. This value will be referred to herein as the “application identifier <b>86</b>.” Thus, by analyzing the application identifier <b>86</b> in the header <b>85</b> of a buffer <b>82</b>, it is possible to determine which application <b>25</b> produced the data that is stored in the data portion <b>88</b> of the buffer <b>82</b>. Utilization of the application identifier <b>86</b> will be described in more detail hereafter. Note that the application identifier <b>86</b> of each application <b>25</b> may be predefined and provided by the graphics applications <b>25</b>, or the transport manager <b>36</b> may be configured to assign a unique application identifier to each application <b>25</b> that initiates a session request transmitted to the transport manager <b>36</b>.</p>
<p id="p-0041" num="0040">The session logic <b>49</b> of each active communication session <b>39</b> preferably searches the queue <b>52</b> for any entries <b>91</b> that have session identifiers <b>94</b> identifying its communication session <b>39</b>. When such an entry <b>91</b> is found, the session logic <b>49</b> pulls the entry <b>91</b> from the queue <b>52</b> or, in other words, “pops” the entry <b>91</b> such that the entry <b>91</b> is no longer stored in the queue <b>52</b> thereby disabling other components of the transmitting unit <b>21</b> from accessing the popped entry <b>91</b>. The session logic <b>49</b> also retrieves the graphical data stored in the buffer <b>82</b> identified by the popped entry's pointer <b>96</b> (<figref idref="DRAWINGS">FIG. 4</figref>) and provides the retrieved data to a network interface <b>101</b>, which transmits the retrieved data to the network <b>22</b> (<figref idref="DRAWINGS">FIG. 1</figref>). As described above, when a session <b>39</b> is activated, it is instructed by the transport manager <b>36</b> to communicate, via a certain protocol, over the network <b>22</b> to a set of identified receiving units <b>24</b>. Moreover, when the session <b>39</b> pops an entry <b>91</b> from the queue <b>52</b> and retrieves the graphical data stored at the buffer <b>82</b> identified by the popped entry <b>91</b>, the session <b>39</b> transmits, according to the certain protocol, the retrieved data over the network <b>22</b> to the identified receiving units <b>24</b>.</p>
<p id="p-0042" num="0041">It should be noted, that when the transport manager <b>36</b> selects more than one session <b>39</b> to service the transmitting graphics application <b>25</b>, there are a plurality of sessions <b>39</b> searching the queue <b>52</b> for entries <b>91</b> that point to buffers <b>82</b> storing graphical data from the transmitting application <b>25</b>. In particular, each of the sessions <b>39</b> selected, by the transport manager <b>36</b>, to service the transmitting application <b>25</b> searches the queue <b>52</b> for entries <b>91</b> having the session identifier <b>94</b> associated with the selected set of sessions <b>39</b>. However, since each session <b>39</b> pops an entry <b>91</b> from the queue <b>52</b> when it locates an entry <b>91</b> having the associated session identifier <b>94</b>, the other selected sessions <b>39</b> that are searching for the same session identifier <b>94</b> are prevented or disabled from finding the popped entry <b>91</b>. Thus, only the session <b>39</b> that pops the entry <b>91</b> from the queue <b>52</b> accesses and transmits, across the network <b>22</b>, the data stored in-the buffer <b>82</b> pointed to by the popped entry <b>91</b>. Therefore, multiple transmissions of the same graphical data by multiple sessions <b>39</b> is prevented even though multiple sessions <b>39</b> may be allocated for servicing the same application <b>25</b> and, therefore, assigned the same session identifier. Such a feature helps to reduce needless additional transmissions of the same graphical data thereby helping to enhance the efficiency of the system <b>20</b>.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 5</figref> depicts a communication session <b>39</b> in accordance with an exemplary embodiment of the present invention. As shown by <figref idref="DRAWINGS">FIG. 5</figref>, the session <b>39</b> comprises a data packet pipeline <b>92</b> for transferring data from the buffers <b>82</b> (<figref idref="DRAWINGS">FIG. 2</figref>) to the network socket <b>50</b>. Packetization logic <b>97</b> within the pipeline <b>92</b> is configured to retrieve and packetize data from the buffers (<figref idref="DRAWINGS">FIG. 2</figref>). In this regard, a packet pointer pool <b>98</b> and a plurality of pre-allocated memory blocks <b>99</b> preferably reside within memory <b>100</b>. The packet pointer pool <b>98</b> preferably has a plurality of pointer entries <b>102</b> that respectively point to the memory blocks <b>99</b>. In this regard, each pointer entry <b>102</b> in the packet pointer pool <b>98</b> preferably points to an available one of the memory blocks <b>99</b> (i.e., one of the memory blocks <b>99</b> that may be written to without corrupting data within the memory block <b>99</b>). Initially, all of the memory blocks <b>99</b> are available, and the packet pointer pool <b>98</b> comprises a pointer entry <b>102</b> for each of the memory blocks <b>99</b>. However, when a memory block <b>99</b> is written to, as will be described in more detail hereinbelow, the pointer entry <b>102</b> associated with (i.e., pointing to) this memory block <b>99</b> is pulled from the pool <b>98</b> and is not returned until the memory block <b>99</b> is again available. Thus, the entries <b>102</b> of the packet pointer pool <b>98</b> may be analyzed to determine which of the memory blocks <b>99</b> may be written to.</p>
<p id="p-0044" num="0043">Note that it is not necessary for the blocks <b>99</b> to be pre-allocated. In this regard, it is possible for the packetization logic <b>97</b> to dynamically allocate a memory block <b>99</b> and an associated pointer entry <b>98</b> for each packet generated by the packetization logic <b>97</b>. However, the allocation of memory blocks <b>99</b> and packet pointer entries <b>102</b> consumes time and processing resources potentially slowing the rate at which the packetization logic <b>97</b> can process data packets. Thus, pre-allocating memory blocks <b>99</b> and-pointer entries <b>102</b> helps to improve the performance of the packetization logic <b>97</b> by eliminating the step of dynamically allocating memory for the data packetized by the packetization logic <b>97</b>.</p>
<p id="p-0045" num="0044">For each packet packetized by the logic <b>97</b>, the logic <b>97</b> pulls a pointer entry <b>102</b> from the packet pointer pool <b>98</b> and stores the packetized packet into the memory block <b>99</b> pointed to by the pulled entry <b>102</b>. The packetization logic <b>97</b> also inserts the pulled entry <b>102</b> into a queue <b>103</b>. Thus, the queue <b>103</b> may store several entries <b>102</b> pointing to memory blocks <b>99</b> storing packetized data. Queue logic <b>105</b> preferably retains each entry <b>102</b> in the queue <b>103</b> until it can be ensured that a retransmission request, from the receiving units <b>24</b>, for retransmitting the packet stored at the corresponding block <b>99</b> will not be received. Once it can be ensured that such a retransmission request will not be received, the queue logic <b>105</b> preferably stores the entry <b>102</b> into the packet pointer pool <b>98</b>. Returning an entry <b>102</b> to the packet-pointer pool <b>98</b>, as described above, has the effect of freeing the memory block <b>99</b> pointed to by the returned entry <b>102</b>. In this regard, once an entry <b>102</b> is returned to the pointer pool <b>98</b>, the entry <b>102</b> may be pulled by the packetization logic <b>97</b>, and the corresponding memory block <b>99</b> may be used by the logic <b>97</b> to store a data packet that is packetized by the logic <b>97</b>.</p>
<p id="p-0046" num="0045">Interface logic <b>107</b> periodically reads entries <b>102</b> from the queue <b>103</b>. For each entry <b>102</b> read from the queue <b>103</b>, the interface logic <b>107</b> retrieves the packet stored at the memory block <b>99</b> pointed to by the entry <b>102</b>. The interface logic <b>107</b> passes the retrieved data to network interface <b>101</b> (<figref idref="DRAWINGS">FIG. 2</figref>), which communicates the data via the network <b>22</b> (<figref idref="DRAWINGS">FIG. 1</figref>) to at least one receiving unit <b>24</b>. In a preferred embodiment, the interface logic <b>107</b>, with certain possible exceptions, such as the servicing of a retransmission request, for example, generally pulls entries <b>102</b> from the queue <b>103</b> in the same order that such entries <b>102</b> are inserted into the queue <b>103</b> by the packetization logic <b>97</b>. Thus, data packets are generally transmitted to the network <b>22</b> and the receiving units <b>24</b> generally in the same order that the packets are generated by the packetization logic <b>97</b>.</p>
<p id="p-0047" num="0046">At each receiving unit <b>24</b>, similar techniques for buffering the graphical data received from the network <b>22</b> may be employed. In this regard, as shown by <figref idref="DRAWINGS">FIG. 6</figref>, each receiving unit <b>24</b> preferably comprises, at least one receiver <b>111</b>, a transport manager <b>113</b>, a shared resource <b>121</b>, and at least one rendering session <b>123</b>. The shared resource <b>121</b> is preferably accessible by each receiver <b>111</b> and each rendering session <b>123</b>. Further, similar to the shared resource <b>45</b> described above, the shared resource <b>121</b> at the receiving unit <b>24</b> preferably comprises an entry queue <b>125</b> and shared memory <b>128</b>, and the shared memory <b>128</b> is preferably partitioned into multiple buffers <b>134</b>.</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 7</figref> depicts a receiver <b>111</b> in accordance with an exemplary embodiment of the present invention. As shown by <figref idref="DRAWINGS">FIG. 7</figref>, the receiver <b>111</b> comprises a data packet pipeline <b>162</b> for transferring data packets from the network socket <b>50</b> to the buffers <b>134</b> (<figref idref="DRAWINGS">FIG. 6</figref>). Receive logic <b>161</b> within the pipeline <b>162</b> is configured to receive data packets from a network interface <b>110</b>. In this regard, a packet pointer pool <b>165</b> and a plurality of pre-allocated memory blocks <b>167</b> preferably reside within memory <b>168</b>. The packet pointer pool <b>165</b> preferably has a plurality of pointer entries <b>171</b> that respectively point to the memory blocks <b>167</b>. In this regard, each pointer entry <b>171</b> in the packet pointer pool <b>65</b> preferably points to an available one of the memory blocks <b>167</b> (i.e., one of the memory blocks <b>167</b> that may be written to without corrupting data within the memory block <b>167</b>). Initially, all of the memory blocks <b>167</b> are available, and the packet pointer pool <b>165</b> comprises a pointer entry <b>171</b> for each of the memory blocks <b>167</b>. However, when a memory block <b>167</b> is written to, as will be described in more detail hereinbelow, the pointer entry <b>171</b> associated with (i.e., pointing to) this memory block <b>167</b> is pulled from the pool <b>165</b> and is not returned until the memory block <b>167</b> is again available. Thus, the entries <b>171</b> of the packet pointer pool <b>165</b> may be analyzed to determine which of the memory blocks <b>167</b> may be written to.</p>
<p id="p-0049" num="0048">Note that it is not necessary for the blocks <b>167</b> to be pre-allocated. In this regard, it is possible for the receive logic <b>161</b> to dynamically allocate a memory block <b>167</b> and an associated pointer entry <b>171</b> for each packet generated by the receive logic <b>161</b>. However, the allocation of memory blocks <b>167</b> and packet pointer entries <b>171</b> consumes time and processing resources potentially slowing the rate at which the receive logic <b>161</b> can process data packets. Thus, pre-allocating memory blocks <b>167</b> and pointer entries <b>171</b> helps to improve the performance of the receive logic <b>161</b> by eliminating the step of dynamically allocating memory for the data packets received by the receive logic <b>161</b>.</p>
<p id="p-0050" num="0049">For each packet received by the logic <b>161</b>, the logic <b>161</b> pulls a pointer entry <b>171</b> from the packet pointer pool <b>165</b> and inserts the data packet into the memory block <b>167</b> pointed to by the pulled entry <b>171</b>. The receive logic <b>161</b> inserts the pulled entry <b>171</b> into an ordered queue <b>173</b>. Thus, the queue <b>173</b> may store several entries <b>171</b>, pointing to memory blocks <b>167</b> storing packetized data.</p>
<p id="p-0051" num="0050">Packet delivery logic <b>177</b> periodically pulls an entry <b>171</b> from the queue <b>173</b>. For each entry <b>171</b> pulled from the queue <b>173</b>, the packet delivery logic <b>177</b> retrieves the data stored at the memory block <b>167</b> pointed to by the pulled entry <b>171</b>. The packet delivery logic <b>177</b> then writes the retrieved data to the shared resource, according to techniques that will be described in more detail hereinbelow. The packet delivery logic <b>177</b> also returns the pulled entry <b>171</b> to the packet pointer pool <b>168</b>. Note that returning an entry <b>171</b> to the packet pointer pool <b>168</b> has the effect of freeing the memory block <b>167</b> pointed to by the returned entry <b>171</b>. In this regard, once an entry <b>171</b> is returned to the pointer pool <b>168</b>, the entry <b>171</b> may be pulled by the receive logic <b>161</b>, and the corresponding memory block <b>167</b> may be used by the logic <b>161</b> to store a data packet received by the logic <b>161</b>.</p>
<p id="p-0052" num="0051">Note that the queue <b>173</b> is preferably ordered such that packets are retrieved by the packet delivery logic <b>177</b> and written to the shared resource <b>121</b> is the same order that such packets are originally transmitted from the transmitting unit <b>21</b> (<figref idref="DRAWINGS">FIG. 1</figref>). In this regard, the queue <b>173</b> is preferably ordered such that each entry <b>171</b> pulled from the queue <b>173</b> by the packet delivery logic <b>177</b> points to a successively transmitted packet relative to the previous packet written to the shared resource <b>121</b>. Exemplary techniques for achieving the foregoing are described in more detail in co-pending and commonly-assigned U.S. patent application entitled “Apparatus and Method for Receiving Data from a Network,” and filed on Feb. 8, 2003, which is incorporated herein by reference.</p>
<p id="p-0053" num="0052">Further, flow control logic <b>181</b> preferably monitors the packets received by the receive logic <b>161</b> and determines whether any packets are missing from a received sequence of packets. If so, the flow control logic <b>181</b> transmits a retransmission request to the transmitting unit <b>21</b> requesting retransmission of the missing data packets. In response, the transmitting unit <b>21</b> retransmits the requested packets, and these packets may be received in a similar manner as the received packets described above. In this regard, for each such packet, an entry <b>171</b> may be pulled from the pool <b>165</b>, and the packet may be written to the memory block <b>167</b> identified by this entry <b>171</b>, which is inserted into the queue <b>173</b> and processed according to the aforedescribed techniques.</p>
<p id="p-0054" num="0053">As shown by <figref idref="DRAWINGS">FIG. 6</figref>, the entry queue <b>125</b> preferably stores a plurality of queued entries <b>142</b>, and each entry <b>142</b>, as shown by <figref idref="DRAWINGS">FIG. 8</figref>, has a pointer <b>144</b> and an application identifier (ID) <b>146</b>, which is received from the network <b>22</b>. Like the pointers <b>96</b> of the queue entries <b>91</b> of <figref idref="DRAWINGS">FIG. 4</figref> that identify buffers <b>82</b> (<figref idref="DRAWINGS">FIG. 2</figref>) in shared memory <b>55</b>, the pointers <b>144</b> of the queue entries <b>142</b> point to or, in other words, identify buffers <b>134</b> in the shared memory <b>128</b>. Initially, the number of entries <b>142</b> corresponds to the number of buffers <b>134</b>. More specifically, there is initially one entry <b>142</b> for each buffer <b>134</b>. Further, each entry <b>142</b> preferably corresponds to a different buffer <b>134</b>, and the pointer <b>144</b> of the entry <b>142</b> corresponding to a particular buffer <b>134</b> preferably points to (i.e., identifies) the particular buffer <b>134</b>. Thus, initially, each entry <b>142</b> corresponds to and points to a different buffer <b>134</b>.</p>
<p id="p-0055" num="0054">Like the session identifiers <b>94</b> of the entries <b>91</b> in <figref idref="DRAWINGS">FIG. 2</figref>, the application identifier <b>146</b> of each entry <b>142</b> initially comprises an empty buffer value indicating that the buffer <b>134</b> identified by the entry's pointer <b>144</b> is empty (i.e., may be written to without corrupting or losing data). Note that once operation of the system <b>20</b> is begun, new entries <b>142</b> having other values stored as the application identifier <b>146</b> are preferably pushed into the queue <b>125</b>, as will be described in more detail hereafter. Thus, after operation of the system <b>20</b> is initiated, some of the entries <b>142</b> may have the empty buffer value stored as their application identifiers <b>146</b>, and some of the entries <b>142</b> may other values stored as their application identifiers <b>146</b>.</p>
<p id="p-0056" num="0055">Moreover, when a receiver <b>111</b> receives graphical data from the network <b>111</b>, buffer logic <b>151</b> within the receiver <b>111</b> searches the queue <b>125</b> for an entry <b>142</b> having the empty buffer value stored as the entry's application identifier <b>146</b>. Such an entry <b>142</b> is referred to as an “empty buffer entry <b>142</b>.” When the foregoing logic <b>151</b>, referred to hereafter as the “receiving buffer logic <b>151</b>,” locates such an empty buffer entry <b>142</b>, the receiving buffer logic <b>151</b> pulls the empty buffer entry <b>142</b> from the queue <b>125</b> or, in other words, “pops” the entry <b>142</b> such that the empty buffer entry <b>142</b> is no longer stored in the queue <b>125</b>. The receiving buffer logic <b>151</b>, then writes the received graphical data to the buffer <b>134</b> pointed to or, in other words, identified by the pointer <b>144</b> of the popped entry <b>142</b>. For illustrative purposes, the foregoing buffer <b>134</b> will be referred to hereafter as the “used buffer <b>134</b>.”</p>
<p id="p-0057" num="0056">As shown by <figref idref="DRAWINGS">FIG. 9</figref>, each buffer <b>134</b> comprises data portion <b>155</b> and a header <b>158</b>. In general, graphical data is stored in the data portion <b>155</b>, and various control information is stored in the header <b>158</b>. As an example, the buffer logic <b>151</b> may write, into the header <b>158</b>, the application identifier <b>146</b> identifying the application <b>25</b> that produced the data presently stored in the data portion <b>155</b>.</p>
<p id="p-0058" num="0057">After popping, from the queue <b>125</b>, the empty buffer entry <b>142</b> identifying the used buffer <b>134</b>, the receiving buffer logic <b>151</b> pushes, into the queue <b>125</b>, at least one entry <b>142</b> having the same pointer <b>144</b> as the popped entry <b>142</b> (i.e., having a pointer <b>144</b> identifying the used buffer <b>134</b>). However, the receiving receiver <b>111</b> assigns the application identifier <b>146</b> of the pushed entry <b>142</b> the value of the application identifier transmitted along with the graphical data over the network <b>142</b>. Thus, the application identifier <b>146</b> of the pushed entry <b>142</b> identifies the graphics application <b>25</b> that originally produced the graphical data being stored in the used buffer <b>134</b> by the receiving buffer logic <b>151</b>.</p>
<p id="p-0059" num="0058">Note that each receiver <b>111</b> is preferably configured to write data to a particular buffer <b>134</b> only when the receiver <b>111</b> is able to locate an empty buffer entry <b>142</b> in the queue <b>125</b> that points to the particular buffer <b>134</b>. Thus, by popping, from the queue <b>125</b>, an empty buffer entry <b>134</b> identifying a buffer <b>134</b>, a receiver <b>111</b> temporarily prevents or disables other receivers <b>111</b> from writing to the buffer <b>134</b>, thereby preventing corruption of the graphical data written to the buffer <b>134</b>.</p>
<p id="p-0060" num="0059">Like the transport manager <b>36</b> of <figref idref="DRAWINGS">FIG. 2</figref>, the transport manager <b>113</b> of the receiving unit <b>24</b> depicted by <figref idref="DRAWINGS">FIG. 6</figref> preferably allocates at least one rendering session <b>123</b> for rendering the graphical data from a particular application <b>25</b>. This may be achieved by providing the application's identifier to each rendering session <b>123</b> that is to render the application's graphical data. Session logic <b>132</b> of each such rendering session <b>123</b> then searches the entry queue <b>125</b> for entries <b>142</b> having the application identifier <b>146</b> provided to the session <b>123</b> much in the same manner that each rendering session <b>92</b> of <figref idref="DRAWINGS">FIG. 2</figref> searches the queue <b>52</b> for entries <b>91</b> having the session identifier <b>94</b> provided to the session <b>92</b> by the transport manager <b>36</b>. When the session logic <b>132</b> finds such an entry <b>142</b>, the session logic <b>132</b> pops the entry <b>142</b> from the queue <b>125</b> and retrieves the graphical data stored in the buffer <b>134</b> pointed to by the popped entry <b>142</b>. The session logic <b>132</b> then renders the retrieved data to at least one display device <b>135</b> via a graphics accelerator <b>137</b>. Note that the application identifier of each application <b>25</b>, if not already known by the transport manager <b>113</b>, may be transmitted to the transport manager <b>113</b> by the transport manager <b>36</b> of <figref idref="DRAWINGS">FIG. 2</figref> or some other component of the transmitting unit <b>21</b>.</p>
<p id="p-0061" num="0060">Note that exemplary techniques that may be used by the system <b>20</b> to communicate and buffer data are described in more detail in co-pending and commonly-assigned U.S. patent application entitled “Apparatus and Method for Communicating with a Network,” and filed on Feb. 8, 2003, which is incorporated herein by reference. Additional techniques are also described in co-pending and commonly-assigned U.S. patent application entitled “Apparatus and Method for Transmitting Data through a Network,” and filed on Feb. 8, 2003, which is incorporated herein by reference</p>
<p id="p-0062" num="0061">Monitoring of the communication system <b>20</b> may be desirable for a variety of reasons, such as enabling debugging and/or tuning of the communication occurring across the system <b>20</b>. Thus, as shown by <figref idref="DRAWINGS">FIG. 2</figref>, the transmitting unit <b>21</b> preferably comprises a transmit monitoring element <b>300</b> for monitoring and/or improving the performance of the transmitting unit <b>21</b>. The monitoring element <b>300</b> preferably communicates with various components of the unit <b>21</b> requesting that such components provide the monitoring element <b>300</b> with data indicative of the components' performance. By analyzing such data, the monitoring element <b>300</b> may identify and isolate various problems occurring within the unit <b>21</b>. Depending on the type of problem encountered, the monitoring element <b>300</b> may attempt to adjust the configuration of the unit <b>21</b> in an effort to correct the problem, and the monitoring element <b>300</b> may output a message to a user in order to notify the user of a detected problem. Further, the monitoring element <b>300</b> may also output a report indicative of the performance of various components of the transmitting unit <b>21</b>, and a user may utilize such report to debug or improve the configuration or design of the unit <b>21</b>.</p>
<p id="p-0063" num="0062">Note that when outputting a message or report, as described above, the monitoring element <b>300</b> may render or otherwise transmit data defining such message or report to an output device <b>302</b>, such as a display device or printer. The output device <b>302</b> may then display to a user the message or report defined by such data.</p>
<p id="p-0064" num="0063">To better illustrate monitoring techniques that may be performed by the transmit monitoring element <b>300</b>, refer to <figref idref="DRAWINGS">FIG. 5</figref>. As shown by <figref idref="DRAWINGS">FIG. 5</figref>, the monitoring element <b>300</b> is preferably coupled to the packetization logic <b>97</b> and the interface logic <b>107</b>. The monitoring element <b>300</b> may be configured to transmit, to the packetization logic <b>97</b>, a message requesting that the logic <b>97</b> return a value indicative of the rate that the packetization logic <b>97</b> inserts entries <b>102</b> into the queue <b>103</b>. In response, the packetization logic <b>97</b> counts the number of entries <b>102</b> input to the queue <b>103</b> during a particular time period and calculates a rate of entry insertion into the queue <b>103</b> based on the count. The packetization logic <b>97</b> transmits, to the monitoring element <b>300</b>, a value indicative of the calculated rate.</p>
<p id="p-0065" num="0064">Further, the monitoring element <b>300</b> may also be configured to transmit, to the interface logic <b>107</b>, a message requesting that the logic <b>107</b> return a value indicative of the rate that the interface logic <b>177</b> pulls entries <b>102</b> from the queue <b>103</b>. In response, the interface logic <b>177</b> counts the number of entries <b>102</b> that it pulls from the queue <b>103</b> during a particular time period and calculates a rate that entries <b>102</b> are pulled from the queue <b>103</b>. The interface logic <b>107</b> transmits, to the monitoring element <b>300</b>, a value indicative of the calculated rate.</p>
<p id="p-0066" num="0065">Moreover, based on the aforementioned values provided by the packetization logic <b>97</b> and the interface logic <b>107</b>, the monitoring element <b>300</b> may detect a possible problem with the operation of the transmitting unit <b>21</b>. For example, the monitoring element <b>300</b> may determine that the interface logic <b>107</b> is pulling entries <b>107</b> at a much slower rate than the packetization logic <b>97</b> inserts entries <b>102</b>. In such an example, the monitoring element <b>300</b> may be configured to slow the rate at which the packetization logic <b>97</b> inserts entries <b>102</b> into the queue <b>103</b> in order to prevent a possible data overrun in the queue <b>103</b>. Also, the monitoring element <b>300</b> may output a message indicative of the respective performances the packetization logic <b>97</b> and interface logic <b>107</b>, and a user may utilize the information gleaned by this message to debug or redesign the unit <b>21</b>.</p>
<p id="p-0067" num="0066">Further, the monitoring element <b>300</b> may also utilize the information provided by the packetization logic <b>97</b> and interface logic <b>107</b> to automatically debug an operational problem associated with the transmitting unit <b>21</b>. As an example, based on the aforementioned rates provided by the packetization logic <b>97</b> and the interface logic <b>107</b>, the monitoring element <b>300</b> may determine that an operational problem exists downstream of the queue <b>103</b> (e.g., between the interface logic <b>107</b> and the network <b>22</b> (<figref idref="DRAWINGS">FIG. 1</figref>)). Thus, in such an example, the monitoring element <b>300</b> is configured to perform additional monitoring with respect to components downstream of the queue <b>107</b> in an effort to isolate and diagnose the operational problem.</p>
<p id="p-0068" num="0067">Note that, in some circumstances, more precise performance information may be desired in order to better debug or tune the transmitting unit <b>21</b>. In this regard, a problem in one component of the transmitting unit <b>21</b> may ripple through the unit <b>21</b> and cause poor performance for many of the unit's other components. As an example, a problem with interfacing data packets with the network <b>22</b> may cause a data bottleneck at the network interface <b>101</b> resulting in poor performance for many of the network components. In this regard, such a problem may reduce that rate at which the interface logic <b>107</b> pulls entries <b>102</b> from the queue <b>103</b> thereby reducing the rate at which the packetization logic <b>97</b> inserts entries <b>102</b> into the queue <b>103</b>. In such a situation, it may be difficult to determine whether a network interface problem is causing poor performance of the packetization logic <b>97</b> or whether a problem with the packetization logic <b>97</b> is causing poor performance of the network interface <b>101</b>.</p>
<p id="p-0069" num="0068">Further, when a single monitored component performs multiple tasks, it may be difficult to determine which task is causing poor performance by the component. For example, if it is determined that interface logic <b>107</b> is pulling entries from the queue <b>103</b> at a slow rate, then the source of the problem may not be readily apparent. More specifically, it may not be clear as to whether the interface logic's task of retrieving data packets is causing poor performance or whether the interface logic's task of writing to the socket <b>50</b> is causing poor performance.</p>
<p id="p-0070" num="0069">To provide better operational performance information in an attempt to address the aforedescribed monitoring issues, the monitoring element <b>300</b> may request that a component being monitored perform a limited number of tasks as compared to what the component would otherwise perform during normal operation. For example, the monitoring element <b>300</b> may disable a portion of the logic <b>107</b> that writes packets to the socket <b>50</b> of network interface <b>101</b>. In response to such a request, the interface logic <b>107</b> may operate as described above except that the interface logic <b>107</b>, rather than writing retrieved data packets to the socket <b>50</b>, discards such data packets. Accordingly, any operational problems associated with the network interface <b>101</b>, do not significantly affect the upstream components (e.g., packetization logic <b>97</b>, queue <b>103</b>, etc.). Thus, the process of diagnosing or isolating operational problems is simplified.</p>
<p id="p-0071" num="0070">In this regard, if the operational performance of the packetization logic <b>97</b> (e.g., the rate at which the logic <b>97</b> inserts entries <b>102</b> into the queue <b>103</b>) does not improve after disabling the interface logic <b>107</b> from writing to the socket <b>50</b>, then the monitoring element <b>300</b> may determine that an operational problem affecting the performance of the packetization logic <b>97</b> is upstream of the network interface (e.g., is between the graphics application <b>25</b> and the network interface <b>101</b>). However, if the performance of the packetization logic <b>97</b> is improved after disabling the interface logic <b>107</b> from writing to the network socket <b>50</b>, then the monitoring element <b>300</b> may determine that an operational problem is downstream of the interface logic <b>107</b> (e.g., between the interface logic <b>108</b> and the network <b>22</b>).</p>
<p id="p-0072" num="0071">However, by limiting or disabling the performance of one or more components of the transmitting unit <b>21</b>, data may be lost. For example, in the example described above where the interface logic <b>107</b> refrains from writing data packets to the socket <b>50</b>, the data packets are discarded or, in other words, lost. Moreover, losing data produced by an application <b>25</b> running on the system <b>20</b> may have undesirable consequences. Thus, in an effort to limit the effects of the testing performed by the monitoring element <b>300</b>, the monitoring element <b>300</b> is preferably configured to create or otherwise provide a synthetic application or producer <b>312</b> (<figref idref="DRAWINGS">FIG. 2</figref>). The synthetic producer <b>312</b> preferably produces data that may be discarded without adversely affecting another component of the system <b>20</b>. In this regard, the data produced by the synthetic producer <b>312</b> may be arbitrary or meaningless in that the data is not to be utilized in the operation of the receiving units <b>24</b>.</p>
<p id="p-0073" num="0072">Moreover, the synthetic producer <b>312</b> preferably operates in a similar manner as the applications <b>25</b> except that the data produced by the synthetic producer <b>312</b> is discarded. In this regard, the synthetic producer <b>312</b>, via the same techniques utilized by the graphics applications <b>25</b>, may initiate a session request, which is transmitted to the transport manager <b>36</b> by the synthetic application's corresponding buffer logic <b>33</b>. The transport manager <b>36</b> may be configured to handle the session request in the same manner described above for handling the session requests initiated by the graphics applications <b>25</b>. Thus, the transport manager <b>36</b> allocates at least one communication session <b>39</b> to the synthetic producer <b>312</b> and returns the session identifier of the allocated session <b>39</b>.</p>
<p id="p-0074" num="0073">Using the returned session identifier, the corresponding buffer logic <b>33</b> may process the data produced by the synthetic producer <b>312</b> according to the techniques described above such that the allocated session <b>39</b> retrieves and processes such data. However, the monitoring element <b>300</b> is preferably configured to communicate with the allocated session <b>39</b> and request that the allocated session <b>39</b> provide performance data to the monitoring element <b>300</b>.</p>
<p id="p-0075" num="0074">Continuing with the example described above, the monitoring element <b>300</b> may request the interface logic <b>107</b> of the allocated session <b>39</b> to discard any data retrieved by it and to provide the monitoring element <b>300</b> with a value indicative of the number of data packets retrieved and/or discarded during a particular time period, as shown by blocks <b>401</b> and <b>404</b> of <figref idref="DRAWINGS">FIG. 10</figref>. Further, the monitoring element <b>300</b> may request performance data from other components of the transmitting unit <b>21</b> as well. Thus, the monitoring element <b>300</b> may collect, from the components of the transmitting unit <b>21</b>, various performance information that is substantially free of various effects associated with the writing of data packets to the socket <b>50</b>.</p>
<p id="p-0076" num="0075">As shown by decision block <b>408</b> and block <b>411</b>, the monitoring element <b>300</b> analyzes the aforementioned performance data when it is received by the monitoring element <b>300</b>. The monitoring element <b>300</b> then outputs, via output device <b>302</b> (<figref idref="DRAWINGS">FIG. 2</figref>), the results of the analysis, as shown by block <b>415</b>. If the monitoring element <b>300</b> determines, based on the analysis, that performance of the transmitting unit <b>21</b> may be improved by adjusting the configuration of the transmitting unit <b>21</b>, then the transmit monitoring element <b>300</b> requests the appropriate adjustment to improve the unit's performance, as shown by decision block <b>417</b> and block <b>421</b>.</p>
<p id="p-0077" num="0076">As an example, the monitoring element <b>300</b> may initially determine a data throughput of the interface logic <b>107</b> (<figref idref="DRAWINGS">FIG. 5</figref>). In this regard, the monitoring element <b>300</b> determines, based on performance data provided by the interface logic <b>107</b>, a value indicative of a number of data packets retrieved from the buffers <b>99</b> and provided to the network interface <b>101</b> during a particular time period. Note that such a value is indicative of the throughput rate of the interface logic <b>107</b>. Then, in block <b>401</b>, the monitoring element <b>300</b> requests the interface logic <b>107</b> to discard the retrieved data packets rather than interfacing such packets with the network interface <b>101</b>. In other words, the monitoring element <b>300</b> disables the portion of the logic <b>107</b> that transmits data packets to the network interface <b>101</b>, thereby disabling the network interface <b>101</b> from handling the data packets retrieved by the interface logic <b>107</b>.</p>
<p id="p-0078" num="0077">The monitoring element <b>300</b> may also request, in block <b>404</b>, performance data indicative of the data throughput of the interface logic <b>107</b> when the transmitting portion of the interface logic <b>107</b> is disabled. In this regard, the transmit monitoring element <b>300</b> requests that the interface logic <b>107</b> provide a value indicative of the number of data packets retrieved and discarded by the interface logic <b>107</b> during a particular time period or, in other words, indicative of the throughput rate of the logic <b>107</b>. The monitoring element <b>300</b> may then compare the aforementioned throughput rate values to determine whether disabling of the transmitting portion of the interface logic <b>107</b> significantly affected the data throughput of the logic <b>107</b>. A significant change in the throughput rate may indicate that there is an operational problem or inefficiency associated with writing data packets to the socket <b>50</b>. Thus, the monitoring element <b>300</b>, in blocks <b>415</b> and <b>421</b>, may respectively output data indicative of the detected operational problem or inefficiency and may adjust the configuration of the transmitting unit <b>21</b> in an attempt to compensate for the problem or inefficiency.</p>
<p id="p-0079" num="0078">For example, the monitoring element <b>300</b> may adjust the packet lengths of the data packets produced by the packetization logic <b>97</b> by submitting an appropriate request to the logic <b>97</b>. The monitoring element <b>300</b> may repeat the aforedescribed process of determining and comparing values indicative of the data throughput of the interface logic <b>107</b> to determine whether the adjustment improved the operation of the transmitting unit <b>21</b> and, more particularly, whether the adjustment compensated for or alleviated the detected problem or inefficiency. If the adjustment did not sufficiently improve performance or alleviate the detected problem or inefficiency, then the monitoring element <b>300</b> may undo the adjustment and/or attempt further adjustments according to similar techniques.</p>
<p id="p-0080" num="0079">In another example, the monitoring element <b>300</b> may collect performance data from various points in the transmitting unit <b>21</b> and the pipeline <b>92</b>, in particular, in an attempt to isolate operational problems. In this regard, as shown by block <b>502</b> of FIG. <b>11</b>, the monitoring element <b>300</b> may request data indicative of at least one performance data indicative of at least one performance parameter (e.g., throughput) from multiple components of the pipeline <b>92</b>. For illustrative purposes, assume that the monitoring element <b>300</b> requests data throughput information from the packetization logic <b>97</b> and interface logic <b>107</b>. The monitoring element <b>300</b> may request that each such component track data throughput during the same particular time and provide information indicative of such throughput to the monitoring element <b>300</b>. Alternatively, the monitoring element <b>300</b> may indicate, to each such component, to expect a certain amount of data from the synthetic producer <b>312</b> and to provide timing information on how long it takes the component to process the certain amount of data from the synthetic producer <b>312</b>.</p>
<p id="p-0081" num="0080">In block <b>505</b>, the monitoring element <b>300</b> instructs the synthetic producer <b>312</b> to initiate a data transfer of the certain amount of data described above. In response, the producer <b>312</b> produces the certain amount of data, which is handled by the packetization logic <b>97</b> and the interface logic <b>107</b> according to techniques described herein. In block <b>508</b> the monitoring element <b>300</b> collects the requested performance data from the packetization logic <b>97</b> and the interface logic <b>107</b>. Such collected data may take various forms. For example, the data may indicate the amount of time it took each set of logic <b>97</b> and <b>107</b> to process the certain amount of data. Alternatively, the data may comprise a calculated data throughput values indicative of the respective processing rate of each set of logic <b>97</b> and <b>107</b>. Other forms of such data are possible in other examples.</p>
<p id="p-0082" num="0081">In block <b>511</b>, the monitoring element <b>300</b> analyzes collected data and may isolate an operational problem based on the collected data. For example, the monitoring element <b>300</b> may determine that the data throughput of the packetization logic <b>97</b> is relatively high and that the data throughput of the interface logic <b>107</b> is relatively low. Such results may indicate an operational problem between the packetization logic <b>97</b> and the interface logic <b>107</b>.</p>
<p id="p-0083" num="0082">Moreover, in block <b>514</b>, the monitoring element <b>300</b> outputs the collected data to a user and, in decision block <b>517</b>, determines whether to make an adjustment of the configuration of the transmitting unit <b>21</b>. If the monitoring element <b>300</b> can determine, based on the collected data, that an adjustment of the transmitting unit <b>21</b> may improve the performance or alleviate an operational problem of the unit <b>21</b>, then the monitoring element <b>300</b> requests the adjustment in block <b>519</b>. If an adjustment is indeed requested, then the monitoring element <b>300</b> may repeat the aforedescribed process and compare the results to determine whether the adjustment actually improved performance or alleviated an operational problem. If not, the monitoring element <b>300</b> may undo the adjustment or attempt another adjustment.</p>
<p id="p-0084" num="0083">Note that the monitoring element <b>300</b> may dynamically collect performance information in the aforedescribed manner while the graphics applications <b>25</b> are running and are being serviced by various other communication sessions <b>39</b>. By using a synthetic producer <b>312</b> and testing components allocated to such producer <b>312</b>, the testing performed by the monitoring element <b>300</b> preferably does not have a substantial effect on the operational performance of the other applications <b>25</b>. Further, the monitoring element <b>300</b> may make changes to the configuration of the transmitting unit <b>21</b>, in an effort to improve the unit's performance, without significantly interrupting the operation of the graphics applications <b>25</b>. In other words, the monitoring element <b>300</b>, based on the information collected by it, may adjust the configuration of the transmitting element <b>21</b> “on the fly.”</p>
<p id="p-0085" num="0084">As an example, if the transmit monitoring element <b>300</b> determines, based on the information collected by it, that a detected operational problem may be alleviated or solved by adjusting the packet sizes of the packets produced by the transmitting unit <b>21</b>, then the monitoring element <b>300</b> may notify the transport manager <b>36</b> of such a determination. In response, the transport manager <b>36</b> may adjust the settings of the communication sessions <b>39</b> such that the sizes of the packets packetized by the packetization logic <b>97</b> of each session <b>39</b> are adjusted in a desirable manner that generally improves the performance of the transmitting unit <b>21</b>. In other examples, other parameters of the transmitting unit <b>21</b> may be adjusted based on the information provided by the monitoring element <b>300</b> in order to improve the performance of the transmitting unit <b>21</b>.</p>
<p id="p-0086" num="0085">It should be noted that similar monitoring and testing techniques may be employed at the receiving units <b>24</b> (<figref idref="DRAWINGS">FIG. 1</figref>). In this regard, as shown by <figref idref="DRAWINGS">FIG. 6</figref>, each receiving unit <b>24</b> preferably comprises a receive monitoring element <b>342</b> configured to test and monitor the components of the receiving unit <b>24</b> according to techniques similar to those employed by the transmit monitoring element <b>300</b>. In particular, the receive monitoring element <b>342</b> may be configured to communicate with various components of the receiving unit <b>24</b> to determine data indicative of the performance of,such components. Further, the monitoring element <b>342</b> may request at least one of the components to refrain from performing a task that it normally would perform during normal operation. For example, to isolate the testing of the receiver <b>111</b> from other components of the receiving unit <b>24</b>, the monitoring element <b>342</b> may instruct the packet delivery logic <b>177</b> (<figref idref="DRAWINGS">FIG. 7</figref>) to discard data that the logic <b>177</b> would otherwise store in the shared resource <b>121</b> (<figref idref="DRAWINGS">FIG. 6</figref>). In another example, the monitoring element <b>342</b> may instruct a rendering session <b>123</b> to discard data that it would otherwise normally submit to a graphics accelerator <b>137</b>.</p>
<p id="p-0087" num="0086">To prevent the discarding of useful data from the graphics applications <b>25</b> (<figref idref="DRAWINGS">FIG. 2</figref>), the monitoring element <b>342</b> may be configured to create or otherwise provide a synthetic producer <b>345</b> to produce data that may be discarded similar to the synthetic producer <b>312</b> of <figref idref="DRAWINGS">FIG. 2</figref>. Further, when requesting a component of the receiving unit <b>24</b> to discard data, the monitoring element <b>342</b> may also instruct the receive logic <b>161</b> (<figref idref="DRAWINGS">FIG. 7</figref>) to receive data from the synthetic producer <b>345</b> rather than the network interface <b>110</b> coupled to it. Thus, any data discarded by the receiving unit <b>24</b> is preferably not useful data transmitted from the transmitting unit <b>21</b>.</p>
<p id="p-0088" num="0087">As an example, assume that it is desirable to determine the actual rate at which the receiver <b>111</b> is able to buffer data packets independent of the performance of the rest of the receiving unit <b>24</b>. In such an example, the receive monitoring element <b>342</b> maybe configured to instruct the packet delivery logic <b>177</b> to refrain from storing data to the shared resource <b>121</b> (<figref idref="DRAWINGS">FIG. 6</figref>). Further, the monitoring element <b>342</b> may be configured to provide the synthetic producer <b>345</b> and to instruct the receive logic <b>161</b> to receive data from the synthetic producer <b>345</b> rather than the network interface <b>110</b>. In such an example, data packets from the synthetic producer <b>345</b> are received by the receive logic <b>161</b>. For each data packet, the receive logic <b>161</b> then pulls an entry <b>171</b> from the packet pointer pool <b>165</b> and stores the packet in the memory block <b>167</b> identified by the pulled entry <b>171</b>. The receive logic <b>161</b> then inserts the pulled entry into the queue <b>173</b>.</p>
<p id="p-0089" num="0088">According to the techniques described above, the packet delivery logic <b>177</b> pulls entries <b>171</b> from the queue <b>173</b> and retrieves the data packets stored in the memory blocks <b>167</b> identified by these entries <b>171</b>. However, rather than storing the retrieved data packets in the shared resource <b>121</b>, the packet delivery logic <b>177</b>, as instructed by the monitoring element <b>342</b>, discards the retrieved packets and provides the receive monitoring element <b>342</b> with a value indicative of the rate at which the packet delivery logic <b>177</b> retrieves the data packets that are discarded by the packet delivery logic <b>177</b>. The monitoring element <b>342</b> may then use the data provided by the packet delivery logic <b>177</b> to determine or report the operational status of the receiver <b>111</b>. Further, the monitoring element <b>342</b> may use such data to diagnose or debug operational problems associated with the receiver <b>111</b>.</p>
<p id="p-0090" num="0089">To enable the monitoring element <b>342</b> to report operational status information, the receiving unit <b>24</b> may comprises an output device <b>352</b>, such as a display device or printer. In this regard, similar to the transmit monitoring element <b>300</b>, the receive monitoring element <b>342</b> may output data indicative of the operational state of the receiving unit <b>24</b> by rendering or otherwise transmitting such information to the output device <b>352</b>, which then displays such data to a user.</p>
<p id="p-0091" num="0090">It should be noted that monitoring and testing techniques may be employed within transmitting and receiving units having a configuration different than the configuration of the transmitting unit <b>21</b> and receiving units <b>24</b> described hereinabove. In addition, it is possible for a monitoring element <b>300</b> or <b>342</b> to reside external to the respective unit <b>21</b> or <b>24</b> being tested by the monitoring element <b>300</b> or <b>342</b>.</p>
<p id="p-0092" num="0091">For example, it is possible for the transmit monitoring element <b>300</b> to communicate with components of a receiving unit <b>24</b> in order to test and monitor the performance of the receiving unit <b>24</b>, and it is possible for the receive monitoring element <b>342</b> to communicate with components of the transmitting unit <b>21</b> in order to test and monitor the performance of the transmitting unit <b>21</b>. In such an embodiment, data from the synthetic producer <b>312</b> (<figref idref="DRAWINGS">FIG. 2</figref>) may be transmitted through the network <b>22</b> and discarded by a component of a receiving unit <b>24</b> for more precisely monitoring such component according to the techniques described hereinabove.</p>
<p id="p-0093" num="0092">It should that it is not necessary for the steps of the exemplary methodologies depicted by <figref idref="DRAWINGS">FIGS. 10 and 11</figref> to be formed in the depicted order. In this regard, the order of such steps may be rearranged from that shown in <figref idref="DRAWINGS">FIGS. 10 and 11</figref> in various other embodiments of the present invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>Now, therefore, the following is claimed:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An apparatus for communicating with a network, comprising:
<claim-text>a data packet pipeline configured to transfer data between a buffer and a network socket, the pipeline having a first component and a second component; and</claim-text>
<claim-text>a monitoring element configured to generate a first value indicative of an operational performance parameter for the first component while the second component is disabled, the monitoring element further configured to generate a second value indicative of the operational performance parameter for the first component while the second component is enabled and to isolate an operational problem within the pipeline based on a comparison of the first and second values.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first value indicates a data throughput of the first component and the second value indicates a data throughput of the first component.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the monitoring element is configured to adjust a configuration of the apparatus based on the indication.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the monitoring element is configured to disable the second component.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the monitoring element is configured to cause the pipeline to discard a plurality of data packets flowing through the pipeline while the second component is disabled, wherein the first value is based on the plurality of data packets.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second component is configured to receive a data packet transmitted by the first component.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. An apparatus for communicating with a network, comprising:
<claim-text>a data packet pipeline between a buffer and a network socket and defining a data path from the buffer to the network socket; and</claim-text>
<claim-text>a monitoring element configured to disable a first portion of the pipeline from processing a plurality of data packets flowing through the pipeline, the monitoring element configured to monitor a second portion of the pipeline while the second portion is processing the plurality of data packets and the first portion is disabled, wherein the monitoring element is configured to determine whether disabling of the first portion by the monitoring element affects a data throughput of the second portion, wherein the first and second portions are within the data path.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The apparatus of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the monitoring element is configured to cause the second pipeline portion to discard the plurality of data packets.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The apparatus of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein, due to disabling the first pipeline portion by the monitoring element, the plurality of data packets are prevented from reaching the network socket.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The apparatus of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein, due to disabling the first pipeline portion by the monitoring element, the plurality of data packets are prevented from reaching the buffer.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. An apparatus for communicating with a network, comprising:
<claim-text>a data packet pipeline configured to transfer data between a buffer and a network socket; and</claim-text>
<claim-text>a monitoring element configured to disable a first portion of the pipeline from processing a plurality of data packets flowing through the pipeline, the monitoring element configured to monitor a second portion of the pipeline that is processing the plurality of data packets while the first portion is disabled,</claim-text>
<claim-text>wherein the monitoring element is configured to determine whether disabling of the first portion by the monitoring element affects a data throughput of the second portion, wherein the monitoring element is configured to determine a first value indicative of an operational performance of the second pipeline portion while the first pipeline portion is disabled and to determine a second value indicative of an operational performance of the second pipeline portion while the first pipeline portion is enabled, and wherein the monitoring element is further configured to isolate a communication problem within the pipeline by comparing the first and second values.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. An apparatus for communicating with a network, comprising:
<claim-text>a data packet pipeline configured to transfer data between a buffer and a network socket; and</claim-text>
<claim-text>a monitoring element configured to cause a portion of the data packet pipeline to discard a plurality of data packets flowing through the pipeline thereby preventing the plurality of data packets from reaching a network component downstream of the pipeline portion, the monitoring element further configured to determine a value indicative of an operational performance of the pipeline in processing the plurality of packets, the monitoring element further configured to isolate a communication problem with the network component based on the value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the monitoring element is configured to adjust a configuration of the data packet pipeline based on the value.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the monitoring element is configured to output the value.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the monitoring element is further configured to determine a value indicative of an operational performance of the pipeline in processing other packets, the monitoring element further configured to isolate the communication problem based on a comparison of the values.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. An apparatus for communicating with a network, comprising:
<claim-text>pipeline means for transferring data between a buffer and a network socket, the pipeline means having a first component and a second component; and</claim-text>
<claim-text>monitoring means for generating a first value indicative of an operational performance parameter for the first component while the second component is disabled and for generating a second value indicative of the operational performance parameter for the first component while the second component is enabled, the monitoring means configured to isolate an operational problem within the pipeline based on a comparison of the first and second values.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. A method for use in a network communication apparatus, comprising:
<claim-text>transferring data, via a data packet pipeline, between a buffer and a network socket;</claim-text>
<claim-text>monitoring the pipeline;</claim-text>
<claim-text>determining, based on the monitoring, a first value indicative of an operational performance parameter for a first component of the data packet pipeline while a second component of the data packet pipeline is disabled;</claim-text>
<claim-text>determining, based on the monitoring, a second value indicative of the operational performance parameter for the first component while the second component is enabled;</claim-text>
<claim-text>comparing the first and second values; and</claim-text>
<claim-text>isolating an operational problem within the pipeline based on the comparing.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising:
<claim-text>disabling the second component from processing a plurality of data packets flowing through the pipeline; and</claim-text>
<claim-text>determining whether the disabling affects a data throughput of the first component.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising:
<claim-text>causing the pipeline to discard at least one data packet flowing through the pipeline, wherein the first value is based on the one packet.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising transmitting a data packet through the first and second components.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. A method for use in a network communication apparatus, comprising:
<claim-text>transferring data, via a data packet pipeline, between a buffer and a network socket along a data path;</claim-text>
<claim-text>disabling a first portion of the pipeline from processing a plurality of data packets flowing through the pipeline;</claim-text>
<claim-text>monitoring a second portion of the pipeline that is processing the data packets during the disabling, wherein the first and second portions are within the data path; and</claim-text>
<claim-text>defining data that indicates whether the disabling affects a data throughput of the second pipeline portion.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, further comprising communicating the defined data to a user.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, further comprising adjusting a configuration of the pipeline based on the defined data.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, further comprising causing the second pipeline portion to discard the data packets.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein, due to the disabling, the data packets are prevented from reaching the network socket.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein, due to the disabling, the data packets are prevented from reaching the buffer.</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. A method for use in a network communication apparatus, comprising:
<claim-text>transferring data, via a data packet pipeline, between a buffer and a network socket;</claim-text>
<claim-text>causing a portion of the pipeline to discard at least one data packet flowing through the pipeline thereby preventing the at least one data packet from reaching a network component downstream of the pipeline portion;</claim-text>
<claim-text>determining a value indicative of an operational performance of the pipeline in processing the one packet; and</claim-text>
<claim-text>indicating a communication problem with the network component based on the value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The method of <claim-ref idref="CLM-00027">claim 27</claim-ref>, further comprising adjusting a configuration of the pipeline based on the value.</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. The method of <claim-ref idref="CLM-00027">claim 27</claim-ref>, further comprising outputting data indicative of the value to a user of the apparatus.</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. The method of <claim-ref idref="CLM-00027">claim 27</claim-ref>, further comprising:
<claim-text>determining a value indicative of an operational performance of the pipeline in processing other data packets;</claim-text>
<claim-text>comparing the values; and</claim-text>
<claim-text>isolating the communication problem based on the comparing.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
