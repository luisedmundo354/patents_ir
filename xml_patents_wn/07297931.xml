<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07297931-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07297931</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10690237</doc-number>
<date>20031020</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>148</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>01</class>
<subclass>J</subclass>
<main-group>1</main-group>
<subgroup>04</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>01</class>
<subclass>J</subclass>
<main-group>3</main-group>
<subgroup>14</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>02</class>
<subclass>B</subclass>
<main-group>6</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>02</class>
<subclass>B</subclass>
<main-group>6</main-group>
<subgroup>04</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>25022714</main-classification>
<further-classification>25022711</further-classification>
<further-classification>250216</further-classification>
<further-classification>385 12</further-classification>
<further-classification>385120</further-classification>
</classification-national>
<invention-title id="d0e53">Method and apparatus to effectively reduce a non-active detection gap of an optical sensor</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4189207</doc-number>
<kind>A</kind>
<name>Fisher et al.</name>
<date>19800200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>385116</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>4573082</doc-number>
<kind>A</kind>
<name>Jeskey</name>
<date>19860200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>358250</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>4674834</doc-number>
<kind>A</kind>
<name>Margolin</name>
<date>19870600</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>350 9625</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>4748680</doc-number>
<kind>A</kind>
<name>Margolin</name>
<date>19880500</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382 65</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>4871228</doc-number>
<kind>A</kind>
<name>Roos</name>
<date>19891000</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>350 9625</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>4896965</doc-number>
<kind>A</kind>
<name>Goff et al.</name>
<date>19900100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>356417</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>4904049</doc-number>
<kind>A</kind>
<name>Hegg</name>
<date>19900200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>385120</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>4910395</doc-number>
<kind>A</kind>
<name>Frankel</name>
<date>19900300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>2502033</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5061036</doc-number>
<kind>A</kind>
<name>Gordon</name>
<date>19911000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>385116</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>5729640</doc-number>
<kind>A</kind>
<name>Castonguay</name>
<date>19980300</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382321</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6191413</doc-number>
<kind>B1</kind>
<name>Hegyi</name>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>25022711</main-classification></classification-national>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>6377739</doc-number>
<kind>B1</kind>
<name>Richardson et al.</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>385115</main-classification></classification-national>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2004/0109653</doc-number>
<kind>A1</kind>
<name>Kerr et al.</name>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>385120</main-classification></classification-national>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2004/0178329</doc-number>
<kind>A1</kind>
<name>Kare et al.</name>
<date>20040900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>25022711</main-classification></classification-national>
</citation>
</references-cited>
<number-of-claims>43</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>358482</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358483</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358484</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3589011</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>385113</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>385116</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>385120</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>385121</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>385 12</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382321</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348359</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348832</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>250216</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>25022711</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>25022714</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>2502272</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>8</number-of-drawing-sheets>
<number-of-figures>10</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20050082464</doc-number>
<kind>A1</kind>
<date>20050421</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Krantz</last-name>
<first-name>Eric P.</first-name>
<address>
<city>Ithaca</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>DeAngelis</last-name>
<first-name>Douglas J.</first-name>
<address>
<city>Ipswitch</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Sigel</last-name>
<first-name>Kirk</first-name>
<address>
<city>Ithaca</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Lathrop &amp; Gage LC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Lynx System Developers, Inc.</orgname>
<role>02</role>
<address>
<city>Haverhill</city>
<state>MO</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Epps</last-name>
<first-name>Georgia</first-name>
<department>2878</department>
</primary-examiner>
<assistant-examiner>
<last-name>Williams</last-name>
<first-name>Don</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An apparatus is provided to effectively reduce the non-active detection gap between sensor elements of an optical sensor. Reducing the non-active gap can subsequently reduce the time delay between sensor elements, mitigating the image degrading effects of a composite element time delay. While applicable to use with a wide range of optical sensors, the invention may be used for detecting aspects of a variable-rate dynamic colorful object using a matrix sensor or a tri-linear color CCD sensor. In one variation, optical fibers extend from a first fiber optic faceplate to a second fiber optic faceplate. The optical fibers can be oriented toward or directly mounted to the sensor elements. A spacer may be used to separate the optical fibers for alignment with the sensor elements and the other end of the optical fibers are attached to each other.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="123.95mm" wi="117.35mm" file="US07297931-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="114.81mm" wi="84.07mm" file="US07297931-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="130.22mm" wi="113.37mm" orientation="landscape" file="US07297931-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="156.72mm" wi="129.20mm" file="US07297931-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="174.16mm" wi="127.42mm" file="US07297931-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="146.81mm" wi="112.01mm" file="US07297931-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="142.66mm" wi="81.79mm" file="US07297931-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="189.65mm" wi="118.19mm" file="US07297931-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="220.05mm" wi="151.47mm" file="US07297931-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">This invention relates to optical sensors and more specifically relates to methods and apparatus for redirecting light in order to effectively reduce a non-active detection gap between optical sensor elements of one or more optical sensors.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">Optical sensors are used for a wide variety of imaging purposes. An optical sensor, such as a linear sensor, may have multiple sensor elements, each of which captures a portion of the light information of an object or scene of interest. The manufacture of optical sensors may require a non-active gap between these sensor elements. The non-active gap is a portion of the optical sensor that can not detect an optical signal. In one example, linear arrays of distinct red, green and blue light capturing sensor elements are separated by a linear area, the non-active gap, where the combined sensor is not capable of capturing an optical signal.</p>
<p id="p-0004" num="0003">Similarly, optical sensors with one optical sensor element may be used collectively with other such sensors to form a larger combined sensor. In such cases, non-active gaps will typically exist between the sensor elements of neighboring sensors.</p>
<p id="p-0005" num="0004">For many applications that rely upon a predictable rate and distance of subject movement, such as, for example, a color imaging scanner, the size of a non-active gap does not create difficulty in the recording of subjects and subsequent accurate replay of images. However, for subjects that are dynamic or moving with unpredictable speed and/or distance relative to the sensor, this non-active gap can cause the inaccurate recording of an object or scene and result in a significant loss of image fidelity.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0006" num="0005">The present invention concerns methods of ameliorating the problems caused by non-active gaps. One example of an image sensor having separation between sensor elements, e.g. non-active gaps, is the three-color linear CCD detector that is used for various and extensive commercial purposes, including color scanners and machine vision. Typically, this optical sensor is constructed with significant non-active gaps between the linear red, green and blue element arrays. The presence of these non-active gaps may pose little difficulty in high fidelity imaging for many applications. Examples of this type of application include the detection of objects which move at a constant rate along a fixed focal plane and which themselves are not dynamically active, such as a sheet of paper along a scanner. Similarly, this includes examples where the object is stationary and the optical sensor moves at a constant rate along a fixed focal plane.</p>
<p id="p-0007" num="0006">Dynamically active objects moving at variable rates pose a difficulty in high fidelity color imaging, particularly when a large depth-of-field is required. An example of such a situation is an optical line sensor used at the finish line of a race or other competition. In such a case, the separation of sensor elements results in an inaccurate representation of the events as the contestants cross the finish line. For instance, the color aspects of a competitor, such as the uniform, may be blurred in the image. This arises as the first sensor detects one color aspect of the uniform, for example, red, as the competitor crosses the line and the subsequent sensors in succession detect other color aspects, such as, for example, green then blue.</p>
<p id="p-0008" num="0007">The non-active gap between color sensors therefore presents a time and space difference in real terms for red, green and blue color information intended to be recorded simultaneously. It may not be possible to accurately interpolate such information in the combined red, green and blue color image. This can cause an image to be blurred substantially, to the point where loss of image fidelity is responsible for the inability to determine the outcome of a competition, or even to determine the distinguishing characteristics of competitors.</p>
<p id="p-0009" num="0008">The present invention addresses the difficulties of the prior art by the use of optical fibers oriented to obtain visual images from a field of view at one location and distribute components of the optical images to more widely-spaced sensor elements of one or more optical sensors.</p>
<p id="p-0010" num="0009">This invention effectively reduces the non-active gap between sensor elements and thus reduces the time delay between such sensor elements in receiving image information, such as for example, the red, green and blue image components of a moving subject. The image fidelity is therefore improved because the combined image components present a closer match to the true image at an instantaneous moment or “snapshot” of interest. In other words, optical congruence may be enhanced by the use of the invention.</p>
<p id="p-0011" num="0010">One implementation includes an optical sensor apparatus for effectively reducing a non-active gap. The optical sensor may have a first linear array of sensor segments and a second linear array of sensor segments separated by a first non-active gap having a first width. A first optical fiber has a first end oriented toward a field of view and a second end oriented toward a sensor segment of the first linear array of sensor segments. A second optical fiber has a first end oriented toward the field of view and located a first distance, less than the first width, from the first end of the first optical fiber and a second end oriented toward a sensor segment of the second linear array of sensor segments. This effectively reduces the distance between corresponding elements of the first and second linear arrays and therefore enhances the optical congruence of the first linear array in relation to the second linear array.</p>
<p id="p-0012" num="0011">An optical sensor system for effectively reducing a non-active gap may have a tri-linear optical sensor with a first linear sensor element and a second linear sensor element separated by a first non-active gap with a first width. A third linear sensor element separated from the second linear sensor element by a second non-active gap having a second width can also be included. First, second and third optical fibers each have their first end oriented toward the field of view and the second end oriented toward the linear sensor elements. The second optical fiber is located a first distance, less than the first width, from the first end of the first optical fiber. The third optical fiber is located a third distance, less than the second width, from the first end of the second optical fiber.</p>
<p id="p-0013" num="0012">An apparatus for effectively reducing a non-active gap of an optical sensor may include a first and second fiber optic faceplate each configured to accommodate a plurality of optical fibers. A first and second optical fibers of the plurality of optical fibers each have a first end mounted to the first fiber optic faceplate and a second end mounted to the second fiber optic faceplate. The first end of the second optical fiber is mounted to the first fiber optic faceplate a first distance, less than the non-active gap, from the first end of the first optical fiber, and the second end of the second optical fiber is mounted to the second fiber optic faceplate such that the second end of the first optical fiber and the second end of the second optical fiber are spaced to align with a first linear array and a second linear array, respectively, of a multiple-linear array image sensor.</p>
<p id="p-0014" num="0013">The separation of the second ends of the optical fibers may involve at least one spacer for proper positioning. The apparatus for effectively reducing a non-active gap of an optical sensor may have a first optical fiber and a second optical fiber are mounted such that a first end of the each optical fiber is oriented toward the field of view and the second end is directed towards a sensor. A first spacer is mounted between the second end of the first optical fiber and the second end of the second optical fiber to locate the second ends further apart than the first ends so as to correspond to elements of an optical sensor.</p>
<p id="p-0015" num="0014">The invention also provides a method of effectively reducing a non-active gap of an optical sensor. The optical sensor has a first linear sensor element and a second linear sensor element separated by a first non-active gap having a first width and a third linear sensor element separated from the second linear sensor element by a second non-active gap of a second width. A first end of each optical fiber is oriented toward the field of view and the second end of each optical fiber is oriented toward the first, second and third linear sensor elements, respectively. The first end of a second optical fiber is located a first distance, less than the first width, from the first end of the first optical fiber and the first end of a third optical fiber is located a third distance, less than the second width, from the first end of the second optical fiber. Using this method, the optical congruence of said linear sensors may be enhanced in relation to each other.</p>
<p id="p-0016" num="0015">The apparatus effectively reduces a non-active gap of an optical sensor or sensors. The apparatus gathers light information at or near a field of view and directs the image information to at least two linear sensor elements of an optical sensor so as to improve the image fidelity of the subject by enhancing the optical congruence capability of the optical sensor at an instantaneous or “photographic” time of interest.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWING</heading>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a top view of an optical sensor system oriented toward the field of view;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 2</figref> illustrates a side view of the optical sensor system of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIGS. 3A &amp; 3B</figref> illustrate first and second fiber optic faceplates of a gap reduction apparatus;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 4</figref> illustrates sample pixel configurations of the first and second fiber optic faceplates of <figref idref="DRAWINGS">FIGS. 3A and 3B</figref>;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 5</figref> illustrates a gap reduction apparatus arranging one end of optical fibers in a single column;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 6</figref> illustrates an optical sensor;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 7</figref> illustrates an optical sensor system having a gap reduction apparatus according to an alternative embodiment of the present invention; and</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIGS. 8 and 9</figref> illustrate example manufacturing steps that may be used for the construction of the gap reduction apparatus of <figref idref="DRAWINGS">FIG. 7</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0025" num="0024">The invention addresses the difficulties of the prior art by the use of optical fibers oriented to obtain visual images from a field of view and distribute components of the optical images to more widely-spaced sensor elements of one or more optical sensors. This can enhance the optical congruence of the image obtained through the more widely-spaced sensor elements and eliminate inaccuracies caused by non-active optical gaps in the sensors. The image fidelity of a subject can be improved at an instantaneous or “photographic” time of interest by reducing the potential image degrading effects between the sensor elements. Such image degrading effects can include a differential time delay, angular and/or positional differences between the sensor elements. Specifically, optical congruence is enhanced in that the image information received by each sensor element at any instantaneous time is a closer representation of the original subject field than it would be if the sensor elements received image information directly from the field of view without non-active gap mitigation. Thus, the invention compensates for the image degrading effects, more severe in dynamically moving objects, that arise from the ordinarily non-active gap between sensor elements.</p>
<p id="p-0026" num="0025">As shown in <figref idref="DRAWINGS">FIGS. 1 and 2</figref>, a gap reduction apparatus <b>100</b> is used with an optical sensor <b>200</b> in order to obtain an optical image over a field of view <b>10</b>. The gap reduction apparatus <b>100</b> and the optical sensor <b>200</b> form an optical sensor system <b>300</b>. Lenses <b>150</b> or other optical elements may optionally be incorporated into the optical sensor system <b>300</b>. For example one or more lenses <b>150</b> may be located between the field of view <b>10</b> and the gap reduction apparatus <b>100</b> and/or between the gap reduction apparatus <b>100</b> and the optical sensor system <b>300</b>.</p>
<p id="p-0027" num="0026">As used herein, the term “non-active gap” relates to the separation between sensor elements of one or more optical sensors. Each sensor element of an optical sensor is active in that it is able to optically detect light at the location of the sensor element.</p>
<p id="p-0028" num="0027">The term “sensor element” relates to a plurality of sensor segments arranged in a group. Examples of sensor elements include, but are not limited to, a linear array of sensor segments, and a matrix sensor, or a subset of sensor segments of a matrix sensor.</p>
<p id="p-0029" num="0028">The term “segment” relates to any portion, such as a pixel or other identifiable sub-unit, of the sensor elements of the optical sensor <b>200</b>.</p>
<p id="p-0030" num="0029">The space between each sensor element is typically caused by manufacturing limitations. This space is non-active in that the optical sensor is not able to detect light at locations between the sensor elements. The present invention serves to minimize the detrimental effects of this non-active gap, while not physically altering the dimensions of the non-active gap. The present apparatus and method are suitable for use with a wide range of non-active gaps.</p>
<p id="p-0031" num="0030">The apparatus and method may also be used with separate optical sensors, each having one or more sensor elements. In such a case, the method involves directing light from a field of view to each of the multiple sensor elements located on one or more optical sensors and separated by at least one non-active gap.</p>
<p id="p-0032" num="0031">As shown in <figref idref="DRAWINGS">FIG. 2</figref>, the gap reduction apparatus <b>100</b> may be formed of a first fiber optic faceplate <b>110</b> and a second fiber optic faceplate <b>120</b>. The first fiber optic faceplate <b>110</b> and a second fiber optic faceplate <b>120</b> are optically coupled by optical fibers <b>130</b>. In one implementation, the optical fibers <b>130</b> may be oriented to correspond with sensor elements of an optical sensor <b>200</b>. The present invention is suitable for use with a wide variety of optical sensors <b>200</b>.</p>
<p id="p-0033" num="0032">The gap reduction apparatus <b>100</b> serves to orient ends of the optical fibers close together at the first fiber optic faceplate <b>110</b>. Opposite ends of the optical fibers <b>130</b> are then arranged on the second fiber optic faceplate <b>120</b> so as to correspond with the sensor elements of the optical sensor <b>200</b>.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIGS. 3A</figref>, <b>3</b>B, <b>4</b> and <b>5</b> illustrate the gap reduction apparatus <b>100</b> and optical sensor <b>200</b>. As shown in <figref idref="DRAWINGS">FIG. 3A</figref>, the first fiber optic faceplate <b>110</b> is shown having a first element <b>112</b>, a second element <b>114</b> and a third element <b>116</b>. Each of these elements is formed of segments illustratively shown in the third element <b>116</b> by pixel <b>118</b>.</p>
<p id="p-0035" num="0034">The first, second and third elements <b>112</b>, <b>114</b>, <b>116</b> are shown as being located contiguous to each other, thereby minimizing any separation between them. However, the first, second and third elements <b>112</b>, <b>114</b>, <b>116</b> may be separated from each other by similar or different distances. The ends of the optical fibers <b>130</b> that are coupled to the second fiber optic faceplate <b>120</b> are further separated from each other than the ends of the optical fiber <b>130</b> coupled to the first fiber optic faceplate <b>110</b>. Therefore, the distance between each of the first, second and third elements <b>112</b>, <b>114</b>, <b>116</b> is smaller than the non-active gap of an optical sensor optionally interfacing with the second fiber optic faceplate <b>120</b>. Although the pixels and optical fibers are illustrated herein as square, optical fibers may also be, and typically are, of round or any other arbitrary shape.</p>
<p id="p-0036" num="0035">As shown in <figref idref="DRAWINGS">FIGS. 3A</figref>, <b>3</b>B and <b>4</b>, distance A represents the width of an optical segment. If distance A is about 14 microns, the overall dimensions of the first fiber optic faceplate <b>110</b> are approximately 3 centimeters by 2 centimeters. However, a wide range of dimensions and sizes of optical fibers <b>130</b> and faceplates <b>110</b> are possible.</p>
<p id="p-0037" num="0036">The second fiber optic faceplate <b>120</b> is illustrated in <figref idref="DRAWINGS">FIG. 3B</figref>. Similar to the first fiber optic faceplate <b>110</b>, the second fiber optic faceplate <b>120</b> has a first element <b>212</b>, a second element <b>214</b> and a third element <b>216</b>. An average size for distance B is 98 microns. As discussed above, the invention is suitable to a wide range of dimensions.</p>
<p id="p-0038" num="0037">The overall dimensions of the second fiber optic faceplate <b>120</b> may be similar to those of the first fiber optic faceplate <b>110</b>. The first fiber optic faceplate <b>110</b> may be sized so as to be no larger than the arrangement of optical fibers <b>130</b> mounted thereon. Considerations involved in sizing the second fiber optic faceplate <b>120</b> involve interfacing the second fiber optic faceplate <b>120</b> with the optic sensor <b>200</b> and specifically, the sensor elements of the optical sensor <b>200</b>.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 4</figref> illustrates the optical fibers <b>130</b> mounted between the first fiber optic faceplate <b>110</b> and the second fiber optic faceplate <b>120</b>. A first optical fiber <b>132</b>, a second optical fiber <b>134</b> and a third optical fiber <b>136</b> are shown for illustrative purposes only as corresponding to the upper-most pixels of the elements of the fiber optic faceplates. Specifically, the first optical fiber <b>132</b> is mounted to a first element <b>112</b> of the first fiber optic faceplate <b>110</b> and the first element <b>212</b> of the second fiber optic faceplate <b>120</b>. Alternatively, the apparatus and method may include coupling different elements among the fiber optic faceplates. For example, the first element <b>112</b> of the first fiber optic faceplate <b>110</b> may be coupled to the third element <b>216</b> of the second fiber optic faceplate <b>120</b>.</p>
<p id="p-0040" num="0039">Also, for purposes of illustration, the optical fibers <b>130</b> are drawn as corresponding only to the top row of pixels. Each pixel of the first fiber optic faceplate <b>110</b> may be optically coupled by the use of an optical fiber <b>130</b> to a pixel of the second fiber optic faceplate <b>120</b>. However, pixels of different rows may be optically coupled to pixels of other rows among fiber optic faceplates. For example, a top pixel of the first element <b>112</b> of the first fiber optic faceplate <b>110</b> may be coupled to a pixel approximately half way along the length of the second element <b>214</b> of the second fiber optic faceplate <b>120</b>.</p>
<p id="p-0041" num="0040">Similarly, one or more matrix optical sensors may be used. In such a variation, one or more sensor elements may be formed of segments of one or more matrix sensors.</p>
<p id="p-0042" num="0041">The optical fibers <b>130</b> may be mounted to the fiber optic faceplates <b>110</b>, <b>120</b> by the use of an adhesive, such as glue, or by the use of a grid sized to hold the ends of the optical fibers <b>130</b> without the use of an adhesive, such as by the use of a compressive force. A compressive force may be applied by the use of a band, clamp, frame or similar structure.</p>
<p id="p-0043" num="0042">As noted, color filters may be used in conjunction with the optical fibers <b>130</b> so as to limit the colors to a particular sensor element. As illustrated in <figref idref="DRAWINGS">FIG. 4</figref>, color filters <b>139</b> are mounted on optical fibers <b>130</b> so as to limit the transmission of various colors through the optical fibers <b>130</b>. A wide variety of other filtering arrangements are also within the scope of the invention. For example, a sheet filter may be coupled to the second fiber optic faceplate <b>120</b> and arranged with one of the elements <b>212</b>, <b>214</b>, <b>216</b> of the second fiber optic faceplate <b>120</b>. By the use of such color filtering, a black and white optical sensor <b>200</b> having multiple sensor elements is capable of producing a color image. Specifically, by using color filters <b>139</b>, each black and white sensor element <b>222</b>, <b>224</b>, <b>226</b> is assigned a color. Therefore, by filtering the optical images read by each of the sensor elements and assigning a color to each image based on its associated color filter, such as, for example, red, green or blue, a resulting composite color image can be created, equivalent to an image obtained by a color optical sensor.</p>
<p id="p-0044" num="0043">The spacing and configuration of the mounting of the optical fibers <b>130</b> on the second fiber optic faceplate <b>120</b> may be adapted to correspond to the arrangement of the sensor elements <b>222</b>, <b>224</b>, <b>226</b> on the face <b>201</b> of the optical sensor <b>200</b>. Alternatively, and the apparatus may include optical fibers mounted to the second fiber optic faceplate <b>120</b> that do not correspond to a sensor element of the optical sensor. Such additional optical fibers may be ignored by the optical sensor and/or may be used for other signaling or communication purposes.</p>
<p id="p-0045" num="0044">The second fiber optic faceplate <b>120</b> may be securely mounted to the optical sensor <b>200</b> by the use of brackets or an adhesive. There is no requirement that the first fiber optic faceplate be securely mounted to either the second fiber optic faceplate or the optical sensor <b>200</b>, as the optical fibers <b>130</b> allow for relative movement of the first fiber optic faceplate <b>110</b>. Ideally, the first fiber optic faceplate <b>110</b> will be securely mounted to a frame that provides a stable orientation toward the field of view <b>10</b>.</p>
<p id="p-0046" num="0045">The second fiber optic faceplate <b>120</b> may be omitted, allowing direct mounting of the optical fibers <b>130</b> to the sensor elements <b>222</b>, <b>224</b>, <b>226</b> of the optical sensor <b>200</b>.</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 5</figref> illustrates a gap reduction apparatus <b>100</b> having a first fiber optic faceplate <b>111</b> used with a second fiber optic faceplate <b>120</b>, coupled by optical fibers <b>130</b>. The first fiber optic faceplate <b>111</b> arranges the ends of the optical fibers <b>130</b> in a single column. The optical fibers <b>130</b> may be randomly arranged in a single column or may alternate among each of the columns provided in the second fiber optic faceplate <b>120</b>. Color filters may also be used as well.</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 6</figref> illustrates a sample optical sensor <b>200</b> having sensor elements arranged linearly. Specifically, a first sensor element <b>222</b>, a second sensor element <b>224</b>, and a third sensor element <b>226</b> are provided on a face <b>201</b> of the optic sensor <b>200</b>. The optical sensor <b>200</b> may be a tri-linear CCD image sensor such as the Kodak 2098×3 Tri-Linear CCD image sensor, model number: KLI-2113, manufactured by Eastman Kodak Company. The optical sensor <b>200</b> may be a color optical sensor, a matrix sensor and/or may be black and white.</p>
<p id="p-0049" num="0048">The apparatus may also use at least one spacer. An optical sensor system <b>500</b>, as illustrated in <figref idref="DRAWINGS">FIG. 7</figref>, includes a gap reduction apparatus <b>400</b> in a block structure formed by the use of spacers <b>440</b> to arrange optical fibers <b>130</b> to correspond to sensor elements <b>222</b>, <b>224</b>, <b>226</b> of optical sensor <b>200</b>, as discussed above. At an opposite end of optical fibers <b>130</b>, the optical fibers are ideally arranged proximate to each so as to minimize a separation between them, thereby minimizing the separation of the optical image obtained. Although spacers <b>440</b> are illustrated in <figref idref="DRAWINGS">FIG. 7</figref> as wedges extending along the length the optical fibers <b>130</b>, this is not necessary. Specifically, spacers <b>440</b> may be used only at the end of the optical fiber approximate to the optical sensor <b>200</b>. Furthermore, the spacers <b>440</b> may be in a variety of shapes, such a rectangular block, a square block, an oval or any other arbitrary shape able to separate optical fibers. Spacers may be formed of a wide variety of materials, including, but not limited to the following: plastics, glass, metals, composites, paper or other wood products.</p>
<p id="p-0050" num="0049">The gap reduction apparatus <b>400</b> of <figref idref="DRAWINGS">FIG. 7</figref> may be formed so as to arrange one end of the optical fibers in a single column as illustrated with respect to the first fiber optic faceplate <b>111</b> of <figref idref="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0051" num="0050">The gap reduction apparatus <b>400</b> may use adhesive to mount the optical fibers <b>130</b> to each other at a side <b>402</b> distant from the optical sensor <b>200</b> and to mount the optical fibers <b>130</b> to the one or more spacers <b>440</b> and to each other at a side <b>404</b> approximately to the optical sensor <b>200</b>. Alternatively, other forms of mounting optical fibers <b>130</b> to each other and/or to the spacers <b>440</b> may be used to form a block structure. Examples include a band or frame surrounding at least one end of the gap reduction apparatus <b>400</b> or a compressive wrapping arranged to maintain the configuration of the sides <b>402</b>, <b>404</b> of the gap reduction apparatus. Another example involves fusing of the optical fibers <b>130</b> to each other.</p>
<p id="p-0052" num="0051">One example of construction of the gap reduction apparatus <b>400</b> of <figref idref="DRAWINGS">FIG. 7</figref> is illustrated by way of example in <figref idref="DRAWINGS">FIGS. 8 and 9</figref>. As shown in <figref idref="DRAWINGS">FIG. 8</figref>, the spacers <b>440</b> are mounted to optical elements <b>312</b>, <b>314</b>, <b>316</b>. According to various implementations, the spacers are mounted with the optical elements <b>312</b>, <b>314</b>, <b>316</b> by fusing and/or injection molding manufacture techniques. The spacers <b>440</b> are then ground down in the grinding areas <b>450</b> to shape the spacers <b>440</b> to position a first element <b>312</b>, a second element <b>314</b> and a third element <b>316</b>. The spacers <b>440</b> form components that may be assembled as shown in <figref idref="DRAWINGS">FIG. 9</figref> such that a first end <b>322</b>, <b>324</b>, <b>326</b> of the elements <b>312</b>, <b>314</b>, <b>316</b> may be aligned with elements of an optical sensor and a second end <b>332</b>, <b>334</b>, <b>336</b> of the elements <b>312</b>, <b>314</b>, <b>316</b> may be oriented toward a field of view, such as, for example, a focal plane. Optionally, a mirrored surface <b>460</b> may be provided along outer side surfaces to inhibit the entry of light through the outer side surfaces.</p>
<p id="p-0053" num="0052">The gap reduction apparatus <b>400</b> of <figref idref="DRAWINGS">FIG. 9</figref> may be coupled together by the use of epoxy or heat treatment and optionally may be ground down along the dashed lines <b>350</b> to conform to the dimensions of an optical sensor or other optical components used in conjunction with the gap reduction apparatus <b>400</b>.</p>
<p id="p-0054" num="0053">It is understood that embodiments of the invention may be implemented in a wide variety of scales, such as by using large optical fibers or by the use of nanotechnology manufacturing techniques. According to one implementation, optical fibers of 14 microns in diameter are used. In another implementation, 5 micron diameter fibers are used.</p>
<p id="p-0055" num="0054">These examples are meant to be illustrative and not limiting. The present invention has been described by way of example, and modifications of the exemplary embodiments, implementations and variations will suggest themselves to skilled artisans in this field without departing from the spirit of the invention. Aspects and characteristics of the above-described embodiments, implementations and variations may be used in combination. The scope of the invention is to be measured by the appended claims, rather than the preceding description, and all variations and equivalents that fall within the range of the claims are intended to be embraced therein.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An optical sensor apparatus for effectively reducing a non-active gap, comprising:
<claim-text>an optical sensor having a first linear array of sensor segments and a second linear array of sensor segments separated by a first non-active gap having a first width;</claim-text>
<claim-text>a first optical fiber having a first end oriented toward a field of view and a second end oriented toward a sensor segment of said first linear array of sensor segments, for directing first image information from said field of view to said first linear array; and</claim-text>
<claim-text>a second optical fiber for directing second image information from said field of view to said second linear array, said second optical fiber having a first end oriented toward said field of view and located a first distance, less than said first width, from said first end of said first optical fiber and a second end oriented toward a sensor segment of said second linear array of sensor segments and located a second distance, greater than said first distance, from said second end of said first optical fiber, thereby providing optical congruence between said field of view and said first and second image information without substantial time delay.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The optical sensor apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said optical sensor has a third linear array of sensor segments separated from said second linear array of sensor segments by a second non-active gap having a second width, said optical sensor apparatus further comprising:
<claim-text>a third optical fiber having a first end oriented toward said field of view and located a third distance, less than said second width, from said first end of said second optical fiber and a second end oriented toward a sensor segment of said third linear array of sensor segments, for directing third image information from said field of view to said third linear array.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The optical sensor apparatus of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising:
<claim-text>a first color filter positioned to filter light reaching said first linear array of sensor segments;</claim-text>
<claim-text>a second color filter, different from said first color filter, positioned to filter light reaching said second linear array of sensor segments;</claim-text>
<claim-text>a third color filter, different from said first color filter and said second color filter, positioned to filter light reaching said third linear array of sensor segments.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The optical sensor apparatus of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising a first fiber optic faceplate configured to accommodate said first end of said first optical fiber and said first end of said second optical fiber.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The optical sensor apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said first ends of said first and second optical fibers are arranged in a single column.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The optical sensor apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said optical fibers are mounted within a block structure.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The optical sensor apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said field of view is along a plane intersecting said first end of said first optical fiber and said first end of said second optical fiber.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The optical sensor apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said optical sensor is a linear sensor.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The optical sensor apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said optical sensor is a tri-linear sensor having three sensor elements.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The optical sensor apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said optical sensor is at least one matrix sensor.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The optical sensor apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said optical sensor comprises at least one linear array formed on a matrix sensor.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The optical sensor apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said optical sensor comprises three linear arrays formed on a matrix sensor.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The optical sensor apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said second end of said first optical fiber is mounted to said sensor segment of said first linear array of sensor segments and said second end of said second optical fiber is mounted to said sensor segment of said second linear array of sensor segments.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The optical sensor apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising at least one lens, located between said field of view and said first ends of said first optical fiber and said second optical fiber.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. An optical sensor apparatus for effectively reducing a non-active gap, comprising:
<claim-text>a tri-linear optical sensor having a first linear sensor element and a second linear sensor element separated by a first non-active gap having a first width and a third linear sensor element separated from said second linear sensor element by a second non-active gap having a second width;</claim-text>
<claim-text>a first optical fiber having a first end oriented toward a field of view and a second end oriented toward a sensor segment of said first linear sensor element, for directing first image information from said field of view to said sensor segment of said first linear sensor element;</claim-text>
<claim-text>a second optical fiber having a first end oriented toward said field of view and located a first distance, less than said first width, from said first end of said first optical fiber and a second end oriented toward a sensor segment of said second linear sensor element and located a second distance, greater than said first distance, from said second end of said first optical fiber, said second optical fiber directing second image information from said field of view to said sensor segment of said second linear sensor element; and</claim-text>
<claim-text>a third optical fiber having a first end oriented toward said field of view and located a third distance, less than said second width, from said first end of said second optical fiber and a second end oriented toward a sensor segment of said third linear sensor element and located a fourth distance, greater than said third distance, from said second end of said second optical fiber, said third optical fiber directing third image information from said field of view to said sensor segment of said third linear array; thereby providing optical congruence between said field of view and said first, second and third image information without substantial time delay.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The optical sensor apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein said first optical fiber includes a plurality of first optical fibers and said second optical fiber includes a plurality of second optical fibers and said third optical fiber includes a plurality of third optical fibers.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The optical sensor apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein said first ends of said first, second and third optical fibers are arranged in a single column.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The optical sensor apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein said second end of said first optical fiber is mounted to said sensor segment of said first linear sensor element, said second end of said second optical fiber is mounted to said sensor segment of said second linear sensor element and said second end of said third optical fiber is mounted to said sensor segment of said third linear sensor element.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. An apparatus for effectively reducing a non-active gap of an optical sensor, comprising:
<claim-text>a first fiber optic faceplate oriented toward a field of view and configured to accommodate a plurality of optical fibers;</claim-text>
<claim-text>a second fiber optic faceplate oriented toward an optical sensor and configured to accommodate said plurality of optical fibers;</claim-text>
<claim-text>a first optical fiber of said plurality of optical fibers having a first end mounted to said first fiber optic faceplate and a second end mounted to said second fiber optic faceplate; and</claim-text>
<claim-text>a second optical fiber of said plurality of optical fibers having a first end mounted to said first fiber optic faceplate a first distance, less than said non-active gap, from said first optical fiber and said second optical fiber having a second end mounted to said second fiber optic faceplate a second distance, greater than said first distance, from said first optical fiber such that said second end of said first optical fiber and said second end of said second optical fiber are spaced to (a) align with, and (b) direct first and second image information from said field of view to, a first linear array and a second linear array, respectively, of said optical sensor;</claim-text>
<claim-text>wherein said spacing of said second ends of said first and second optical fibers provides optical congruence between said field of view and said first and second image information without substantial time delay.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The apparatus of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein said plurality of optical fibers includes a plurality of said first optical fibers and a plurality of said second optical fibers.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The apparatus of <claim-ref idref="CLM-00019">claim 19</claim-ref>, further comprising a third optical fiber of said plurality of optical fibers having a first end mounted to said first fiber optic faceplate a distance from said first end of said second optical fiber less than said non-active gap, a second end mounted to said second fiber optic faceplate such that said second end of said third optical fiber is located to align with a third linear array of said optical sensor, to direct third image information from said field of view to said third linear array.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The apparatus of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein said first ends of said first, second and third optical fibers are arranged in a single column.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The apparatus of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein said first ends of said first optical fiber and said second optical fiber are mounted normal to a plane formed by said first fiber optic faceplate and said second ends of said first optical fiber and said second optical fiber are mounted normal to a plane formed by said second fiber optic faceplate.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The apparatus of <claim-ref idref="CLM-00019">claim 19</claim-ref>, further comprising said optical sensor mounted to said second fiber optic faceplate.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The apparatus of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein said optical sensor is a tri-linear CCD image sensor.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The apparatus of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein said optical sensor is at least one matrix sensor.</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The apparatus of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein said optical sensor comprises at least one linear array formed on a matrix sensor.</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The apparatus of <claim-ref idref="CLM-00019">claim 19</claim-ref>, further comprising a plurality of color filters used with said plurality of optical fibers so as to separate colors provided to said arrays of said optical sensor.</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. An apparatus for effectively reducing a non-active gap of an optical sensor, comprising:
<claim-text>a first optical fiber and a second optical fiber mounted to each other such that a first end of said first optical fiber and a first end of said second optical fiber are oriented toward a field of view; and</claim-text>
<claim-text>a first spacer mounted between a second end of said first optical fiber and a second end of said second optical fiber for locating said second end of said first optical fiber and said second end of said second optical fiber further apart than said first end of said first optical fiber and said first end of said second optical fiber, to correspond to elements of an optical sensor and to provide optical congruence between said field of view and image information directed from said field of view to said elements via said first and second optical fibers, without substantial time delay.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. The apparatus of <claim-ref idref="CLM-00029">claim 29</claim-ref>, further comprising:
<claim-text>a second spacer; and</claim-text>
<claim-text>a third optical fiber for directing image information from said field of view to said elements of an optical sensor, said third optical fiber having a first end oriented toward said field of view and a second end located such that said second end of said third optical fiber and said second end of said second optical fiber are further apart than said first end of said third optical fiber and said first end of said second optical fiber and to correspond to said elements;</claim-text>
<claim-text>wherein said optical sensor is a tri-linear optical sensor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00031" num="00031">
<claim-text>31. The apparatus of <claim-ref idref="CLM-00030">claim 30</claim-ref>, wherein said first ends of said first second and third optical fibers are arranged in a single column.</claim-text>
</claim>
<claim id="CLM-00032" num="00032">
<claim-text>32. The apparatus of <claim-ref idref="CLM-00029">claim 29</claim-ref>, further comprising a plurality of color filters used with said optical fibers so as to separate colors provided to said elements of said optical sensor.</claim-text>
</claim>
<claim id="CLM-00033" num="00033">
<claim-text>33. The apparatus of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein said optical sensor is a tri-linear CCD image sensor.</claim-text>
</claim>
<claim id="CLM-00034" num="00034">
<claim-text>34. The apparatus of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein said optical sensor is at least one matrix sensor.</claim-text>
</claim>
<claim id="CLM-00035" num="00035">
<claim-text>35. The apparatus of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein said optical sensor comprises at least one linear array formed on a matrix sensor.</claim-text>
</claim>
<claim id="CLM-00036" num="00036">
<claim-text>36. A method of effectively reducing a non-active gap of an optical sensor, comprising the steps of:
<claim-text>providing an optical sensor having a first linear sensor element and a second linear sensor element separated by a first non-active gap having a first width and a third linear sensor element separated from said second linear sensor element by a second non-active gap having a second width;</claim-text>
<claim-text>orienting a first end of a first optical fiber toward a field of view; orienting a second end of said first optical fiber toward said first linear sensor element;</claim-text>
<claim-text>locating a first end of a second optical fiber a first distance, less than said first width, from said first end of said first optical fiber and oriented toward said field of view;</claim-text>
<claim-text>orienting a second end of said second optical fiber toward said second linear sensor element and at a second distance, greater than said first distance, from said second end of said first optical fiber;</claim-text>
<claim-text>locating a first end of a third optical fiber a third distance, less than said second width, from said first end of said second optical fiber and oriented toward said field of view;</claim-text>
<claim-text>orienting a second end of said third optical fiber toward said third linear sensor element and at a fourth distance, greater than said third distance, from said second end of said second optical fiber;</claim-text>
<claim-text>wherein said first, second and third optical fibers direct image information, from said field of view to said first, second and third sensor elements, respectively, thereby providing optical congruence between said field of view and said image information, without substantial time delay.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00037" num="00037">
<claim-text>37. The method of <claim-ref idref="CLM-00036">claim 36</claim-ref>, further comprising the step of providing a plurality of color filters used with said optical fibers so as to separate colors provided to said elements of said optical sensor.</claim-text>
</claim>
<claim id="CLM-00038" num="00038">
<claim-text>38. The method of <claim-ref idref="CLM-00036">claim 36</claim-ref>, wherein said optical sensor is a tri-linear CCD image sensor.</claim-text>
</claim>
<claim id="CLM-00039" num="00039">
<claim-text>39. The method of <claim-ref idref="CLM-00036">claim 36</claim-ref>, wherein said optical sensor is at least one matrix sensor.</claim-text>
</claim>
<claim id="CLM-00040" num="00040">
<claim-text>40. The method of <claim-ref idref="CLM-00036">claim 36</claim-ref>, wherein said optical sensor comprises at least one linear array formed on a matrix sensor.</claim-text>
</claim>
<claim id="CLM-00041" num="00041">
<claim-text>41. The optical sensor apparatus of <claim-ref idref="CLM-00036">claim 36</claim-ref>, wherein said second end of said first optical fiber is mounted to said first linear sensor element, said second end of said second optical fiber is mounted to said second linear sensor element and said second end of said third optical fiber is mounted to said third linear sensor element.</claim-text>
</claim>
<claim id="CLM-00042" num="00042">
<claim-text>42. An apparatus for effectively reducing a non-active gap of an optical sensor, comprising:
<claim-text>means for obtaining optical information from a field of view; and</claim-text>
<claim-text>means for orienting said optical information to at least two linear sensor elements of at least one optical sensor so as to enhance an optical congruence capability of said optical sensor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00043" num="00043">
<claim-text>43. The apparatus of <claim-ref idref="CLM-00042">claim 42</claim-ref>, further comprising means for positioning said means for obtaining in relation to said optical sensor.</claim-text>
</claim>
</claims>
</us-patent-grant>
