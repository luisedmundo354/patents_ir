<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298920-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298920</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10460544</doc-number>
<date>20030611</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1065</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>36</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382290</main-classification>
<further-classification>382289</further-classification>
</classification-national>
<invention-title id="d0e53">Method and device for determining orientation of text</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5557689</doc-number>
<kind>A</kind>
<name>Huttenlocher et al.</name>
<date>19960900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382177</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5594815</doc-number>
<kind>A</kind>
<name>Fast et al.</name>
<date>19970100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382254</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5854853</doc-number>
<kind>A</kind>
<name>Wang</name>
<date>19981200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6490376</doc-number>
<kind>B1</kind>
<name>Au et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6574375</doc-number>
<kind>B1</kind>
<name>Cullen et al.</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>37</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382290</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382173</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382177</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382286</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382288</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382291</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382292</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382289</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>9</number-of-drawing-sheets>
<number-of-figures>9</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20040252911</doc-number>
<kind>A1</kind>
<date>20041216</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Zuniga</last-name>
<first-name>Oscar A.</first-name>
<address>
<city>Fort Collins</city>
<state>CO</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Hewlett-Packard Development Company, L.P.</orgname>
<role>02</role>
<address>
<city>Houston</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Couso</last-name>
<first-name>Yon J.</first-name>
<department>2624</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method of determining the orientation of text is disclosed herein. An embodiment of the method may comprise measuring the contrasts associated with an upper edge of the text relative to a background. A first length of the upper edge of text having contrasts that are at least a first preselected value is measured. In addition to measuring the contrasts associated with the upper edge of the text, contrasts associated with a lower edge of the text are measured relative to the background. A second length of the lower edge of text having contrasts that are at least the first preselected value is then measured. The first length is compared to the second length, wherein the text is improperly oriented if the first length is greater than the second length.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="221.40mm" wi="143.26mm" file="US07298920-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="193.04mm" wi="157.40mm" orientation="landscape" file="US07298920-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="191.09mm" wi="143.43mm" orientation="landscape" file="US07298920-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="192.28mm" wi="141.82mm" orientation="landscape" file="US07298920-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="193.46mm" wi="140.29mm" orientation="landscape" file="US07298920-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="190.75mm" wi="143.51mm" orientation="landscape" file="US07298920-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="223.10mm" wi="146.22mm" file="US07298920-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="217.59mm" wi="143.43mm" file="US07298920-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="216.75mm" wi="139.45mm" file="US07298920-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="217.93mm" wi="139.02mm" file="US07298920-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND</heading>
<p id="p-0002" num="0001">Imaging devices, such as scanning devices and digital cameras, generate machine-readable image data (sometimes referred to simply as image data) representative of an image of an object. The process of generating image data representative of an image of the object is sometimes referred to as scanning the object. One example of an object is a document having text printed thereon. In some scanning devices, the document is set on a platen, and image data is generated by a carriage moving relative to the platen within the scanning device. The carriage has devices that generate image data representative of an image of the object located on the platen. In other scanning devices, the document is placed into an automatic document feeder and then moved past a stationary component, such as a stationary carriage, that scans the document. Digital cameras, on the other hand, generate image data by focusing the image onto a two-dimensional photosensor device that generates image data without the need for moving a carriage.</p>
<p id="p-0003" num="0002">The image data is typically transmitted to a viewing device that replicates the image of the scanned object based on the image data. For example, the viewing device may be a video monitor that processes the image data to display the image of the object. In another example, the viewing device may be a printer that processes the image data to print an image of the object.</p>
<p id="p-0004" num="0003">The viewing device replicates the image of the object as it was scanned. For example, if the document was placed upside down in a scanner, the viewing device will display the replicated image upside down. Likewise, if the document is scanned side ways, it will be replicated on the viewing device side ways. A viewer of the replicated image must then manipulate the image in order to rotate it to the proper orientation. This process is typically time consuming and may be cumbersome to the inexperienced viewer.</p>
<p id="p-0005" num="0004">Furthermore, optical character recognition engines are typically unable to recognize improperly oriented text. Accordingly, the image data generated by an improperly oriented document typically cannot have an optical character recognition engine applied to it.</p>
<heading id="h-0002" level="1">SUMMARY</heading>
<p id="p-0006" num="0005">A method of determining the orientation of text is disclosed herein. An embodiment of the method may comprise measuring the contrasts associated with an upper edge of the text relative to a background. A first length of the upper edge of text having contrasts that are at least a first preselected value is measured. In addition to measuring the contrasts associated with the upper edge of the text, contrasts associated with a lower edge of the text are measured relative to the background. A second length of the lower edge of text having contrasts that are at least the first preselected value is then measured. The first length is compared to the second length, wherein the text is improperly oriented if the first length is greater than the second length.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 1</figref> is an illustration of text displayed on a viewing device.</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 2</figref> is an embodiment of the image displayed on the viewing device of <figref idref="DRAWINGS">FIG. 1</figref> arranged as a plurality of tiles.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 3</figref> is an embodiment of the tiles of <figref idref="DRAWINGS">FIG. 2</figref> sampled using averaging.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 4</figref> is an embodiment of the tiles of <figref idref="DRAWINGS">FIG. 3</figref> after application of an edge detection algorithm.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 5</figref> shows the results of an embodiment of a search routine applied to the tiles of <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 6</figref> is an embodiment of vertically or landscape oriented text.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 7</figref> is an embodiment of sideways-displayed text.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 8</figref> is an embodiment of the tiles of <figref idref="DRAWINGS">FIG. 7</figref> after application of an edge detection algorithm.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 9</figref> shows the results of an embodiment of a search routine applied to the tiles of <figref idref="DRAWINGS">FIG. 8</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0016" num="0015">An illustration of text <b>100</b> displayed on the face <b>102</b> of a viewing device <b>104</b> is shown in <figref idref="DRAWINGS">FIG. 1</figref>. That the viewing device <b>104</b> of <figref idref="DRAWINGS">FIG. 1</figref> is, for illustration purposes, an enlarged, partial view of a conventional viewing device. A typical viewing device may have several long lines of text instead of the one short line of text <b>100</b> shown in <figref idref="DRAWINGS">FIG. 1</figref>. The viewing device <b>104</b> may be any device that produces an image based on machine-readable image data (sometimes referred to herein simply as image data). Examples of imaging devices include video monitors and documents printed by printers.</p>
<p id="p-0017" num="0016">The image data may be stored on a computer-readable medium. Likewise, a computer program that analyzes the image data, as set forth below, to determine the orientation of images represented by the image data may also be stored on a computer-readable medium. The computer-readable medium may include an electronic, magnetic, optical or other physical device or means that can store a computer program and data for use by or in connection with a computer-related system or method. The computer-related system or method may run the program and analyze the image data to determine the proper orientation of an image represented by the image data. The computer-related system or method may also manipulate the image data to properly orient the image as is described in greater detail below.</p>
<p id="p-0018" num="0017">An image is typically displayed on the face <b>102</b> of the viewing device <b>104</b> using a plurality of picture elements or pixels (not shown). A pixel is similar to a dot that may be bright, dark, or multiple levels of gray therebetween. The image data determines the gray scale associated with each pixel depending on a pixel value assigned to each pixel. Therefore, the image data and thus, the pixel values, determine whether pixels are bright, dark, or levels of gray therebetween. When displaying text, a plurality of dark pixels may be combined on a background of bright pixels to generate black text characters displayed on a white background. The pixel values representative of relatively bright pixels may be relatively high numbers, and the pixel values representative of relatively dark pixels may be relatively low numbers. In some imaging systems, bright pixels are representative of relatively low pixel values and dark pixels are representative of relatively high pixel values.</p>
<p id="p-0019" num="0018">In one embodiment, the viewing device <b>104</b> is a video monitor having the text <b>100</b> displayed thereon. In another embodiment, the viewing device <b>104</b> is a piece of paper wherein the text <b>100</b> is printed on the paper by a printer. The image data from which the text <b>100</b> was produced may be generated by many sources. In one embodiment, a document (not shown) having the text <b>100</b> printed thereon is scanned by a scanner. The scanner generates the image data representative of the text, which may be replicated by the viewing device <b>104</b> to display the text <b>100</b>. In another embodiment, a digital camera (not shown) generates the image data.</p>
<p id="p-0020" num="0019">For orientation purposes, four directions and two axes are used as references for the viewing device <b>104</b> and for images displayed thereon. An X axis extends along an edge of the viewing device <b>104</b>. For example, if the viewing device <b>104</b> is a video monitor, the X axis may extend parallel to the lower edge of the video monitor. A Y axis extends substantially perpendicular to the X axis. In the aforementioned example of the viewing device <b>104</b> being a video monitor, the Y axis may extend parallel to the left edge of the video monitor. The aforementioned directions are along the X axis and the Y axis and are referred to as positive and negative directions along both the Y axis and the X axis as shown in <figref idref="DRAWINGS">FIG. 1</figref>. In the embodiment of the viewing device <b>104</b> described herein, properly oriented text extends parallel to the X axis and in the positive X direction.</p>
<p id="p-0021" num="0020">Having described the text <b>100</b> and the viewing device <b>104</b>, an embodiment of the process of determining the proper orientation of the text <b>100</b> will now be described. As described above, the process may be accomplished using a computer (not shown), wherein the computer processes image data representative of the text <b>104</b>, <figref idref="DRAWINGS">FIG. 1</figref>. It should be noted that the text <b>100</b> shown in <figref idref="DRAWINGS">FIG. 1</figref> is properly oriented. Examples of improperly oriented text are provided further below.</p>
<p id="p-0022" num="0021">For reference purposes, the text <b>100</b> is described as having three reference lines. The reference lines are referred to as the upper line <b>110</b>, the middle line <b>112</b> and the lower line <b>114</b>. The upper line <b>110</b> contacts the upper edge of the text <b>100</b>. More specifically, the upper line <b>110</b> contacts the top edges of upper-case characters and the top edges of some longer lower-case characters. The lower line <b>114</b> contacts the lower edges of the upper-case characters in addition to the lower edges of most lower-case characters. The lower edge of the characters associated with the lower line <b>114</b> is sometimes referred to as the baseline. The middle line <b>112</b> extends between the upper line <b>110</b> and the lower line <b>114</b>. Accordingly, the middle line <b>112</b> bisects most upper-case characters and contacts the top edges of many lower-case letters.</p>
<p id="p-0023" num="0022">Portions of the characters that extend above the middle line <b>112</b> are sometimes referred to as ascenders and portions of the characters extending below the lower line <b>114</b> are sometimes referred to as descenders. Both the ascenders and the descenders contribute to noise that decreases the contrasts in the proximity of the ascenders and the descenders relative to the background. Text typically has more ascenders than descenders. Therefore, the contrasts associated with the text <b>100</b> in the proximity of the lower line <b>114</b> is typically higher and more well-defined than the contrasts associated with the upper line <b>110</b> and the middle line <b>112</b>.</p>
<p id="p-0024" num="0023">Furthermore, the contrasts in the proximity of the lower line <b>114</b> are more consistent than the contrasts in the proximity of the upper line <b>110</b>. The contrasts tend to be higher and more consistent because of the few descenders proximate the lower line <b>114</b>. These contrasts yield a well-defined bright/dark transition along the lower line <b>114</b> relative to the background, and this transition causes relatively high and consistent contrasts. The contrasts associated with the upper line <b>110</b> and the middle line <b>112</b>, on the other hand, tend to be lower and less consistent because of the large number of characters that have ascenders. This inconsistency results in less defined transitions between the upper edges of the characters and the background and results in less consistent and lower contrasts.</p>
<p id="p-0025" num="0024">The process for determining the orientation of the text <b>100</b> relative to the X axis, in summary, compares the contrasts associated with the upper edges of the characters with the contrasts associated with the lower edges of the characters. The analysis forms lines of high constrasts along portions of the text <b>100</b> that correspond to the top and bottom of the text <b>100</b>. If longer lines of high contrasts are located in the proximity of lower portions of the text <b>100</b> than the upper portions of the text <b>100</b>, then the text <b>100</b> is properly oriented. On the other hand, if longer lines of high contrasts are located in the proximity of the upper portions of the text <b>100</b> than the lower portions of the text <b>100</b>, then the text <b>100</b> is upside down.</p>
<p id="p-0026" num="0025">An embodiment of the above-described analysis may be applied to the image data to determine if the text represented by the image data is oriented in a landscape or portrait orientation. In summary, the image data is analyzed as though the text <b>100</b> is oriented along the X axis. If the analysis creates a plurality of small segments of high contrasts, the text is likely misoriented. The analysis may continue as though the text extends along the Y axis. If this second analysis creates longer lines of high contrasts, the text is more likely misoriented. An algorithm may be applied to the image data in order to correct the orientation.</p>
<p id="p-0027" num="0026">Having summarily described the process of determining the orientation of text, the process will now be described in greater detail. The following description describes determining if the text is upside down followed by a description of determining whether the text is oriented as landscape instead of portrait. The face <b>102</b> of the viewing device <b>104</b> may be divided into an array <b>115</b> as shown in <figref idref="DRAWINGS">FIG. 2</figref>. It should be noted that the face <b>102</b> of the viewing device <b>104</b> is shown as being divided into the array <b>115</b>, which is for illustration purposes only. In reality, the image data representative of images displayed on the face <b>102</b> of the imaging device <b>104</b> is processed based on the array <b>115</b>. As described below, the text <b>100</b> of <figref idref="DRAWINGS">FIG. 2</figref> has been elongated in order to better illustrate the array <b>115</b>. The array <b>115</b> has a plurality of tiles <b>116</b> or pixel groupings. The tiles <b>116</b> are arranged to form a plurality of columns <b>118</b> extending parallel to the Y axis and a plurality of rows <b>120</b> extending parallel to the X axis. The columns <b>118</b> and the rows <b>120</b> are sometimes referred to as the first and second pluralities of pixel groupings, respectively or visa versa.</p>
<p id="p-0028" num="0027">In the non-limiting embodiment described herein, the tiles <b>116</b> are rectangular and have approximately sixty-four pixels extending parallel to the X axis and four pixels extending parallel to the Y axis. Accordingly, each tile represents sixty-four pixel values extending parallel to the X axis and four pixel values extending parallel to the Y axis. The length to which a tile extends parallel to the Y axis is referred to as the height of the tile and the length to which a tile extends parallel to the X axis is referred to as the width of the tile. The heights of the tiles <b>116</b> in such an embodiment are one-sixteenth the widths of the tiles <b>116</b>. In order to illustrate such short tiles <b>116</b>, the text <b>100</b> has been elongated, which has caused the tiles <b>116</b> to be elongated for better illustration. Tile sizes other than those described herein may be generated depending on the image data and the image that is represented by the image data. For example, in one embodiment, the tiles have heights of eight pixels and widths of sixty four pixels.</p>
<p id="p-0029" num="0028">The use of tiles <b>116</b> being sixty-four pixel values wide is an example of an embodiment used to determine the proper orientation of certain types of text. The following example is based on determining the orientation of text having a pitch of approximately ten characters per inch. The following example is further based on the image data representative of the text being generated using a sampling rate or precision of three-hundred dots per inch (dpi) or pixel values per inch. Based on the tile sizes, each tile <b>116</b>, on average, contains horizontal portions of 2.2 characters. Therefore, the probability is high that adjacent tiles <b>116</b> extending parallel to the X axis and through a sentence or word will contain at least one portion of a text character. These adjacent tiles <b>116</b> may be analyzed to determine the proper orientation of the text <b>100</b> as described in greater detail below. The number of pixel values constituting each of the tiles <b>116</b> may be set for a specific purpose and for a specific sampling rate. For example, if the image data is generated at a sampling rate of six-hundred dpi, the tiles <b>116</b> may have one-hundred twenty-eight pixel values extending along the X axis to yield an average of 2.2 horizontal portions of characters per tile.</p>
<p id="p-0030" num="0029">The array <b>115</b> of tiles <b>116</b> forms a Cartesian coordinate system wherein the columns <b>118</b> are referenced as columns X<b>1</b> to X<b>6</b>, and the rows <b>120</b> are referenced as rows Y<b>1</b> to Y<b>16</b>. The locations of the pixels that generate the text <b>106</b> are known by the aforementioned computer or the like that determines whether the orientation is correct. Accordingly, the tile to which each pixel value representative of each pixel is known and may be analyzed to determine the proper orientation as described in further detail below.</p>
<p id="p-0031" num="0030">The tiles <b>116</b> are then down-sampled. More specifically, the pixel values constituting the tiles <b>116</b> are down-sampled. Down-sampling reduces the number of pixel values represented by a tile. The processes of creating the array of columns <b>118</b> and sampling the tiles <b>118</b> may constitute down-sampling. In the example of the tiles <b>116</b> being sixty-four pixel values wide and four pixel values high, the two-hundred fifty-six pixel values in each tile may be represented by a single pixel value. In the non-limiting embodiment described herein, the pixel values are represented by the average pixel value. The same sampling procedure may be applied to the example of the tiles being sixty-four pixel values wide and eight pixel values high wherein the five-hundred twelve values in each tile may be represented by a single pixel value that is the average of the five-hundred twelve pixel values. In the non-limiting embodiment described above, the average pixel value will vary between zero for a very dark tile and two-hundred fifty-five for a very bright tile. Sampling techniques other than averaging may be applied to the tiles <b>116</b> as described in greater detail below.</p>
<p id="p-0032" num="0031">Down-sampling causes the loss of some data. In the examples of the above-described rectangular tiles <b>116</b>, the tiles <b>116</b> have widths that are greater than their heights. Therefore, more data is retained regarding the pixel values extending along the heights or parallel to the Y axis than is retained regarding pixel values extending along the widths or parallel to the X axis. Accordingly, small increments in pixel values along the Y axis may be analyzed to accurately detect changes in the contrasts of the image represented by the image data. Other embodiments of the methods described herein may detect small changes in the contrasts along the X axis. These changes in contrast are used to determine orientation of the text as described in greater detail below.</p>
<p id="p-0033" num="0032">An example of the average pixel values associated with the text <b>100</b> is shown in <figref idref="DRAWINGS">FIG. 3</figref>. The numbers in the tiles <b>116</b> of <figref idref="DRAWINGS">FIG. 3</figref> represent the average pixel values in each of the tiles <b>116</b>. Thus, a tile of <figref idref="DRAWINGS">FIG. 3</figref> that has a large number means that its corresponding tile in <figref idref="DRAWINGS">FIG. 2</figref> includes few, if any, portions the text <b>100</b>. A tile of <figref idref="DRAWINGS">FIG. 3</figref> that has a low number, on the other hand, means that its corresponding tile in <figref idref="DRAWINGS">FIG. 2</figref> includes many portions of the text <b>100</b>. The background tiles have average pixel values of two-hundred fifty, which is for illustration purposes. The background may vary slightly, but the variation would have little, if any, affect on the determination of proper orientation of the text <b>100</b>.</p>
<p id="p-0034" num="0033">An edge detection algorithm is applied to the down-sampled array of <figref idref="DRAWINGS">FIG. 3</figref> along an axis to detect bright/dark transitions along the axis. The edge detection algorithm, in summary, is used to detect portions of the text that have high contrasts relative to the background. The embodiment of the edge detection algorithm described herein calculates the differences between sampled values of the tiles <b>116</b> along the axis to which it is applied. In order to detect upper and lower edges of text, the edge detection algorithm may be applied in a first direction followed by an opposite second direction. In the example described herein, the edge detection algorithm is applied in the Y direction. Accordingly, differences are calculated in the Y direction and bright/dark transitions in the columns <b>118</b> along the Y axis are detected.</p>
<p id="p-0035" num="0034">In the example described herein, the edge detection algorithm detects the lower edges of the text characters. In a separate process, the upper edges of the text characters are detected using an edge detection algorithm. As described above, properly oriented text will have higher and more consistent contrasts along the lower edges of the characters relative to the background than along the upper edges of the characters. Accordingly, if the text is properly oriented, the edge detection algorithm applied to the lower edges of the characters will detect higher and more consistent contrasts than the algorithm applied to the upper edges of the characters.</p>
<p id="p-0036" num="0035">An example of an edge detection algorithm to detect the lower edges of characters is achieved by application of a minus one over one kernel. The minus one over one kernel outputs high values when high dark to bright contrasts exist between adjacent values when applied in the negative Y direction. Accordingly, the minus one over one kernel outputs high numbers when applied to the lower edges of the text <b>100</b>. An example of an algorithm to detect the upper edges of characters is achieved by application of a one over minus one kernel. The one over minus one kernel functions opposite the minus one over one kernel and outputs high numbers when applied to dark to bright transitions in the positive Y direction. Accordingly, the one over minus one kernel outputs high numbers when applied to the top edges of the text <b>100</b>.</p>
<p id="p-0037" num="0036">In another embodiment, the minus one over one kernel is applied to the sampled data in the negative Y direction. The minus one over one kernel will output large positive numbers when dark to bright transitions are located, which are indicative of the lower edges of text characters. In addition, the minus one over one kernel outputs large negative numbers when bright to dark transitions are located. The large negative numbers are indicative of the upper edges of text characters.</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 4</figref> shows the results of a minus one over one kernel applied to the array <b>115</b> of <figref idref="DRAWINGS">FIG. 3</figref>. The results are illustrated as an array <b>128</b> consisting of a plurality of tiles <b>130</b> that contain the results of the minus one over one kernel. Large positive numbers are indicative of dark to bright transitions located when the minus one over one kernel is applied to the text <b>100</b> in the negative Y direction. Accordingly, the large positive numbers are indicative of detections of the lower edges of the text <b>100</b>. Large negative numbers are indicative of bright to dark transitions located when the minus one over one kernel is applied to the text <b>100</b> in the negative Y direction. Accordingly, the large negative numbers are indicative of detections of the upper edges of the text <b>100</b>.</p>
<p id="p-0039" num="0038">The analysis to determine the proper orientation of the text <b>100</b> continues by searching the array <b>128</b> of <figref idref="DRAWINGS">FIG. 4</figref> for strings of large positive and negative differences. The positive differences locate the lower edges of the text <b>100</b> and the negative differences locate the upper edges of the text <b>100</b>. The detection of long strings of large positive differences are indicative of properly oriented text. Likewise, the detection of long strings of large negative differences is indicative of text that is oriented upside down. The terms “long” and “short” as used herein are relative. For example, a histogram of the lengths of strings of negative and positive differences may be created. The mean length of the strings of negative differences may be compared to the mean length of the strings of positive differences. The longer mean may be considered to be “long” and the shorter mean may be considered to be “short.”</p>
<p id="p-0040" num="0039">In the present example, the text <b>100</b> is properly oriented. Therefore, the string of positive differences will be larger than the string of negative numbers. In other words, the edge contrasts at the lower line <b>114</b>, <figref idref="DRAWINGS">FIG. 1</figref>, are greater and more consistent than the edge contrasts at the upper line <b>110</b> or the middle line <b>112</b>. Had the text <b>100</b> been upside down, the aforementioned detections would have detected longer strings of negative differences than positive differences.</p>
<p id="p-0041" num="0040">Searching for the strings of differences may commence with searching for a difference that exceeds a first preselected value. This difference is sometimes referred to as the first difference. The search for the first difference may commence at one edge of the array <b>128</b> and continue in a raster-type scan parallel to the Y axis. The search in the non-limiting embodiment described herein commences in the column X<b>1</b> and scans the rows between row Y<b>1</b> and row Y<b>16</b>. The first difference corresponds to a bright to dark transition that exceeds a contrast corresponding to the first preselected value.</p>
<p id="p-0042" num="0041">After the first difference is located, a search is conducted for a second difference located in a column that is adjacent the column of the first difference. The search for the second difference is performed to locate a bright to dark transition that is adjacent the bright to dark transition associated with the first difference. For example, the second difference may be representative of lower edges of characters that are adjacent the lower edges of characters corresponding to the first difference. The second difference may be a difference that exceeds a second preselected value. In addition, the second difference is adjacent or close to the first difference and is located in a column that is adjacent or close to the column containing the first difference. Subsequent differences are located in the same manner that the second difference is located.</p>
<p id="p-0043" num="0042">With reference to the array <b>128</b> of <figref idref="DRAWINGS">FIG. 4</figref>, the search may locate a first difference that has a value of at least a first preselected value of one-hundred. In the search technique described above, the difference of one-hundred twenty-five located at column X<b>1</b>, row Y<b>5</b> will be located and identified as the first difference. As shown in <figref idref="DRAWINGS">FIG. 4</figref>, the above-described search locates differences that correspond to the lower edges of the characters ‘A’ and ‘b’.</p>
<p id="p-0044" num="0043">With reference to the above-described embodiment, the second difference corresponds to edges of characters in a tile that is next to the tile containing the lower edges of the characters ‘A’ and ‘b’. Further to the above-described embodiment, the second difference is a difference that is adjacent the first difference and is located in a column adjacent the column containing the first difference. The second difference in the present embodiment is the greatest difference that meets the aforementioned criteria and exceeds a second preselected value. In the following example, the second preselected value is seventy-five. The difference meeting the above criteria has the value of one-hundred twenty-five and is located at column X<b>2</b>, row Y<b>5</b>. One embodiment for searching the second and subsequent differences has been described above; however, other embodiments may be used, and some of these embodiments are described in greater detail further below.</p>
<p id="p-0045" num="0044">The second and subsequent differences may exceed second preselected values that are smaller than the first preselected value. These differences reduce the probability that a string of differences commences on noise. By setting the first preselected value high, the process significantly reduces the probability that the first difference will be caused by noise. Therefore, it is much more likely that the string of differences is caused by the edge of characters as described herein.</p>
<p id="p-0046" num="0045">As set forth above, pursuant to the present embodiment, the second difference is located at the tile located at column X<b>2</b>, row Y<b>5</b>. More specifically, as shown in <figref idref="DRAWINGS">FIG. 4</figref>, the first difference was located in column X<b>1</b>; accordingly, the second difference must be located in column X<b>2</b>. The differences adjacent the first difference are column X<b>2</b>, rows Y<b>4</b>, Y<b>5</b>, and Y<b>6</b>. Only the difference of one-hundred twenty-five located at the tile in column X<b>2</b>, row Y<b>5</b> meets the second preselected value of seventy-five. If other adjacent tiles <b>130</b> met or exceeded the second preselected value, the tile having the greatest difference would be selected as the second difference.</p>
<p id="p-0047" num="0046">As set forth above, subsequent differences are located in the same manner that the second difference was located. For example, a third difference of ninety is located at column X<b>3</b>, row Y<b>5</b>, a fourth difference of one-hundred ten is located at column X<b>4</b>, row Y<b>5</b>, a fifth difference is located at column X<b>5</b>, row Y<b>5</b>, and a sixth difference is located at column X<b>6</b>, row Y<b>5</b>. In the present embodiment differences are continually located until one of the aforementioned criteria cannot be achieved. In one embodiment, differences subsequent to the first difference may be located in both directions along the X axis rather than the one direction described in the above example.</p>
<p id="p-0048" num="0047">A string of differences meeting the above-described search criteria is created and its length is measured. Referring again to the example provided herein, a string of differences meeting the above-described difference criteria are shown by a line <b>134</b> in <figref idref="DRAWINGS">FIG. 5</figref>. Markers are placed in the tiles <b>128</b> that meet the above-described search criteria. As shown in <figref idref="DRAWINGS">FIG. 5</figref>, the line <b>134</b> has a length of six tiles and would likely be longer had more characters been illustrated in the example.</p>
<p id="p-0049" num="0048">A second string of differences corresponding to the upper edges of the text <b>100</b> will also be created and measured. The second string of differences will be compared to the first string of differences to determine whether the text <b>100</b>, <figref idref="DRAWINGS">FIG. 1</figref>, is properly oriented. If the second string of differences is longer than the first string of differences, then the text <b>100</b>, <figref idref="DRAWINGS">FIG. 1</figref>, is upside down. Likewise, if the second string of differences is shorter than the first string of differences, the text <b>100</b> is properly oriented. If the text <b>100</b> is upside down, an algorithm may be applied to the image data to rotate the image data one-hundred eighty degrees. In the example provided herein, the text <b>100</b> is properly oriented, so the first string of differences will be longer than the second string of differences.</p>
<p id="p-0050" num="0049">In the non-limiting example described herein, the top edge of the text <b>100</b> is detected by application of the minus one over one kernel. As described above, the minus one over one kernel outputs high negative numbers upon the detection of the upper edges of text. The output of the kernel is shown in <figref idref="DRAWINGS">FIG. 4</figref>, wherein the differences associated with the top edges of the text <b>100</b> are relatively large negative numbers.</p>
<p id="p-0051" num="0050">The process of detecting the upper edges of the text <b>100</b> is similar to the process of detecting the lower edges of the text <b>100</b>. A first negative difference that is less than a third preselected value is located. In the non-limiting example described herein, the third preselected value is the negative of the first preselected value. Accordingly, the third preselected value in this example is negative one-hundred. Likewise, second and subsequent negative differences are located that are less than a fourth preselected value. In the non-limiting embodiment described herein, the fourth difference is the negative of the second preselected value, which is negative seventy-five. When these values are located, a second string or strings of differences are measured as was described above.</p>
<p id="p-0052" num="0051">Because the text <b>100</b> is properly oriented in the example provided herein, the upper edges of the text <b>100</b> have lower and less consistent contrasts than the upper edges of the text. These lower and less consistent contrasts are indicative of the lower values of the differences shown in <figref idref="DRAWINGS">FIG. 4</figref>. The only difference less than the fourth preselected value is negative one-hundred forty and is located in the tile at column X<b>4</b>, row Y<b>12</b>. There is no difference in column X<b>5</b> that is less than the negative second preselected value. Additionally, there are no other differences less than the negative of the first preselected value. Thus, the string of differences associated with the upper edges of the text <b>100</b> is much smaller than the above-described string of differences associated with the lower edges of the text <b>100</b>.</p>
<p id="p-0053" num="0052">The string of differences associated with the upper edges of the text <b>100</b> is shown in <figref idref="DRAWINGS">FIG. 5</figref>. As shown and described above, the string of differences consists of a single tile at row X<b>4</b>, column Y<b>12</b>. Accordingly, the string of differences associated with the lower edges of the text <b>100</b> (represented by the line <b>134</b>) is longer than the string of differences associated with the upper edges of the text <b>100</b>. Therefore, the text <b>100</b> is oriented properly. Had the string of differences associated with the upper edges of the text <b>100</b> being longer than the string of differences associated with the lower edges of the text <b>100</b>, the text would be upside down. In such a situation, an algorithm may be applied to the text to rotate the text one-hundred eighty degrees.</p>
<p id="p-0054" num="0053">In most circumstances, a document has many more lines of text than the text <b>100</b> shown in <figref idref="DRAWINGS">FIG. 1</figref>. There are typically several lines of text that are substantially longer than the line of text <b>100</b> shown in <figref idref="DRAWINGS">FIG. 1</figref>. Therefore, when a typical document is analyzed, there may be a plurality of strings of differences that are to be analyzed. In such a situation, the mean length of strings of differences associated with the upper edges of text may be compared to the mean length of strings of differences associated with lower edges of text. If the mean length associated with the upper edges is shorter than the mean length associated with the lower edges, the text is most likely properly oriented. It should be noted that other analysis methods may be applied to the plurality of strings of differences.</p>
<p id="p-0055" num="0054">Having described embodiments to determine whether text is upside down, embodiments will now be described to determine whether text is sideways or perpendicular to the X axis of <figref idref="DRAWINGS">FIG. 1</figref>. Sideways text is sometime referred to as being vertically oriented or having a landscape orientation.</p>
<p id="p-0056" num="0055">An example of vertically or landscape oriented text <b>150</b> is shown in <figref idref="DRAWINGS">FIG. 6</figref>. In summary, the analysis described above is applied to the image data to generate the strings of differences. The analysis is then performed orthogonal to the previous analysis. The differences are analyzed to determine which direction yields the longest strings, among other criteria. A rotation algorithm may then be applied to the image data to properly orient the text.</p>
<p id="p-0057" num="0056">Having summarily described embodiments of detecting vertically oriented text, the embodiments will now be described in greater detail. In order to better illustrate the methods for determining orientation of the text <b>150</b>, it has been extended along the X axis in the same manner that the text <b>100</b> of <figref idref="DRAWINGS">FIG. 2</figref> was extended along the Y axis. For convenience, the same text used in the example of <figref idref="DRAWINGS">FIG. 2</figref> has been used as the text <b>150</b> in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0058" num="0057">An array <b>154</b> may be generated by a plurality of tiles <b>156</b> in a manner similar to the array <b>115</b> of <figref idref="DRAWINGS">FIG. 2</figref>. In order to illustrate the vertical text <b>150</b>, the array <b>154</b> extends in the Y direction to form a plurality of rows <b>158</b> referenced as row Y<b>1</b> to row Y<b>24</b>. The array <b>154</b> forms a plurality of columns <b>160</b> referenced as column X<b>1</b> to column X<b>4</b>. The pixel values of the tiles <b>156</b> are sampled in a similar manner as the pixel values of the tiles <b>116</b> in the array <b>115</b> of <figref idref="DRAWINGS">FIG. 3</figref>. For example, the average pixel value of each of the tiles <b>156</b> may be calculated.</p>
<p id="p-0059" num="0058">Differences between adjacent sampled values of the tiles <b>156</b> is calculated in the Y direction as described above. Strings of differences extending along the X direction are then located and analyzed. For example, the lengths of the strings of differences may be measured as described above. The strings of differences will only extend for lengths equal to the height of the text <b>150</b>. Then the strings will be terminated by the spacing between lines of text. Accordingly, when the above-described analysis is applied to the vertically oriented text <b>150</b>, the result is a plurality of very short strings of differences. These strings of differences may be compared to the strings of differences generated by the analysis described below.</p>
<p id="p-0060" num="0059">Referring to <figref idref="DRAWINGS">FIG. 7</figref>, the analysis continues by generating tiles that are orthogonal to the tiles <b>156</b> in the array <b>154</b> of <figref idref="DRAWINGS">FIG. 6</figref>. An array <b>162</b> is generated comprising a plurality of tiles <b>164</b>. Unlike the above-described tiles, the tiles <b>164</b> of the array <b>162</b> extend in the Y direction further than the X direction. For example, the tiles <b>164</b> may have heights of sixty-four pixels and widths of four pixels. In one embodiment, the heights of the tiles <b>164</b> are the same as the widths of the tiles <b>116</b> of <figref idref="DRAWINGS">FIG. 2</figref>. Likewise, in this embodiment, the widths of the tiles <b>164</b> are the same as the heights of the tiles <b>116</b> of <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0061" num="0060">After the tiles <b>164</b> have been generated, the pixel values located therein are sampled. The text <b>150</b> of <figref idref="DRAWINGS">FIG. 7</figref> is the same as the text <b>100</b> of <figref idref="DRAWINGS">FIG. 2</figref>, therefore, the average pixel values of the tiles <b>164</b> correspond to the average pixel values of the tiles <b>116</b> of <figref idref="DRAWINGS">FIG. 3</figref>. For example, the average pixel values in the tiles of column X<b>5</b> of <figref idref="DRAWINGS">FIG. 7</figref> correspond to the average pixel values of the row Y<b>5</b> of <figref idref="DRAWINGS">FIG. 3</figref>. Due to illustration constraints, not all the average pixel values have are able to be included in the array <b>162</b> of <figref idref="DRAWINGS">FIG. 7</figref>. However, the more relevant average pixel values along the edge of the text <b>150</b> have been included in the array <b>162</b>. The tiles having no portions of the text <b>150</b> are deemed to have an average pixel value of two-hundred fifty.</p>
<p id="p-0062" num="0061">An edge detection algorithm similar to the ones described above is applied to the image data in the X direction to detect the edges of the text. In the embodiment described herein, the edge detection algorithm is applied by calculating differences between average pixel values in rows <b>158</b> parallel to the X axis rather than in columns <b>160</b> parallel to the Y axis as was described above. The application of the edge detection algorithm will yield large positive numbers upon detection of dark to bright transitions and large negative numbers upon the detection of bright to dark transitions when applied in the positive X direction. Thus, the edges of the text <b>150</b> facing the negative X direction will be represented by large positive numbers.</p>
<p id="p-0063" num="0062">The results of the application of an edge detection algorithm applied to the array <b>162</b> of <figref idref="DRAWINGS">FIG. 7</figref> are shown in an array <b>170</b> <figref idref="DRAWINGS">FIG. 8</figref>, which is made of a plurality of tiles <b>172</b>. Due to illustration constraints only the differences along the edges of the text <b>150</b> have been shown in <figref idref="DRAWINGS">FIG. 8</figref>. Two strings of differences are calculated as described above. One string is based on positive differences and the other string is based on negative differences. These two string extend parallel to the Y axis rather than parallel to the X axis as described in the previous embodiment.</p>
<p id="p-0064" num="0063">The two strings of differences are shown in <figref idref="DRAWINGS">FIG. 9</figref>. The string of positive differences is represented by a line <b>174</b>. The negative differences only extend one tile at column X<b>12</b> row Y<b>3</b>. Accordingly, the longer string of differences is positive and correspond to the lower edges of the text <b>150</b>, <figref idref="DRAWINGS">FIG. 7</figref>, which faces the negative X direction. Therefore, the text <b>150</b> is oriented so that it extends in the negative Y direction and must be rotated ninety degrees counterclockwise to be properly oriented. If, on the other hand, the longer string of differences faced the positive X direction relative to the text <b>150</b>, <figref idref="DRAWINGS">FIG. 7</figref>, the text <b>150</b> would extend in the positive Y direction. The text <b>150</b> would need to be rotated ninety degrees clockwise to be properly oriented.</p>
<p id="p-0065" num="0064">Having described some embodiments of the orientation methods, other embodiments will now be described.</p>
<p id="p-0066" num="0065">Referring to the application of the edge detection algorithms, in some situations, a difference exceeding the first preselected value may not exist. In such situations, the image may not contain a contrast that exceeds the first preselected value. Therefore, the first preselected value may be lowered to accommodate the features of the image. The same may apply to the second preselected value.</p>
<p id="p-0067" num="0066">In the non-limiting embodiment described herein, the second preselected value is less than the first preselected value. The preselected values are minimal differences that are searched. Thus, the greater first preselected value assures that an edge of a character, and not noise, is initially located. The use of the lower second preselected value enables the searching to locate character edges that may not be as sharp as the ones resulting in the aforementioned first difference. Therefore, a continuous string of differences may be located even though some of the differences do not represent contrasts that are as sharp as the first difference. In another embodiment, the first and second preselected values are the same.</p>
<p id="p-0068" num="0067">The search for the second and subsequent differences may proceed in a first direction and a second direction that is opposite the first direction. For example, with reference to <figref idref="DRAWINGS">FIG. 4</figref>, after the first difference is located, second and subsequent differences may be located in both the positive and negative X directions. Therefore, if a contrast meeting the criteria of the first difference is located in the middle of a line of text, a string of differences as long as the whole line of text may be located.</p>
<p id="p-0069" num="0068">In one embodiment, strings of differences that are unusually long are not analyzed. For example, if the strings of differences have an average length of one-thousand pixel values and one string of differences has a length of one-thousand five-hundred pixel values, the longer string of differences may be discarded. The long string of differences may be due to features other than text. For example, the long string of differences may be due to an extraneous line or other printed material on the document. Such objects typically should not be analyzed to determine the proper orientation of text.</p>
<p id="p-0070" num="0069">In another embodiment, the user is prompted as to whether the image contains text. For example during a scanning process, the user may be prompted as to whether the image is a text document. If the image is a text document, the analysis to determine proper orientation of the text may be commenced.</p>
<p id="p-0071" num="0070">Other embodiments exist for down-sampling the image data. In the example described above, sampling was achieved by calculating the average pixel value of the tiles <b>116</b>, <figref idref="DRAWINGS">FIG. 2</figref>. In other embodiments, sampling is achieved by bilinear sampling, bicubic sampling, and weighted averaging. In yet another embodiment, the image data has a low-pass filter or convolution applied to it prior to down sampling. The filtering serves to attenuate extraneous data so as to lessen its affect on the orientation analysis.</p>
<p id="p-0072" num="0071">Referring again to <figref idref="DRAWINGS">FIG. 4</figref>, in some situations, a column may not have a difference that meets the aforementioned second preselected values. For example, the text may have punctuation or spaces that result in their tiles <b>118</b>, <figref idref="DRAWINGS">FIG. 3</figref>, having low values. Accordingly, the differences associated with these low tile values will be small, which may cause a string of differences to terminate before it should. In such situations, the second preselected value may be lowered or eliminated during a search of one or more columns. This lowered second preselected value enables a line to be generated through portions of the image where the bright/dark transitions are relatively subtle.</p>
<p id="p-0073" num="0072">In a similar situation, a difference that meets the aforementioned first preselected value may not exist. In this situation, the first preselected value may be lowered to a point where the first difference may be located. If the first preselected value has to be lowered a great amount, the analysis may conclude that analysis of the text orientation is not prudent.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of determining the orientation of text, said text extending substantially horizontal, said method comprising:
<claim-text>measuring the contrasts associated with an upper edge of said text relative to a background;</claim-text>
<claim-text>measuring a first length of said upper edge of text having contrasts that are at least a first preselected value;</claim-text>
<claim-text>measuring the contrasts associated with a lower edge of said text relative to said background;</claim-text>
<claim-text>measuring a second length of said lower edge of text having contrasts that are at least said first preselected value; and</claim-text>
<claim-text>comparing said first length to said second length, wherein said text is improperly oriented if said first length is greater than said second length.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> and further comprising rotating said text one-hundred eighty degrees if said first length is greater than said second length.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said measuring a first length comprises:
<claim-text>locating a first portion of said text having a contrast that exceeds a first preselected value; and</claim-text>
<claim-text>locating subsequent portions of said text having contrasts that exceed a second preselected value;</claim-text>
<claim-text>said first length being the distance between said first portion of said text and one of said subsequent portions of said text.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein said first preselected value is greater than said second preselected value.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein said first length is the longest distance between any of the portions of said text.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said measuring a second length comprises:
<claim-text>locating a first portion of said text having a contrast that exceeds a first preselected value; and</claim-text>
<claim-text>locating subsequent portions of said text having contrasts that exceed a second preselected value;</claim-text>
<claim-text>said second length being the distance between said first portion of said text and one of said subsequent portions of said text.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein said second length is the longest distance between any of the portions of said text.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where said first length and said second length are compared to a third preselected value, and wherein said text is rotated ninety degrees if said first length and said second length are less than said third preselected value.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A method of determining the orientation of a text relative to a first axis, said method comprising:
<claim-text>measuring first contrasts relative to a background of at least one first edge of said text parallel to said first axis;</claim-text>
<claim-text>measuring at least one first length of said at least one first edge of text having contrasts that are at least a first preselected value;</claim-text>
<claim-text>measuring second contrasts relative to said background of at least one second edge of said text parallel to said first axis, said second edge being opposite said first edge;</claim-text>
<claim-text>measuring at least one second length of said at least one second edge of text having contrasts that are at least a second preselected value;</claim-text>
<claim-text>measuring third contrasts relative to said background of at least one second edge of said text parallel to a second axis, said second axis being perpendicular to said first axis;</claim-text>
<claim-text>measuring at least one third length of said at least one second edge of text having contrasts that are at least a third preselected value;</claim-text>
<claim-text>measuring fourth contrasts relative to said background of at least one fourth edge of said text parallel to said second axis, said fourth edge being opposite said third edge; and</claim-text>
<claim-text>measuring at least one fourth length of said at least one second edge of text having contrasts that are at least a fourth preselected value;</claim-text>
<claim-text>wherein the longer of either said first length, said second length, said third length, or said fourth length corresponds to the lower edge of said text.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein said first axis is horizontal, wherein said at least one first edge of said text is the lower edge of said text relative to said first axis, and wherein said at least one third edge of text is the left edge of said text relative to said second axis.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, and further comprising:
<claim-text>rotating said text one-hundred eighty degrees if said second length is the longest length;</claim-text>
<claim-text>rotating said text ninety degrees counterclockwise if said third length is the longest length; and</claim-text>
<claim-text>rotating said text ninety degrees clockwise if said fourth length is the longest length.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein said measuring comprises:
<claim-text>locating a first portion of said text having at least one contrast that exceed a first preselected value; and</claim-text>
<claim-text>locating subsequent portions of said text having contrasts that exceed a preselected value that is lower than said first preselected value;</claim-text>
<claim-text>the corresponding length being the distance between said first portion of said text and one of said subsequent portions of said text.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein said first preselected value, said second preselected value, said third preselected value, and said fourth preselected value are equal.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A method of determining the orientation of text relative to an axis, said text being represented by image data comprising a plurality of pixel values, said method comprising:
<claim-text>generating an array of pixel value groupings, said array comprising pluralities of pixel value groupings extending perpendicular to said axis;</claim-text>
<claim-text>sampling at least one pixel value in each of said pixel groupings;</claim-text>
<claim-text>calculating first differences between adjacent sampled pixel values in said pluralities of pixel groupings, said first differences corresponding to a first edge of said text;</claim-text>
<claim-text>locating a first difference among said first differences, said first difference exceeding a first preselected value;</claim-text>
<claim-text>locating a first line of differences of said first differences including said first difference, said first line of differences being the greatest differences between subsequent ones of said pluralities of pixel groupings that exceed a second preselected value;</claim-text>
<claim-text>calculating the length of said first line;</claim-text>
<claim-text>calculating second differences between adjacent sampled pixel values in said pluralities of pixel groupings, said second differences corresponding to a second edge of said text, wherein said second edge is opposite said first edge;</claim-text>
<claim-text>locating a second difference among said second differences, said second difference exceeding a third preselected value;</claim-text>
<claim-text>locating a second line of differences of said second differences including said second difference, said second line of differences being the greatest differences between subsequent ones of said pluralities of pixel groupings that exceed a fourth preselected value; and</claim-text>
<claim-text>calculating the length of said second line;</claim-text>
<claim-text>wherein said text is oriented properly if said first line is greater than said second line.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein said text is oriented horizontally and wherein said first edge of said text is the lower edge of said text.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, and further comprising rotating said text one-hundred eighty degrees if said first line is shorter than said second line.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein said sampling at least one pixel value comprises calculating the average pixel value of at least two of said pixel values.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein said sampling at least one pixel value comprises applying bicubic sampling of at least two of said pixel values.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein said sampling at least one pixel value comprises applying weighted averaging to at least two of said pixel values.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein said calculating the differences between adjacent sampled pixel values comprises applying an edge detection algorithm to the sampled pixel values.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein said calculating the differences between adjacent sampled pixel values comprises applying a minus one over one kernel to the sampled pixel values.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein said first preselected value is equal to said second preselected value.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein said first preselected value is greater than said second preselected value.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein said first preselected value is the negative of said third preselected value and wherein said locating a first difference comprises locating a first difference in one of said pluralities of pixel groupings, said first difference being less than said first preselected value.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein at least one of said pixel value groupings is rectangular and comprises a first number of pixel values extending parallel to said axis and a second number of pixel values extending perpendicular to said axis, said first number of pixel values being greater than said second number of pixel values.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The method of <claim-ref idref="CLM-00025">claim 25</claim-ref>, wherein said first number of pixels is about four.</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The method of <claim-ref idref="CLM-00025">claim 25</claim-ref>, wherein said second number of pixels is about sixty-four.</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. A device for determining the orientation of text, said text extending substantially horizontal, said device comprising:
<claim-text>first measuring means for measuring the contrasts associated with an upper edge of said text relative to a background, and for measuring the contrasts associated with a lower edge of said text relative to said background;</claim-text>
<claim-text>second measuring means for measuring a first length of said upper edge of text having contrasts that are at least a first preselected value, and for measuring a second length of said lower edge of text having contrasts that are at least said first preselected value; and</claim-text>
<claim-text>comparing means for comparing said first length to said second length, wherein said text is improperly oriented if said first length is greater than said second length.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. The device of <claim-ref idref="CLM-00028">claim 28</claim-ref>, and further comprising a third measuring means for measuring said contrasts associated with said lower edge of said text relative to said background.</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. The device of <claim-ref idref="CLM-00028">claim 28</claim-ref>, and further comprising a fourth measuring means for measuring said second length of said lower edge of text having contrasts that are at least said first preselected value.</claim-text>
</claim>
<claim id="CLM-00031" num="00031">
<claim-text>31. The device of <claim-ref idref="CLM-00028">claim 28</claim-ref> and further comprising a rotating means for rotating said text one-hundred eighty degrees if said first length is greater than said second length.</claim-text>
</claim>
<claim id="CLM-00032" num="00032">
<claim-text>32. The device of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein said measuring a first length comprises:
<claim-text>locating a first portion of said text having a contrast that exceeds a first preselected value; and</claim-text>
<claim-text>locating subsequent portions of said text having contrasts that exceed a second preselected value;</claim-text>
<claim-text>said first length being the distance between said first portion of said text and one of said subsequent portions of said text.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00033" num="00033">
<claim-text>33. The device of <claim-ref idref="CLM-00032">claim 32</claim-ref>, wherein said first preselected value is greater than said second preselected value.</claim-text>
</claim>
<claim id="CLM-00034" num="00034">
<claim-text>34. The device of <claim-ref idref="CLM-00032">claim 32</claim-ref>, wherein said first length is the longest distance between any of the portions of said text.</claim-text>
</claim>
<claim id="CLM-00035" num="00035">
<claim-text>35. The device of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein said measuring a second length comprises:
<claim-text>locating a first portion of said text having a contrast that exceeds a first preselected value; and</claim-text>
<claim-text>locating subsequent portions of said text having contrasts that exceed a second preselected value;</claim-text>
<claim-text>said second length being the distance between said first portion of said text and one of said subsequent portions of said text.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00036" num="00036">
<claim-text>36. The device of <claim-ref idref="CLM-00035">claim 35</claim-ref>, wherein said second length is the longest distance between any of the portions of said text.</claim-text>
</claim>
<claim id="CLM-00037" num="00037">
<claim-text>37. The device of <claim-ref idref="CLM-00028">claim 28</claim-ref>, where said first length and said second length are compared to a third preselected value, and wherein said text is rotated ninety degrees if said first length and said second length are less than said third preselected value.</claim-text>
</claim>
</claims>
</us-patent-grant>
