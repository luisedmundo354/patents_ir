<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07299378-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07299378</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10759894</doc-number>
<date>20040115</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>680</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>11</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>714 15</main-classification>
<further-classification>714  6</further-classification>
<further-classification>714 16</further-classification>
<further-classification>714 19</further-classification>
</classification-national>
<invention-title id="d0e53">Geographically distributed clusters</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5530855</doc-number>
<kind>A</kind>
<name>Satoh et al.</name>
<date>19960600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5917998</doc-number>
<kind>A</kind>
<name>Cabrera et al.</name>
<date>19990600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6035379</doc-number>
<kind>A</kind>
<name>Raju et al.</name>
<date>20000300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711162</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6144999</doc-number>
<kind>A</kind>
<name>Khalidi et al.</name>
<date>20001100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6163856</doc-number>
<kind>A</kind>
<name>Dion et al.</name>
<date>20001200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6505307</doc-number>
<kind>B1</kind>
<name>Stell et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6643795</doc-number>
<kind>B1</kind>
<name>Sicola et al.</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6757790</doc-number>
<kind>B2</kind>
<name>Chalmer et al.</name>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2002/0083036</doc-number>
<kind>A1</kind>
<name>Price</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2003/0014523</doc-number>
<kind>A1</kind>
<name>Teloh et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709226</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2003/0079019</doc-number>
<kind>A1</kind>
<name>Lolayekar et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2003/0187861</doc-number>
<kind>A1</kind>
<name>Lubbers et al.</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2003/0188114</doc-number>
<kind>A1</kind>
<name>Lubbers et al.</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2004/0024979</doc-number>
<kind>A1</kind>
<name>Kaminsky et al.</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711162</main-classification></classification-national>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>EP</country>
<doc-number>1274012</doc-number>
<kind>A</kind>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00016">
<othercit>“RAM.” Microsoft Computer Dicitonary (fifth edition). Copyright 2002. Microsoft Press.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00017">
<othercit>International Searching Authority, “Notification of Transmittal of the International Search Report and the Written Opinion of the International Searching Authority, or the Declaration,” PCT/US2005/001057, dated May 24, 2006, 21 pages.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00018">
<othercit>Frank, Lars, “Evaluation of Basic Remote Backup and Replication Methods for High Availability Databases,” Software Practice and Experience, vol. 29, No. 15, Dec. 25, 1999, pp. 1339-1353., XP000873605.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00019">
<othercit>Gray, Jim et al., “Transaction Processing: Concepts and Techniques,” Transaction Processing: Concepts and Techniques, excerpts from chapter 9, 1993, pp. 493-525, XP002947548.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00020">
<othercit>Gray, Jim et al., “Transaction Processing: Concepts and Techniques,” Transaction Processing: Concepts and Techniques 1993, excerpts from chapter 10, 1993, pp. 546-548, 556-558, 713-714, XP002187740.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00021">
<othercit>Garcia-Molina, Hector et al., “Coping with System Failure,” <i>Database Systems: The Complete Book</i>—chapter 17, 2002, pp. 875-916, XP002379771.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00022">
<othercit>Härder, Theo et al., “Logging und Recovery,” <i>Datenbanksysteme Konzepte und Techniken der Implementierung</i>—chapter 15, 1999, pp. 455-497, XP002379770.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00023">
<othercit>Lyon, Jim, “Design Consideration in Replicated Database Systems for Disaster Protection,” Tandem Computer, Inc., IEEE Feb. 29, 1988, pp. 428-430, XP010011545.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00024">
<othercit>International Searching Authority, “Notification of the Transmittal of the International Search Report and the Written Opinion of the International Searching Authority, or the Declaration,” PCT/US2005/001056, dated Dec. 1, 2005, 14 pages.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00025">
<othercit>Current Claims, PCT/US2005/001056, 5 pages.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00026">
<othercit>Patent Cooperation Treaty, “Written Opinion of the International Preliminary Examining Authority,” PCT/US2005/001057, dated Feb. 26, 2007, 14 pages.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>56</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>714  5</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>714  6</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>714 15</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>714 16</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>714 19</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>714 20</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711161</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711162</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707204</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709219</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>10</number-of-drawing-sheets>
<number-of-figures>10</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20050160315</doc-number>
<kind>A1</kind>
<date>20050721</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Chandrasekaran</last-name>
<first-name>Sashikanth</first-name>
<address>
<city>Belmont</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Kehoe</last-name>
<first-name>William F.</first-name>
<address>
<city>Moss Beach</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Hickman Palermo Truong &amp; Becker LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Oracle International Corporation</orgname>
<role>02</role>
<address>
<city>Redwood Shores</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Bonzo</last-name>
<first-name>Bryce P.</first-name>
<department>2113</department>
</primary-examiner>
<assistant-examiner>
<last-name>Manoskey</last-name>
<first-name>Joseph D</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method and apparatus for mirroring data between a plurality of sites is provided. At a first site of the plurality of sites, a record is maintained that identifies which changes made to one or more data blocks that are stored at the first site have had associated redo information replicated to the other sites of the plurality of sites. A priority value associated with a transaction that is to be performed at the first site is determined. The transaction specifies a modification to a data block. Thereafter, if the priority value indicates that the transaction should not be lost if the first site becomes inoperable, then the transaction is committed only after the record indicates that all other changes that have updated the data block at the first site have had their respective redo information replicated to the other sites of the plurality of sites.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="167.98mm" wi="151.38mm" file="US07299378-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="180.34mm" wi="167.05mm" file="US07299378-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="180.68mm" wi="167.98mm" file="US07299378-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="182.37mm" wi="165.35mm" file="US07299378-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="203.45mm" wi="167.30mm" file="US07299378-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="89.83mm" wi="168.32mm" file="US07299378-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="229.87mm" wi="168.74mm" file="US07299378-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="227.75mm" wi="161.21mm" file="US07299378-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="241.47mm" wi="169.08mm" file="US07299378-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="100.08mm" wi="156.04mm" file="US07299378-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="262.21mm" wi="171.79mm" orientation="landscape" file="US07299378-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">RELATED APPLICATION</heading>
<p id="p-0002" num="0001">This application is related to U.S. patent application Ser. No. 10/760,013, filed concurrently herewith, titled “Cluster Database with Remote Data Mirroring,” naming as inventors Sashikanth Chandrasekaran and William F. Kehoe, the entire disclosure of which is hereby incorporated by reference for all purposes as if fully set forth herein.</p>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention relates to mirroring data between a plurality of sites.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">Data mirroring is a technique wherein data is copied from a first location to one or more secondary locations contemporaneous with when the data is stored at the first location. The data copied from the first location to the one or more secondary locations is an exact copy of the data stored at the first location. Consequently, data mirroring is useful for both providing a backup of the mirrored data and recovering data after a disaster in a timely manner. Data mirroring is independent of whether data is being copied to a location that is either geographically close to or distant from the location being mirrored.</p>
<p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram illustrating a system <b>100</b> employing a first approach to data mirroring, wherein data stored at site A is being mirrored to site B. File server <b>130</b> synchronously replicates data stored in database <b>140</b> to database <b>142</b>. Each time file server <b>130</b> processes a transaction issued by database server <b>120</b> that makes a change to a data block in database <b>140</b>, file server <b>130</b> transmits a message reflecting the change to file server <b>132</b>. Upon receiving the message, file server <b>132</b> updates data stored in database <b>142</b> to reflect the change made to database <b>140</b>. Database <b>142</b> may be updated using a variety of techniques, such as either performing the same transaction to database <b>142</b> as was performed on database <b>140</b> or by updating non-volatile memory at database <b>142</b> to reflect the current state of data stored at database <b>140</b>.</p>
<p id="p-0006" num="0005">Clients, such as client <b>110</b> and client <b>112</b>, may issue I/O requests to a database server to read or write data in a database. To ensure the consistency of databases <b>140</b> and <b>142</b>, all clients in system <b>100</b> issue all I/O requests through database server <b>120</b> at site A, thus guaranteeing that all clients will have the same view of the data being mirrored, regardless of the site with which the client is associated.</p>
<p id="p-0007" num="0006">The approach for data mirroring illustrated in <figref idref="DRAWINGS">FIG. 1</figref> has several problems. First, all I/O requests from clients not associated with site A, such as client <b>112</b>, may encounter a performance penalty because those clients must transmit their I/O request to a database server at a different site. Since all I/O requests from a client are routed through a single database server, which may be geographically distant from the requesting client, those clients who are located remotely may encounter a significant transmission delay associated with the I/O request. Further, the single database server will act as a bottleneck for all I/O requests from clients in system <b>100</b>.</p>
<p id="p-0008" num="0007">Second, if site A becomes inoperable, e.g., file server <b>130</b> crashes or becomes unavailable, then database server <b>120</b> and all clients in system <b>100</b> connecting to database server <b>120</b> will encounter a temporary loss of service until a backup system, such as site B, that replaces the failed system of site A becomes operational.</p>
<p id="p-0009" num="0008">Third, in the event that file server <b>130</b> cannot replicate a write operation to file server <b>132</b>, perhaps due to the communications link between file server <b>130</b> and file server <b>132</b> becoming inoperable, then care must be applied in determining whether database <b>140</b> or database <b>142</b> should be used as a backup system to recover from the encountered problem, as database <b>140</b> and <b>142</b> are no longer synchronized with each other since one or more write operations could not be replicated. A change made to a database will be lost if a database is chosen as a backup system and the chosen database does not reflect all write operations that have been performed on any database in the system.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram illustrating a second approach for data mirroring. As <figref idref="DRAWINGS">FIG. 2</figref> depicts, each database stored at each site is partitioned into two or more partitions. For example, database <b>240</b> has partitions A and B′, and database <b>242</b> has partitions A′ and B. Data stored in partition A in database <b>240</b> is mirrored to partition A′ in database <b>242</b>, and data stored in partition B in database <b>242</b> is mirrored to partition B′ in database <b>240</b>. Database <b>240</b> is considered the primary site for partition A and database <b>242</b> is considered the primary site for partition B.</p>
<p id="p-0011" num="0010">Requests from clients to write or read data may be performed locally (i.e., the client issuing the request and the database servicing the request are both in the same site) if and only if the request only involves data stored in the partition that is being mirrored at that site. For example, if client <b>210</b> issues a write or read request to a data block in partition A, then the request may be performed locally at database <b>240</b>. However, if client <b>210</b> issues a write or read request to a data block in partition B, then database server <b>220</b> would route that request to file server <b>232</b> so the request can be performed at database <b>242</b>. Partitioning data in this manner helps reduce the performance delay of processing a transaction against data in partitions where the primary site is the local site, although this technique does not reduce the performance delay of processing a transaction against data in partitions where the primary site is a remote site.</p>
<p id="p-0012" num="0011">However, this approach is problematic if data cannot be replicated between sites or if a particular site becomes inoperable. When data cannot be replicated from a partition on a first site (the primary site) to a corresponding partition on a second site (the secondary site), the database at the primary site is not notified that the replication was not successful. As a result, partitions storing replicated data at the secondary site may grow stale and outdated. Thereafter, if the primary site becomes inoperable, then a partition storing replicated data at the secondary site cannot be used to recover from the inoperability of the primary site because the data stored therein is outdated. Use of the outdated data would violate database consistency principles.</p>
<p id="p-0013" num="0012">Accordingly, there is an unaddressed need in the art to mirror data while avoiding the problems associated with the approaches described above.</p>
<p id="p-0014" num="0013">The approaches described in this section are approaches that could be pursued, but not necessarily approaches that have been previously conceived or pursued. Therefore, unless otherwise indicated, it should not be assumed that any of the approaches described in this section qualify as prior art merely by virtue of their inclusion in this section.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0015" num="0014">The present invention is illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings and in which like reference numerals refer to similar elements and in which:</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram illustrating a first approach to data mirroring;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram illustrating a second approach to data mirroring;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 3</figref> is a block network diagram illustrating a data mirroring system according to an embodiment of the invention;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating the steps of mirroring data between a plurality of sites according to an embodiment;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart illustrating the functional steps of initiating a membership voting operation according to an embodiment of the invention;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart illustrating the steps of mirroring data between a plurality of sites according to an embodiment of the invention;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart illustrating the steps of mirroring data between a plurality of sites according to an embodiment of the invention;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart illustrating the steps of mirroring data between a plurality of sites according to an embodiment of the invention;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart illustrating the steps of mirroring data between a plurality of sites according to an embodiment of the invention; and</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 10</figref> is a block diagram that illustrates a computer system upon which an embodiment of the invention may be implemented.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0026" num="0025">A method and system for mirroring data between a plurality of sites are described. In the following description, for the purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the present invention. It will be apparent, however, that the present invention may be practiced without these specific details. In other instances, well-known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the present invention.</p>
<heading id="h-0006" level="1">Architecture Overview</heading>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 3</figref> is a block network diagram illustrating a data mirroring system <b>300</b> according to an embodiment of the invention. The data mirroring system <b>300</b> may be used to bi-directionally replicate data between each site in the data mirroring system <b>300</b>. Additionally, as described herein, other benefits may be achieved using data mirroring system <b>300</b>. The data mirroring system <b>300</b> of <figref idref="DRAWINGS">FIG. 3</figref> includes site <b>310</b> and site <b>312</b>, client <b>320</b> and client <b>322</b>, database server <b>330</b> and database server <b>332</b>, file server <b>340</b> and file server <b>342</b>, database <b>350</b> and database <b>352</b>, quorum device <b>360</b>, and communications links <b>370</b>, <b>372</b>, <b>374</b>, and <b>376</b>.</p>
<p id="p-0028" num="0027">A site, as broadly used herein, refers to a logical grouping of physical components in data mirroring system <b>300</b>. Data may be replicated from a first site to a second site in data mirroring system <b>300</b>. Numerous components of data mirroring system <b>300</b> may be stored in a single site. For example, a single site may have one or more clients, one or more database servers, one or more file servers, one or more databases, and one or more quorum devices. The logical grouping of physical components in a site may be physically located in areas of varying size. For example, a site may correspond to a particular building, a particular floor of a building, or a particular room of a building. Sites may also be physically close or distant to one other. For ease of explanation, <figref idref="DRAWINGS">FIG. 3</figref> only depicts two sites; however, embodiments may have any number of sites, including only a single site.</p>
<p id="p-0029" num="0028">A client, as broadly used herein, refers to any software or hardware component that is capable of issuing a request for a service. For example, a component that is capable of issuing a request to a database server is typically referred to as a database client. For ease of explanation, each site is illustrated with a single client in <figref idref="DRAWINGS">FIG. 3</figref>; however, a site may contain any number of clients. Non-limiting, illustrative examples of a client, such as client <b>320</b> and <b>322</b>, include a software application, a personal computer, a machine capable of issuing requests to a database server, and a database server.</p>
<p id="p-0030" num="0029">A database server, such as database server <b>330</b> and database server <b>332</b>, is one or more software and/or hardware components used for managing data. Among other functions of database management, a database server typically governs and facilitates access to a database, and processes requests by database clients to access the database. While only two database servers, namely database server <b>330</b> and database server <b>332</b>, are depicted in <figref idref="DRAWINGS">FIG. 3</figref>, any number of database servers may be employed in data mirroring system <b>300</b>.</p>
<p id="p-0031" num="0030">A file server, as broadly used herein, refers to any hardware or software component capable of performing file handling and storage functionality. A file server, such as file server <b>340</b> and file server <b>342</b>, processes write and read operations that are received from a database server and that are performed on a database. Note that the term “file server” is used broadly herein, as a file server may include a system that executes separate from and independent of a database management system, or a module within a database management system.</p>
<p id="p-0032" num="0031">A database, such as database <b>350</b> and database <b>352</b>, is a durable store of electronic information. Non-limiting, illustrative examples of a database include a relational database, an object oriented database, a multidimensional database, a database in a distributed cluster of computers, and a database in a grid of server blades. A distributed cluster of database servers is explained in further detail in U.S. Pat. No. 6,353,836, which is incorporated herein by reference in its entirety. A grid on which a set of database servers is running is explained in further detail in U.S. Provisional Patent Application Ser. No. 60/500,050, which is incorporated herein by reference in its entirety.</p>
<p id="p-0033" num="0032">A quorum device, as broadly used herein, refers to any hardware of software component that is capable of performing a membership voting operation. In an embodiment, a membership voting operation determines which database server(s) should be removed from a replication membership. The operation of a quorum device, such as quorum device <b>360</b>, shall be explained in further detail below in the section entitled “Bi-Directional Replication.” For ease of explanation, only one quorum device is depicted in <figref idref="DRAWINGS">FIG. 3</figref>; however, embodiments of data mirroring system <b>300</b> may include any number of quorum devices.</p>
<p id="p-0034" num="0033">Communications links <b>370</b> and <b>372</b> may be implemented by any medium or mechanism that provides for the exchange of data between a database server, e.g., database server <b>330</b> or database server <b>332</b>, and quorum device <b>360</b>. Communications links <b>374</b> and <b>376</b> may be implemented by any medium or mechanism that provides for the exchange of data between file servers, e.g., file server <b>340</b> and file server <b>342</b>. Examples of communications links <b>370</b>, <b>372</b>, <b>374</b>, and <b>376</b> include, without limitation, a network such as a Local Area Network (LAN), Wide Area Network (WAN), Ethernet or the Internet, or one or more terrestrial, satellite or wireless links.</p>
<heading id="h-0007" level="1">Error Handling in a Mirroring Environment—Overview</heading>
<p id="p-0035" num="0034">Methods and mechanisms are presented for mirroring data between a plurality of sites. According to one technique, a replication relationship is established between the plurality of sites, including a first site and a second site. In an embodiment, the replication relationship provides that at least some changes made at any site of the plurality of sites are replicated at each other site of the plurality of sites.</p>
<p id="p-0036" num="0035">A first database server that is associated with the first site of the replication relationship requests performance of a write operation. Thereafter, the write operation is performed at the first site. A message is sent to request that the write operation be mirrored at the second site of the replication relationship.</p>
<p id="p-0037" num="0036">For the purpose of explanation, it shall be assumed that the second site could not successfully perform the write operation. Consequently, the first database server receives an indication that the write operation could not be successfully performed at the second site. In response, the first database server initiates a membership voting operation to determine whether the first database server or a second database server associated with the second site should be removed from the replication membership.</p>
<p id="p-0038" num="0037">In an embodiment, the first database server initiates the membership voting operation by communicating with a quorum device. A quorum device is a hardware or software component that is capable of performing a membership voting operation. The quorum device may determine which database server should be removed from the replication membership based on a number of factors, such as which database server is more important or more reliable. The quorum device may employ a variety of membership voting protocols to determine membership.</p>
<p id="p-0039" num="0038">If it is determined that the second database server associated with the second site should be removed from the replication membership, then the first database server may send a message to a file server at the first site to indicate that write operations are no longer to be replicated at the second site. Additional embodiments are described in further detail below.</p>
<heading id="h-0008" level="1">Priority-Based Commit Handling—Overview</heading>
<p id="p-0040" num="0039">Techniques are also provided for handling the commit of transactions based on priority values associated with the transactions. According to one technique, data is mirrored between a plurality of sites. At a first site of the plurality of sites, a first record is maintained that identifies which transactions that have been executed at the first site have had their redo information replicated to the other sites of the plurality of sites. Redo information, as broadly used herein, refers to information that describes a transaction. Also at the first site, a second record is maintained that identifies which transaction that have executed at the first site have had their redo information logged to persistent storage at the first site.</p>
<p id="p-0041" num="0040">A priority value associated with a transaction that is to be performed at the first site is determined. The transaction specifies a modification to a data block. Redo information is typically stored in a redo log file. In most implementations, the redo log file stores redo information sequentially in the order in which transactions commit. Thus, ensuring that the redo information associated with a high priority transaction (a transaction with a priority value that indicates the transaction should not be lost if the site where it was issued becomes inoperable) has been replicated ensures that the redo information that is associated with a low priority transaction (a transaction with a priority value that indicates the transaction may be lost if the site where it was issued becomes inoperable) that has committed before the high priority transaction has also already been replicated.</p>
<p id="p-0042" num="0041">If the priority value indicates that the transaction should not be lost if the first site becomes inoperable, then the transaction is committed only after the first record indicates that all other transactions that have committed before the transaction at the first site have had their respective redo information replicated to the other sites of the plurality of sites.</p>
<p id="p-0043" num="0042">However, in an embodiment, if the priority value indicates that the transaction can be lost if the first site becomes inoperable, then the transaction is committed before the first record indicates that all other transactions that have committed before the transaction at the first site have had their respective redo information replicated to the other sites of the plurality of sites. In another embodiment, if the priority value indicates that the transaction can be lost if the first site becomes inoperable, then the transaction is committed after the second record indicates that all other transactions that have committed before the transaction at the first site have had their respective redo information stored to persistent storage at the first site.</p>
<p id="p-0044" num="0043">Additional embodiments are described in further detail below.</p>
<heading id="h-0009" level="1">Bi-Directional Replication</heading>
<p id="p-0045" num="0044">As explained in further detail below, embodiments support simultaneous local read operations and local write operations in each site of the system <b>300</b>. Write operations may be replicated synchronously or asynchronously to each other site in the system <b>300</b>. In an embodiment, the performance of a write operation may be enhanced by deferring the replication of the write operation to another site. For example, the replication of a write operation to another site may be deferred until a high priority transaction needs to commit or to a point where write-ahead logging or write-back logging needs to be preserved. The deferring of write operations allows the replication of the write operations to be batched efficiently.</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart <b>400</b> illustrating the steps of mirroring data between a plurality of sites according to an embodiment. Initially, in step <b>410</b>, a replication relationship is established between a plurality of sites. In an embodiment, a replication relationship is established for each site in data mirroring system <b>300</b>, e.g., a replication relationship is established for site <b>310</b> and site <b>312</b> in <figref idref="DRAWINGS">FIG. 3</figref>. In an embodiment, the replication relationship provides that at least some changes made at any site in data mirroring system <b>300</b> is replicated at each other site in data mirroring system <b>300</b>. After the performance of step <b>410</b>, processing proceeds to step <b>420</b>.</p>
<p id="p-0047" num="0046">In step <b>420</b>, a first database server associated with a first site in the plurality of sites requests performance of a write operation. In an embodiment, step <b>420</b> may be performed by database server <b>330</b>, in site <b>310</b>, requesting performance of a write operation. The write operation may be an operation to write data to a database located at the first site, such as database <b>350</b>. After the performance of step <b>420</b>, processing proceeds to step <b>430</b>.</p>
<p id="p-0048" num="0047">In step <b>430</b>, the write operation that was requested in step <b>420</b> is performed at the first site. In an embodiment, the write operation may be performed at site <b>310</b> by database server <b>330</b> instructing file server <b>340</b> to perform the write operation at database <b>350</b>, and thereafter file server <b>340</b> perform the write operation at database <b>350</b>. Also in step <b>430</b>, a message is sent to request that the write operation be mirrored at the second site. In an embodiment, file server <b>340</b> may send the request that the write operation be mirrored at site <b>312</b> to file server <b>342</b>. After the performance of step <b>430</b>, processing proceeds to step <b>440</b>.</p>
<p id="p-0049" num="0048">It is noted that write operations may be performed at each site in the system because each database server at each site uses a mechanism to ensure that no more than one write operation may change the same data block durably stored on disk at the same time. Such a mechanism could be implemented using a variety of techniques, which may include a form of global lock management (shared-disk clusters) or a partitioning of the disks (shared-nothing clusters).</p>
<p id="p-0050" num="0049">In step <b>440</b>, the first database server receives an indication that the write operation could not be successfully performed at the second site. For example, database server <b>330</b> receives an indication that the write operation could not be successfully performed at site <b>312</b>. In an embodiment, the indication is an input/output error that indicates that a membership voting operation should be performed. The input/output error may be expressed using a unique error code that is received in a message by database server <b>330</b>. The indication received at site <b>310</b> may be an input/output error that identifies that the write operation cannot be replicated at site <b>312</b>. In an embodiment, the indication is only received in step <b>440</b> when the one site in the data mirroring system <b>300</b> does not reflect a write operation performed at another site in the data mirroring system <b>300</b>; consequently, the indication of step <b>440</b> is not received by site <b>310</b> if database server <b>332</b> fails. In an embodiment, site <b>310</b> receives the indication of step <b>440</b> if file server <b>342</b> fails, database <b>352</b> fails, communications link <b>374</b> fails, or communications link <b>376</b> fails. After the performance of step <b>440</b>, processing proceeds to step <b>450</b>.</p>
<p id="p-0051" num="0050">In step <b>450</b>, the first database server initiates a membership voting operation to determine whether the first database server or a second database server associated with the second site should be removed from the replication membership. For example, step <b>450</b> may be performed by database server <b>330</b> initiating a membership voting operation to determine whether database server <b>330</b> or database server <b>332</b> should be removed from the replication membership.</p>
<p id="p-0052" num="0051">In an embodiment, the first database server initiates the membership voting operation by communicating with a quorum device. For example, database server <b>330</b> initiates the membership voting operation by communicating over communications link <b>370</b> with quorum device <b>360</b>.</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart illustrating the functional steps of initiating a membership voting operation according to an embodiment of the invention. In step <b>510</b>, a quorum device is notified that the write operation could not be successfully performed. For example, step <b>510</b> may be performed by database server <b>330</b> notifying quorum device <b>360</b> over communications link <b>370</b> that the write operation could not be successfully performed at site <b>312</b>. After the performance of step <b>510</b>, processing proceeds to step <b>520</b>.</p>
<p id="p-0054" num="0053">In step <b>520</b>, the quorum device notified in step <b>510</b> determines which database server should be removed from the replication membership. For example, step <b>520</b> may be performed by quorum device <b>360</b> determining which database server should be removed from the replication relationship. In an embodiment, the determination of which database server should be removed from the replication relationship includes determining which database server is more important or more reliable. If all database servers in the data mirroring system <b>300</b> are equally important or reliable, a default database server may be chosen by the quorum device.</p>
<p id="p-0055" num="0054">In an embodiment, if quorum device <b>360</b> determines that database server <b>332</b> should be removed from the replication membership, then database server <b>330</b> sends a message to file server <b>340</b> that indicates write operations performed at site <b>310</b> are no longer to be replicated at site <b>312</b>. Alternatively, if quorum device <b>360</b> determines that site <b>310</b> should be removed from the replication membership, then database server <b>332</b> informs file server <b>342</b> that data is no longer to be replicated at site <b>310</b>. A file server can still process read and write operations locally even if the write operations are no longer replicated to a different site.</p>
<p id="p-0056" num="0055">In an embodiment, quorum device <b>360</b> is comprised of a plurality of mirrored devices and step <b>510</b> is performed by a primary file server. The primary file server is a file server, associated with one of the plurality of sites, through which all other files servers, associated with other sites in the plurality of sites, communicate with the quorum device. For example, database server <b>330</b> may be a primary file server; consequently, database server <b>332</b> communicates with quorum device <b>360</b> through database sever <b>330</b>.</p>
<p id="p-0057" num="0056">In another embodiment, quorum device <b>360</b> is located in a different site associated with a different failure domain than any other site in the data mirroring system <b>300</b>. In this embodiment, each database server in data mirroring system <b>300</b> may directly contact quorum device <b>360</b>. However, if the quorum device <b>360</b> fails, then each site in data mirroring system <b>300</b> fails because each site cannot communicate with quorum device <b>360</b>, even though those sites are otherwise healthy and have network and input/output connectivity with each other.</p>
<p id="p-0058" num="0057">In an embodiment, a site may rejoin the replication relationship after the quorum device determines that a database server at the site should be removed from the replication membership. For example, if site <b>312</b> was removed from the replication relationship, then site <b>312</b> may rejoin the replication relationship. In response to site <b>312</b> rejoining the replication relationship, data in site <b>312</b> is resynchronized with data in site <b>310</b>, and database <b>352</b> is remounted.</p>
<heading id="h-0010" level="1">Improving the Performance of Writing Redo Information</heading>
<p id="p-0059" num="0058">Synchronous replication of write operations increases the latency and cost of write operations. File servers may also replicate write operations asynchronously, although care must be applied to coordinate write operations initiated elsewhere that have not yet been replicated and write operations that are about to issue. Numerous embodiments that advantageously employ asynchronous replication are discussed below.</p>
<p id="p-0060" num="0059">Several embodiments that improve the performance of writing redo information through asynchronous replication shall be discussed below. Redo information, as broadly used herein, refers to information that describes a transaction. In an embodiment, redo information describes transaction that have committed or are about to commit. In an embodiment, redo information may be recorded in a redo log file. Redo information may be used in rolling back or “undoing” a transaction that has been committed.</p>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart illustrating the steps of mirroring data between a plurality of sites according to an embodiment of the invention. The steps illustrated in <figref idref="DRAWINGS">FIG. 6</figref> may be used to mirror redo information between a plurality of sites. Initially, in step <b>610</b>, a first record is maintained, at a first site of the plurality of sites, that identifies which transactions that have been executed at the first site have had their redo information replicated to the other sites of the plurality of sites. Step <b>610</b> may be performed by database server <b>330</b> of site <b>310</b>. In an embodiment, step <b>610</b> may be performed by identifying a portion of a redo log file. All transactions reflected in the identified portion of the redo log file of step <b>610</b> have been replicated to the other sites of the plurality of sites.</p>
<p id="p-0062" num="0061">For example, the portion of the redo log file identified in step <b>610</b> may be identified by maintaining a record that identifies a particular transaction reflected in the redo log file that has had its respective redo information replicated to the other sites of the plurality of sites and is associated with the largest log sequence number (LSN). All transactions in the redo log file that have a LSN that is less than or equal to the LSN associated with the particular transaction are in the identified portion of the redo log file that have had their redo information replicated to the other sites of the plurality of sites. After the performance of step <b>610</b>, processing proceeds to step <b>620</b>.</p>
<p id="p-0063" num="0062">In step <b>620</b>, a second record is maintained, at a first site of the plurality of sites, that identifies which transactions that have been executed at the first site have had their redo information logged to persistent storage at the first site. Step <b>620</b> may be performed by database server <b>330</b> of site <b>310</b>. In an embodiment, step <b>620</b> may be performed by identifying a portion of a redo log file. All transactions reflected in the identified portion of the redo log file of step <b>620</b> have been logged to persistent storage at the first site.</p>
<p id="p-0064" num="0063">For example, the portion of the redo log file identified in step <b>620</b> may be identified by maintaining a record that identifies a particular transaction reflected in the redo log file that has had its respective redo information logged to persistent storage at the first site and is associated with the largest log sequence number (LSN). All transactions in the redo log file that have a LSN that is less than or equal to the LSN associated with the particular transaction are in the identified portion of the redo log file that have had their redo information logged to persistent storage at the first site. After the performance of step <b>620</b>, processing proceeds to step <b>630</b>.</p>
<p id="p-0065" num="0064">In step <b>630</b>, a priority value that is associated with a transaction is determined. The priority value may be used to determine when a transaction should be committed based on the importance of the transaction. For example, if a particular transaction should not be lost if the first site becomes inoperable, then the transaction may be given a higher priority value than a transaction that can be lost if the first site becomes inoperable.</p>
<p id="p-0066" num="0065">In an embodiment, the transaction associated with the priority value of step <b>630</b> is to be performed at the first site. In an embodiment, the transaction specifies that a modification is to be made to at least one data block. A data block modified by the transaction may reside in the database <b>350</b> of site <b>310</b>. For the ease of explanation, the transaction shall be discussed as modifying one data block, although a transaction may modify two or more data blocks. Step <b>630</b> may be performed by database server <b>330</b> of site <b>310</b>. After the performance of step <b>630</b>, processing proceeds to step <b>640</b>.</p>
<p id="p-0067" num="0066">In step <b>640</b>, a determination is made as to whether the prior value indicates that the transaction should not be lost if the first site becomes inoperable. Step <b>640</b> may be performed by database server <b>330</b> of site <b>310</b>.</p>
<p id="p-0068" num="0067">If the determination of step <b>640</b> is positive (the priority value indicates that the transaction should not be lost if the first site becomes inoperable), then processing proceeds to step <b>650</b>. In step <b>650</b>, the transaction is committed only after the first record indicates that the redo information associated with the transaction has been replicated to each other site in data mirroring system <b>300</b>. Step <b>650</b> maybe performed by database server <b>330</b> of site <b>310</b>.</p>
<p id="p-0069" num="0068">In an embodiment, the determination made in step <b>650</b> of whether redo information associated with the transaction has been replicated to the other sites of the plurality of sites is performed by comparing a commit record associated with the transaction to the first record.</p>
<p id="p-0070" num="0069">If the determination of step <b>640</b> is negative (the priority value indicates that the transaction may be lost if the first site becomes inoperable), then processing proceeds to step <b>660</b>. In step <b>660</b>, the transaction is committed only after the second record indicates that the redo information associated with the transaction has been stored to persistent storage at the first site. Step <b>660</b> may be performed by database server <b>330</b> of site <b>310</b>.</p>
<p id="p-0071" num="0070">In an embodiment, the determination made in step <b>660</b> of whether the redo information associated with the transaction has been stored to persistent storage is performed by comparing a commit record associated with the transaction to the second record.</p>
<p id="p-0072" num="0071">In an alternative embodiment (not depicted in <figref idref="DRAWINGS">FIG. 6</figref>), step <b>660</b> may be performed by committing the transaction before the first record indicates that the redo information associated with the transaction has been replicated to the other sites of the plurality of sites. In an embodiment, database server <b>330</b> of site <b>310</b> commits the transaction before the first record indicates that the redo information associated with the transaction has been replicated to the other sites of the plurality of sites. Redo information generated by a transaction is considered to be associated with the transaction.</p>
<p id="p-0073" num="0072">The embodiments discussed above advantageously enable the determination of when to commit a transaction to be based on the importance of the transaction. For example, if a particular transaction is a very important transaction (it must not be lost under any circumstance), then the transaction is only committed after the first record indicates that all other transactions that have committed before the transaction have had their respective redo information replicated to the other sites. However, a transaction that is not as important may be committed after the second record indicates that all other transactions that have committed before the transaction have had their respective redo information stored to persistent storage at the first site. In this fashion, a transaction that is not as important may be committed earlier than a very important transaction, although the committed transaction that is not as important may be lost if first site becomes inoperable before the change associated with the committed transaction is mirrored in the other sites of the plurality of sites.</p>
<p id="p-0074" num="0073">If the replication of a write operation is delayed and the particular site that issued the write operation becomes inoperable, then a surviving site must wait for all messages transmitted from the inoperable site to be received at each other site in the plurality of sites before initiating recovery of the site that is inoperable. This practice ensures that a message that has been sent from the inoperable site prior to that site becoming inoperable, and which has not yet been received, is not processed by the surviving site after it has initiated recovery or has completed recovery of the site that is inoperable. Alternately, the surviving sites may ignore any messages transmitted from the site that is inoperable after one or more of the surviving sites has initiated or completed recovery of the site that is inoperable.</p>
<p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart illustrating the steps of mirroring data between a plurality of sites according to an embodiment of the invention. The steps illustrated in <figref idref="DRAWINGS">FIG. 7</figref> may be used to advantageously delay replication of a write operation to a redo log. It is advantageous for a database server to reduce the latency of writing data to a redo log. A database server can delay the replication of writes to a redo log provided the loss of the most recently committed transactions can be tolerated in the event of a site failure. Embodiments of the invention discussed below advantageously delay replication of writes to a redo log until a data block that reflects changes that have not been durably stored is either durably stored or transferred to another site.</p>
<p id="p-0076" num="0075">Initially, in step <b>710</b>, a transaction is processed at a first site in a plurality of sites. Step <b>710</b> may be performed by database server <b>330</b> of site <b>310</b> processing a transaction, such as a write operation.</p>
<p id="p-0077" num="0076">In step <b>720</b>, information is generated that reflects the processed transaction. The information may be generated in volatile memory. The information may include redo information about the processed transaction. Step <b>720</b> may be performed by database server <b>330</b> of site <b>310</b>. After information is generated that reflects the processed transaction, processing proceeds to step <b>730</b>.</p>
<p id="p-0078" num="0077">In step <b>730</b>, a determination is made as to whether the information generated in step <b>720</b> has been durably stored before either a data block associated with the processed transaction is durably stored or the data block is transferred to another site. Step <b>730</b> may be performed by database server <b>330</b> of site <b>310</b>.</p>
<p id="p-0079" num="0078">If the determination of step <b>730</b> is negative (the information generated in step <b>720</b> has not been durably stored before either a data block associated with the processed transaction is durably stored or the data block is transferred to another site), then processing proceeds to step <b>740</b>. In step <b>740</b>, the information generated in step <b>720</b> is durably stored before either the data block is durably stored or the data block is transferred to another site of the plurality of sites.</p>
<p id="p-0080" num="0079">In an embodiment, step <b>740</b> may be performed such that information about multiple transactions is durably stored. For example, at the first site, a second transaction may be processed, and information may be generated in volatile memory at the first site that reflects the processed second transaction. If the information generated in step <b>720</b> (hereinafter the “first information”) and the information that reflects the second transaction (hereinafter the “second information”) has not been durably stored before either a second data block associated with the processed second transaction is durably stored or the second data block is transferred to another site of the plurality of sites, then the first information and the second information may be durably stored using a batch process before either the second data block is durably stored or the second data block is transferred to another site of the plurality of sites. In an embodiment, database server <b>330</b> durably stores the first information and the second information using a batch process. In an embodiment, the batch process may be asynchronous. The result of the asynchronous batch process may be determined using an input/output result descriptor, e.g., aio_result_t in UNIX. The asynchronous input/output result descriptor may be used to determine when the batch process has completed processing.</p>
<p id="p-0081" num="0080">If the determination of step <b>730</b> is positive (the information generated in step <b>720</b> has been durably stored before either a data block associated with the processed transaction is durably stored or the data block is transferred to another site), then processing proceeds to step <b>750</b>. In step <b>750</b>, the data block associated with the processed transaction is durably stored or transferred.</p>
<heading id="h-0011" level="1">Improving the Performance of Writing to Database Files</heading>
<p id="p-0082" num="0081">Several embodiments that improve the performance of writing to database files through asynchronous replication shall be discussed below. <figref idref="DRAWINGS">FIG. 8</figref> is a flowchart illustrating the steps of mirroring data between a plurality of sites according to an embodiment of the invention. The steps illustrated in <figref idref="DRAWINGS">FIG. 8</figref> may be used to write to database files using a write-ahead logging scheme.</p>
<p id="p-0083" num="0082">Initially, in step <b>810</b>, a first record is maintained, at a first site of the plurality of sites, that identifies which changes made to one or more data blocks stored at the first site have had associated redo information replicated to the other sites of the plurality of sites. The first site implements a write-ahead logging scheme. In a write-ahead logging scheme, a data block in a buffer cache that reflects changes that are not durably stored (a “dirty” data block) is durably stored only after redo information associated with the one or more data blocks has been durably stored. In an embodiment, the first site replicates transactions to the other sites of the plurality of sites asynchronously relative to the execution of the transaction. Step <b>810</b> may be performed by database server <b>330</b> of site <b>310</b> maintaining a first record that identifies which changes made to one or more data blocks stored in database <b>350</b> at site <b>310</b> have had associated redo information replicated to site <b>312</b>. The changes made to one or more data blocks that have associated redo information replicated to the other sites of the plurality of sites may be tracked by assigning each change to a log sequence number (LSN) in a redo log and storing the log sequence number of the most recent change that has been replicated. Additionally, the LSN associated with the last change that has been made to a particular data block is stored in the header of the particular data block. After the performance of step <b>810</b>, processing proceeds to step <b>820</b>.</p>
<p id="p-0084" num="0083">In step <b>820</b>, a second record is maintained, at a first site of the plurality of sites, that identifies which changes made to one or more data blocks stored at the first site have had associated redo information logged to persistent storage at the first site of the plurality of sites. The changes made to one or more data blocks that have associated redo information logged to persistent storage at the first site of the plurality of sites may be tracked by assigning each change to a log sequence number (LSN) in a redo log and storing the log sequence number of the most recent change that has been logged to persistent storage. Step <b>820</b> may be performed by database server <b>330</b> of site <b>310</b> maintaining a second record that identifies which changes made to one or more data blocks stored in database <b>350</b> at site <b>310</b> have had associated redo information logged to persistent storage at site <b>310</b>. After the performance of step <b>820</b>, processing proceeds to step <b>830</b>.</p>
<p id="p-0085" num="0084">In step <b>830</b>, a determination is made as to whether the first site replicates write transactions in the same order in which the write transactions were issued at the first site. Database server <b>330</b> of site <b>310</b> may perform step <b>830</b>.</p>
<p id="p-0086" num="0085">If the determination of step <b>830</b> is positive (the first site does replicate write transactions in the same order in which the write transactions were completed at the first site), then processing proceeds to step <b>840</b>. In step <b>840</b>, a data block is durably stored after the second record indicates that any changes made to the one or more data blocks stored at the first site have had redo information logged to persistent storage. The changes made to the one or more data blocks may be performed by one or more transactions. Step <b>840</b> may be performed by durably storing a particular data block in database <b>350</b> after the second record indicates that that any changes made to the one or more data blocks stored in database <b>350</b> at site <b>310</b> have had associated redo information logged to persistent storage at site <b>310</b>.</p>
<p id="p-0087" num="0086">If the determination of step <b>830</b> is negative (the first site does not replicate write transactions in the same order in which the write transactions were completed at the first site), then processing proceeds to step <b>850</b>. In step <b>850</b>, a data block is durably stored after the first record indicates that any changes made to the one or more data blocks stored at the first site have had redo information replicated to the other sites of the plurality of sites. The changes made to the one or more data blocks may be performed by one or more transactions. Step <b>850</b> may be performed by durably storing a particular data block in database <b>350</b> in site <b>310</b> after the first record indicates that any changes made to the one or more data blocks stored in database <b>350</b> at site <b>310</b> have had associated redo information replicated to the other sites of the plurality of sites. After the first record indicates that changes made to a particular data block have been replicated to the other sites of the plurality of sites, then a lock associated with the data block may be released. Specifically, in a shared-disk or shared-cache cluster database, wherein concurrent access to a data block is coordinated using global lock management, the lock associated with a data block may be released only after the first record indicates that redo information associated with changes made to the data block has been replicated to the other sites of the plurality of sites. This ensures that any site that receives a data block from a remote site does not read or write the data block unless all the prior redo information associated with prior changes made to the data block is available in the site's local persistent storage.</p>
<p id="p-0088" num="0087">Using the embodiment depicted in <figref idref="DRAWINGS">FIG. 8</figref>, if write operations to different files are replicated in the order in which the write operations are issued, then a particular data block may be durably stored as soon as the second record reflects all transactions that have updated the particular data block. In this manner, replication of the particular data block will occur only after the redo information associated with changes made to the particular data block by the one or more transactions has been replicated.</p>
<p id="p-0089" num="0088">Embodiments of the invention improve the performance of writing to database files using a write-back logging scheme. In a write-back logging scheme a data block is durably stored before redo information for the data block is generated. <figref idref="DRAWINGS">FIG. 9</figref> is a flowchart illustrating the steps of mirroring data between a plurality of sites according to an embodiment of the invention. The steps illustrated in <figref idref="DRAWINGS">FIG. 9</figref> may be used to write to database files using a write-back logging scheme. Initially, in step <b>910</b>, at a first site of the plurality of sites, a data block is durably stored prior to durably storing redo information about changes made to the data block. Step <b>910</b> may be performed by database server <b>330</b> of site <b>310</b> durably storing a data block in database <b>350</b> prior to durably storing redo information about changes made to the data block. After the performance of step <b>910</b>, processing proceeds to step <b>920</b>.</p>
<p id="p-0090" num="0089">In step <b>920</b>, at the first site, the redo information reflecting changes made to the data block is durably stored after the changes have been replicated to the other sites in the plurality of sites. Step <b>920</b> may be performed by database server <b>330</b> of site <b>310</b> durably storing the redo information that reflects changes made to the data block after the changes have been replicated to site <b>312</b>.</p>
<p id="p-0091" num="0090">In an embodiment, in step <b>920</b>, a determination is made as to when the changes made to the data block have been replicated to the other sites in the plurality of sites. In an embodiment, database server <b>330</b> of site <b>310</b> makes the determination as to when the changes made to the data block have been replicated to site <b>312</b>.</p>
<p id="p-0092" num="0091">In an embodiment, a single process may issue one or more transactions that each make changes to a data block. In another embodiment, the one or more transactions may be issued by two or more processes. Database server <b>330</b> may determine when the one or more transactions making changes to one or more data blocks have completed. After the one or more transactions making changes to one or more data blocks have completed, the one or more data blocks may be durably stored as described in step <b>910</b>.</p>
<p id="p-0093" num="0092">Using the steps illustrated in <figref idref="DRAWINGS">FIG. 9</figref>, a database server can wait until a file server completes the replication of all write operations to data blocks that have been durably stored before durably storing the redo information for the write operations. For example, database server <b>330</b> in site <b>310</b> can wait until file server <b>340</b> completes the replication to site <b>312</b> of all write operations to data blocks that have been durably stored at site <b>310</b> before database server <b>330</b> durably stores the redo information for the write operations in database <b>350</b>.</p>
<heading id="h-0012" level="1">Site Recovery</heading>
<p id="p-0094" num="0093">In an embodiment, if a particular site in data mirroring system <b>300</b> becomes inoperable, then recovery of the particular site is initiated after it is determined that all messages transmitted from the particular site to each other site in data mirroring system <b>300</b> have been received at their destination. For example, in the embodiment depicted in <figref idref="DRAWINGS">FIG. 3</figref>, if site <b>310</b> became inoperable, then recovery of site <b>310</b> is not initiated until after it is determined that all messages transmitted from site <b>310</b> to site <b>312</b> have been received at site <b>312</b>. Alternately, the surviving sites may ignore any messages transmitted from the site that is inoperable after one or more of the surviving sites has initiated or completed recovery of the site that is inoperable.</p>
<heading id="h-0013" level="1">Improving Performance of Writing to Temporary Files</heading>
<p id="p-0095" num="0094">Temporary files may be used by a database server in certain database operations, such as a sort and a hash join. The temporary files are used like a scratch pad to hold data for a limited duration. In some cases, the meta-data changes regarding the space allocation of temporary files needs to be replicated. However, if a temporary file is not needed by other sites of the plurality of sites, then the temporary file does not need to be replicated.</p>
<p id="p-0096" num="0095">In an embodiment, a determination is made at a database server at a first site of a plurality of sites as to whether a data structure, such as a temporary file, is to be replicated to each other site of the plurality of sites. The data structure at the first site is replicated to each other site of the plurality of sites unless it is determined that the data structure is not to be replicated to each other site of the plurality of sites. For example, in the embodiment depicted in <figref idref="DRAWINGS">FIG. 3</figref>, database server <b>330</b> of site <b>310</b> may determine that a particular temporary file does not need to be replicated to site <b>312</b>. Consequently, database server <b>330</b> does not replicate the temporary file to site <b>312</b>.</p>
<heading id="h-0014" level="1">Implementing Mechanisms</heading>
<p id="p-0097" num="0096"><figref idref="DRAWINGS">FIG. 10</figref> is a block diagram that illustrates a computer system <b>1000</b> upon which an embodiment of the invention may be implemented. Computer system <b>1000</b> includes a bus <b>1002</b> or other communication mechanism for communicating information, and a processor <b>1004</b> coupled with bus <b>1002</b> for processing information. Computer system <b>1000</b> also includes a main memory <b>1006</b>, such as a random access memory (RAM) or other dynamic storage device, coupled to bus <b>1002</b> for storing information and instructions to be executed by processor <b>1004</b>. Main memory <b>1006</b> also may be used for storing temporary variables or other intermediate information during execution of instructions to be executed by processor <b>1004</b>. Computer system <b>1000</b> further includes a read only memory (ROM) <b>1008</b> or other static storage device coupled to bus <b>1002</b> for storing static information and instructions for processor <b>1004</b>. A storage device <b>1010</b>, such as a magnetic disk or optical disk, is provided and coupled to bus <b>1002</b> for storing information and instructions.</p>
<p id="p-0098" num="0097">Computer system <b>1000</b> may be coupled via bus <b>1002</b> to a display <b>1012</b>, such as a cathode ray tube (CRT), for displaying information to a computer user. An input device <b>1014</b>, including alphanumeric and other keys, is coupled to bus <b>1002</b> for communicating information and command selections to processor <b>1004</b>. Another type of user input device is cursor control <b>1016</b>, such as a mouse, a trackball, or cursor direction keys for communicating direction information and command selections to processor <b>1004</b> and for controlling cursor movement on display <b>1012</b>. This input device typically has two degrees of freedom in two axes, a first axis (e.g., x) and a second axis (e.g., y), that allows the device to specify positions in a plane.</p>
<p id="p-0099" num="0098">The invention is related to the use of computer system <b>1000</b> for implementing the techniques described herein. According to one embodiment of the invention, those techniques are performed by computer system <b>1000</b> in response to processor <b>1004</b> executing one or more sequences of one or more instructions contained in main memory <b>1006</b>. Such instructions may be read into main memory <b>1006</b> from another computer-readable medium, such as storage device <b>1010</b>. Execution of the sequences of instructions contained in main memory <b>1006</b> causes processor <b>1004</b> to perform the process steps described herein. In alternative embodiments, hard-wired circuitry may be used in place of or in combination with software instructions to implement the invention. Thus, embodiments of the invention are not limited to any specific combination of hardware circuitry and software.</p>
<p id="p-0100" num="0099">The term “computer-readable medium” as used herein refers to any medium that participates in providing instructions to processor <b>1004</b> for execution. Such a medium may take many forms, including but not limited to, non-volatile media, volatile media, and transmission media. Non-volatile media includes, for example, optical or magnetic disks, such as storage device <b>1010</b>. Volatile media includes dynamic memory, such as main memory <b>1006</b>. Transmission media includes coaxial cables, copper wire and fiber optics, including the wires that comprise bus <b>1002</b>. Transmission media can also take the form of acoustic or light waves, such as those generated during radio-wave and infra-red data communications.</p>
<p id="p-0101" num="0100">Common forms of computer-readable media include, for example, a floppy disk, a flexible disk, hard disk, magnetic tape, or any other magnetic medium, a CD-ROM, any other optical medium, punchcards, papertape, any other physical medium with patterns of holes, a RAM, a PROM, and EPROM, a FLASH-EPROM, any other memory chip or cartridge, a carrier wave as described hereinafter, or any other medium from which a computer can read.</p>
<p id="p-0102" num="0101">Various forms of computer readable media may be involved in carrying one or more sequences of one or more instructions to processor <b>1004</b> for execution. For example, the instructions may initially be carried on a magnetic disk of a remote computer. The remote computer can load the instructions into its dynamic memory and send the instructions over a telephone line using a modem. A modem local to computer system <b>1000</b> can receive the data on the telephone line and use an infra-red transmitter to convert the data to an infra-red signal. An infra-red detector can receive the data carried in the infra-red signal and appropriate circuitry can place the data on bus <b>1002</b>. Bus <b>1002</b> carries the data to main memory <b>1006</b>, from which processor <b>1004</b> retrieves and executes the instructions. The instructions received by main memory <b>1006</b> may optionally be stored on storage device <b>1010</b> either before or after execution by processor <b>1004</b>.</p>
<p id="p-0103" num="0102">Computer system <b>1000</b> also includes a communication interface <b>1018</b> coupled to bus <b>1002</b>. Communication interface <b>1018</b> provides a two-way data communication coupling to a network link <b>1020</b> that is connected to a local network <b>1022</b>. For example, communication interface <b>1018</b> may be an integrated services digital network (ISDN) card or a modem to provide a data communication connection to a corresponding type of telephone line. As another example, communication interface <b>1018</b> may be a local area network (LAN) card to provide a data communication connection to a compatible LAN. Wireless links may also be implemented. In any such implementation, communication interface <b>1018</b> sends and receives electrical, electromagnetic or optical signals that carry digital data streams representing various types of information.</p>
<p id="p-0104" num="0103">Network link <b>1020</b> typically provides data communication through one or more networks to other data devices. For example, network link <b>1020</b> may provide a connection through local network <b>1022</b> to a host computer <b>1024</b> or to data equipment operated by an Internet Service Provider (ISP) <b>1026</b>. ISP <b>1026</b> in turn provides data communication services through the world wide packet data communication network now commonly referred to as the “Internet” <b>1028</b>. Local network <b>1022</b> and Internet <b>1028</b> both use electrical, electromagnetic or optical signals that carry digital data streams. The signals through the various networks and the signals on network link <b>1020</b> and through communication interface <b>1018</b>, which carry the digital data to and from computer system <b>1000</b>, are exemplary forms of carrier waves transporting the information.</p>
<p id="p-0105" num="0104">Computer system <b>1000</b> can send messages and receive data, including program code, through the network(s), network link <b>1020</b> and communication interface <b>1018</b>. In the Internet example, a server <b>1030</b> might transmit a requested code for an application program through Internet <b>1028</b>, ISP <b>1026</b>, local network <b>1022</b> and communication interface <b>1018</b>.</p>
<p id="p-0106" num="0105">The received code may be executed by processor <b>1004</b> as it is received, and/or stored in storage device <b>1010</b>, or other non-volatile storage for later execution. In this manner, computer system <b>1000</b> may obtain application code in the form of a carrier wave.</p>
<p id="p-0107" num="0106">In the foregoing specification, embodiments of the invention have been described with reference to numerous specific details that may vary from implementation to implementation. Thus, the sole and exclusive indicator of what is the invention, and is intended by the applicants to be the invention, is the set of claims that issue from this application, in the specific form in which such claims issue, including any subsequent correction. Any definitions expressly set forth herein for terms contained in such claims shall govern the meaning of such terms as used in the claims. Hence, no limitation, element, property, feature, advantage or attribute that is not expressly recited in a claim should limit the scope of such claim in any way. The specification and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for mirroring data between a plurality of sites, comprising:
<claim-text>maintaining, at a first site of the plurality of sites, a record that identifies which transactions that have been executed at the first site have had their redo information replicated to the other sites of the plurality of sites;</claim-text>
<claim-text>determining a priority value associated with a transaction that is to be performed at the first site, wherein the transaction specifies a modification to a data block;</claim-text>
<claim-text>if the priority value is a first value in a set of possible values, then committing the transaction only after the record indicates that redo information associated with the transaction has been replicated to the other sites of the plurality of sites; and</claim-text>
<claim-text>if the priority value is a second value in said set of possible values, then committing the transaction even though the record does not indicate that redo information associated with the transaction has been replicated to the other sites of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first value indicates that the transaction should not be lost if the first site becomes inoperable.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second value indicates the transaction can be lost if the first site becomes inoperable.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step of:
<claim-text>determining whether all other transactions that have committed before the transaction has committed have had their respective redo information replicated to the other sites of the plurality of sites by comparing a commit record associated with the transaction to the record.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the record is a first record, and the method further comprises the step of:
<claim-text>maintaining, at the first site, a second record that identifies which transactions that have executed at the first site have had their redo information logged to persistent storage at the first site.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, further comprising the step of:
<claim-text>if the priority value is the second value in the set of possible values, then committing the transaction after the second record indicates that the redo information generated by the transaction has been stored to persistent storage at the first site.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, further comprising the step of:
<claim-text>determining which transactions that have executed at the first site have had their redo information logged to persistent storage by comparing a commit record associated with the transaction to the second record.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the second record identifies which transactions that have executed at the first site have had their redo information logged to persistent storage at the first site by identifying a portion of a redo log file, and wherein all transactions reflected in the identified portion of the redo log file have been logged to persistent storage at the first site.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step of:
<claim-text>if the priority value is the second value in the set of possible values, then committing the transaction before the record indicates that the redo information generated by the transaction has been replicated to the other sites of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step of:
<claim-text>if a particular site of the plurality of sites becomes inoperable, then initiating recovery of the particular site after it is determined that all messages transmitted from the particular site to each other site of the plurality of sites have been received at their destination.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the steps of:
<claim-text>at each site of the plurality of sites, determining if a data structure is to be replicated to each other site of the plurality of sites; and</claim-text>
<claim-text>replicating the data structure to each other site of the plurality of sites unless it is determined that the data structure is not to be replicated to each other site of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the record identifies which transactions that have been executed at the first site have had their redo information replicated to the other sites of the plurality of sites by identifying a portion of a redo log file, and wherein all transactions reflected in the identified portion of the redo log file have been replicated to the other sites of the plurality of sites.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. A method for storing data, comprising:
<claim-text>at a first site in a plurality of sites, processing a transaction;</claim-text>
<claim-text>generating in volatile memory redo information for the processed transaction;</claim-text>
<claim-text>delaying storing the redo information to durable storage as long as (1) a data block associated with the processed transaction is not durably stored and (2) the data block is not transferred to another site of the plurality of sites; and</claim-text>
<claim-text>storing the redo information to the durable storage in response to detecting that (1) the data block is about to be durably stored or (2) the data block is about to be transferred to another site of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the data block is a first data block, wherein the transaction is a first transaction, the redo information is first redo information, and the method further comprises the steps of:
<claim-text>at the first site, processing a second transaction;</claim-text>
<claim-text>generating in the volatile memory second redo information for the processed second transaction;</claim-text>
<claim-text>delaying storing the first redo information and the second redo information to the durable storage as long as (1) the first data block and a second data block associated with the processed second transaction are not durably stored and (2) the first data block and the second data block are not transferred to another site of the plurality of sites; and</claim-text>
<claim-text>storing, using a batch process, the first redo information and the second redo information to the durable storage in response to detecting that (1) the first data block or the second data block is about to be durably stored or (2) the first data block or the second data block is about to be transferred to another site of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising the step of:
<claim-text>determining whether the batch process has completed durably storing the first redo information and the second redo information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. A method for mirroring data between a plurality of sites, comprising:
<claim-text>maintaining, at a first site of the plurality of sites, a record that identifies which changes made to one or more data blocks stored at the first site have had associated redo information replicated to the other sites of the plurality of sites, wherein the first site implements a write-ahead logging scheme;</claim-text>
<claim-text>determining if the first site replicates, to the other sites of the plurality of sites, write transactions that are executed at the first site in the order in which the write transactions were issued; and</claim-text>
<claim-text>if the first site does not replicate, to the other sites of the plurality of sites, write transactions that are executed at the first site in the order in which the write transactions were issued, then durably storing a data block, in the one or more data blocks, associated with a transaction only after the record indicates that any write transactions that have updated the data block at the first site have had their respective redo information replicated to the other sites of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the record is a first record, and further comprising the steps of:
<claim-text>maintaining, at the first site, a second record that identifies which changes made to the one or more data blocks stored at the first site have had associated redo information logged to persistent storage at the first site; and</claim-text>
<claim-text>if the first site does replicate, to the other sites of the plurality of sites, write transactions that are executed at the first site in the order in which the write transactions were issued, then durably storing the data block after the second record indicates that any write transactions that have updated the data block at the first site have had their respective redo information logged to persistent storage at the first site.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the first site replicates write transactions to the other sites of the plurality of sites asynchronously to the completion of the write transaction at the first site.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the second record identifies which changes are made to the one or more data blocks stored at the first site have had associated redo information logged to persistent storage by identifying a portion of a redo log file, and wherein all changes in the identified portion of the redo log file have been logged to persistent storage.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, further comprising the step of:
<claim-text>releasing a lock associated with the data block after the first record indicates that redo information associated with changes made to the data block has been replicated to the other sites of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, further comprising the step of:
<claim-text>if a particular site of the plurality of sites becomes inoperable, then initiating recovery of the particular site after it is determined that all messages transmitted from the particular site to each other site of the plurality of sites have been received at their destination.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, further comprising the steps of:
<claim-text>at each site of the plurality of sites, determining if a data structure is to be replicated to each other site of the plurality of sites; and</claim-text>
<claim-text>replicating the data structure to each other site of the plurality of sites unless it is determined that the data structure is not to be replicated to each other site of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the record identifies which changes are made to the one or more data blocks stored at the first site have had associated redo information replicated to the other sites of the plurality of sites by identifying a portion of a redo log file, and wherein all changes in the identified portion of the redo log file have been replicated to the other sites of the plurality of sites.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. A method for minoring data between a plurality of sites, wherein the plurality of sites includes a first site, comprising:
<claim-text>at the first site, durably storing a data block prior to durably storing redo information about changes made to the data block; and</claim-text>
<claim-text>at the first site, durably storing the redo information after the changes have been replicated to the other sites in the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The method of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the data block is in a plurality of data blocks, wherein changes made to the plurality of data blocks are performed by transactions issued by a single process, and further comprising the step of:
<claim-text>determining if a set of transactions issued by the single process have completed, wherein the set of transactions made the changes to the plurality of data blocks.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The method of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the data block is in a plurality of data blocks, wherein changes made to the plurality of data blocks are performed by transactions issued by two or more processes, and further comprising the step of:
<claim-text>determining when the changes have been replicated to the other sites in the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The method of <claim-ref idref="CLM-00024">claim 24</claim-ref>, further comprising the step of:
<claim-text>if a particular site of the plurality of sites becomes inoperable, then initiating recovery of the particular site after it is determined that all messages transmitted from the particular site to each other site of the plurality of sites have been received at their destination.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The method of <claim-ref idref="CLM-00024">claim 24</claim-ref>, further comprising the steps of:
<claim-text>at each site of the plurality of sites, determining if a data structure is to be replicated to each other site of the plurality of sites; and</claim-text>
<claim-text>replicating the data structure to each other site of the plurality of sites unless it is determined that the data structure is not to be replicated to each other site of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. A machine-readable medium carrying one or more sequences of instructions for mirroring data between a plurality of sites, wherein the machine-readable medium is one of a volatile medium or a non-volatile medium, wherein execution of the one or more sequences of instructions by one or more processors causes the one or more processors to perform the steps of:
<claim-text>maintaining, at a first site of the plurality of sites, a record that identifies which transactions that have been executed at the first site have had their redo information replicated to the other sites of the plurality of sites;</claim-text>
<claim-text>determining a priority value associated with a transaction that is to be performed at the first site, wherein the transaction specifies a modification to a data block;</claim-text>
<claim-text>if the priority value is a first value in a set of possible values, then committing the transaction only after the record indicates that redo information associated with the transaction has been replicated to the other sites of the plurality of sites; and</claim-text>
<claim-text>if the priority value is a second value in said set of possible values, then committing the transaction even though the record does not indicate that redo information associated with the transaction has been replicated to the other sites of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. The machine-readable medium of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the first value indicates that the transaction should not be lost if the first site becomes inoperable.</claim-text>
</claim>
<claim id="CLM-00031" num="00031">
<claim-text>31. The machine-readable medium of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the second value indicates the transaction can be lost if the first site becomes inoperable.</claim-text>
</claim>
<claim id="CLM-00032" num="00032">
<claim-text>32. The machine-readable medium of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the step of:
<claim-text>determining whether all other transactions that have committed before the transaction has committed have had their respective redo information replicated to the other sites of the plurality of sites by comparing a commit record associated with the transaction to the record.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00033" num="00033">
<claim-text>33. The machine-readable medium of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the record is a first record, and wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the step of:
<claim-text>maintaining, at the first site, a second record that identifies which transactions that have executed at the first site have had their redo information logged to persistent storage at the first site.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00034" num="00034">
<claim-text>34. The machine-readable medium of <claim-ref idref="CLM-00033">claim 33</claim-ref>, wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the step of:
<claim-text>if the priority value is the second value in the set of possible values, then committing the transaction after the second record indicates that the redo information generated by the transaction has been stored to persistent storage at the first site.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00035" num="00035">
<claim-text>35. The machine-readable medium of <claim-ref idref="CLM-00033">claim 33</claim-ref>, wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the step of:
<claim-text>determining which transactions that have executed at the first site have had their redo information logged to persistent storage by comparing a commit record associated with the transaction to the second record.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00036" num="00036">
<claim-text>36. The machine-readable medium of <claim-ref idref="CLM-00033">claim 33</claim-ref>, wherein the second record identifies which transactions that have executed at the first site have had their redo information logged to persistent storage at the first site by identifying a portion of a redo log file, and wherein all transactions reflected in the identified portion of the redo log file have been logged to persistent storage at the first site.</claim-text>
</claim>
<claim id="CLM-00037" num="00037">
<claim-text>37. The machine-readable medium of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the step of:
<claim-text>if the priority value is the second value in the set of possible values, then committing the transaction before the record indicates that the redo information generated by the transaction has been replicated to the other sites of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00038" num="00038">
<claim-text>38. The machine-readable medium of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the step of:
<claim-text>if a particular site of the plurality of sites becomes inoperable, then initiating recovery of the particular site after it is determined that all messages transmitted from the particular site to each other site of the plurality of sites have been received at their destination.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00039" num="00039">
<claim-text>39. The machine-readable medium of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the steps of:
<claim-text>at each site of the plurality of sites, determining if a data structure is to be replicated to each other site of the plurality of sites; and</claim-text>
<claim-text>replicating the data structure to each other site of the plurality of sites unless it is determined that the data structure is not to be replicated to each other site of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00040" num="00040">
<claim-text>40. The machine-readable medium of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the record identifies which transactions that have been executed at the first site have had their redo information replicated to the other sites of the plurality of sites by identifying a portion of a redo log file, and wherein all transactions reflected in the identified portion of the redo log file have been replicated to the other sites of the plurality of sites.</claim-text>
</claim>
<claim id="CLM-00041" num="00041">
<claim-text>41. A machine-readable medium carrying one or more sequences of instructions for storing data, wherein the machine-readable medium is one of a volatile medium or a non-volatile medium, wherein execution of the one or more sequences of instructions by one or more processors causes the one or more processors to perform the steps of:
<claim-text>at a first site in a plurality of sites, processing a transaction;</claim-text>
<claim-text>generating in volatile memory redo information for the processed transaction;</claim-text>
<claim-text>delaying storing the redo information to durable storage as long as (1) a data block associated with the processed transaction is not durably stored and (2) the data block is not transferred to another site of the plurality of sites; and</claim-text>
<claim-text>storing the redo information to the durable storage in response to detecting that (1) the data block is about to be durably stored or (2) the data block is about to be transferred to another site of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00042" num="00042">
<claim-text>42. The machine-readable medium of <claim-ref idref="CLM-00041">claim 41</claim-ref>, wherein the data block is a first data block, wherein the transaction is a first transaction, the redo information is a first redo information, and wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the steps of:
<claim-text>at the first site, processing a second transaction;</claim-text>
<claim-text>generating in the volatile memory second redo information for the processed second transaction;</claim-text>
<claim-text>delaying storing the first redo information and the second redo information to the durable storage as long as (1) the first data block and a second data block associated with the processed second transaction are not durably stored and (2) the first data block and the second data block are not transferred to another site of the plurality of sites; and</claim-text>
<claim-text>storing, using a batch process, the first redo information and the second redo information to the durable storage in response to detecting that (1) the first data block or the second data block is about to be durably stored or (2) the first data block or the second data block is about to be transferred to another site of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00043" num="00043">
<claim-text>43. The machine-readable medium of <claim-ref idref="CLM-00042">claim 42</claim-ref>, wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the step of:
<claim-text>determining whether the batch process has completed durably storing the first redo information and the second redo information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00044" num="00044">
<claim-text>44. A machine-readable medium carrying one or more sequences of instructions for mirroring data between a plurality of sites, wherein the machine-readable medium is one of a volatile medium or a non-volatile medium, wherein execution of the one or more sequences of instructions by one or more processors causes the one or more processors to perform the steps of:
<claim-text>maintaining, at a first site of the plurality of sites, a record that identifies which changes made to one or more data blocks stored at the first site have had associated redo information replicated to the other sites of the plurality of sites, wherein the first site implements a write-ahead logging scheme;</claim-text>
<claim-text>determining if the first site replicates, to the other sites of the plurality of sites, write transactions that are executed at the first site in the order in which the write transactions were issued; and</claim-text>
<claim-text>if the first site does not replicate, to the other sites of the plurality of sites, write transactions that are executed at the first site in the order in which the write transactions were issued, then durably storing a data block, in the one or more data blocks, associated with a transaction only after the record indicates that any write transactions that have updated the data block at the first site have had their respective redo information replicated to the other sites of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00045" num="00045">
<claim-text>45. The machine-readable medium of <claim-ref idref="CLM-00044">claim 44</claim-ref>, wherein the record is a first record, and wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the steps of:
<claim-text>maintaining, at the first site, a second record that identifies which changes made to the one or more data blocks stored at the first site have had associated redo information logged to persistent storage at the first site; and</claim-text>
<claim-text>if the first site does replicate, to the other sites of the plurality of sites, write transactions that are executed at the first site in the order in which the write transactions were issued, then durably storing the data block after the second record indicates that any write transactions that have updated the data block at the first site have had their respective redo information logged to persistent storage at the first site.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00046" num="00046">
<claim-text>46. The machine-readable medium of <claim-ref idref="CLM-00045">claim 45</claim-ref>, wherein the first site replicates write transactions to the other sites of the plurality of sites asynchronously to the completion of the write transaction at the first site.</claim-text>
</claim>
<claim id="CLM-00047" num="00047">
<claim-text>47. The machine-readable medium of <claim-ref idref="CLM-00045">claim 45</claim-ref>, wherein the second record identifies which changes are made to the one or more data blocks stored at the first site have had associated redo information logged to persistent storage by identifying a portion of a redo log file, and wherein all changes in the identified portion of the redo log file have been logged to persistent storage.</claim-text>
</claim>
<claim id="CLM-00048" num="00048">
<claim-text>48. The machine-readable medium of <claim-ref idref="CLM-00044">claim 44</claim-ref>, wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the step of:
<claim-text>releasing a lock associated with the data block after the first record indicates that redo information associated with changes made to the data block has been replicated to the other sites of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00049" num="00049">
<claim-text>49. The machine-readable medium of <claim-ref idref="CLM-00044">claim 44</claim-ref>, wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the step of:
<claim-text>if a particular site of the plurality of sites becomes inoperable, then initiating recovery of the particular site after it is determined that all messages transmitted from the particular site to each other site of the plurality of sites have been received at their destination.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00050" num="00050">
<claim-text>50. The machine-readable medium of <claim-ref idref="CLM-00044">claim 44</claim-ref>, wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the steps of:
<claim-text>at each site of the plurality of sites, determining if a data structure is to be replicated to each other site of the plurality of sites; and</claim-text>
<claim-text>replicating the data structure to each other site of the plurality of sites unless it is determined that the data structure is not to be replicated to each other site of the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00051" num="00051">
<claim-text>51. The machine-readable medium of <claim-ref idref="CLM-00044">claim 44</claim-ref>, wherein the record identifies which changes are made to the one or more data blocks stored at the first site have had associated redo information replicated to the other sites of the plurality of sites by identifying a portion of a redo log file, and wherein all changes in the identified portion of the redo log file have been replicated to the other sites of the plurality of sites.</claim-text>
</claim>
<claim id="CLM-00052" num="00052">
<claim-text>52. A machine-readable medium carrying one or more sequences of instructions for mirroring data between a plurality of sites, wherein the plurality of sites includes a first site, wherein the machine-readable medium is one of a volatile medium or a non-volatile medium, wherein execution of the one or more sequences of instructions by one or more processors causes the one or more processors to perform the steps of:
<claim-text>at the first site, durably storing a data block prior to durably storing redo information about changes made to the data block; and</claim-text>
<claim-text>at the first site, durably storing the redo information after the changes have been replicated to the other sites in the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00053" num="00053">
<claim-text>53. The machine-readable medium of <claim-ref idref="CLM-00052">claim 52</claim-ref>, wherein the data block is in a plurality of data blocks, wherein changes made to the plurality of data blocks are performed by transactions issued by a single process, and wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the step of:
<claim-text>determining if a set of transactions issued by the single process have completed, wherein the set of transactions made the changes to the plurality of data blocks.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00054" num="00054">
<claim-text>54. The machine-readable medium of <claim-ref idref="CLM-00052">claim 52</claim-ref>, wherein the data block is in a plurality of data blocks, wherein changes made to the plurality of data blocks are performed by transactions issued by two or more processes, and wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the step of:
<claim-text>determining when the changes have been replicated to the other sites in the plurality of sites.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00055" num="00055">
<claim-text>55. The machine-readable medium of <claim-ref idref="CLM-00052">claim 52</claim-ref>, wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the step of:
<claim-text>if a particular site of the plurality of sites becomes inoperable, then initiating recovery of the particular site after it is determined that all messages transmitted from the particular site to each other site of the plurality of sites have been received at their destination.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00056" num="00056">
<claim-text>56. The machine-readable medium of <claim-ref idref="CLM-00052">claim 52</claim-ref>, wherein execution of the one or more sequences of instructions by the one or more processors causes the one or more processors to further perform the steps of:
<claim-text>at each site of the plurality of sites, determining if a data structure is to be replicated to each other site of the plurality of sites; and</claim-text>
<claim-text>replicating the data structure to each other site of the plurality of sites unless it is determined that the data structure is not to be replicated to each other site of the plurality of sites.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
