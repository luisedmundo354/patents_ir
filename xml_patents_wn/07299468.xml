<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07299468-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07299468</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10425470</doc-number>
<date>20030429</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1014</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>9</main-group>
<subgroup>46</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>9</main-group>
<subgroup>455</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>7</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>12</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>718104</main-classification>
<further-classification>718  1</further-classification>
<further-classification>718100</further-classification>
<further-classification>707 10</further-classification>
<further-classification>711  6</further-classification>
</classification-national>
<invention-title id="d0e53">Management of virtual machines to utilize shared resources</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4916608</doc-number>
<kind>A</kind>
<name>Shultz</name>
<date>19900400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>718104</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5506975</doc-number>
<kind>A</kind>
<name>Onodera</name>
<date>19960400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5592625</doc-number>
<kind>A</kind>
<name>Sandberg</name>
<date>19970100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39520008</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5692192</doc-number>
<kind>A</kind>
<name>Sudo</name>
<date>19971100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>395675</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5884077</doc-number>
<kind>A</kind>
<name>Suzuki</name>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>395675</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5991893</doc-number>
<kind>A</kind>
<name>Snider</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6003066</doc-number>
<kind>A</kind>
<name>Ryan et al.</name>
<date>19991200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709201</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6075938</doc-number>
<kind>A</kind>
<name>Bugnion et al.</name>
<date>20000600</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39550048</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6081833</doc-number>
<kind>A</kind>
<name>Okamoto</name>
<date>20000600</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709213</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6148378</doc-number>
<kind>A</kind>
<name>Bordaz</name>
<date>20001100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>711147</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6170045</doc-number>
<kind>B1</kind>
<name>Bobak et al.</name>
<date>20010100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>711169</main-classification></classification-national>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>6205528</doc-number>
<kind>B1</kind>
<name>Kingsbury</name>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>711170</main-classification></classification-national>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>6389482</doc-number>
<kind>B1</kind>
<name>Bobak et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709312</main-classification></classification-national>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>6438663</doc-number>
<kind>B1</kind>
<name>Agarwal et al.</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>711148</main-classification></classification-national>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>6477560</doc-number>
<kind>B1</kind>
<name>Murayama et al.</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709104</main-classification></classification-national>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>6542926</doc-number>
<kind>B2</kind>
<name>Zalewski et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709213</main-classification></classification-national>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>6732220</doc-number>
<kind>B2</kind>
<name>Babaian et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711  6</main-classification></classification-national>
</citation>
<citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>6738977</doc-number>
<kind>B1</kind>
<name>Berry et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39550048</main-classification></classification-national>
</citation>
<citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>7089558</doc-number>
<kind>B2</kind>
<name>Baskey et al.</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>718104</main-classification></classification-national>
</citation>
<citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>7136800</doc-number>
<kind>B1</kind>
<name>Vega</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>703 23</main-classification></classification-national>
</citation>
<citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>7158972</doc-number>
<kind>B2</kind>
<name>Marsland</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707 10</main-classification></classification-national>
</citation>
<citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2001/0047482</doc-number>
<kind>A1</kind>
<name>Harris et al.</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2002/0013802</doc-number>
<kind>A1</kind>
<name>Mori et al.</name>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709  1</main-classification></classification-national>
</citation>
<citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2002/0016812</doc-number>
<kind>A1</kind>
<name>Uchishiba et al.</name>
<date>20020200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709104</main-classification></classification-national>
</citation>
<citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2003/0037178</doc-number>
<kind>A1</kind>
<name>Vessey et al.</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709319</main-classification></classification-national>
</citation>
<citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2003/0065676</doc-number>
<kind>A1</kind>
<name>Gbadegesin et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>7071041</main-classification></classification-national>
</citation>
<citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>2004/0010787</doc-number>
<kind>A1</kind>
<name>Traut et al.</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>718  1</main-classification></classification-national>
</citation>
<citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>2004/0221285</doc-number>
<kind>A1</kind>
<name>Donovan et al.</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>2004/0230972</doc-number>
<kind>A1</kind>
<name>Donovan et al.</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>718  1</main-classification></classification-national>
</citation>
<citation>
<patcit num="00030">
<document-id>
<country>JP</country>
<doc-number>63-036445</doc-number>
<date>19880200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00031">
<document-id>
<country>JP</country>
<doc-number>2112055</doc-number>
<kind>A</kind>
<date>19900400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00032">
<document-id>
<country>JP</country>
<doc-number>07-013823</doc-number>
<date>19950100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00033">
<document-id>
<country>JP</country>
<doc-number>09-319653</doc-number>
<date>19971200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00034">
<document-id>
<country>JP</country>
<doc-number>2000-215071</doc-number>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00035">
<document-id>
<country>JP</country>
<doc-number>2001142725</doc-number>
<kind>A</kind>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00036">
<document-id>
<country>JP</country>
<doc-number>20010216172</doc-number>
<kind>A</kind>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00037">
<document-id>
<country>JP</country>
<doc-number>2002-073358</doc-number>
<date>20020300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00038">
<document-id>
<country>JP</country>
<doc-number>2002-140202</doc-number>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00039">
<document-id>
<country>WO</country>
<doc-number>WO 00/73902</doc-number>
<kind>A1</kind>
<date>20001200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00040">
<othercit>Uhlig et al., “Towards Scalable Multiprocessor Virtual Machines”, Proceedings of the 3<sup>RD </sup>Virtula Machine Research &amp; Technology Symposium, CA, 2004, pp. 1-14.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00041">
<othercit>IBM TDB vol. 37 No. 06A Jun. 1994 “Shared Memory Cluster—A Scalable Multiprocessor Design” pp. 503-507.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00042">
<othercit>IBM TDB vol. 35 No. 18 Jun. 1992 “Logically Shared Memory” pp. 44-49.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00043">
<othercit>U.S. Appl. No. 10/280,987 entitled “System and Method for Transferring Data Between Virtual Machines or Other Computer Entities” filed on Oct. 24, 2002 by Shultz and Tkatschow.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00044">
<othercit>Azzedin et al., “Integrating Trust Into Grid Resource Management Systems”, Proceedings of the International Conference on Parallel Processing, 2002, pp. 1-8.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00045">
<othercit>Back et al, “Processes in Kaffeos: Isolation, Resource Management, and Sharing in Java”, Symposium on Operating Systems Design and Implementation, 4th, Sand Diego, Oct. 22-25, 2000, Proceedings of OSDI 2000; 14 pages.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00046">
<othercit>Bagley et al, “Sharing Data and Services in a Virtual Machine System”, IBM Reseach Laboratory; pp. 82-88.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00047">
<othercit>Binder et al, “Portable Resource Control in Java”, OOPSLA 01 Tampa, Florida, ACM 2001; pp. 139-155.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00048">
<othercit>Cosell et al, “An Operation System for Computer Sharing”, ACM; pp. 75-81.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00049">
<othercit>Yau et al, “Resource Management in Software-Programmable Router Operating Systems”, IEEE, 2001; pp. 489-500.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>8</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>718  1</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>718100-108</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711  6</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>703 23</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>707 10</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>7071041</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>6</number-of-drawing-sheets>
<number-of-figures>6</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20040221290</doc-number>
<kind>A1</kind>
<date>20041104</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Casey</last-name>
<first-name>Christine T.</first-name>
<address>
<city>Endicott</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Shultz</last-name>
<first-name>Steven S.</first-name>
<address>
<city>Endicott</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Tkatschow</last-name>
<first-name>Xenia</first-name>
<address>
<city>Jamesville</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Samodovitz</last-name>
<first-name>Arthur J.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>International Business Machines Corporation</orgname>
<role>02</role>
<address>
<city>Armonk</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>An</last-name>
<first-name>Meng-Al T.</first-name>
<department>2195</department>
</primary-examiner>
<assistant-examiner>
<last-name>To</last-name>
<first-name>Jennifer N.</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A technique for utilizing resources in a virtual machine operating system. The virtual machine operating system comprises a multiplicity of virtual machines. A share of resources is allocated to each of the virtual machines. Utilization by one of the virtual machines of the resources allocated to the one virtual machine is automatically monitored. If the one virtual machine needs additional resources, the one virtual machine is automatically cloned. The clone is allocated a share of the resources taken from the shares of other of the virtual machines, such that the resultant shares allocated to the one virtual machine and the clone together are greater than the share allocated to the one virtual machine before the one virtual machine was cloned. The clone performs work with its resources that would have been performed by the one virtual machine if not for the existence of said clone.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="173.82mm" wi="253.41mm" file="US07299468-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="251.21mm" wi="173.06mm" orientation="landscape" file="US07299468-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="253.66mm" wi="174.33mm" orientation="landscape" file="US07299468-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="255.27mm" wi="178.65mm" orientation="landscape" file="US07299468-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="261.37mm" wi="179.49mm" orientation="landscape" file="US07299468-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="259.16mm" wi="173.48mm" orientation="landscape" file="US07299468-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="106.26mm" wi="176.95mm" orientation="landscape" file="US07299468-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">The invention relates generally to computer systems, and deals more particularly with management of virtual machines to effectively allocate and utilize virtual resources.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">A virtual machine operating system is well known today, and includes a common base portion and separate user portions formed by the common base portion. In an IBM z/VM operating system, the common base portion is called the “Control Program” or “CP” and each user portion is called a “virtual machine” or “guest”. A virtual machine or guest is a virtual sharing/partitioning of real resources such as real memory, CPU and I/O. Examples of I/O devices are DASD, network cards, printers and displays. A guest operating system executes/runs on each virtual machine, and one or more applications run on the guest operating system. Each application and guest operating system behave as if they are running on their own private, real computer.</p>
<p id="p-0004" num="0003">Typically, each virtual machine is allocated a finite amount of resources, such as private virtual memory, real CPU and real I/O. The amounts allocated are intended to accommodate maximum needs of the virtual machine during most operating conditions. However, during operation of the virtual machine, the virtual machine has varying needs for each of these resources. During some periods, the virtual machine may be executing applications requiring complex arithmetic computations which are CPU intensive and during other periods the virtual machine may be executing applications such as data backup applications which hardly use the CPU. Likewise, during some periods the virtual machine may be executing applications such as data base searching, reading and writing applications which require much private memory and during other periods the virtual machine may be executing applications such as text editing applications which require little private memory. Likewise, during some periods the virtual machine may be executing applications such as data backup applications which require substantial I/O activity and during other periods the virtual machine may be executing applications such as arithmetic computation applications which require little I/O activity. During some of the periods of operation, the virtual machine may need more of a virtual resource than has been allocated, in which case the finite virtual resource allocation may constrain the operation of the virtual machine. During other periods of operation, the virtual machine does not utilize its full allocation of one or more virtual resources, so these virtual resources may be wasted in the sense that another virtual machine could have used the excess allocation.</p>
<p id="p-0005" num="0004">The following is an example of how a known virtual machine utilizes its CPU to perform work items. Each virtual machine has its own dispatch function which consists of its synchronization or lock function, work queue assignment function, work scheduler and associated work queue of work items or tasks assigned by and to the virtual machine. The synchronization or lock function, work queue assignment function, work scheduler and the work queue are all private to the virtual machine. The synchronization or lock function manages locks for a work queue to control which work items must run sequentially and which tasks can run in parallel. A work queue assignment function is a program function within the virtual machine which adds work items to the work queue of the virtual machine when generated by the virtual machine. The work items are added to the queue at a position based on an assignment algorithm. The assignment algorithm may consider such factors as relative priority level of each work item and the order in which work items were created, i.e. first in first out. Each work item on the queue includes information indicating its type, and therefore, which function within the virtual machine is best suited to handle it. A “work scheduler” is a program function which schedules each of the work items on its queue for execution. Generally, the work scheduler removes work items from an end of the queue. The work scheduler passes the work items to the appropriate function within the virtual machine for execution by the virtual CPU. If the work items on the work queue are CPU intensive and the allocation of virtual CPU is inadequate, the work queue may grow in length as the existing work items on the queue are removed more slowly than new work items are added to the queue. In such a case, the virtual machine will fall behind in its work.</p>
<p id="p-0006" num="0005">It was also known for multiple virtual machines to share a work queue to distribute the work items amongst the virtual machines and their respective shares of real CPUs. A server virtual machine was utilized for the purpose of “hosting” this shared work queue for the other, “working” virtual machines. The shared work queue resides in memory private to the server virtual machine. When a working virtual machine creates a new work item, and the work queue assignment function for this working virtual machine decides to send this new work item to the server virtual machine, it uses a communication protocol (e.g. TCP/IP) and a virtual I/O device driver to send that work item to this server virtual machine. Then, the server virtual machine places the new work item on the shared work queue in an order determined by the server virtual machine. When the virtual CPU within a working virtual machine is available to execute a work item on the shared work queue, the work scheduler within this working virtual machine uses a communication protocol and virtual I/O device driver to make that request to the server virtual machine. In response, the server virtual machine uses a communication protocol to send a work item to the working virtual machine that made the request. While this arrangement provides a shared work queue, it requires a high overhead communication protocol to both send a work item to the work queue and obtain a work item from the work queue. Furthermore, the server virtual machine attempts to balance the load among the working virtual machines by monitoring the working virtual machines and estimating which working virtual machine will be able to handle the work item most expeditiously. The server virtual machine must also be able to re-balance the load among working virtual machines when working virtual machines are dynamically added and/or deleted. Still further, the server virtual machine must synchronize the work items as determined by its private synchronization function. All these server virtual machine functions require considerable communication and “overhead” between the server virtual machine and the working virtual machines.</p>
<p id="p-0007" num="0006">An object of the present invention is to provide functionality in a virtual machine operating system which helps to match the needs of the application(s) running on each virtual machine to the available resources.</p>
<p id="p-0008" num="0007">Another object of the present invention is to provide functionality in a virtual machine operating system of the foregoing type which operates dynamically to help match the changing needs of the application(s) running on each virtual machine to the available resources.</p>
<p id="p-0009" num="0008">Another object of the present invention is to provide functionality of the foregoing type which also considers limits set by the system administrator for resources available to the application(s) running on each virtual machine.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0010" num="0009">The invention resides in a system, computer program product and method for utilizing resources in a virtual machine operating system. The virtual machine operating system comprises a multiplicity of virtual machines. A share of resources is allocated to each of the virtual machines. Utilization by one of the virtual machines of the resources allocated to the one virtual machine is automatically monitored. If the one virtual machine needs additional resources, the one virtual machine is automatically cloned. The clone is allocated a share of the resources taken from the shares of other of the virtual machines, such that the resultant shares allocated to the one virtual machine and the clone together are greater than the share allocated to the one virtual machine before the one virtual machine was cloned.</p>
<p id="p-0011" num="0010">According to one feature of the present invention, the clone performs work with its resources that would have been performed by the one virtual machine if not for the existence of said clone.</p>
<p id="p-0012" num="0011">According to another feature of the present invention, the one virtual machine and the clone share a work queue, such that both the one virtual machine with its resources and the clone with its resources perform work items on the shared work queue.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE FIGURES</heading>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a computer system with multiple virtual machines in one state according to the present invention.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of the computer system of <figref idref="DRAWINGS">FIG. 1</figref> with multiple virtual machines in another state according to the present invention</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of a synchronization or lock function that allows a virtual machine and its clone(s) to be collectively synchronized.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 4</figref> is a flow chart illustrating the synchronization function of <figref idref="DRAWINGS">FIG. 3</figref> and associated operation of the virtual machine and its clone(s).</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIGS. 5(</figref><i>a</i>) and <b>5</b>(<i>b</i>) form a flow chart illustrating operation of a resource manager within the computer system of <figref idref="DRAWINGS">FIG. 1</figref> to create and delete clones of a virtual machine.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0018" num="0017">Referring now to the drawings in detail wherein like reference numbers indicate like elements throughout, <figref idref="DRAWINGS">FIG. 1</figref> illustrates a computer system generally designated <b>10</b> in accordance with the present invention. Computer system <b>10</b> includes a physical computer <b>20</b> (which includes a CPU <b>23</b>) and a virtual machine operating system <b>11</b>. By way of example, the virtual machine operating system can be IBM z/VM version 4.2.0 or 4.3.0 modified to include the present invention. The details of z/VM 4.2.0 are disclosed in IBM publication “z/VM 4.2.0 General Information” (Document Number: GC24-5991-03) which is available from International Business Machines Corp. at PO Box 29570, IBM Publications, Raleigh, N.C. 27626-0570 or on the WWW at the website of IBM selecting/shop/publications/order. This publication is hereby incorporated by reference as part of the present disclosure. Operating system <b>11</b> executes in the physical computer <b>10</b> such as an IBM zSeries mainframe although the present invention can be implemented in other server computers or personal computers as well. Operating system <b>11</b> includes a common base portion <b>21</b> (called “CP” in the z/VM operating system).</p>
<p id="p-0019" num="0018">The systems administrator, during installation of the virtual machine operating system <b>11</b>, defines user virtual machines <b>12</b>, <b>14</b>, <b>16</b> and resource manager virtual machine <b>17</b> in a directory <b>191</b>. The directory <b>191</b> contains a name or identifier of each virtual machine, a “soft” limit for allocation of virtual and real resources to each virtual machine and a specification of a number of permitted clones of each virtual machine. The systems administrator can also specify in the directory <b>191</b> an initial virtual and real resource allocation for each virtual machine. In the absence of such a specification, each of the virtual machines shares equally in the total available virtual and real resources. Based on the “default” allocation, each of the virtual machines <b>12</b>, <b>14</b>, <b>16</b> and <b>17</b> initially has one quarter of the total virtual and real resources. In response to these definitions, common base portion <b>21</b> logically partitions the resources (including the CPU, I/O and memory) of the physical computer to form user portions <b>12</b>, <b>14</b> and <b>16</b> and resource manager portion <b>17</b> (called “virtual machines” or “guests virtual machines” in the z/VM operating system). The resource manager virtual machine <b>17</b> is responsible for creating and deleting virtual machine clones, as described below. The common base portion also performs functions such as virtualizing memory, virtualizing I/O devices and virtualizing CPU.</p>
<p id="p-0020" num="0019">Guest operating systems <b>22</b>, <b>24</b> and <b>26</b> execute on user portions <b>12</b>, <b>14</b> and <b>16</b>, respectively, and applications <b>32</b>, <b>34</b> and <b>36</b> execute on guest operating systems <b>22</b>, <b>24</b> and <b>26</b> respectively. There may be multiple applications executing on each operating system. By way of example, guest operating systems <b>22</b> and <b>24</b> are the Linux (TM of Linus Torvalds) operating system and operating system <b>26</b> is an IBM CMS operating system. Other guest operating systems executing on user portions are also feasible such as Microsoft Windows (tm) operating system, Unix (tm) operating system, Sun Microsystems Solaris (tm) operating system or Hewlett Packard HP UX operating system. By way of example, applications <b>32</b>, <b>34</b> and <b>36</b> can be IBM DB2 data base management application, IBM WebSphere application, communications applications, etc. The nature of applications <b>32</b>, <b>34</b> and <b>36</b> form no part of the present invention, except that they may generate work items.</p>
<p id="p-0021" num="0020">Each virtual machine has its own private memory for its private data, applications and operating system functions such as Work Queue Assignment Functions <b>62</b>, <b>64</b> and <b>66</b> (“WQAFs”) and work schedulers <b>42</b>, <b>44</b> and <b>46</b> in user virtual machines <b>12</b>, <b>14</b> and <b>16</b>, respectively. Consequently, each virtual machine is afforded a measure of privacy from the other virtual partitions as in separate physical computers. The logical partition between virtual machines is also provided by the allocation of a share of real CPU, a share of real I/O and virtual private memory to each virtual machine. A share of real CPU is a time share of the total system's real CPU(s). The CPU share appears to the guest operating system as its own CPU. Likewise, a share of real I/O is a time share of the system's total real I/O capability. The I/O resources comprise the processing power devoted to I/O, e.g. “Channels” on an IBM zSeries mainframe. Virtual memory is a series of virtual addresses assigned to a virtual machine, which are translated by CP into real addresses of real memory. As explained in more detail below, each WQAF <b>62</b>, <b>64</b> and <b>66</b> assigns each work item created by its own virtual machine to a proper location in its respective work queue <b>52</b>, <b>54</b> or <b>56</b> in shared memory based on its assignment algorithm. Examples of work items are to read or write data, execute an application, make a request to an application, etc. The work items are initiated by a user of the application and passed via the application to the guest operating system for handling. The assignment algorithm may be based on priority level of each work item, and/or first in first out, etc. If the assignment algorithm is simply first in first out, then the WQAF assigns each new work item to the beginning of the work queue, so it is last to be removed. If the assignment algorithm is based on priority level, then the WQAF assigns each new work item to a position within the work queue before other work items of lower priority and after work items of the same priority (to prevent work items from becoming stale) or higher priority. Each WQAF also monitors and updates a status of the respective virtual machine as “idle” or “not idle” as described below. Each scheduler schedules the execution of work items from its virtual machines' work queue, and generally removes work items from the end of the work queue.</p>
<p id="p-0022" num="0021">Computer <b>10</b> also includes a memory area <b>25</b> which is shared by all of the virtual machines <b>12</b>, <b>14</b> and <b>16</b>. Being “shared” each virtual machine can directly access the shared memory <b>25</b> and the data and data structures (including lock structures) stored in the shared memory by appropriate address, when it knows the address. The work queues <b>52</b>, <b>54</b> and <b>56</b> for the WQAFs <b>62</b>, <b>64</b> and <b>66</b> and respective schedulers <b>42</b>, <b>44</b> and <b>46</b> are located in shared memory (even though the WQAFs and schedulers are all in the private memory of the respective virtual machines). Consequently, each WQAF can access all the work queues to add a work item to any of the work queues, when it knows the address of the work queues. In the preferred embodiment of the present invention, each WQAF is programmed to add a work item only to the work queue dedicated to its virtual machine and its clones, and each scheduler is programmed to remove work items only from the work queue dedicated to its virtual machine and its clones. Work queue <b>52</b> is dedicated to virtual machine <b>12</b> and its clones, work queue <b>54</b> is dedicated to virtual machine <b>14</b> and its clones, and work queue <b>56</b> is dedicated to virtual machine <b>16</b> and its clones.</p>
<p id="p-0023" num="0022">In the state illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, work queue <b>52</b> has three work items <b>70</b>, <b>71</b> and <b>73</b> acquired from virtual machine <b>12</b> by action of WQAF <b>62</b>, work queue <b>54</b> is empty, and work queue <b>56</b> has three work items <b>72</b>, <b>74</b> and <b>76</b> acquired from virtual machine <b>16</b>. Also in the state illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, virtual machine <b>12</b> will acquire work item <b>73</b> from work queue <b>52</b> by action of scheduler <b>42</b>, and virtual machine <b>16</b> will acquire work item <b>76</b> from work queue <b>56</b> by action of scheduler <b>46</b>. A control block <b>58</b> indicates the current state, “idle” or “non idle”, of the virtual machines and which, if any, of the work items from each work queue is the next to be scheduled. In the state illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, virtual machine <b>12</b> is idle with its work queue pointer in scheduler <b>42</b> pointing to work item <b>73</b>. Also in the state illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, virtual machine <b>14</b> is idle with its work queue pointer in scheduler <b>44</b> indicating “null” because there are currently no work items in work queue <b>54</b>. Also in the state illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, virtual machine <b>16</b> is “not idle”; it is currently performing a work item previously acquired from one of the work queues. The work queue pointer of scheduler <b>46</b> within virtual machine <b>16</b> is currently indicating work item <b>76</b>, so this work item has not yet been removed by scheduler <b>46</b> for execution by virtual machine <b>16</b>.</p>
<p id="p-0024" num="0023">After each virtual machine completes a work item or receives an interrupt, it alerts its scheduler to checks control block <b>58</b> to determine if the respective work queue contains a work item. If so, the scheduler can remove the work item indicated by the respective work queue pointer, parse it to determine the appropriate function within the virtual machine for handling, and then pass it to that function for handling. Some of the work items are CPU intensive, others are I/O device intensive and still others require substantial private memory of the virtual machine. Conversely, some of the work items require little CPU activity, others require little or no I/O activity and still others require little private memory of the virtual machine. It is often the case that work items executed during certain periods of time are virtual resource intensive and work items executed during other periods of time require little virtual resources. For example, if virtual machine <b>12</b> is executing an application that gets heavy use at a certain time of day, then virtual machine <b>12</b> may require substantial virtual resources then. Conversely, the same application may be substantially idle at another time of day and require little virtual resources then. In the state illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, there are four virtual machines, and by default, each has been allocated twenty five percent of the total virtual resources available.</p>
<p id="p-0025" num="0024">A resource monitor function <b>84</b> within the common base portion routinely monitors the utilization level of each virtual and real resource by each virtual machine and the system's total real resource utilization. Resource monitor <b>84</b> stores these levels in memory as usage records <b>85</b>. The real CPU utilization of each virtual machine is measured by how much processor time each virtual machine uses when it is operated. The real I/O utilization by each virtual machine is measured by counting the number of I/O accesses and the time utilized during each such access. The virtual private memory utilization is measured by counting the number of pages referenced by a virtual machine during a time period. A resource manager function <b>217</b> within virtual machine <b>17</b> monitors the level of virtual and real resources being used by each of the user virtual machines <b>12</b>, <b>14</b> and <b>16</b> by reading records <b>85</b>. As described in more detail below, resource manager <b>217</b> compares these usage levels to needs by the virtual machines for virtual resources and soft limits set by the system administrator for virtual and real resources for each virtual machine.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 2</figref> illustrates the state of computer system <b>10</b> a short time after that of <figref idref="DRAWINGS">FIG. 1</figref>. The following is a general explanation of how computer system <b>10</b> changed from the state of <figref idref="DRAWINGS">FIG. 1</figref> to the state of <figref idref="DRAWINGS">FIG. 2</figref>. Between states, the resource manager <b>217</b> determined the current virtual and real resource utilization of virtual machine <b>12</b> from the usage records <b>85</b> (step <b>83</b>). The virtual and real resource utilization comprises the current amount of real CPU utilization, current amount of real I/O utilization and current amount of virtual private memory utilization. In step <b>83</b>, the resource manager <b>217</b> determined that virtual machine <b>12</b> was entitled to or should get more virtual and real resources than currently has, i.e. more than the (default) one quarter of the total virtual and real resources available. The need for additional virtual resources by virtual machine <b>12</b> can be based on additional need for one or more of the virtual or real resources. According to the present invention, resource manager <b>217</b> then created a single virtual machine clone <b>12</b>A of virtual machine <b>12</b>. (Virtual machine clone <b>12</b>B was subsequently created as described below.) Resource manager <b>217</b> created virtual machine clone <b>12</b>A by calling an activate function <b>86</b> within the common base portion, specifying the name or identifier of virtual machine <b>12</b> and requesting that another virtual machine identical to virtual machine <b>12</b> be created (step <b>87</b>). Activate function <b>86</b> created virtual machine clone <b>12</b>A by reading the directory <b>191</b> to determine the guest operating system of virtual machine <b>12</b> and the attributes of virtual machine <b>12</b>, i.e. virtual and real resource allocation and operating privileges. Guest operating system <b>22</b> within virtual machine <b>12</b> includes a list of the applications currently running on virtual machine <b>12</b> and how to fetch and start a copy of them. So, when virtual machine <b>12</b>A begins operating, it fetches and starts a copy <b>32</b>A of application <b>32</b>. With the default of equal allocation of virtual resources amongst all virtual machines, virtual machines <b>12</b> and <b>12</b>A together have forty percent of the total virtual resources available, virtual machine <b>14</b> has twenty percent, virtual machine <b>16</b> has twenty percent and virtual machine <b>17</b> has twenty percent.</p>
<p id="p-0027" num="0026">To collectively utilize the virtual resources of virtual machine <b>12</b> and its virtual machine clone <b>12</b>A, the resource manager <b>212</b> grants to the virtual machine clone <b>12</b>A access to work queue <b>52</b> (step <b>89</b>). This access is “granted” by the resource manager <b>212</b> furnishing to the virtual machine clone <b>12</b>A an authorization to access a portion or segment of the shared memory containing the work queue <b>52</b> of virtual machine <b>12</b>. The beginning of the shared memory segment may contain the address of the shared work queue <b>52</b> and control block <b>58</b>, or the resource manager can provide these addresses separately to the WQAF <b>62</b>A and the scheduler <b>42</b>A. The shared access by virtual machines <b>12</b> and <b>12</b>A to work queue <b>52</b> also requires possession of a lock <b>90</b> described in more detail below with reference to <figref idref="DRAWINGS">FIGS. 3 and 4</figref>.</p>
<p id="p-0028" num="0027">In one embodiment of the present invention, all the work items are created by users of application <b>32</b> on virtual machine <b>12</b> and not by users of application <b>32</b>A on virtual machine <b>12</b>A, i.e. no users were assigned to application <b>32</b>A. In such a case, WQAF <b>62</b>A does not have any work items to assign to the work queue <b>52</b>. However, scheduler <b>42</b>A obtains work items from the work queue <b>52</b> along with scheduler <b>42</b>, so that the virtual resources of both virtual machines <b>12</b> and <b>12</b>A are used to perform the work items on work queue <b>52</b>. In this embodiment, clone <b>12</b>A need not include a copy of application <b>32</b> if the copy is not needed to perform the work items generated by application <b>32</b> on virtual machine <b>12</b>. Consider now an alternate embodiment of the present invention where the work items are created by users of application <b>32</b> on virtual machine <b>12</b> and users of application <b>32</b>A on virtual machine <b>12</b>A. In this case, the users of application <b>32</b>A could have been reassigned from application <b>32</b> on virtual machine <b>12</b> or new users assigned to application <b>32</b>A. In either case, both WQAFs <b>62</b> and <b>62</b>A have work items to assign to the work queue <b>52</b>, and both schedulers <b>42</b> and <b>42</b>A obtain work items from the work queue <b>52</b>. So, the virtual resources of both virtual machines <b>12</b> and <b>12</b>A are used to perform the work items on work queue <b>52</b>. (In this alternate embodiment, it is also possible to create a separate work queue for virtual machine <b>12</b>A, so that virtual machine <b>12</b>A does not share work queue <b>52</b>.)</p>
<p id="p-0029" num="0028">Virtual machine <b>14</b> and its interaction with work queue <b>54</b> remains unchanged by the creation of the virtual machine clone <b>12</b>A except for the diminished virtual and real resources available to virtual machine <b>14</b> to execute the work items on work queue <b>54</b>. Likewise, virtual machine <b>16</b> and its interaction with work queue <b>56</b> remains unchanged by the creation of the virtual machine clone <b>12</b>A except for the diminished virtual and real resources available to virtual machine <b>16</b> to execute the work items on work queue <b>56</b>.</p>
<p id="p-0030" num="0029">Then, resource manager <b>212</b> repeated the foregoing analysis and determined that virtual machines <b>12</b> and <b>12</b>A still have insufficient resources. So, resource manager <b>212</b> created another virtual machine clone <b>12</b>B including clone application <b>32</b>B. Consequently, virtual machine <b>12</b> and its virtual machine clones <b>12</b>A and <b>12</b>B together have fifty percent of the virtual and real resource total, virtual machine <b>14</b> has 16.7 percent of the virtual and real resource total, virtual machine <b>16</b> has 16.7 percent of the virtual and real resource total, and virtual machine <b>17</b> has 16.7 percent of the virtual and real resource total. To collectively utilize the virtual and real resources of virtual machine <b>12</b> and its virtual machine clones <b>12</b>A and <b>12</b>B, the resource manager <b>212</b> now grants to virtual machine clone <b>12</b>B access to work queue <b>52</b> (step <b>89</b>). (Virtual machine clone <b>12</b>A retains its earlier granted access to work queue <b>52</b>.) This access to virtual machine clone <b>12</b>B is “granted” by the resource manager <b>212</b> furnishing to the virtual machine clone <b>12</b>B an authorization to access a portion or segment of the shared memory containing the work queue <b>52</b> of virtual machine <b>12</b>. The beginning of the shared memory segment may contain the address of the shared work queue <b>52</b> and control block <b>58</b>, or the resource manager can provide these addresses separately to the WQAF <b>62</b>B and the scheduler <b>42</b>B. The shared access by virtual machines <b>12</b>, <b>12</b>A and <b>12</b>B to work queue <b>52</b> also requires possession of the lock <b>90</b> described in more detail below.</p>
<p id="p-0031" num="0030">In one embodiment of the present invention, all the work items are created by users of application <b>32</b> on virtual machine <b>12</b> and not by users of applications <b>32</b>A or <b>32</b>B on virtual machines <b>12</b>A and <b>12</b>B, respectively. In such a case, WQAFs <b>62</b>A and <b>62</b>B do not have any work items to assign to the work queue <b>52</b>. However, schedulers <b>42</b>A and <b>42</b>B obtain work items from the work queue <b>52</b>. In the state illustrated in <figref idref="DRAWINGS">FIG. 2</figref>, virtual machine <b>12</b> obtains and executes work item <b>73</b>, virtual machine <b>12</b>A obtains and executes work item <b>71</b> and virtual machine <b>12</b>B obtains and executes work item <b>70</b>. Thus, the virtual and real resources of all three virtual machines <b>12</b>, <b>12</b>A and <b>12</b>B are collectively used to execute the work items on work queue <b>52</b>. In an alternate embodiment of the present invention, the work items are created by users of application <b>32</b> on virtual machine <b>12</b>, users of application <b>32</b>A on virtual machine <b>12</b>A and users of application <b>32</b>B on virtual machine <b>12</b>B. The users of applications <b>32</b>A and <b>32</b>B could have been reassigned from application <b>32</b> on virtual machine <b>12</b> or they can be new users. In such a case, WQAFs <b>62</b>, <b>62</b>A and <b>62</b>B all have work items to assign to the work queue <b>52</b>, and schedulers <b>42</b>, <b>42</b>A and <b>42</b>B all obtain work items from the work queue <b>52</b>. So, the virtual and real resources of virtual machines <b>12</b>, <b>12</b>A and <b>12</b>B are all used to perform the work items on work queue <b>52</b>. (In this alternate embodiment, it is also possible to create a separate work queue for virtual machine <b>12</b>A and a separate work queue for virtual machine <b>12</b>B, so that virtual machines <b>12</b>A and <b>12</b>B do not share work queue <b>52</b>.)</p>
<p id="p-0032" num="0031">Virtual machine <b>14</b> and its interaction with work queue <b>54</b> remains unchanged by the creation of the virtual machine clones <b>12</b>A and <b>12</b>B except for the diminished virtual and real resources available to virtual machine <b>14</b> to execute the work items on work queue <b>54</b>. Likewise, virtual machine <b>16</b> and its interaction with work queue <b>56</b> remains unchanged by the creation of the virtual machine clones <b>12</b>A and <b>12</b>B except for the diminished virtual and real resources available to virtual machine <b>16</b> to execute the work items on work queue <b>56</b>.</p>
<p id="p-0033" num="0032">Other distributions of the virtual and real resources are available depending on which virtual machines are cloned, and how many clones are created. The resource manager periodically determines the virtual and real resource utilization of the virtual machines, and the need to create or delete a clone.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 3</figref> figuratively illustrates a synchronization or lock structure generally designated <b>90</b> within the shared memory <b>25</b> of computer system <b>10</b>. A lock is required for any work queue which is shared by more than one virtual machine. This will be the case when a virtual machine has one or more clones which share a work queue, such as work queue <b>52</b> shared by virtual machines <b>12</b>, <b>12</b>A and <b>12</b>B illustrated in <figref idref="DRAWINGS">FIG. 2</figref>. When there are no clones for a virtual machine, then the lock structure can be bypassed or the virtual machine can continuously hold the lock. (<figref idref="DRAWINGS">FIG. 3</figref> does not illustrate virtual machines <b>14</b> or <b>16</b> or their work queues <b>54</b> or <b>56</b>, respectively.) In the illustrated example, virtual machine <b>12</b>A holds lock <b>91</b>, virtual machine <b>12</b> has a place holder <b>92</b> waiting for the lock from virtual machine <b>12</b>A, and virtual machine <b>12</b>B has a place holder <b>93</b> waiting for the lock from virtual machine <b>12</b>. This is actually recorded in control block <b>58</b> which indicates that virtual machine <b>12</b>A holds the lock and virtual machines <b>12</b> and <b>12</b>B are currently waiting for the lock. The “waiter list” <b>95</b> of control block <b>58</b> indicates the order of the waiters, i.e. virtual machine <b>12</b> is first in line waiting for the lock and virtual machine <b>12</b>B will attempt to obtain the lock after virtual machine <b>12</b> obtains the lock. In the example, virtual machine <b>12</b>A holds lock <b>91</b> exclusively, that is, no other virtual machine may concurrently hold this lock. Virtual machine <b>12</b> and <b>12</b>B are waiting for the lock and willing to hold the lock shared, that is, they may concurrently hold the lock with each other.</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 4</figref> illustrates each of the synchronization or lock functions <b>562</b>, <b>562</b>A and <b>562</b>B within virtual machines <b>12</b>, <b>12</b>A and <b>12</b>B, respectively, and associated operation of each of the virtual machines that is trying to obtain the lock for the shared work queue <b>52</b> in shared memory. In the following example, a virtual machine (such as virtual machine <b>12</b>B) requests a lock for the shared work queue <b>52</b> (step <b>700</b>). If the virtual machine just wants to read the shared work queue, then the virtual machine need only request a shared lock. However, if the virtual machine wants to remove a work item from the shared work queue (which is more typically the case), then the virtual machine will request an exclusive lock. Typically, the virtual machine will want to remove a work item from the work queue, so will request an exclusive lock for this objective and decision <b>702</b> leads to decision <b>704</b>. In decision <b>704</b>, the synchronization function determines if the requested lock is currently held by another virtual machine (either in a shared or exclusive manner). If so, the exclusive lock is not available to the current requester, and synchronization function updates the control block to indicate that the requesting virtual machine is idle and “waiting” for the exclusive lock (step <b>706</b>). Also, the virtual machine enters a waiting/quiescent state (step <b>708</b>) where it waits for an interrupt (decision <b>710</b>). Referring again to decision <b>704</b>, if the requested lock is not currently held by anyone, then the synchronization function marks the virtual machine as “not idle” (step <b>712</b>) and grants the lock to the virtual machine (step <b>714</b>). This granting of the lock is accomplished by corresponding update to control block <b>58</b>. Next, the virtual machine removes the next work item from the shared work queue <b>52</b> and performs the task indicated by the work item (step <b>716</b>). Afterwards, the virtual machine notifies the synchronization function that it has performed the work item, and it is “releasing” the lock (step <b>718</b>). In response, the synchronization function updates the control block <b>58</b> to indicate that the lock has been released. Also, the synchronization function determines from the control block <b>58</b> if any other virtual machine is currently waiting for the lock (decision <b>720</b>). If not, the processing of the synchronization function is complete (step <b>722</b>). If so, the synchronization function determines from the control block <b>58</b> if the first virtual machine marked “waiting” is “idle” (decision <b>724</b>). If not, the processing of the synchronization function is complete (step <b>722</b>) because it would be too disruptive of the non idle, waiting virtual machine to be interrupted at this time. Instead, when the non idle, waiting virtual machine completes its current work item or at some other time that is convenient for the waiting virtual machine, it will likely request the lock on its own at step <b>700</b>. Referring again to decision <b>724</b>, if the waiting virtual machine is idle, then the synchronization function issues an interrupt to the waiting virtual machine (step <b>728</b>). This will not be wasteful to the waiting virtual machine because it is idle anyway. After receiving the interrupt, the idle virtual machine will awaken and can request the lock at step <b>700</b>.</p>
<p id="p-0036" num="0035">Referring back again to decision <b>702</b>, if the lock requested by the virtual machine is shared and not exclusive, such as to read the shared work queue, then the synchronization function determines if the lock is currently being held in an exclusive manner (decision <b>740</b>). If not (i.e. no lock is currently being held or only a shared lock is currently being held), then the synchronization function proceeds to step <b>712</b> and continues as described above. However, if the lock is currently being held in an exclusive manner, then the synchronization function marks in the control block <b>58</b> that the requesting virtual machine as “idle” and “waiting” for a shared lock (step <b>742</b>). Then, the requesting virtual machine enters into a waiting/quiescent state (step <b>744</b>), waiting for an interrupt (decision <b>748</b>). Upon receipt of such an interrupt, it can proceed to step <b>700</b> to request the lock.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIGS. 5(</figref><i>a</i>) and <b>5</b>(<i>b</i>) illustrate the foregoing operation of resource manager <b>217</b> in more detail. The resource manager <b>217</b> performs the steps of <figref idref="DRAWINGS">FIGS. 5(</figref><i>a</i>) and <b>5</b>(<i>b</i>) for each user virtual machine <b>12</b>, <b>14</b> and <b>16</b> to determine the need to create a clone of the virtual machine or delete a clone of the virtual machine. Initially, the resource manager <b>217</b> sets new soft limits for the real CPU, the virtual private memory and the real I/O allocated to the virtual machine or reads the original ones from the directory <b>191</b> if available there (step <b>100</b>). The real CPU allocation for a virtual machine is the amount of CPU processing time available to the virtual machine. The virtual private memory is the amount of private memory allocated to the virtual machine; the addresses assigned for this private memory are mapped to the real memory. The real I/O is the amount of real I/O bandwidth available to the virtual machine. Next, the resource manager fetches from the usage records <b>85</b> the current utilization levels of the foregoing resources by the virtual machines (step <b>102</b>). As noted above, the common base portion periodically monitors these virtual and real utilization levels for the resources. Then, the resource manager reads the real CPU utilization level of the virtual machine (step <b>104</b>). Next, the resource manager determines if the current real CPU utilization by the virtual machine is more than its soft limit (decision <b>106</b>). If not, then the resource manager determines if the virtual machine needs additional virtual resources (decision <b>107</b>). This determination is made by monitoring the workload of the virtual machine each time it has a time slice of the real CPU. If the virtual machine usually or always has outstanding work to complete when it has access to the real CPU, then it probably needs a greater share of the real CPU. If so, then the resource manager creates a clone of the virtual machine in the manner described above (step <b>108</b>). Also, the resource manager gives the clone access to the shared work queue in the manner described above (step <b>110</b>).</p>
<p id="p-0038" num="0037">Referring again to decision <b>106</b>, if the current real CPU utilization level of the virtual machine is equal or more than the soft limit, then the resource manager determines if the total, real CPU for the system is under utilized (decision <b>112</b>). If not, then it is likely that one or more other virtual machines are “starved” for the CPU and it is fair to give additional real CPU resource to the other virtual machines and take some back from the virtual machine currently under review. So the resource manager will proceed to delete a clone of the virtual machine as follows. The resource manager determines if the virtual machine (currently under review) is currently performing a work item (decision <b>114</b>). If so, the resource manager waits for the virtual machine to complete its current work item (step <b>116</b>). If not or after the resource manager completes its current work item, the resource manager deletes a clone of the virtual machine, assuming one exists (step <b>120</b>).</p>
<p id="p-0039" num="0038">Referring again to decision <b>112</b>, if the total, real CPU for the system is under utilized, then it is not necessary to delete a clone of the virtual machine; the other virtual machines should not be starved. However, it may be necessary to delete a clone to free up other real or virtual resources. So, the resource manager checks the virtual, private-memory utilization of the virtual machine (step <b>130</b>). (Referring again to decision <b>107</b>, if the virtual machine does not need real CPU, then the resource manager also proceeds to step <b>130</b>.) If the virtual private-memory utilization of the virtual machine is one hundred percent of the allocation (decision <b>132</b>), then the resource manager proceeds to step <b>108</b> as described above to create a clone of the virtual machine. However, if the virtual private-memory utilization is less than one hundred percent, then the resource manager compares the utilization level to the soft limit for virtual private memory (decision <b>136</b>). If the current, virtual, private-memory utilization is over the soft limit (decision <b>138</b>), then the resource manager proceeds to decision <b>114</b> and then to step <b>120</b> as described above to delete a clone of the virtual machine, if one currently exists. Referring again to decision <b>136</b>, if the current virtual private-memory utilization is not over the soft limit, then the resource manager determines if the virtual machine needs additional private virtual memory (step <b>140</b>). This determination is made by monitoring the amount of paging required for this virtual machine. “Paging” occurs when a virtual machine has inadequate virtual private memory and must write its excess data out to disk storage. If the virtual machine needs additional private memory, then the resource manager proceeds to step <b>108</b> to create a clone. If not, then the resource manager checks the total, real I/O bandwidth for the system (step <b>144</b>). Then, the resource manager checks the current real I/O utilization by the virtual machine (step <b>146</b>). If the current real I/O utilization by the virtual machine is less than the soft limit (decision <b>148</b>), then the resource manager proceeds to step <b>108</b> to create a clone. If not, the resource manager determines if the total, real I/O for the system is under utilized (decision <b>150</b>). If not, then the resource manager proceeds to decision <b>114</b> and step <b>120</b> to delete a clone, if one exists. If so, then the resource manager loops back to step <b>100</b> to repeat the foregoing process.</p>
<p id="p-0040" num="0039">Based on the foregoing, a computer system embodying the present invention has been disclosed. However, numerous modifications and substitutions can be made without deviating from the scope of the present invention. For example, logical partitions could be substituted for the virtual machines. Also, other virtual resource allocation techniques can be combined with the foregoing techniques. For example, a human systems administrator acting through the common base portion can manually change the virtual resource allocation to each virtual machine and the respective soft limits for such virtual machines, including the clones. After such a change, the resource manager would use the new allocations and soft limits to determine when to add or delete a clone. Therefore, the present invention has been disclosed by way of illustration and not limitation, and reference should be made to the following claims to determine the scope of the present invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A process for utilizing resources by a virtual machine operating system, said virtual machine operating system defining a multiplicity of virtual machines, a share of resources being allocated to each of said virtual machines, said process comprising the steps of:
<claim-text>automatically monitoring utilization by one of said virtual machines of the resources allocated to said one virtual machine, and</claim-text>
<claim-text>determining that said one virtual machine needs additional resources to effectively perform work items on a work queue, and in response, automatically cloning said one virtual machine, said clone being allocated a share of said resources taken from the shares of other of said virtual machines, such that the resultant shares allocated to said one virtual machine and the clone of said one virtual machine together are greater than the share allocated to said one virtual machine before said one virtual machine was cloned; and</claim-text>
<claim-text>wherein said one virtual machine and said clone share said work queue, such that both said one virtual machine with its resources and said clone with its resources perform said work items on said shared work queue.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. A process as set forth in <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein said shared work queue resides in a memory shared by said one virtual machine and said clone.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. A process as set forth in <claim-ref idref="CLM-00002">claim 2</claim-ref> wherein both said one virtual machine and said clone can directly access said shared work queue by appropriate address.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A process as set forth in <claim-ref idref="CLM-00002">claim 2</claim-ref> further comprising a lock in said shared memory for said shared work queue, and wherein said one virtual machine and said clone obtain said lock before accessing said shared work queue.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A process as set forth in <claim-ref idref="CLM-00004">claim 4</claim-ref> wherein both said one virtual machine and said clone can directly access said lock by appropriate address.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A process for utilizing resources by a virtual machine operating system, said virtual machine operating system defining a multiplicity of virtual machines, a share of resources being allocated to each of said virtual machines, said process comprising the steps of:
<claim-text>automatically monitoring utilization by one of said virtual machines of the resources allocated to said one virtual machine, and</claim-text>
<claim-text>determining that said one virtual machine needs additional resources to effectively perform work requests from a user of said one virtual machine, and in response, automatically cloning said one virtual machine, said clone being allocated a share of said resources taken from the shares of other of said virtual machines, such that the resultant shares allocated to said one virtual machine and the clone of said one virtual machine together are greater than the share allocated to said one virtual machine before said one virtual machine was cloned; and</claim-text>
<claim-text>wherein said one virtual machine includes an application which receives some of said work requests from said user of said one virtual machine, said clone includes a copy of said application, and said clone uses said copy of said application to perform other of said work requests made by said user of said one virtual machine.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A computer system comprising:
<claim-text>a processor;</claim-text>
<claim-text>a multiplicity of virtual machines, a share of resources including a share of said processor being allocated to each of said virtual machines;</claim-text>
<claim-text>means for monitoring utilization by one of said virtual machines of the resources allocated to said one virtual machines, and</claim-text>
<claim-text>means, responsive to said one virtual machine needing additional resources to effectively perform work items on a work queue, for automatically cloning said one virtual machine, said clone being allocated a share of said resources taken from the shares of other of said virtual machines, such that the resultant shares allocated to said one virtual machine and the clone of said one virtual machine together are greater than the share allocated to said one virtual machine before said one virtual machine was cloned; and</claim-text>
<claim-text>wherein said one virtual machine and said clone share said work queue, such that both said one virtual machine with its resources and said clone with its resources perform said work items on said shared work queue.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A computer system as set forth in <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein said shared work queue resides in a memory shared by said one virtual machine and said clone.</claim-text>
</claim>
</claims>
</us-patent-grant>
