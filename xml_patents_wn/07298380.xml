<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298380-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298380</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11114835</doc-number>
<date>20050426</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2004-130151</doc-number>
<date>20040426</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>380</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>G</subclass>
<main-group>5</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>03</class>
<subclass>F</subclass>
<main-group>3</main-group>
<subgroup>08</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>1</main-group>
<subgroup>46</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>G</subclass>
<main-group>5</main-group>
<subgroup>02</subgroup>
<symbol-position>L</symbol-position>
<classification-value>N</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>9</main-group>
<subgroup>64</subgroup>
<symbol-position>L</symbol-position>
<classification-value>N</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345590</main-classification>
<further-classification>345617</further-classification>
<further-classification>348576</further-classification>
<further-classification>358518</further-classification>
<further-classification>358520</further-classification>
<further-classification>358  11</further-classification>
<further-classification>358537</further-classification>
<further-classification>382162</further-classification>
<further-classification>382167</further-classification>
</classification-national>
<invention-title id="d0e71">Image processing method and apparatus for white eye correction</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>2005/0117173</doc-number>
<kind>A1</kind>
<name>Kugo</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358  11</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>JP</country>
<doc-number>2002-247596</doc-number>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>13</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>345589</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345597</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345600</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345616-618</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348 78</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348251</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348576-578</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348660</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358515-520</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358  11</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358  327</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358536-537</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382162</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382167</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>7</number-of-drawing-sheets>
<number-of-figures>12</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20050238230</doc-number>
<kind>A1</kind>
<date>20051027</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Yoshida</last-name>
<first-name>Ikuko</first-name>
<address>
<city>Arida</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Fulbright &amp; Jaworski LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Noritsu Koki Co., Ltd.</orgname>
<role>03</role>
<address>
<city>Wakayama-ken</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Sajous</last-name>
<first-name>Wesner</first-name>
<department>2628</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A technique for correcting white eye in image data is disclosed. In this technique, a white eye candidate pixel is detected from an eye extracted from the image data based on a predetermined detection condition. The white eye candidate pixel as a white eye pixel based on a predetermined determination condition. Then, white eye correction is effected on the determined white eye pixel by changing its luminance.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="110.74mm" wi="239.10mm" file="US07298380-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="231.39mm" wi="148.17mm" orientation="landscape" file="US07298380-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="213.19mm" wi="158.24mm" orientation="landscape" file="US07298380-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="251.88mm" wi="175.51mm" orientation="landscape" file="US07298380-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="241.98mm" wi="124.29mm" orientation="landscape" file="US07298380-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="258.06mm" wi="176.19mm" file="US07298380-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="251.54mm" wi="196.34mm" file="US07298380-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="251.54mm" wi="178.90mm" file="US07298380-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<p id="p-0002" num="0001">This application claims priority from JP2004-130151 filed Apr. 26, 2004 herein incorporated by reference in its entirety.</p>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention relates to an image processing technique for correcting or improving a white eye representation in image data.</p>
<heading id="h-0002" level="1">DESCRIPTION OF THE RELATED ART</heading>
<p id="p-0004" num="0003">Recently, with ever increasing popularity of digital cameras as well as film scanners, a photographic image of a photographic film is often digitized for its processing. As a result, correction or retouching operation of a photography which conventionally required an experienced or professional skill can now be realized also with an inexpensive processing apparatus such as an apparatus commonly known as “digital mini-lab” for producing photo prints.</p>
<p id="p-0005" num="0004">For example, in flash pictures of such subject as a human or an animal, there can occur a so-called red eye phenomenon resulting from reflection of the flash light off the blood vessels of the retina of the subject's eyes, causing the center of the eye to appear red or in a color different from the actual color thereof. Various and numerous solutions have been proposed to tackle this problem by means of image processing technique. According to a technique disclosed by Japanese Patent Application “Kokai” No. 2002-247596 (paragraphs [0041] through [0046] and [0071] through [0075]), for example, from a specified eye area, a red eye area is determined which has predetermined characteristic amounts such as hue, chroma, luminance. Then, the red eye area thus determined is corrected by being completely replaced by black color which is believed most similar to the color of the iris or by reducing values of R components (reducing their lightness) of pixel values of R, G, B image data.</p>
<p id="p-0006" num="0005">More recently, there has been an increasing demand for correction other than the red eye correction described above. In particular, in a portrait photography for use in e.g. a certificate, a face of the photographic human subject appears large in the photo and eyes of the subject give strong visual impression. Hence, it is strongly desired to improve the visual impression of the eyes, such as aesthetic improvement of white eye representation. However, the art has not yet come up with any method for enabling such correction or an apparatus for implementing such method.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0007" num="0006">The present invention has been made to address to the above-described state of the art. A primary object of the present invention is to provide a technique capable of extracting pixels of white eye areas and correcting the white eye areas to an appropriate color.</p>
<p id="p-0008" num="0007">For accomplishing the above-noted object, according to one aspect of the present invention, there is proposed a method for correcting white eye in image data, comprising the steps of
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0008">detecting a white eye candidate pixel from an eye extracted from the image data based on a predetermined detection condition;</li>
        <li id="ul0002-0002" num="0009">determining said white eye candidate pixel as a white eye pixel based on a predetermined determination condition; and</li>
        <li id="ul0002-0003" num="0010">effecting white eye correction of the determined white eye pixel by changing its luminance.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0009" num="0011">With the above construction, the white eye correction is effected not on all pixels (white eye candidate pixels) detected based on the predetermined detection condition from the extracted image data, but on those limited pixels which have been determined as white eye pixels based on the predetermined determination condition. Hence, this method can effect the white eye correction in a reliable manner by avoiding erroneous color correction of e.g. the skin around the eye.</p>
<p id="p-0010" num="0012">According to one preferred embodiment of the invention, the above method further comprises the step of detecting an iris from the image data, and at said white eye pixel determining step, said white eye candidate pixel is determined as the white eye pixel if said white eye candidate pixel has been detected from an area adjacent said iris.</p>
<p id="p-0011" num="0013">With the above construction, first, an iris is detected from the image data. Then, a white eye candidate pixel is determined as a white eye pixel only if this candidate pixel has been detected from an area adjacent the iris. Hence, the determination of white eye pixel can be made with higher reliability, without erroneous determination of a pixel from e.g. the skin around the eye as a white eye pixel. Further, a pixel which is present within the area adjacent the iris, but not detected as a white eye candidate pixel as failing to satisfy the predetermined detection condition due to e.g. a noise can be “recovered” and appropriately determined a white eye candidate pixel, then as a white eye pixel.</p>
<p id="p-0012" num="0014">Preferably, in the above-described construction, said white eye correcting step is effected by changing a chroma of the white eye pixel first prior to the change of its luminance.</p>
<p id="p-0013" num="0015">With the above construction, the method changes the chroma before changing the luminance. Hence, the tint of the white eye portion can be corrected to be similar to an achromatic color. By subsequently effecting the luminance on this achromatic side, the subsequent monochromatic correction of the white eye by the change of luminance can be carried out more effectively.</p>
<p id="p-0014" num="0016">Preferably, in the above-described construction, the white eye correcting step is effected by changing a hue of the white eye pixel.</p>
<p id="p-0015" num="0017">This construction allows correction to such hue as can improve aesthetic impression of the white color. Hence, the white eye correction can be carried out even more effectively.</p>
<p id="p-0016" num="0018">Further, in the white eye correcting method of the invention, the white eye correcting step effects the white eye correction by a ratio determined based on a difference between a predetermined pixel value of a target pixel and a pixel value of each white eye pixel.</p>
<p id="p-0017" num="0019">With the above construction, the white eye correction can be made with maintaining e.g. the so-called gradation due to difference in the pixel value of each white eye pixel. Therefore, the white eye correction can be made not to provide unnatural impression, but by an appropriate degree to provide a natural visual impression.</p>
<p id="p-0018" num="0020">Still preferably, in the white eye correcting method of the invention, said predetermined detection condition employed at said step of detecting a white eye candidate pixel is predetermined based on a luminance distribution of the image data.</p>
<p id="p-0019" num="0021">With this construction, as the white eye candidate pixel is detected based on the condition predetermined on the luminance distribution of the image data, the white eye candidate pixel can be detected based on a condition which is variable to suits each particular image data, in comparison with detection of a white eye candidate pixel based on a uniformly fixed threshold value. For instance, if the image data has high luminance as a whole, its luminance distribution too is concentrated on the higher luminance side. Hence, the predetermined luminance value as the detection threshold can be set to a higher luminance (brighter) side than usual. Conversely, if the image data has low luminance as a whole, the predetermined luminance value as the detection threshold can be set to a lower luminance side (darker) than usual. In these manners, the detection condition for the white eye candidate pixel can vary according to each particular image data. As a result, the white eye correction can be made more appropriately and reliably.</p>
<p id="p-0020" num="0022">According to further aspects of the present invention, there are proposed a program for causing a computer to execute the above-described white eye correcting method of the invention and a medium storing such program therein.</p>
<p id="p-0021" num="0023">Namely, the program causes a computer to carry out the functions of detecting a white eye candidate pixel from an eye extracted from the image data based on a predetermined detection condition; determining said white eye candidate pixel as a white eye pixel based on a predetermined determination condition; and effecting white eye correction of the determined white eye pixel by changing its luminance.</p>
<p id="p-0022" num="0024">According to a still further aspect of the present invention, there is proposed an image processing apparatus for implementing the above-described white eye correcting method. This apparatus comprises:
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0000">
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0025">a white eye candidate pixel detecting section for detecting a white eye candidate pixel from an eye extracted from the image data based on a predetermined detection condition</li>
        <li id="ul0004-0002" num="0026">a white eye pixel determining section for determining said white eye candidate pixel as a white eye pixel based on a predetermined determination condition; and</li>
        <li id="ul0004-0003" num="0027">a white eye correcting section for effecting white eye correction of the determined white eye pixel by changing its luminance.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0023" num="0028">Needless to say, such program and image processing apparatus can achieve the same functions and effects as the above-described white eye correcting method of the invention.</p>
<p id="p-0024" num="0029">Further and other features and advantages of the invention will become apparent upon reading the following detailed description of preferred embodiments thereof with reference to the accompanying drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0025" num="0030"><figref idref="DRAWINGS">FIG. 1</figref> is a view showing an outer appearance of a photographic printing system employing the white eye correcting technique according to the present invention,</p>
<p id="p-0026" num="0031"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram schematically showing a construction of a print station of the photographic printing system,</p>
<p id="p-0027" num="0032"><figref idref="DRAWINGS">FIG. 3</figref> is a functional block diagram for illustrating functional blocks or sections provided in a controller of the photographic printing system,</p>
<p id="p-0028" num="0033"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram showing functional blocks of a white eye correcting means shown in <figref idref="DRAWINGS">FIG. 3</figref>,</p>
<p id="p-0029" num="0034"><figref idref="DRAWINGS">FIG. 5</figref> shows an example of a subject image to be corrected by the white eye correcting technique of the invention,</p>
<p id="p-0030" num="0035"><figref idref="DRAWINGS">FIG. 6</figref> shows an example of eye area data to be corrected by the white eye correcting technique of the invention,</p>
<p id="p-0031" num="0036"><figref idref="DRAWINGS">FIG. 7</figref> illustrates an example of a method for determining a white eye pixel to be corrected by the white eye correcting technique of the invention,</p>
<p id="p-0032" num="0037"><figref idref="DRAWINGS">FIG. 8</figref> shows an example of a method for obtaining a luminance condition for detection of a white eye pixel to be corrected by the white eye correcting technique of the invention,</p>
<p id="p-0033" num="0038"><figref idref="DRAWINGS">FIG. 9</figref> is an explanatory view of an example of the invention's white eye correcting technique by way of changing luminance,</p>
<p id="p-0034" num="0039"><figref idref="DRAWINGS">FIG. 10</figref> is an explanatory view of another example of the invention's white eye correcting technique by way of changing chroma,</p>
<p id="p-0035" num="0040"><figref idref="DRAWINGS">FIG. 11</figref> is an explanatory view of a still another example of the invention's white eye correcting technique by way of changing hue, and</p>
<p id="p-0036" num="0041"><figref idref="DRAWINGS">FIG. 12</figref> is an explanatory view of a still another example of the invention's white eye correcting technique by way of changing pixel value.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0037" num="0042">Preferred embodiments of the present invention will be described in details with reference to the accompanying drawings.</p>
<p id="p-0038" num="0043"><figref idref="DRAWINGS">FIG. 1</figref> shows an outer appearance of a photographic printing system employing the red eye correction technique of the present invention. As shown, this printing system consists mainly of a printing station <b>1</b>B as a photographic printer for effecting exposure and development on a print paper P and an operating station <b>1</b>A for processing photographic images taken from a developed photographic film <b>2</b><i>a </i>or various image input media such as a memory card <b>2</b><i>b </i>for a digital camera and effecting production/transmission of print data to be used in the printing station <b>1</b>B. This photographic printing system is known also as “digital mini-lab”. As best understood from <figref idref="DRAWINGS">FIG. 2</figref>, in the printing station <b>1</b>B, a print paper P stored in the form of a roll in either one of two print paper magazines <b>11</b> is drawn out and cut by a sheet cutter <b>12</b> to a print size strip. On this print paper P (or print size strip), a back printing unit <b>13</b> prints on its back face, color correction information and various print processing information such as a frame number, and a print exposing unit <b>14</b> exposes a front face of each paper P with a photographically recorded image. Then, a plurality of such exposed print papers P are fed into a developing tank unit <b>15</b> having a plurality of developing solution tanks for their development. After being dried, the developed print papers P are conveyed by a transverse conveyer <b>16</b> to a sorter <b>17</b>, by which the papers P are sorted according to each customer's order and stacked in a plurality of trays (see <figref idref="DRAWINGS">FIG. 1</figref>).</p>
<p id="p-0039" num="0044">For transporting the print papers P at a speed adapted or suited for each of the above-described various operations, there is provided a print paper transporting mechanism <b>18</b>. This print paper transporting mechanism <b>18</b> has a plurality of pinch transport roller pairs including chucker type print paper transport units <b>18</b><i>a </i>disposed before and after the print exposing unit <b>14</b> relative to the print paper transporting direction.</p>
<p id="p-0040" num="0045">The print exposing unit <b>14</b> has line exposure heads for effecting irradiation of laser beams of three primary colors, R (red), G (green) and B (blue) along a main scanning direction of the print paper P which is being transported in a sub scanning direction, based on the print data sent from the operating station <b>1</b>A. The developing solution tank unit <b>15</b> includes a color developing solution tank <b>15</b><i>a </i>whish stores therein color developing solution, a bleaching/fixing solution tank <b>15</b><i>b </i>which stores therein bleaching/fixing solution and stabilizing solution tanks <b>15</b><i>c </i>which store stabilizing solutions therein.</p>
<p id="p-0041" num="0046">At an upper position of a desk-like console of the operating station <b>1</b>A, there is disposed a film scanner <b>20</b> for obtaining photographic image data (“image data” hereinafter) from the respective photographically exposed frames of the photographic film <b>2</b><i>a</i>. Whereas, a media reader <b>21</b> for obtaining image date from various types of semiconductor memories, CD-R or the like is incorporated within a general-purpose personal computer which functions as a controller <b>3</b> for this photographic printing system. The general-purpose PC is connected also to a monitor <b>23</b> for displaying various kinds of information and a keyboard <b>24</b> and a mouse <b>25</b> which function as operation input devices (pointing devices) employed as an instruction inputting section when various settings or adjustments are to be effected.</p>
<p id="p-0042" num="0047">The controller <b>3</b> for the photographic printing system includes a CPU as a core component thereof and includes also various functional blocks or sections for effecting various operations of the photographic printing system realized in the form of hardware and/or software. Of these functional sections, as shown in <figref idref="DRAWINGS">FIG. 3</figref>, the following sections are of particular relevance to the present invention. An image inputting section <b>31</b> is provided for inputting the image data read by the scanner <b>20</b> or the media reader <b>21</b> and effecting any preparatory operation needed for a subsequence process. A GUI section <b>33</b> constitutes a graphic user interface (i.e. GUI) configured for creating a graphically assisted operation screen having various windows, various operation buttons or the like and generating control commands from user's operation inputs (via the keyboard <b>24</b>, the mouse <b>25</b> or the like) effected through such graphic operation screen. A print managing section <b>32</b> effects e.g. an image processing operation on the image data transmitted from the image inputting section <b>31</b> to a memory <b>30</b> in order to generate desired print data according to a control command sent from the GUI section <b>33</b> or an operation command directly inputted via e.g. the keyboard <b>24</b>. A video controlling section <b>35</b> generates wide signals for causing the monitor <b>32</b> to display a print source image or a simulated image as an expected finished print image during a pre-judge printing operation for e.g. color correction and to display also the graphic data sent from the GUI section <b>33</b>. A print data generating section <b>36</b> generates print data suited for the print exposing unit <b>14</b> mounted in the print station ID, based on final image data whose image processing has been completed. A formatter section <b>37</b> formats raw image data or the finally processed image data into a format writable in e.g. a CD-R, in accordance with a customer's request.</p>
<p id="p-0043" num="0048">Referring more particularly to the image inputting section <b>31</b>, in case the photographic image recording media is a film <b>2</b><i>a</i>, this image inputting section <b>31</b> transmits scanned data scanned in a pre-scanning mode and a main scanning mode, separately to the memory <b>30</b>, to effect a preparatory operation suited for each particular purpose. Whereas, in case the photographic image recording media is a memory card <b>2</b><i>b</i>, if the inputted image data contains thumbnail image data (low resolution data), the section <b>31</b> transmits this thumbnail data to the memory <b>30</b> separately from the main data (high resolution data) of the photographic image, so that the thumbnail data may be used for e.g. list (summary) display on the monitor <b>23</b>. On the other hand, if no thumbnail data are contained therein, the image inputting section <b>31</b> creates reduced images from the main data and sent these as thumbnail data to the memory <b>30</b>. Further, this image inputting section <b>31</b> is connected also to a device commonly known as photographic print order receiving device, for automatically receiving a customer's order for prints. Then, when the image inputting section <b>31</b> receives print order data relating to a print size, a number of prints to be made, etc., image attribute data relating to photographic condition and image data, the image inputting section <b>31</b> transmits the image data to the memory <b>30</b>, and transmits the print order data and the image attribute data to the print managing section <b>32</b>, respectively. In the case of an order for standard photos, then, this the print order data relating to e.g. a print size, the number of prints, etc. and also, if necessary, the image attribute data relating to presence/absence of flash photography, the type of camera used, etc. will be sent to the print managing section <b>32</b> in response to an operator's input operation to that effect via e.g. the keyboard <b>24</b>.</p>
<p id="p-0044" num="0049">The print managing section <b>32</b> includes a print order processing unit <b>60</b> for managing the print size, the number of prints, etc. and an image processing unit <b>70</b> for effecting photo retouching operations such as color correction, filtering (for color softening or sharpness adjustment) on the image data mapped in the memory <b>30</b>.</p>
<p id="p-0045" num="0050">The above-described image processing unit <b>70</b> includes a white eye correcting means <b>90</b> implementing the white eye correcting method of the invention. More particularly, as shown in <figref idref="DRAWINGS">FIG. 4</figref>, this white eye correcting means <b>90</b> includes a white eye candidate pixel detecting section <b>91</b>, a white eye pixel determining section <b>92</b>, a white eye correcting unit <b>93</b>, a white eye determination condition calculating section <b>94</b> and a histogram analyzing section <b>95</b>. The white eye candidate pixel detecting section <b>91</b> is configured to effect the step of a white eye candidate pixel from image data (to be referred to as “eye area data” hereinafter) extracted from the image data, based on a predetermined determination condition. The white eye pixel determining section <b>92</b> is configured to effect the step of determining the white eye candidate pixel as a white eye pixel based on a predetermined determination condition. The white eye correcting section <b>92</b> is configured to effect the step of effecting white eye correction on the determined white eye pixel by changing its luminance by its luminance correcting subsection <b>93</b><i>b</i>. In addition to this luminance correcting subsection <b>93</b><i>b</i>, as also shown in <figref idref="DRAWINGS">FIG. 4</figref>, the white eye correcting section <b>93</b> further includes a chroma correcting subsection <b>93</b><i>a </i>for changing chroma of the white eye pixel prior to the change of luminance thereof and a hue correcting subsection <b>93</b><i>c </i>for effecting white eye correction by changing hue of the white eye pixel.</p>
<p id="p-0046" num="0051">The white eye determination condition calculating section <b>94</b> is configured to obtain a condition based on which the white eye candidate pixel is determined as a white eye pixel or not. For instance, this white eye determination condition calculating section <b>94</b> includes a step of detecting an iris from the eye area data, so that the white eye pixel determining section <b>92</b> (for determining a white eye pixel) may determine each white eye candidate pixel detected based on the predetermined condition as a white eye pixel if this detected candidate pixel is present in an area adjacent the detected iris. The histogram analyzing section <b>95</b> is configured to analyze luminance distribution of the image data and then determine the predetermined detection condition based on which the white eye candidate pixel detecting section <b>91</b> effects the white eye candidate pixel detection. In this case, the white eye candidate pixel detecting section <b>91</b> (for effecting the step of detecting a white eye candidate pixel) effects the detection of white eye candidate pixel based on the detection condition determined based on the particular luminance distribution of the image data.</p>
<p id="p-0047" num="0052">Next, the operations (respective steps or functions) of the respective operating sections described above will be described in further details. <figref idref="DRAWINGS">FIG. 5</figref> shows an example of a subject image to be corrected by the white eye correcting method relating to the present invention. First, the image processing unit <b>70</b> extracts (retrieves), from e.g. one frame amount of image data A (source data) of an entire photograph stored in the memory <b>30</b>, an image data area B representing a face. Then, an eye (s) is (are) detected from the face image data area B by means of an image processing utilizing e.g. a face detecting algorithm, thereby to obtain eye area data D. Alternatively, the eye area data D can be obtained manually by an operator through an operation of the keyboard <b>24</b> or the mouse <b>25</b> with displaying the face image data area B on the monitor <b>23</b> for the operator. The eye area data D thus obtained is then subjected to the operation by the white eye correcting means <b>90</b>.</p>
<p id="p-0048" num="0053">Incidentally, the description of the instant embodiment employs the language “extracting an image data area”. It should be understood that this does not mean that the subject entire image data (e.g. the eye area data D) should necessarily be retained in a work area such as a temporary memory. For instance, while the subject image data is stored within the memory <b>30</b> or any other storage, the extracting section can store only address data corresponding to the subject image data, so that corresponding pixels may be retrieved from the memory <b>30</b> or the like in “on-demand” fashion for each image processing operation.</p>
<p id="p-0049" num="0054"><figref idref="DRAWINGS">FIG. 6</figref> shows an example of eye area data D to be subjected to the white eye correcting method of the invention. As shown, the eye area data D includes white eye areas (a) (a<b>1</b>, a<b>2</b>), an iris area (b), a pupil area (c) and a skin area (d). From this eye area data D, a white eye candidate pixel is detected based on the predetermined detection condition. This predetermined detection condition can, for example, be a predetermined minimum luminance value of the pixel. Or, the detection condition can include also condition(s) of hue and/or chroma. Or, each of these conditions can be a predetermined range, rather than a single threshold value. Namely, from the eye area data D, a pixel having luminance, chroma and/or hue value within a predetermined range can be detected as a white eye candidate pixel. For instance, supposing a pixel subjected to the detection (“target pixel” hereinafter) has R, G, B pixel values of Rn, Gn, Bn, then, with using the following window comparator, the detection condition can be expressed e.g. as:
<ul id="ul0005" list-style="none">
    <li id="ul0005-0001" num="0000">
    <ul id="ul0006" list-style="none">
        <li id="ul0006-0001" num="0055">R component lower threshold≦Rn≦R component upper threshold; AND</li>
        <li id="ul0006-0002" num="0056">G component lower threshold≦Gn≦G component upper threshold; AND</li>
        <li id="ul0006-0003" num="0057">B component lower threshold≦Bn≦B component upper threshold.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0050" num="0058">Incidentally, if the above window comparator is adapted to use a maximum value as the upper threshold, rather than using the upper and lower two thresholds, such modified comparator can be used in case a pixel having pixel values greater than predetermined luminance (brightness) is detected as a white eye candidate pixel.</p>
<p id="p-0051" num="0059">As described above, a white eye candidate pixel detected based on a pixel value of a target pixel does not necessarily belong in the white eye area (a). Rather, in case light is reflected from the pupil area (c) thus causing this area illuminant and to appear white or the skin area (d) appears white, a pixel from such area too will be detected as a white eye candidate pixel. For this reason, the white eye determining section <b>92</b> determines whether each detected white eye candidate pixel is really a white eye pixel, i.e. a pixel belonging in the white eye area (d), or not. This determination is possible for instance, based on distribution pattern of a plurality of such white eye candidate pixels detected. Specifically, a pixel which belongs in the skin area (d) but has been detected as a white eye candidate pixel will be present only sporadically, that is, present without being accompanied by many other such pixels detected in the vicinity thereof. As the pupil area (c) is smaller than the white eye area (a), it is possible to determine only a candidate pixel belonging in the white eye area (a) as a white eye pixel with reliability, provided that a number of such white eye candidate pixels are present with a certain concentration about that candidate pixel.</p>
<p id="p-0052" num="0060">The above determination can be made alternatively as follows. Namely, in this case, the white eye determination condition calculating section <b>94</b> detects the iris area (b) by using a detection method well-known in the art. Then, the section <b>94</b> obtains borders b<b>1</b> and b<b>1</b> of the iris area (b) and also the contour of the eyelid as a border (e) as shown in <figref idref="DRAWINGS">FIG. 7</figref>. Then, each of pixels present adjacent the border b<b>1</b> or b<b>2</b> will be determined as a white eye pixel one after another along each arrow shown in <figref idref="DRAWINGS">FIG. 7</figref> as long as this pixel is present inside the border (e). In this, it is possible to “recover”, as a white eye pixel, a pixel which belongs in the white eye area (a) but has not been detected as a white eye candidate pixel due to e.g. a noise. In this case, the pixel value of such recovered pixel can be corrected to the threshold value for the white eye candidate pixel, i.e. its detection limit value. Or, as this is actually correction of a noise component, the pixel value of the recovered pixel may be corrected to an average value of pixel values of pixels around it. Incidentally, the iris detection can employ a method which effects a contour enhancement operation on the eye area image data D and then obtains the border coordinates of the iris, eyelid, etc.</p>
<p id="p-0053" num="0061">In the above, the threshold value(s) used for detection of white eye candidate pixel is (are) predetermined. Alternatively, this threshold value may be determined according to the luminance distribution pattern of the eye area data D. Namely, the white eye candidate pixel detection may fail when the luminance of the eye area data D as a whole varies, due to e.g. luminance in the surrounding in the site of the photography and/or a certain orientation of the face of the photographic subject. Then, the luminance distribution of the eye are data D is analyzed by the histogram analyzing section <b>95</b>. And, threshold value information determined based on the result of analysis is transmitted to the white eye candidate pixel detecting section <b>91</b>, so as to detect white eye candidate pixels having luminance greater than a predetermined value (i.e. luminance within a predetermined range). The above analysis can be realized by a method illustrated in <figref idref="DRAWINGS">FIG. 8</figref> for example. Namely, <figref idref="DRAWINGS">FIG. 8</figref> shows an exemplary method for obtaining a luminance condition for detection of a white eye pixel to be corrected by the white eye correcting technique of the invention. <figref idref="DRAWINGS">FIG. 8(</figref><i>a</i>) shows eye area image data D having high luminance (brightness) overall (overall offset to the higher side). Whereas, <figref idref="DRAWINGS">FIG. 8(</figref><i>b</i>) shows eye are image data D having low luminance (brightness) overall (overall offset to the lower side). In these graphs, the pixel value of each pixel has a minimum luminance of “0” and a maximum luminance of “255” (FF in the 8-bit representation). And, the group of pixel values on the lower luminance segment represent the pixels belonging in the iris area (b). Another group of pixel values on the intermediate luminance segment represent the pixels belonging in the skin area (d). The other group of pixel values on the higher luminance segment represent the pixels belonging in the white eye area (a). For effective detection of the white eye candidate pixels, it is advantageous to set the threshold value between the skin area (d) and the white eye area (a).</p>
<p id="p-0054" num="0062">Incidentally, in this embodiment, the histogram analyzing section <b>95</b> is incorporated within the white eye correcting means <b>90</b>. The invention is not limited thereto. Instead, separately from the white eye correction, the luminance distribution may be analyzed within the print managing section <b>32</b> or the image processing unit <b>70</b>, so that only the result of analysis or the threshold value information obtained from the result of the analysis may be transmitted to the white eye correcting means <b>90</b>. Further, in this, the subject image to be subjected to the distribution analysis may be the low-resolution thumbnail data, rather than the raw or source photographic image data, which is high resolution data. Namely, for the purpose of luminance distribution analysis, detailed image data is not needed. Rather, the use of thumbnail data will provide the advantage of reduction in the time required for analysis. Obviously, the same applies to the analysis to be effected by the histogram analyzing section <b>95</b> of the white eye correcting means <b>90</b>.</p>
<p id="p-0055" num="0063">The white eye pixel thus detected and determined is then corrected by the white eye correcting section <b>93</b>. Most briefly, the white eye correction section <b>93</b> effects this white eye correction by changing the luminance of the white eye pixel. In this particular case, this operation is effected solely by the luminance correcting subsection <b>93</b><i>b </i>of the white eye correcting section <b>93</b>. This correction by changing luminance will be explained in greater details by way of an exemplary correction by luminance change according to the invention's white eye correcting method illustrated in <figref idref="DRAWINGS">FIG. 9</figref>. Namely, the correction by luminance change is carried out by increasing/decreasing the pixel values of each pixel in a same direction. The example shown in <figref idref="DRAWINGS">FIG. 9</figref> is a change for increasing the luminance (brighter). By increasing all of the R, G, B pixel values of the pixel, the luminance is increased. With this change (correction), the luminance of the white eye pixel is enhanced to be brighter, so that the white eye area (a) can be brighter (whiter).</p>
<p id="p-0056" num="0064">For even better white eye correction result, prior to the change of luminance of the white eye pixel by the luminance correcting subsection <b>93</b><i>b</i>, the chroma correcting subsection <b>93</b><i>a </i>may change the chroma of the white eye pixel. With this, unneeded tint can be eliminated, thus enabling correction of the chroma closer to the achromatic side. This correction by changing chroma will be explained in greater details by way of an exemplary correction by chroma change according to the invention's white eye correcting method illustrated in <figref idref="DRAWINGS">FIG. 10</figref>. Namely, the correction by chroma change is carried out by approximating the respective pixel values of each pixel to an average value thereof. In <figref idref="DRAWINGS">FIG. 10</figref>, a mark Ave denotes an average value of R, G, B pixel values. If the R, G, B pixel values are same, the color of the pixel represented by these pixels becomes either black or white or a grey therebetween, that is, being achromatic. The change of chroma by the chroma correcting subsection <b>9</b><i>a </i>is not for forcibly rendering the color achromatic. Rather, as shown in <figref idref="DRAWINGS">FIG. 10</figref>, this correction is effected to achieve relative chroma reduction by approximating each pixel to the average value Ave.</p>
<p id="p-0057" num="0065">Furthermore, the white eye correction is also possible by changing the hue of the white eye pixel by the hue correcting subsection <b>93</b><i>c</i>. For obtaining natural appearance of white eye, this is possible by changing the color to slightly bluish. Then, the hue correcting subsection <b>93</b><i>c </i>effects hue correction. The correction by way of hue chance according to the invention's white eye correcting technique will be described next with reference to an example thereof illustrated in <figref idref="DRAWINGS">FIG. 11</figref>. For instance, in order to cause a target pixel to appear slightly bluish, this can be done by either reducing the R pixel value or increasing the B pixel value. Or, both of these operations can be carried out as shown in <figref idref="DRAWINGS">FIG. 11</figref>.</p>
<p id="p-0058" num="0066">In the foregoing embodiment, there have been described the three types of white eye correction in the white eye correcting section <b>93</b> effected by the chroma correcting subsection <b>93</b><i>a</i>, the luminance correcting subsection <b>93</b><i>b </i>and the hue correcting subsection <b>93</b><i>c</i>, respectively. It is not absolutely needed to effect all of these operations. Only one or two of them may be carried out. However, for the best result, all of these three types of correction should be effected. And, in that case, as illustrated in <figref idref="DRAWINGS">FIG. 4</figref>, it is advantageous to effect these operations in the order of the chroma correcting subsection <b>93</b><i>a</i>, the luminance correcting subsection <b>93</b><i>b </i>and the hue correcting subsection <b>93</b><i>c</i>. Namely, first, the chroma correcting subsection <b>93</b><i>a </i>corrects the color to the achromatic side, thereby to eliminate unnecessary tint. Then, the luminance correcting subsection <b>93</b><i>b </i>changes the pixel value to increase the whiteness. Finally, the hue correcting subsection <b>93</b><i>c </i>adds slight blueness to the pixel whose unnecessary tint has been eliminated. By eliminating unnecessary tint first, it becomes easier to achieve the whiteness improvement to be effected next by the luminance correction. Further, by correcting the hue to slightly bluish after the improvement of whiteness, it becomes easier to obtain the effect of bluish coloring.</p>
<p id="p-0059" num="0067">Next, with reference to <figref idref="DRAWINGS">FIG. 12</figref> illustrating an example of change of pixel value by the invention's white eye correcting method, the method of changing the pixel value for each of the above described types of correction will be described. In this white eye correction (the white eye correcting step), the correction is effected by a predetermined ratio relative to a difference between the white eye pixel value and the target pixel value as shown in this example of <figref idref="DRAWINGS">FIG. 12</figref>. With this, it is possible to avoid creation of unnatural impression which would occur otherwise due to excessive correction. This is advantageous also for allowing the correction to be effected with maintaining e.g. the gradation of the original image. This ratio relative to the difference may be determined for each type of correcting operation. For instance, the chroma correcting subsection <b>93</b><i>a </i>can carry out 10% correction, the luminance correcting subsection <b>93</b><i>b </i>can carry out 20% correction and the hue correcting subsection <b>93</b><i>c </i>can carry out 10% correction, respectively.</p>
<p id="p-0060" num="0068">Further, the above-described proportion of the corrections need not be fixed, but can be variably determined case by case for each image data (for each photographic frame image). And, the operator may input this by way of the user operating means (keyboard <b>24</b>, mouse <b>25</b>, etc.). Or, this can be calculated within the print managing section <b>32</b> or the image processing unit <b>70</b>, independently of the white eye correcting operation. Needless to say, a correction ratio calculating section can be added to the functional blocks of the white eye correcting means shown in <figref idref="DRAWINGS">FIG. 4</figref>. In case, the ratio is calculated by such correction ratio calculating section or within the print managing section <b>32</b> or the image processing unit <b>70</b>, it is possible to employ the low resolution thumbnail data, rather than the high resolution source photographic image data. Namely, for the purpose of correction ratio calculation, detailed image data is not needed. Rather, the use of thumbnail data will provide the advantage of reduction in the time required for the operation.</p>
<p id="p-0061" num="0069">The foregoing embodiment employs R, G, B as the color space for representing image data. The invention is not limited thereto. The white eye correction of the invention is possible also with using any other color space such as CMYK, L*a*b* or XYZ.</p>
<p id="p-0062" num="0070">After completion of the white eye correction on all white eye pixels, the corrected white eye pixels are written back into the memory <b>30</b> to be synthesized to image data of original format. This can be done by e.g. substitution of the image data stored within the memory <b>30</b> or any other storage by the corresponding corrected pixels.</p>
<p id="p-0063" num="0071">The image data which have been subjected to an appropriate degree of white eye correction will be then subjected to a necessary additional image processing and transmitted to the print exposing unit <b>14</b>, which then exposes a print paper P based on this print data, thereby to produce a finished print.</p>
<p id="p-0064" num="0072">In the foregoing embodiment, there is employed the so-called silver salt photographic printing technique wherein the print station <b>1</b>B effects exposure of the print paper P with a photographic image at the print exposing unit <b>14</b> and then develops a plurality of developing operations of this exposed print paper P. Needless to say, in this invention, the print station <b>1</b>B is not limited to such type. Instead, various photographic printing systems such as an ink jet printing for forming an image by jetting ink on to a film or a paper, a heat transfer printing method using a heat-sensitive sheet, etc.</p>
<p id="p-0065" num="0073">The present invention can be used for a variety of applications as a technique to be implemented by any image processing apparatus which requires detection and correction of white eye pixels from photographic image data. For instance, the invention's technique is applicable to a digital camera, a digital video camera, a mobile telephone having a camera function, a printer, a driver software or utility software therefor.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>I claim:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for correcting white eye in image data, comprising the steps of:
<claim-text>detecting a white eye candidate pixel from an eye extracted from the image data based on a predetermined detection condition;</claim-text>
<claim-text>determining said white eye candidate pixel as a white eye pixel based on a predetermined determination condition; and</claim-text>
<claim-text>effecting white eye correction of the determined white eye pixel by changing its luminance.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step of detecting an iris from the image data, and at said white eye pixel determining step, wherein said white eye candidate pixel is determined as the white eye pixel if said white eye candidate pixel has been detected from an area adjacent said iris.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said white eye correcting step is effected by changing a chroma of the white eye pixel first prior to the change of its luminance.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the white eye correcting step is effected by changing a hue of the white eye pixel.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the white eye correcting step effects the white eye correction by a ratio determined based on a difference between a predetermined pixel value of a target pixel and a pixel value of each white eye pixel.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said predetermined detection condition employed at said step of detecting a white eye candidate pixel is predetermined based on a luminance distribution of the image data.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A computer-readable medium comprising computer-executable instructions for correcting white eye in image data, said instructions comprising the steps of:
<claim-text>detecting a white eye candidate pixel from an eye extracted from the image data based on a predetermined detection condition;</claim-text>
<claim-text>determining said white eye candidate pixel as a white eye pixel based on a predetermined determination condition; and</claim-text>
<claim-text>effecting white eye correction of the determined white eye pixel by changing its luminance.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. An image processing apparatus for correcting white eye in image data, the apparatus comprising:
<claim-text>a white eye candidate pixel detecting section for detecting a white eye candidate pixel from an eye extracted from the image data based on a predetermined detection condition</claim-text>
<claim-text>a white eye pixel determining section for determining said white eye candidate pixel as a white eye pixel based on a predetermined determination condition; and</claim-text>
<claim-text>a white eye correcting section for effecting white eye correction of the determined white eye pixel by changing its luminance.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The apparatus according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising: a white eye determination condition calculating section for detecting an iris from the image data;
<claim-text>wherein said white eye pixel determining section determines said white eye candidate pixel as the white eye pixel if said white eye candidate pixel has been detected from an area adjacent said iris.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The apparatus according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said white eye correcting section effects the white eye correction by changing a chroma of the white eye pixel first prior to the change of its luminance.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The apparatus according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein said white eye correcting section effects the white eye correction by changing a hue of the white eye pixel.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The apparatus according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said white eye correcting section effects the white eye correction by a ratio determined based on a difference between a predetermined pixel value of a target pixel and a pixel value of each white eye pixel.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The apparatus according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said white eye candidate pixel detecting section detects a white eye candidate pixel based on a luminance distribution of the image data.</claim-text>
</claim>
</claims>
</us-patent-grant>
