<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298899-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298899</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10445247</doc-number>
<date>20030527</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2002-152491</doc-number>
<date>20020527</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>892</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>34</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>62</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382173</main-classification>
<further-classification>382156</further-classification>
</classification-national>
<invention-title id="d0e71">Image segmentation method, image segmentation apparatus, image processing method, and image processing apparatus</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5274747</doc-number>
<kind>A</kind>
<name>Furuta et al.</name>
<date>19931200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>706 43</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5283839</doc-number>
<kind>A</kind>
<name>Edelman et al.</name>
<date>19940200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382103</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5313532</doc-number>
<kind>A</kind>
<name>Harvey et al.</name>
<date>19940500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382156</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5497430</doc-number>
<kind>A</kind>
<name>Sadovnik et al.</name>
<date>19960300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382156</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2002/0181799</doc-number>
<kind>A1</kind>
<name>Matsugu et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382260</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>JP</country>
<doc-number>7-121695</doc-number>
<date>19950500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>JP</country>
<doc-number>11-185033</doc-number>
<date>19990700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>JP</country>
<doc-number>11-339041</doc-number>
<date>19991200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00009">
<othercit>Naeem Shareff, DeLiang L. Wang and Roni Yagel, “Segmentation of Medical Images Using LEGION”, IEEE Trans. Medical Imaging, vol. 18, No. 1, Jan. 1999.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00010">
<othercit>U.S. Appl. No. 10/445,247, filed May 27, 2003, Koide et al.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00011">
<othercit>U.S. Appl. No. 10/915,559, filed Aug. 11, 2004, Koide et al.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00012">
<othercit>J. C. Russ, The Image Processing Handbook, Third Edition, chapter 6, pp. 371-429, “Segmentation and Thresholding”, 1999.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00013">
<othercit>S. Sarkar, et al., IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 15, No. 3, pp. 256-268, “Integration, Inference, and Management of Spatial Information Using Bayesian Networks: Perceptual Organization”, Mar. 1993.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00014">
<othercit>S. M. Bhandarkar, et al., IEEE Transactions on Evolutionary Computation, vol. 3, No. 1, pp. 1-21, “Image Segmentation Using Evolutionary Computation”, Apr. 1999.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00015">
<othercit>E. Mozef, et al., Proceedings of SPIE, vol. 2784, pp. 120-125, “Parallel Architecture Dedicated to Image Component Labelling in O(n Log n): FPGA Implementation”, 1996.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00016">
<othercit>Y. Ishiyama, et al., Systems and Computers in Japan, vol. 26, No. 14, pp. 67-76, “Labeling Board Based on Boundary Tracking”, 1995.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00017">
<othercit>Y. Ishiyama, et al., The Institute of Electronics, Information, and Communication Engineers Research Paper Magazine D-II, vol. J78-D-II, No. 1, pp. 69-75, “Labelling Board Based on Boundary Tracking”, 1995.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00018">
<othercit>S-D. Jean, et al., Proceedings of Int'l Symp. on Cir. &amp; Sys. (ISCAS), Part 2 (of 6), pp. 565-568, “A New Algorithm and its VLSI Architecture Design for Connected Component Labeling”, 1994.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00019">
<othercit>D-L. Wang, et al., Neutral Computation, vol. 9, No. 4, pp. 1-30, “Image Segmentation Based on Oscillatory Correlation”, 1997.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00020">
<othercit>H. Ando, et al., Proc. 5<sup>th </sup>International Conference on Neutral Information Proceeding (ICONIP'98), pp. 586-589, “Oscillator Networks for Image Segmentation and Their Circuits Using Pulse Modulation Methods”, Oct. 21, 1998.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00021">
<othercit>H. Ando, et al., IEICE Trans. Fundamentals, vol. E83-A, No. 2, pp. 329-336, “A Nonlinear Oscillator Network for Gray-Level Image Segmentation and PWM/PPM Circuits for Its VLSI Implementation” Feb. 2000.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>24</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382155-161</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382173</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>16</number-of-drawing-sheets>
<number-of-figures>47</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20030219157</doc-number>
<kind>A1</kind>
<date>20031127</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Koide</last-name>
<first-name>Tetsushi</first-name>
<address>
<city>Higashihiroshima</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Mattausch</last-name>
<first-name>Hans Juergen</first-name>
<address>
<city>Higashihiroshima</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Morimoto</last-name>
<first-name>Takashi</first-name>
<address>
<city>Higashihiroshima</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="004" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Harada</last-name>
<first-name>Youmei</first-name>
<address>
<city>Higashihiroshima</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Oblon, Spivak, McClelland, Maier &amp; Neustadt, P.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>President of Hiroshima University</orgname>
<role>03</role>
<address>
<city>Higashihiroshima-shi</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Chen</last-name>
<first-name>Wenpeng</first-name>
<department>2624</department>
</primary-examiner>
<assistant-examiner>
<last-name>Ge</last-name>
<first-name>Yuzhen</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Cells i corresponding to pixels are initialized into a non-excitation state, to calculate coupling weights W<sub>ik </sub>between the eight cells k adjacent to the cells i, thereby determining leader cells p<sub>i</sub>=1 based on calculation results. Next, one leader cell yet to be excited is selected as a self-excitable cell. The selected cell is put into the excitation state, the excitable cells are selected based on the coupling weights between the adjacent cells, and the selected cells are put into the excitation state. These operations are repeated until no excitable cell is detected any more and, if there no excitable cell is detected any more, inhibition processing is performed, thereby completing image segmentation of one region. These operations are repeated until there is no non-excited and non-inhibited leader cell any more, thereby pinpointing regions belonging to the same category from an input image and identifying them as an image segmentation regions.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="106.51mm" wi="154.35mm" file="US07298899-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="231.90mm" wi="155.11mm" file="US07298899-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="227.33mm" wi="156.29mm" file="US07298899-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="229.87mm" wi="156.72mm" file="US07298899-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="200.15mm" wi="148.93mm" orientation="landscape" file="US07298899-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="184.32mm" wi="143.93mm" file="US07298899-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="225.81mm" wi="145.63mm" file="US07298899-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="228.77mm" wi="150.88mm" file="US07298899-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="108.46mm" wi="139.87mm" file="US07298899-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="225.98mm" wi="154.26mm" file="US07298899-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="230.80mm" wi="106.51mm" file="US07298899-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="230.72mm" wi="159.00mm" orientation="landscape" file="US07298899-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="224.54mm" wi="147.91mm" file="US07298899-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="226.31mm" wi="163.07mm" orientation="landscape" file="US07298899-20071120-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="229.28mm" wi="150.62mm" file="US07298899-20071120-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="214.38mm" wi="141.73mm" orientation="landscape" file="US07298899-20071120-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="227.41mm" wi="151.05mm" file="US07298899-20071120-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is based upon and claims the benefit of priority from the prior Japanese Patent Application No. 2002-152491, filed May 27, 2002, the entire contents of which are incorporated herein by reference.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to, for example, software for image segmentation/extraction in an image recognition system, a moving body detection system, a digital camera, a digital video camera, a robot vision, an authentication system by means of facial recognition, a security system, an artificial intelligence (AI) system, etc. and an image segmentation method, an image segmentation apparatus, an image processing method, and an image processing apparatus which are applicable to an image segmentation/extraction integrated circuit (IC).</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">Recently, there is a desire for an increase in speed of image recognition in order to realize intelligent information processing technologies. For example, to realize an intelligent robot that behaves and makes a decision in nearly the same way as a human and real-time facial recognition or moving body recognition, it is necessary to speedily process visual information (information of a natural image) which is taken in from a camera etc. Especially in the case of control or image recognition for robots, the visual information needs to be processed on the fly. The visual information, however, is typically vast in amount and so it takes a considerably long time to process it using a general purpose computer, etc.</p>
<p id="p-0007" num="0006">One of the fundamental and indispensable processing items required to perform image processing such as image recognition is image segmentation. This image segmentation is processing to take out an individual object (for example, a human face or a moving body such as a vehicle) from a complicated natural image which is taken in as an input, so that this processing is fundamental and indispensable in order to perform image processing such as image recognition. There have been made a number of proposals for image segmentation so far. Those image segmentation methods proposed are classified as follows.</p>
<p id="p-0008" num="0007">(1) Method based on profile line</p>
<p id="p-0009" num="0008">(2) Method based on region</p>
<p id="p-0010" num="0009">(3) Combination of methods (1) and (2) and method which formulates logical expressions which optimize the combination</p>
<p id="p-0011" num="0010">Method (1) is described in detail in the following references 1 and 2. Further, method (2) is described in detail in reference 1. Even further, combination method (3) is described in detail in the following reference 3.</p>
<p id="p-0012" num="0011">Reference 1: J. C. Russ, “The image Processing Handbook”, CRC PRESS, (1999).</p>
<p id="p-0013" num="0012">Reference 2: S. Sarker and K. L. Boyer, “Integration inference, and management of spatial information using Bayesian networks: Perceptual organization”, IEEE Trans. Pattern Anal. Machine Intel., Vol. 15, pp. 256-274, (1993).</p>
<p id="p-0014" num="0013">Reference 3: S. M. Bhandarker and H. Zhang, “Image segmentation using evolutionary computation”, IEEE Trans. on Evolutionary Computation, Vol. 3, No. 1, (1999).</p>
<p id="p-0015" num="0014">Of these image segmentation methods, method (2) based on the region is referred to as a region growth type one and attracting attention as the one that can segment an object accurately.</p>
<p id="p-0016" num="0015">It is to be noted that the image segmentation methods proposed so far all premise that a color or grayscale image be processed by software. Therefore, these methods involving a complicated processing procedure and take much time in processing. To speed up this processing, preferably it is realized by hardware. A relevant algorithm, however, is complicated, making it difficult to realize the algorithm in a relatively small area. As a result, the algorithm cannot but rely on software, providing a present situation of an extreme difficulty in realization of real time processing (which takes a few seconds or so). Furthermore, the color and grayscale natural images each require one dedicated algorithm for their segmentation.</p>
<p id="p-0017" num="0016">While on the other hand, for a binary image, a few hardware processing methods have been proposed so far which realize high speed labeling. See the following references for example.</p>
<p id="p-0018" num="0017">Reference 4: E. Mozef et al., “Parallel architecture dedicated to image component labeling in 0(nlogn): FPGA implementation”, Proceedings of SPIE, Vol. 2784, pp. 120-125, (1996).</p>
<p id="p-0019" num="0018">Reference 5: Y. Ishiyama et al., “Labeling board based on boundary tracking”, Systems and Computers in Japan, Vol. 26, No. 14, pp. 67-76, (1995).</p>
<p id="p-0020" num="0019">Reference 6: Ishiyama et al., “Labeling board based on boundary tracking”, the Institute of Electronics, Information, and Communication Engineers Research Paper Magazine D-II, Vol. J78-D-II, No. 1, pp. 69-75, (1995).</p>
<p id="p-0021" num="0020">Reference 7: S. D. Jean et al., “New algorithm and its VLSI architecture design for connected component labeling”, Proceedings of Int'l Symp. on Cir. &amp;Sys. (ISCAS), Part 2 (of 6), pp. 565-568, (1994).</p>
<p id="p-0022" num="0021">These methods, however, are dedicated for use in processing of binary images and handle only one-bit values for each pixel, which means that they cannot easily be applied directly to the processing of the color or grayscale natural image.</p>
<p id="p-0023" num="0022">To date, D. L. Wang et al. have proposed an image segmentation algorithm for the grayscale image based on a cell network model LEGION (Locally Excitatory Globally Inhibitory Oscillator Network) (see Reference 8: D. L. Wang and D. Terman, “Image segmentation based on oscillator correlation”, Neural Computation, Vol. 9, No. 4, pp. 805-836, (1997).</p>
<p id="p-0024" num="0023">In this model, cells are correlated with pixels of a segmentation-subject image, so that the image is segmented using the non-linear dynamics of the cell network, based on synchronous and asynchronous oscillation states of each of the cells. To realize this directly, however, it is necessary to solve a plurality of differential equations for each of the pixels, so that the image segmentation is carried out highly accurately, but is time consuming. Therefore, to realize real time processing, it is necessary to speed up the processing by realizing it by hardware.</p>
<p id="p-0025" num="0024">To this end, there is proposed a method to utilize an analog circuit in order to realize the nonlinear dynamics of the cell network based on the LEGION for a grayscale image. See the following references for example.</p>
<p id="p-0026" num="0025">Reference 9: H. Ando, T, Morie, M. Nagata, and A. Iwata, “Oscillator networks for image segmentation and their circuits using pulse modulation methods”, Procs. 5'th International Conference on Neural Information Processing (ICONIP'98), pp. 586-589, Kitakyushu, Oct. 21, (1998).</p>
<p id="p-0027" num="0026">Reference 10: H. Ando, T. Morie, Nagata and A. Iwata, “A nonlinear oscillator network for gray-level image segmentation and PWM/PPM circuits for its VLSI implementation”, IEICE Trans. Fundamentals, Vol. E83-A, No. 2, pp. 329-336, (2000).</p>
<p id="p-0028" num="0027">These methods by use of an analog circuit use a capacitor to store an analog quantity. A larger capacity requires a larger area of the capacitor, which inflicts a significant restriction on a decrease in area and an increase in operating speed of a future integrated circuit in an attempt to increase its integration density. Further, handling of an analog quantity is subject to an effect of fluctuations in a manufacturing process. Therefore, much attention must be paid during the manufacturing process, Making it not easy to realize the algorithm as an LSI chip even by state-of-the-art technologies.</p>
<heading id="h-0003" level="1">BRIEF SUMMARY OF THE INVENTION</heading>
<p id="p-0029" num="0028">It is an object of the invention to provide an image segmentation method which can perform real time image segmentation on color and grayscale natural images and also which is suitable for realization by hardware and also to provide an image segmentation apparatus, an image processing method, and an image processing apparatus which utilities an architecture that is based on an algorithm which provides a basis for this image segmentation method.</p>
<p id="p-0030" num="0029">According to an aspect of the invention, there is provided an image segmentation method which pinpoints one of the regions from an input image belonging to the same category and identifies the one region as an image segmentation region, the method comprising: a preparation step of including, an initialization step of putting, into a non-excitation state, a cell which is an individual image segmentation unit corresponding to pixels of the input image, a taking step of pixel values of the pixels corresponding to the cell, and calculating each coupling weight between a plurality of adjacent cells, and a determination step of leader cells (self-excitable cells candidate) based on each calculation result; a self-excitable cell detection step of selecting one of the leader cells determined by the determination step to detect the one cell as a self-excitable cell; a self-excitation step of putting, into an excitation state, the self-excitable cell detected in the self-excitable cell detection step; an excitable cell detection step of detecting an excitable cell from adjacent cells based on the coupling weights between the cells in the excitation state including the leader cell and the adjacent cells; an excitation step of putting, into an excitation state, the cells detected in the excitable cell detection step; and an inhibition step of putting, into an inhibition state, the cell in the excitation state if no cell is detected in the excitable cell detection step, wherein image segmentation of one region is completed by repeating the excitation until no cell is detected any more in the excitable cell detection step; and the image segmentation of all the regions is completed by repeating the respective steps until no leader cell in the non-excitation state is detected any more in the self-excitable cell detection step.</p>
<p id="p-0031" num="0030">In the image segmentation method having this configuration, the image segmentation can be realized by simple processing and so can be performed in a very short processing time and also accompanied by a simple image segmentation unit (cell) which processes each pixel, so that it can be realized by hardware in a small area, thereby integrating a number of cells in one chip. Further, every cell operates in parallel with each other, thereby enabling increasing the speed of image segmentation even of an image having a large number of pixels. Further, it can be realized also as software, thereby enabling increasing the speed in an application that can be accommodated by the conventional software.</p>
<p id="p-0032" num="0031">According to another aspect of the invention, there is provided an image segmentation apparatus which pinpoints one of the regions from an input image belonging to the same category and identifies the one region as an image segmentation region to selectively output an image of the arbitrary image segmentation region, the apparatus comprising: an input image memory which stores pixel values of the input image; a coupling weight calculation circuit which reads out the pixel values from the input image memory to calculate a coupling weight between each image segmentation cell corresponding to each pixel and the adjacent cell by pipeline processing; a leader cell determination circuit which determines, based on the coupling weights calculated by the coupling weight calculation circuit, as a leader cell, the cell in which a total sum of the coupling weights with the adjacent cells is in excess of a reference value; an image segmentation cell network having decision means in which there are alternately arranged in an array state the image segmentation cells which transit over a non-excitation state, a self-excitable state and an excitation state in accordance with each pixel of the input image and coupling weight registers which hold the inter-cell coupling weights obtained by the coupling weight calculation circuit, the decision means deciding whether each cell is excitable or not based on values held in the coupling weight registers in which the cells are arranged adjacent to each other, the decision means putting, into the excitation state, the leader cell determined by the leader cell determination circuit and putting, into the excitation state, the excitable cell selected from the adjacent cells to expand an excitation region, thereby deciding the image segmentation region; a segmentation region storage circuit which stores information of all the cells in the image segmentation region decided by the image segmentation cell network; and an output image memory which stores the pixel value corresponding to each cell in an arbitrary image segmentation region based on contents stored in the segmentation region storage circuit.</p>
<p id="p-0033" num="0032">In the above configuration, an image segmentation architecture is realized as the image segmentation cell network by arranging the image segmentation units (cells) corresponding to the pixels and the coupling weight registers holding the inter-cell coupling weights alternately in an array, to provide a two-dimensional array structure and in a small area and so can be realized in an integrated circuit extremely easily.</p>
<p id="p-0034" num="0033">As an application example of the invention, there are contemplated such an image processing method and an image processing apparatus as to be required to perform real time processing by use of the above configuration.</p>
<p id="p-0035" num="0034">Additional objects and advantages of the invention will be set forth in the description which follows, and in part will be obvious from the description, or may be learned by practice of the invention. The objects and advantages of the invention may be realized and obtained by means of the instrumentalities and combinations particularly pointed out hereinafter.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWING</heading>
<p id="p-0036" num="0035">The accompanying drawings, which are incorporated in and constitute a part of the specification, illustrate embodiments of the invention, and together with the general description given above and the detailed description of the embodiments given below, serve to explain the principles of the invention.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 1A</figref> and <figref idref="DRAWINGS">FIG. 1B</figref> are explanatory views of an input image and an inter-cell coupling weight in an embodiment of the invention, <figref idref="DRAWINGS">FIG. 1A</figref> shows the input image, and <figref idref="DRAWINGS">FIG. 1B</figref> shows the inter-cell coupling weights;</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 2</figref> is a flowchart which shows a flow of processing of an image segmentation algorithm in the same embodiment;</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 3</figref> is a table which shows a cell state transition in the same embodiment;</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram which shows a hardware configuration example of an image segmentation apparatus in the same embodiment;</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 5A</figref>, <figref idref="DRAWINGS">FIG. 5B</figref>, <figref idref="DRAWINGS">FIG. 5C</figref> and <figref idref="DRAWINGS">FIG. 5D</figref> are explanatory views of a coupling weight calculation circuit shown in <figref idref="DRAWINGS">FIG. 4</figref>, <figref idref="DRAWINGS">FIG. 5A</figref> shows its fundamental configuration, <figref idref="DRAWINGS">FIG. 5B</figref> shows a configuration of a grayscale image weight calculation circuit, <figref idref="DRAWINGS">FIG. 5C</figref> shows a configuration of a color image weight calculation circuit, and <figref idref="DRAWINGS">FIG. 5D</figref> shows an input/output example of an encoder;</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 6A</figref>, <figref idref="DRAWINGS">FIG. 6B</figref> and <figref idref="DRAWINGS">FIG. 6C</figref> are explanatory views of a leader cell determination circuit shown in <figref idref="DRAWINGS">FIG. 4</figref>, <figref idref="DRAWINGS">FIG. 6A</figref> shows a calculation-subject cell, <figref idref="DRAWINGS">FIG. 6B</figref> shows a coupling weight data transferring order, and <figref idref="DRAWINGS">FIG. 6C</figref> shows a basic configuration example of the leader cell determination circuit;</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 7</figref> is a block diagram which shows a configuration example in a case where an input/output operation for the cell network is performed using a shift register in the image segmentation cell network shown in <figref idref="DRAWINGS">FIG. 4</figref>;</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 8</figref> is a block diagram which shows a configuration example in a case where an input/output operation for the cell network is performed using a bus in the image segmentation cell network shown in <figref idref="DRAWINGS">FIG. 4</figref>;</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 9A</figref> and <figref idref="DRAWINGS">FIG. 9B</figref> are illustrations showing connection examples between cells and coupling weight registers used in <figref idref="DRAWINGS">FIG. 7</figref> or <b>8</b>, <figref idref="DRAWINGS">FIG. 9A</figref> shows a connection example with the horizontal coupling weight registers, and <figref idref="DRAWINGS">FIG. 9B</figref> shows a connection example with the vertical coupling weight registers;</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 10</figref> is a block diagram which shows a connection example between an arbitrary cell and four adjacent coupling-weight-register blocks in the same embodiment;</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 11</figref> is a block diagram which shows a configuration example of a coupling-weight-register block containing four coupling-weight-registers, in the same embodiment;</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 12A</figref> and <figref idref="DRAWINGS">FIG. 12B</figref> are illustrations showing configuration examples of image segmentation cells in the same embodiment, <figref idref="DRAWINGS">FIG. 12A</figref> is a block diagram which shows a configuration in a case where addition and subtraction are performed in parallel with each other, and <figref idref="DRAWINGS">FIG. 12B</figref> is a block diagram which shows a configuration in a case where addition and subtraction are performed in serial with each other;</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. 13</figref> is a block diagram which shows a connection example of global suppressors in the same embodiment;</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 14</figref> is a conceptual diagram which shows how non-excited leader cells are sequentially searched by a self-excitation permission signal and a self-excitable cell is detected from among the leader cells in the same embodiment;</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 15A</figref> to <figref idref="DRAWINGS">FIG. 15I</figref> are explanatory views of operations of an image segmentation algorithm in the same embodiment with reference to an execution example on 3×3 grayscale images;</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. 16A</figref> to <figref idref="DRAWINGS">FIG. 16D</figref> are explanatory views of operations of an image segmentation architecture in the same embodiment with reference to an execution example on 7×7 images;</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 17</figref> is a timing chart which shows a result of simulation of image segmentation on the 7×7 images of <figref idref="DRAWINGS">FIG. 16A</figref> to <figref idref="DRAWINGS">FIG. 16D</figref>;</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 18</figref> is an illustration which shows one example of a display screen when the image segmentation algorithm of the same embodiment is realized as a software program in Java to execute image segmentation;</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 19</figref> is a characteristic graph which shows an experiment result of an image segmentation time in a case where the image segmentation algorithm of the same embodiment is realized in software;</p>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. 20A</figref> to <figref idref="DRAWINGS">FIG. 20D</figref> are illustrations respectively showing application examples of image segmentation on grayscale images in the same embodiment;</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 21A</figref> to <figref idref="DRAWINGS">FIG. 21D</figref> are illustrations showing an application example of image segmentation on a color image in the same embodiment; and</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 22</figref> is a characteristic graph which shows a simulation result of the image segmentation time in a case where the image segmentation algorithm of the same embodiment is realized by hardware.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0059" num="0058">The following will describe in detail embodiments of the invention with reference to drawings.</p>
<p id="p-0060" num="0059">A. Configuration of Image Segmentation Algorithm (Method)</p>
<p id="p-0061" num="0060">The following will describe an image segmentation algorithm to realize image segmentation according to an embodiment related to the invention.</p>
<p id="p-0062" num="0061">To realize the image segmentation algorithm based on the above-mentioned LEGION model by D. L. Wang directly by software, it is necessary to solve a plurality of differential equations for each pixel. Therefore, it cannot easily be applied to a case where real time processing is required. Further, to realize it by hardware in order to increase the processing speed, an attempt to directly realize the algorithm by hardware gives rise to complicated and large scale hardware required to solve the differential equations. Therefore, it is considered to be extremely difficult to realize a large scale cell network on one chip.</p>
<p id="p-0063" num="0062">Therefore, the present embodiment proposes an image segmentation algorithm that can realize required hardware by a digital circuit capable of high speed processing rather than realizing the LEGION model directly by hardware. This algorithm features that a behavior of the cell network is interpreted by paying attention to a respect that a cell corresponding to each pixel can be handled in a non-excitation state, a self-excitable state, and an excitation state.</p>
<p id="p-0064" num="0063">It is to be noted that, as shown in <figref idref="DRAWINGS">FIG. 1A and 1B</figref>, each cell corresponds to one pixel of an input image, so that, for example, a coupling weight W<sub>ij </sub>between the cells i and j is calculated using values of the corresponding pixels. <figref idref="DRAWINGS">FIG. 1A</figref> shows one example of the input image, in which one cell corresponds to one pixel and reference symbols A-D indicate image segmentation regions. <figref idref="DRAWINGS">FIG. 1B</figref> shows inter-cell coupling weights and reference symbols i, j, k, and l indicate the cells that correspond to the pixels and reference symbols W<sub>ij</sub>, W<sub>ik</sub>, W<sub>il</sub>, W<sub>kj</sub>, W<sub>kl</sub>, and W<sub>jl </sub>indicate the inter-cell coupling weights.</p>
<p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. 2</figref> is a flowchart which shows a processing procedure of the image segmentation algorithm. This image segmentation algorithm is composed of six processing steps of (a) initialization, (b) self-excitable cell detection, (c) self-excitation, (d) excitable cell detection, (e) excitation of dependent cells, and (f) inhibition. According to this algorithm, each cell which corresponds to each pixel enters the non-excitation state, the self-excitable state, and the excitation state and operates in parallel with each other based on the coupling weights between the adjacent eight pixels.</p>
<p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. 3</figref> shows the cell state transition. In <figref idref="DRAWINGS">FIG. 3</figref>, a variable x<sub>i </sub>represents whether the cell i is in the excitation state or the non-excitation state: x<sub>i</sub>=1 indicates the excitation state and x<sub>i</sub>=0 indicates the non-excitation state. Further, a variable p<sub>i </sub>represents whether the relevant cell is self-excitable or not. p<sub>i</sub>=1 indicates that the cell is leader cell and so becomes a self-excitable cell candidate. The image segmentation algorithm of the present embodiment decides whether the cell of interest belongs to the same image segmentation region as the leader cell based on the excitation or non-excitation state.</p>
<p id="p-0067" num="0066">The following will describe the processing procedure shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0068" num="0067">At “initialization” of step (a), the process once initializes each cell i into the non-excitation state. Then, the process calculates each inter-cell coupling weight W<sub>ik </sub>between the cell i and its adjacent eight cells k and, based on these calculated inter-cell coupling weights, determines the self-excitable cells (which are referred to as leader cells) p<sub>i</sub>=1. At “self-excitable cell detection” of step (b), the process selects one leader cell (p<sub>i</sub>=1) yet to be excited as the self-excitable cell. At “self-excitation” of step (c), the process puts this selected leader cell into the excitation state. At “excitable cell detection” of step (d), the process selects the excitable cells based on the states of the adjacent eight neighboring cells and the inter-cell coupling weights. At “excitation of dependent cells” of step (e), the process puts the cells selected at step (d) into the excitation state.</p>
<p id="p-0069" num="0068">The process repeats these operations until no excitable cell is selected any more. If there is no excitable cell any more, the process performs “inhibition, region labeling” of step (f), thereby completing the image segmentation of one region. The process repeats these operations until there is no non-excited leader cell any more, thereby completing the image segmentation of the image as a whole.</p>
<p id="p-0070" num="0069">The following will describe details of each processing of steps (a) through (f) described above.</p>
<p id="p-0071" num="0070">At the “initialization” of step (a), the process initializes the variable x<sub>i </sub>that indicates whether the cell i is in the excitation or non-excitation state, into x<sub>i</sub>=0 (non-excitation). The process calculates the coupling weights W<sub>ik </sub>based on the pixel values of the cells k∈N(i) which are adjacent to the cell (pixel) i.</p>
<p id="p-0072" num="0071">The N(i) represents a set of the cells adjacent to the cell i (for example, a set of the adjacent eight cells). For example, for a grayscale image, the coupling weight W<sub>ik </sub>is represented by the following equation (1):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>W</i><sub>ik</sub><i>=I</i><sub>max</sub>/(1<i>+|I</i><sub>i</sub><i>−I</i><sub>k</sub>|), <i>k∈N</i>(<i>i</i>)  (1)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where I<sub>i </sub>and I<sub>k </sub>indicate a brightness value of the pixels i and k respectively and I<sub>max </sub>indicates the maximum value of the pixel brightness value and becomes I<sub>max</sub>=255 if the brightness value is represented in eight bits.
</p>
<p id="p-0073" num="0072">In the case of segmenting a color image, color information can be used to improve the accuracy of image segmentation. Since the algorithm of the present embodiment makes transition over the cell states by the coupling weights between the adjacent cells (pixels), for example, coupling weights W(R)<sub>ik</sub>, W(G)<sub>ik</sub>, and W(B)<sub>ik </sub>for the respective red (R), green (G), and blue (B) colors are calculated by the following equations (2):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>W</i>(<i>R</i>)<sub>ik</sub><i>=I</i>(<i>R</i>)<sub>max</sub>/(1<i>+|I</i>(<i>R</i>)<sub>i</sub><i>−I</i>(<i>R</i>)<sub>k</sub>|),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>W</i>(<i>G</i>)<sub>ik</sub><i>=I</i>(<i>G</i>)<sub>max</sub>/(1<i>+|I</i>(<i>G</i>)<sub>i</sub><i>−I</i>(<i>G</i>)<sub>k</sub>|),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>W</i>(<i>B</i>)<sub>ik</sub><i>=I</i>(<i>B</i>)<sub>max</sub>/(1<i>+|I</i>(<i>B</i>)<sub>i</sub><i>−I</i>(<i>B</i>)<sub>k</sub>|)  (2)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0074" num="0073">By calculating an equation (3) based on a calculation result of the equations (2), the inter-cell coupling weight W<sub>ik </sub>is determined. It is thus possible to realize more accurate image segmentation.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>W</i><sub>ik</sub>=min{<i>W</i>(<i>R</i>)<sub>ik</sub><i>, W</i>(<i>G</i>)<sub>ik</sub><i>, W</i>(<i>B</i>)<sub>ik</sub>}  (3)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0075" num="0074">Next, the process decides whether the cell of interest is a leader cell (self-excitable cell candidate) or not based on the inter-cell coupling weights. If a total sum Σ<sub>k∈N(i)</sub>W<sub>ik </sub>of the coupling weights of all the cells adjacent to the cell of interest is larger than a predetermined threshold value φ<sub>p </sub>(Σ<sub>k∈N(i)</sub>W<sub>ik</sub>&gt;φ<sub>p</sub>), the process sets the variable p<sub>i </sub>that indicates whether self-excitation is permitted or not permitted to p<sub>i</sub>=1, to determine the cell of interest to be a self-excitable leader cell. If it is not larger than that (Σ<sub>k∈N(i)</sub>W<sub>ik</sub>≦φp), the process initializes the variable in p<sub>i</sub>=0 (non-self-excitable). The leader cell becomes a candidate of a starting point for the subsequent processing of image segmentation.</p>
<p id="p-0076" num="0075">Finally, the process initializes a variable z (which is referred to as a global suppressor) which decides whether there is an excited cell or not, in z=0. If z=1, it indicates that there is an excited cell, that is, one region is continuously undergoing image segmentation. If z=0, it indicates that there is no excited cell any more, that is, one region is completed in image segmentation. For each cell i, a variable z<sub>i </sub>is provided which indicates whether the state is changed or not, so that only when the cell has transited from the non-excitation state to the excitation state, z<sub>i</sub>=1 is set and, otherwise, z<sub>i</sub>=0 is set. Based on this variable z<sub>i</sub>, the value of the global suppressor z is defined to be z=V<sub>∀i</sub>z<sub>i </sub>as a logical sum of all z<sub>i </sub>values. In this case, V indicates a logical sum (OR) operator.</p>
<p id="p-0077" num="0076">At “self-excitable cell detection” of step (b), the process selects one leader cell (self-excitable cell candidate) yet to be excited, that is, the one that satisfies conditions (x<sub>i</sub>=0Λp<sub>i</sub>=1). In this case, Λ indicates a logical product (AND) operator.</p>
<p id="p-0078" num="0077">At “self-excitation” of step (c), the process sets this selected leader cell into the excitation state x<sub>i</sub>=1 (self-excitation), to start image segmentation on one region. In this case, z<sub>i</sub>=1 is set.</p>
<p id="p-0079" num="0078">At “excitable cell detection” of step (d), the process checks the excitation state of the cells k∈N(i) adjacent to the non-excited cell i and calculates a total sum S<sub>i</sub>=Σ<sub>k∈N</sub>(i)Λxk=1W<sub>ik </sub>of the coupling weights of the cells in the excitation state. If the cells k∈N(i) are in the excitation state, that is, x<sub>k</sub>=1, the process adds a coupling weight between the cell of interest and the adjacent excited cell k to S<sub>i</sub>. If this total sum S<sub>i </sub>of the coupling weights is larger than the predetermined threshold value φz (S<sub>i</sub>&gt;φz), the cell i becomes an excitable cell.</p>
<p id="p-0080" num="0079">At “excitation of dependent” of step (e), the process sets all the excitable cells i detected at “excitable cell detection” of step (d) into the excitation state x<sub>i</sub>=1 and, at the same time, sets z<sub>i</sub>=1. Further, the process sets the state variable z<sub>i</sub>=0 (no state change) for the cells i which are already into the excitation state (x<sub>i</sub>=1 and z<sub>i</sub>=1) other than those cells that have been excited at the processing of “excitation of dependent”.</p>
<p id="p-0081" num="0080">If there is no excitable cell present, the process executes “inhibition” of step (f). In this processing of “inhibition”, x<sub>i</sub>=0 and z<sub>i</sub>=0 are set for the cell i in the excitation state and if p<sub>i</sub>=1, p<sub>i</sub>=0 is set. Thus, one region is completed in image segmentation.</p>
<p id="p-0082" num="0081">Subsequently, the process returns to “self-excitable cell detection” of step (b), to shift to image segmentation of the next region, thereby repeating the processing items described above. If no self-excitable cell yet to be excited is detected any more in the processing of “self-excitable cell detection” of step (b), the process decides that all the regions are completed in image segmentation.</p>
<p id="p-0083" num="0082">The following describes an example of the image segmentation algorithm of the present embodiment. All the cells execute the following algorithm in parallel with each other. It is to be noted that a function of find_leader( ) in the algorithm retrieves a leader cell yet to be excited and returns its cell number. If there is no such cell present, it returns a negative numeral. Further, the variables x<sub>i</sub>, z<sub>i</sub>, and z vary as time passes by, so that at moments t and t+1, the value of x<sub>i </sub>is to be represented in the forms of x<sub>i</sub>(t) and x<sub>i</sub>(t+1) respectively.</p>
<p id="h-0006" num="0000">[Image Segmentation Algorithm]</p>
<p id="p-0084" num="0000">
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0083">1. Initialization
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0084">1. Initialization of global inhibitor z(0)=0;</li>
        <li id="ul0002-0002" num="0085">2. Calculation of coupling weights with adjacent neighboring eight cells
        <ul id="ul0003" list-style="none">
            <li id="ul0003-0001" num="0086">(a) In the case of grayscale image
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>W</i><sub>ik</sub>=(<i>I</i><sub>max</sub>)/(1<i>+|I</i><sub>i</sub><i>−I</i><sub>k</sub>|), <i>k∈N</i>(<i>i</i>);<?in-line-formulae description="In-line Formulae" end="tail"?>
</li>
            <li id="ul0003-0002" num="0087">(b) In the case of color image
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>W</i>(<i>R</i>)<sub>ik</sub>=(<i>I</i>(<i>R</i>)<sub>max</sub>)/(1<i>+|I</i>(<i>R</i>)<sub>i</sub><i>−I</i>(<i>R</i>)<sub>k</sub>|),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>W</i>(<i>G</i>)<sub>ik</sub>=(<i>I</i>(<i>G</i>)<sub>max</sub>)/(1<i>+|I</i>(<i>G</i>)<sub>i</sub><i>−I</i>(<i>G</i>)<sub>k</sub>|),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>W</i>(<i>B</i>)<sub>ik</sub>=(<i>I</i>(<i>B</i>)<sub>max</sub>)/(1<i>+|I</i>(<i>B</i>)<sub>i</sub><i>−I</i>(<i>B</i>)<sub>k</sub>|),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>W</i><sub>ik</sub>=min{<i>W</i>(<i>R</i>)<sub>ik</sub><i>, W</i>(<i>G</i>)<sub>ik</sub><i>, W</i>(<i>B</i>)<sub>ik</sub>}.<?in-line-formulae description="In-line Formulae" end="tail"?>
</li>
        </ul>
        </li>
        <li id="ul0002-0003" num="0088">3. Determination of leader cells if (Σ<sub>k∈N(i)</sub>W<sub>ik</sub>&gt;φ<sub>p</sub>)then p<sub>i</sub>=1; otherwise p<sub>i</sub>=0;</li>
        <li id="ul0002-0004" num="0089">4. Put all cells in non-excitation state x<sub>i</sub>(0)=0;</li>
    </ul>
    </li>
    <li id="ul0001-0002" num="0090">2. Self-excitation
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0091">if (there is no excitable cell present) then stop;//terminate
        <ul id="ul0005" list-style="none">
            <li id="ul0005-0001" num="0092">else if (find_leader( )==iΛp<sub>i</sub>=1) then x<sub>i</sub>(t+1)=12, z(t+1)=1, go to</li>
        </ul>
        </li>
        <li id="ul0004-0002" num="0093">(3. Excitation)//self-excitation else go to (2. Self-excitation);</li>
    </ul>
    </li>
    <li id="ul0001-0003" num="0094">3. Excitation of dependent cells
    <ul id="ul0006" list-style="none">
        <li id="ul0006-0001" num="0095">Setting of global inhibitor z(t)=V<sup>∀i</sup>z<sub>i</sub>(t);//z<sub>i</sub>'s logical or</li>
        <li id="ul0006-0002" num="0096">if(z(t)==0) then//there is no excited cell present if(x<sub>i</sub>(t)==1)then
        <ul id="ul0007" list-style="none">
            <li id="ul0007-0001" num="0097">x<sub>i</sub>(t+1)=0, z<sub>i</sub>(t+1)=0, p<sub>i</sub>=0;//inhibition go to (2. Self-excitation);</li>
        </ul>
        </li>
        <li id="ul0006-0003" num="0098">else if (x<sub>i</sub>(t)==0Λz<sub>i</sub>(t)==0)then//non-excitation S<sub>i</sub>(t)=Σ<sub>k∈N(i)</sub>(W<sub>ik</sub>×x<sub>k</sub>(t));
        <ul id="ul0008" list-style="none">
            <li id="ul0008-0001" num="0099">if(S<sub>i</sub>(t)&gt;φ<sub>z</sub>)then x<sub>i</sub>(t+1)=1;z<sub>i</sub>(t+1)=1;//excitation</li>
            <li id="ul0008-0002" num="0100">else x<sub>i</sub>(t+1)=0;z<sub>i</sub>(t+1)=0;//non-excitation</li>
            <li id="ul0008-0003" num="0101">else if(x<sub>i</sub>(t)==1Λz<sub>i</sub>(t)==1) then x<sub>i</sub>(t+1)=1; z<sub>i</sub>(t+1)=0;</li>
        </ul>
        </li>
        <li id="ul0006-0004" num="0102">go to (3. Excitation of dependent cells);</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0085" num="0103">This image segmentation algorithm of the present embodiment has the following features.</p>
<p id="p-0086" num="0104">(1) The algorithm can be realized by simple processing, so that an image can be segmented in a very short processing time.</p>
<p id="p-0087" num="0105">(2) Furthermore, an element (cell) to be processed for each pixel is simplified, so that the algorithm can be realized by hardware in a small area, thereby integrating the many cells on one chip.</p>
<p id="p-0088" num="0106">(3) Further, the cells all operate in parallel, to make it possible to increase the speed of image segmentation processing on an image having a large number of pixels.</p>
<p id="p-0089" num="0107">(4) The algorithm can be realized also as software, so that high speed processing is possible even in an application that can be accommodated by conventional software.</p>
<p id="p-0090" num="0108">B. Image Segmentation Architecture (Apparatus) and Integrated Circuit Configuration</p>
<p id="p-0091" num="0109">The image segmentation algorithm can be realized as hardware by using a digital circuit. <figref idref="DRAWINGS">FIG. 4</figref> shows a block diagram of an architecture that realizes this algorithm by the digital circuit as an embodiment of an image segmentation apparatus related to the present embodiment.</p>
<p id="p-0092" num="0110">In <figref idref="DRAWINGS">FIG. 4</figref>, first, brightness values (hereinafter referred to as pixel values) I<sub>i </sub>of an image are read out in order from an input image memory <b>11</b>, to calculate the coupling weights W<sub>ik </sub>at a coupling weight calculation circuit <b>12</b>. Based on the coupling weights calculated at the coupling weight calculation circuit <b>12</b>, a leader cell determination circuit <b>13</b> determines leader cells (decision of whether Σ<sub>k∈N(i)</sub>W<sub>ik</sub>&gt;φ<sub>p </sub>is established). In such a manner, pipeline processing is executed on each pixel i of the input image, to transfer data of the calculated W<sub>ik </sub>and p<sub>i </sub>to a cell network <b>14</b> which executes image segmentation. The cell network <b>14</b> performs the operations given by the algorithm concurrently on the respective pixels (cells) to segment the image. A result of this image segmentation is passed through a segmentation region storage circuit <b>15</b> and is output to an output image memory <b>16</b>.</p>
<p id="p-0093" num="0111">The following will describe details of each block.</p>
<p id="h-0007" num="0000">[Coupling Weight Calculation Circuit <b>12</b>]</p>
<p id="p-0094" num="0112">A configuration of the coupling weight calculation circuit <b>12</b> is described with reference to <figref idref="DRAWINGS">FIGS. 5A</figref>, <b>5</b>B, <b>5</b>C, and <b>5</b>D. <figref idref="DRAWINGS">FIG. 5B</figref> shows a basic configuration of a circuit which calculates the coupling weights by the pipeline processing. In this figure, the pixel values I<sub>i</sub>, I<sub>i−1</sub>, . . . , I<sub>j</sub>, I<sub>j−1</sub>, . . . , and I<sub>k</sub>, I<sub>k−1</sub>, . . . given in three vertically consecutive rows y−1, y, and y+1 in the image memory are input in order from the left side in the figure.</p>
<p id="p-0095" num="0113">The pixel values of each of these rows are sent to a data selection circuit <b>122</b> both via a register <b>121</b> which delays the values by one pixel and directly. Based on a control signal, the data selection circuit <b>122</b> selectively transfers each two pixel values necessary to calculate the coupling weights between the relevant pixels (cells), to each of four weight calculation circuits <b>123</b>.</p>
<p id="p-0096" num="0114">The weight calculation circuit <b>123</b> calculates the coupling weight W<sub>ik </sub>based on the two pixel values I<sub>i </sub>and I<sub>k </sub>and transfers a calculation result to the leader cell determination circuit <b>13</b> and the cell network <b>14</b> in order.</p>
<p id="p-0097" num="0115"><figref idref="DRAWINGS">FIGS. 5B and 5C</figref> show examples of the weight calculation circuit <b>123</b> for a grayscale image and a color image respectively. In <figref idref="DRAWINGS">FIGS. 5B and 5C</figref>, a reference numeral <b>123</b>A indicates an absolute value calculation circuit, a reference numeral <b>123</b>B indicates an encoder, and a reference numeral <b>123</b>C indicates a minimum value determination circuit.</p>
<p id="p-0098" num="0116">Although a value of:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>W</i><sub>ik</sub><i>=I</i><sub>max</sub>/(1<i>+|I</i><sub>i</sub><i>−I</i><sub>k</sub>|), <i>k∈N</i>(<i>i</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
can be calculated directly for the grayscale image, a hardware quantity of a division circuit becomes large. In place of doing so, therefore, the weight calculation circuit <b>123</b> of the present embodiment uses the encoder <b>123</b>B which executes encode processing such as shown in <figref idref="DRAWINGS">FIG. 5D</figref>, thereby encoding an eight-bit output of the absolute value calculation circuit <b>123</b>A into a three-bit output. It is thus possible to decrease the area required in the case where the hardware configuration is employed.
</p>
<p id="p-0099" num="0117">In the case of the color image, three data pieces I(R)<sub>i</sub>, I(G)<sub>i</sub>, and I(B)<sub>i </sub>of R, G, and B colors are sequentially transferred from the left side in the figure to calculate W(R)<sub>ik</sub>, W(G)<sub>ik</sub>, and W(B)<sub>ik</sub>, minimum value (W<sub>ik</sub>=min{W(R)<sub>ik</sub>, W(G)<sub>ik</sub>, W(B)<sub>ik</sub>}) are selected by the minimum value determination circuit <b>123</b>C in <figref idref="DRAWINGS">FIG. 5C</figref>, and the value of W<sub>ik </sub>is transferred to the leader cell determination circuit <b>13</b> and the cell network <b>14</b>, thereby enabling the realization.</p>
<p id="p-0100" num="0118">It is to be noted that as for the calculated coupling weight values, values beforehand calculated by software may be given as the input data.</p>
<p id="h-0008" num="0000">[Leader Cell Determination Circuit <b>13</b>]</p>
<p id="p-0101" num="0119">The following will describe a fundamental configuration of the leader cell determination circuit <b>13</b> with reference to <figref idref="DRAWINGS">FIGS. 6A</figref>, <b>6</b>B and <b>6</b>C. This leader cell determination circuit <b>13</b> calculates a total sum of the coupling weights of the adjacent eight neighboring cells, based on a calculation result of the coupling weight calculation circuit <b>12</b>, and decides whether the total sum is larger than a predetermined threshold value φ<sub>p </sub>(decision of whether Σ<sub>k∈N(i)</sub>W<sub>ik</sub>&gt;φ<sub>p </sub>is established). If such is the case, the circuit <b>13</b> outputs p<sub>i</sub>=1 and, otherwise, outputs p<sub>i</sub>=0. The output value is transferred to the cell network <b>14</b>, to be shifted through all of the cells starting from the leftmost row in order in a p<sub>i </sub>register of each image segmentation cell as a shift register, thereby setting p<sub>i </sub>for each cell.</p>
<p id="p-0102" num="0120">In the case of, for example, deciding whether an image segmentation cell P<sub>5 </sub>shown in <figref idref="DRAWINGS">FIG. 6A</figref> is a leader cell or not, results calculated by the coupling weight calculation circuit <b>12</b> as shown in <figref idref="DRAWINGS">FIG. 6B</figref> are input in order to input terminals IN<sub>1</sub>-IN<sub>3 </sub>of the leader cell determination circuit <b>13</b> having a configuration shown in <figref idref="DRAWINGS">FIG. 6C</figref>.</p>
<p id="p-0103" num="0121">This leader cell determination circuit <b>13</b> adds the coupling weight values input through the terminals IN<sub>1 </sub>and IN<sub>3 </sub>at a first adder <b>131</b> and adds this addition result to the coupling weight value input through the terminal IN<sub>2 </sub>at a second adder <b>132</b>. This addition result is adjusted in timing at a first register <b>133</b> and, at the same time, added to an output value of the first adder <b>131</b> at a third adder <b>134</b>. This addition result of the third adder <b>134</b> is adjusted in timing at a register <b>135</b> and, at the same time, added to an output value of the second adder <b>132</b> at a fourth adder <b>135</b>. Finally, the addition result of the fourth adder <b>135</b> is sent to a comparator <b>137</b>, which compares it to the threshold value φ<sub>p </sub>and, if it is larger than the threshold value φ<sub>p</sub>, determines P<sub>5 </sub>as the leader cell and sets the value of pi to 1.</p>
<p id="p-0104" num="0122">Although this example has been described with reference to the cell P<sub>5</sub>, the corresponding coupling weight values can be given in order to the cells respectively, to enable the pipeline processing. Therefore, the calculated results are transferred to the cell network <b>14</b>. In the cell network <b>14</b>, the p<sub>i </sub>register constitutes a shift register. Therefore, by using the shift register, it is possible to transfer data to all of the cells.</p>
<p id="p-0105" num="0123">It is to be noted that in the case of a structure having a later-described bus such as shown in <figref idref="DRAWINGS">FIG. 8</figref>, it is also possible to transfer data directly to the relevant cell by the bus. Further, in calculation of such a leader cell, as in the case of calculation of the coupling weight, it is also possible to give a value beforehand calculated by software as the input data.</p>
<p id="h-0009" num="0000">[Image Segmentation Cell Network <b>14</b>]</p>
<p id="p-0106" num="0124"><figref idref="DRAWINGS">FIGS. 7 and 8</figref> show configuration examples of the cell network <b>14</b> which execute the respective image segmentation processes. In the image segmentation algorithm of the present embodiment, the state to which each cell transits is determined on the basis of the states of the adjacent eight cells and the corresponding coupling weights. Therefore, the cell network <b>14</b> is realized by arranging an image segmentation cell P<sub>i </sub>which corresponds to each pixel and a coupling weight register WR<sub>k </sub>which registers a coupling weight between the adjacent cells alternately with each other in an array.</p>
<p id="p-0107" num="0125"><figref idref="DRAWINGS">FIG. 7</figref> is a block diagram which shows a configuration example in a case where data of the cell network <b>14</b> is input/output using a shift register. In <figref idref="DRAWINGS">FIG. 7</figref>, P<sub>i </sub>indicates the image segmentation cell, WR<sub>k</sub>(V) indicates a vertical coupling weight register, and WR<sub>k</sub>(H) indicates a horizontal coupling weight register. The coupling weight W<sub>ik </sub>and other data such as x<sub>i </sub>are transferred between the cells and the coupling weight registers through a local wiring line indicated by an arrow. Further, in order to input/output data to/from the network data is similarly transferred also between the adjacent cells and between the adjacent coupling weight registers through the local wiring line.</p>
<p id="p-0108" num="0126"><figref idref="DRAWINGS">FIG. 8</figref>, on the other hand, is a block diagram which shows a configuration example in a case where the data is input to and output from the cell network <b>14</b> through a bus. In <figref idref="DRAWINGS">FIG. 8</figref>, P<sub>i </sub>indicates the image segmentation cell, WR<sub>k</sub>(V) indicates the vertical coupling weight register, and WR<sub>k</sub>(H) indicates the horizontal coupling weight register. In order to improve parallel processing, the coupling weight W<sub>ik </sub>and other data such as x<sub>i </sub>are transferred to the cells and the coupling weight registers a bus to which the local wiring indicated by the arrow is connected.</p>
<p id="p-0109" num="0127">There are two kinds of coupling weight registers WR<sub>k</sub>: the horizontal coupling weight register WR<sub>k</sub>(H) shown in <figref idref="DRAWINGS">FIG. 9A</figref> and the vertical coupling weight register WR<sub>k</sub>(V) shown in <figref idref="DRAWINGS">FIG. 9B</figref>. The horizontal coupling weight register WR<sub>k</sub>(H) holds four coupling weight values related to the diagonal and horizontal pixels, while the vertical coupling weight register WR<sub>k</sub>(V) holds four coupling weight values related to the diagonal and vertical pixels. In <figref idref="DRAWINGS">FIGS. 8 and 9</figref>, an arrow in each of the coupling weight registers schematically indicates a positional relationship between the inter-cell coupling weights which are held.</p>
<p id="p-0110" num="0128">As shown in <figref idref="DRAWINGS">FIGS. 7 and 8</figref>, these coupling weight registers WR<sub>k</sub>(H) and WR<sub>k</sub>(V) are each arranged between the image segmentation cells Pi in such a manner that they may alternate. By arranging them in such a manner, they can each share the same coupling weight between themselves and the adjacent cell P<sub>i</sub>. Further, it is possible to reduce the length of the wiring line between the cell P<sub>i </sub>and each of the coupling weight registers WR<sub>k</sub>(H) and WR<sub>k</sub>(V). Furthermore, by causing an external coupling weight calculation circuit to beforehand calculate the coupling weight value between the adjacent pixels to be held in the coupling weight register WR<sub>k</sub>(H) or WR<sub>k</sub>(V), the image segmentation cell P<sub>i </sub>need not perform the calculation. It is thus possible to simplify the structure of the individual cell P<sub>i</sub>, thereby decreasing its area and increasing its operating speed.</p>
<p id="p-0111" num="0129"><figref idref="DRAWINGS">FIG. 10</figref> shows a connection between the image segmentation cell and the adjacent coupling weight register. In this figure, the connection related to P<sub>5 </sub>is shown by a bold line.</p>
<p id="h-0010" num="0000">[Coupling Weight Register WR<sub>k</sub>]</p>
<p id="p-0112" num="0130"><figref idref="DRAWINGS">FIG. 11</figref> shows a configuration example of the coupling weight resistors WR<sub>k</sub>. The coupling weight registers WR<sub>k </sub>are classified into two kinds: a vertical coupling type and a horizontal coupling type. Both of them have the same fundamental internal structure but are identified as the vertical coupling type if the coupling weights held in the register include an inter-vertical-cell coupling weight, and as the horizontal coupling type if they include an inter-horizontal-cell coupling weight.</p>
<p id="p-0113" num="0131">As shown in <figref idref="DRAWINGS">FIG. 11</figref>, the coupling weight register WR<sub>k </sub>is provided therein with a switch <b>21</b> which switches a coupling weight value input from a data input port into four output systems based on the input control signal, four registers <b>221</b>-<b>224</b> which hold the respective coupling weight values given from the switch <b>21</b>, and an output selection circuit <b>23</b> which transfers the coupling weight values to the adjacent image segmentation cells. The coupling weight value takes on a value of 0-255 in the case where the pixel value is represented in eight bits and so needs to have eight bits typically. The number of the coupling weight registers, however, is proportional to the number of the pixels. Therefore, the eight-bit coupling weight value is encoded into a three-bit one and held in the register <b>221</b>-<b>224</b>. It is thus possible to reduce the bit width of the wiring line required to transfer data to the image segmentation cells from each of the coupling weight registers, thereby decreasing the required area.</p>
<p id="p-0114" num="0132">The output selection circuit <b>23</b> of <figref idref="DRAWINGS">FIG. 11</figref> selects and outputs either one of the four coupling weight values respectively held in registers <b>221</b>-<b>224</b> based on the signals x<sub>i </sub>(excitation state: x<sub>i</sub>=1, non-excitation state: x<sub>i</sub>=0) which indicates the excitation or non-excitation state of the adjacent four cells Pi (i=1−4). If, for example, the cell P<b>5</b> is excited (x<sub>i=</sub>1) as shown in <figref idref="DRAWINGS">FIG. 10</figref>, it outputs a coupling weight (portion connected with a bold line in the figure) obtained from the pixel that corresponds to the cell P<b>5</b>. If the cell P<b>5</b> is not excited (x<sub>i</sub>=0), on the other hand, it outputs <b>0</b>.</p>
<p id="h-0011" num="0000">[Image Segmentation Cell P<sub>i</sub>]</p>
<p id="p-0115" num="0133">Configuration examples of the image segmentation cell P<sub>i </sub>are shown in <figref idref="DRAWINGS">FIGS. 12A and 12B</figref>. The image segmentation cell P<sub>i </sub>transits over the “non-excitation”, “self-excitable”, and “excitation” states in accordance with the image segmentation algorithm (<figref idref="DRAWINGS">FIG. 2</figref>).</p>
<p id="p-0116" num="0134">In the image segmentation cell Pi shown in <figref idref="DRAWINGS">FIG. 12A</figref>, the process stores the signal x<sub>i </sub>(one bit) which indicates the excitation state and the variable P<sub>i </sub>(one bit) which indicates permission/non-permission of self-excitation in registers <b>31</b> and <b>32</b> respectively. Further, the process inputs the coupling weights W<sub>ik</sub>×x<sub>i </sub>which each are encoded into three-bit ones between the eight neighboring cells, decodes them by a decoder <b>33</b>, calculates a total sum of the coupling weights S<sub>i</sub>(t) (=Σ<sub>k∈N(i) </sub>(W<sub>ik</sub>×x<sub>k</sub>(t)) by an adder <b>34</b>, and subtracts the threshold value φ<sub>z </sub>which decides “self-excitable” from the total sum S<sub>i</sub>(t) (11 bits) by a subtractor <b>35</b>. At the subtractor <b>35</b>, the process decides whether S<sub>i</sub>(t)−φ<sub>z</sub>&gt;0 and outputs a symbol which indicates a decision result to a control circuit <b>36</b>.</p>
<p id="p-0117" num="0135">It is to be noted that <figref idref="DRAWINGS">FIG. 12A</figref> shows the configuration example in a case of realizing by parallel processing the adder <b>34</b> which calculates the total sum S<sub>i </sub>which decides the excitable state in the image segmentation cell, whereas, as shown in <figref idref="DRAWINGS">FIG. 12B</figref>, such a configuration is possible that a control circuit <b>37</b> may conduct control over a switch <b>38</b> in input selection. In the image segmentation cell P<sub>i </sub>in this case, when the switch <b>38</b> operates to switch an input, the process sequentially and selectively inputs the coupling weights W<sub>ik</sub>×x<sub>i </sub>which are each encoded into the three-bit ones between the eight neighboring cells and the threshold value φ<sub>z </sub>which decides the “self-excitable” state. The process decodes a selection result into eight-bit data by a decoder <b>39</b> and executes additions and subtractions serially by a serial adder/subtractor <b>40</b> and a register <b>41</b>.</p>
<p id="p-0118" num="0136">That is, in the case of the configuration shown in <figref idref="DRAWINGS">FIG. 12A</figref>, additions and subtractions are executed in parallel with each other, so that the operating speed can be increased. This configuration, however, requires eight adders and subtractors, so that the cell area increases as a whole. The configuration shown in <figref idref="DRAWINGS">FIG. 12B</figref>, on the other hand, requires only one adder/subtractor, so that the cell area decreases. However, the time required for each addition/subtraction is increased from one cycle to nine cycles, so that the total processing time becomes longer than in the case of parallel addition/subtraction. Thus, the configuration of <figref idref="DRAWINGS">FIG. 12A</figref> and that of <figref idref="DRAWINGS">FIG. 12B</figref> are in a trade-off relationship. These configurations, therefore, are used properly in accordance with whether the higher-speed or the smaller area is more important than the other in use.</p>
<p id="p-0119" num="0137">The output signal x<sub>i </sub>of the control circuit <b>36</b> or <b>37</b> is sent to an adjacent coupling weight register. Further, the output signal z<sub>i </sub>is used in calculation of the global suppressor z (z(t)=V<sub>∀i</sub>z<sub>i</sub>(t)) <figref idref="DRAWINGS">FIG. 13</figref> shows a connection example of the global suppressors. As shown in <figref idref="DRAWINGS">FIG. 13</figref>, the output signal z<sub>i </sub>of each cell P<sub>i </sub>is OR-tied with the output z<sub>i </sub>of the adjacent cells, and each row is OR-tied with the next row, thereby resulting in the overall global suppressor z. This signal z is fed back to the control circuit <b>36</b> and <b>37</b> of each cell via a buffer circuit. In the case of a configuration in which the bus of <figref idref="DRAWINGS">FIG. 8</figref> is used, the signal z can be supplied to each cell by utilizing the bus.</p>
<p id="p-0120" num="0138">Further, a “next” signal becomes an input signal “pre” for the adjacent image segmentation cells shown in <figref idref="DRAWINGS">FIGS. 7 and 8</figref>. This “next” signal is used to realize the find_leader( ) function of the image segmentation algorithm, that is, to control the order in which the leader cells (self-excitable cells candidate) are to be excited. For example, a “next” signal output terminal and a “pre” signal input terminal are sequentially connected between the adjacent cells as shown in <figref idref="DRAWINGS">FIG. 14</figref>. Each of the cells is self-excitable when the input signal “pre” is set to pre=1 and p<sub>i</sub>=1. Therefore, in this configuration, control can be conducted so that the cells that have the setting of p<sub>i</sub>=1 and are in the non-excitation state may become the leader cell in an order starting from the left top cell.</p>
<p id="h-0012" num="0000">[Segmentation Region Storage Circuit <b>15</b>]</p>
<p id="p-0121" num="0139">Information of one region which has been subject to image segmentation can be detected if the value of x<sub>i </sub>of each cell is set to 1 (x<sub>i</sub>=1). In the case of the embodiment shown in <figref idref="DRAWINGS">FIG. 7</figref>, the x<sub>i </sub>register of each cell P<sub>i </sub>is connected between the adjacent cells in each row, thereby constituting the row-specific shift register. Therefore, the segmentation region storage circuit <b>15</b> arranged on the output side receives data held in the x<sub>i </sub>register from the cells in each column, to store the information of all the cells. It is thus possible to store the information of each of the regions which have been subject to image segmentation. In the case of the embodiment shown in <figref idref="DRAWINGS">FIG. 8</figref>, the same operations can be realized by utilizing the bus.</p>
<p id="p-0122" num="0140">C. Actions of Image Segmentation Algorithm (Method)</p>
<p id="p-0123" num="0141">The following will describe operations of the image segmentation algorithm in the present embodiment in an example of 3×3 grayscale images with reference to <figref idref="DRAWINGS">FIGS. 15</figref>.</p>
<p id="p-0124" num="0142">By the operations of the algorithm of this example, as shown in <figref idref="DRAWINGS">FIGS. 15A-15I</figref>, a segmentation region is grown on the basis of the following coupling weights based on the pixel values of the eight pixels k∈N(i) adjacent to the pixel i:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>W</i><sub>ik</sub><i>=I</i><sub>max</sub>/(1<i>+|I</i><sub>i</sub><i>|I</i><sub>k</sub>|), <i>k∈N</i>(<i>i</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where I<sub>max </sub>is the maximum value of the brightness value of the pixel. The cell corresponding to each pixel becomes a leader cell (self-excitable cell candidate, p<sub>i</sub>=1) if the total sum Σ<sub>k∈N(i)</sub>W<sub>ik </sub>of the coupling weights between itself and the cells that correspond to the adjacent eight pixels is larger than the threshold value φ<sub>p</sub>. In this example, as shown in <figref idref="DRAWINGS">FIG. 15C</figref>, two leader cells are present and so subject to self-excitation in an order starting from the upper left side. The leader cell provides a starting point candidate of image segmentation.
</p>
<p id="p-0125" num="0143">First, at initialization (step (a) of <figref idref="DRAWINGS">FIG. 2</figref>), all of the cells are each subject concurrently to calculation of the coupling weight W<sub>ik </sub>between each of themselves and the adjacent eight neighboring cells k∈N(i), to determine the leader cells (p<sub>i</sub>=1 for the leader cell and p<sub>i</sub>=0 for the others). Next, if there are any leader cells (p<sub>i</sub>=1) present (step (b) of <figref idref="DRAWINGS">FIG. 2</figref>), one of them starts self-excitation (region segmentation), to expand segmentation regions starting from the leader cell (<figref idref="DRAWINGS">FIG. 15E</figref>).</p>
<p id="p-0126" num="0144">Each cell i is subject to calculation of a total sum:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Σ<sub>k∈N(i)Λxk</sub>=1<i>W</i><sub>ik </sub><?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
between itself and the cells k∈N(i) that correspond to the adjacent eight neighboring pixels if they are in the excitation state (x<sub>k</sub>=1) and, if this total sum is larger than the threshold value φ<sub>z</sub>, is excited (x<sub>i</sub>=1) automatically (steps (d) and (e) of <figref idref="DRAWINGS">FIG. 2</figref>). These operations are performed concurrently on all the cells until there is no cell which is excited any more. If there is no cell newly excited any more, the process performs inhibition (x<sub>i</sub>=0, z<sub>i</sub>=0, and p<sub>i</sub>=0) (step (f) of <figref idref="DRAWINGS">FIG. 2</figref>). In this example, there is no excitable cell any more as shown in <figref idref="DRAWINGS">FIG. 15G</figref>, and segmentation of the white regions ends.
</p>
<p id="p-0127" num="0145">This one series of steps completes segmentation of one region. This series of steps is repeated until there is no non-segmented leader cell any more. In the example, gray region segmentation starts from the left bottom leader cell as shown in <figref idref="DRAWINGS">FIG. 15H</figref> and, upon completion of the segmentation, ends as shown in <figref idref="DRAWINGS">FIG. 15I</figref>.</p>
<p id="p-0128" num="0146">D. Actions of Image Segmentation Architecture (Apparatus) and Integrated Circuit</p>
<p id="p-0129" num="0147">An architecture in an image segmentation apparatus of the present embodiment has fundamentally the same operations as those of the image segmentation algorithm. Hereinafter, description is made with reference to an example where there are three regions of A, B, and C in an image consisting of 7×7 pixels as shown in <figref idref="DRAWINGS">FIG. 16A</figref>. Although, normally, a region that corresponds to the background other than the regions A, B, and C is also segmented as one region, this region is supposed to have no leader cell therein for simplicity in explanation.</p>
<p id="p-0130" num="0148">In initialization, values of the coupling weight W<sub>ik </sub>and pi calculated by the coupling weights calculation circuit <b>12</b> and the leader cell determination circuit <b>13</b> are transferred to the cell network <b>14</b> from the respective left-side input ports shown in <figref idref="DRAWINGS">FIGS. 7 and 8</figref>. If, for example, cells indicated by “L<sub>1</sub>, L<sub>2</sub>, and L<sub>3</sub>” in <figref idref="DRAWINGS">FIG. 16B</figref> are to become a leader cell, the p<sub>i </sub>values of the cells are such as shown in <figref idref="DRAWINGS">FIG. 16C</figref>. Therefore, by shifting data in order starting from the right-most side of the <figref idref="DRAWINGS">FIG. 16C</figref> to the cell network <b>14</b> (see <figref idref="DRAWINGS">FIG. 4</figref>), p<sub>i </sub>of each cell is initialized. The same operations are performed on the coupling weight W<sub>ik</sub>, thereby shifting the data to the cell network <b>14</b>.</p>
<p id="p-0131" num="0149">In a case where the order in which the leader cells (self-excitable cells candidate) are connected in self-excitable-cell-selection control as shown in <figref idref="DRAWINGS">FIG. 14</figref>, the process decides the non-excitation cells of p<sub>i</sub>=1 in the connection order starting from the left top cell and determines them as a leader cell in order. In the case of <figref idref="DRAWINGS">FIG. 16B</figref>, the leader cells are processed in an order of L<sub>1</sub>, L<sub>2</sub>, and L<sub>3</sub>. <figref idref="DRAWINGS">FIG. 16D</figref> shows an order in which the cells are excited. The excitation starts from the L<sub>1 </sub>cell and, when segmentation of the region A ends, shifts to the L<sub>2 </sub>cell, to segment the region B. Finally, the process starts excitation of the cell L<sub>3</sub>, to complete segmentation of the region C.</p>
<p id="p-0132" num="0150"><figref idref="DRAWINGS">FIG. 17</figref> shows part of each of signal waveform in a case where image segmentation is performed in <figref idref="DRAWINGS">FIG. 16A</figref>. In the figure, signal names x<sub>0</sub>-x<sub>6 </sub>give hexadecimal representation of the excitation state (value of x<sub>i</sub>) of the cells in columns <b>0</b>-<b>6</b> (which correspond to columns x<sub>0</sub>-x<sub>6 </sub>in <figref idref="DRAWINGS">FIG. 16A</figref>) in a bit configuration in which the upper row is regarded to represent the high-order bits. Besides, the figure shows signal waveforms of a clock signal and the global suppressor z. A check on the excitation order based on this result indicates that the excitation starts in an order indicated by numerals shown in <figref idref="DRAWINGS">FIG. 16D</figref>, to perform region segmentation.</p>
<p id="p-0133" num="0151">E. Effects of Image Segmentation Algorithm (Method)</p>
<p id="p-0134" num="0152">To verify the effectiveness of the algorithm of the present embodiment, the inventor created a simulator in Java (registered trademark) and C languages. The Java language is used to create about 1,300 lines including input/output routines for the image data, while the C language is used to create about 340 lines of the portion of the algorithm.</p>
<p id="p-0135" num="0153"><figref idref="DRAWINGS">FIG. 18</figref> shows an execution example of the image segmentation algorithm simulator created in Java on a grayscale image consisting of 320×240 pixels. As shown in the figure, the body of a white car is segmented.</p>
<p id="p-0136" num="0154"><figref idref="DRAWINGS">FIG. 19</figref> shows a result obtained when the algorithm of the present embodiment is installed as a sequential-processing program in the C language and executed on an Intel Pentium (registered trademark) 4 (1.3 GHz) processor. In this experiment, a plurality of sample images have been given as input data, to measure a square root of the number of pixels (which indicates the length of one side of the image) and a processing time required to segment the image. In the experiment, the processing time has been measured 100 times and averaged. As a result, it has been found that an image consisting of about 10,000 (100×100) pixels can be segmented in about 283 ms (excluding the input/output routines). Thus, the image segmentation algorithm of the present embodiment is speedy in processing and so can be used in real time processing by software on a relatively small image.</p>
<p id="p-0137" num="0155"><figref idref="DRAWINGS">FIGS. 20A-20D</figref> respectively show examples of image segmentation on grayscale images. Further, <figref idref="DRAWINGS">FIGS. 21A-21D</figref> show an example of image segmentation on a color image. As shown in <figref idref="DRAWINGS">FIGS. 21B and 21C</figref>, when the color image is converted into a grayscale image, the green and red colors take on the same brightness value (coupling weight) and so are segmented into the same region, which makes making image segmentation difficult in some cases. Therefore, by segmenting the color image directly by using coupling weights in the case of the color image, accurate segmentation is possible as shown in <figref idref="DRAWINGS">FIG. 21D</figref> even in an example where image segmentation is impossible, in the case of the grayscale image. It is thus possible to segment an image by the same algorithm and the same cell network only by changing the calculation of the coupling weight W<sub>ik</sub>, which provides a very significant advantage.</p>
<p id="p-0138" num="0156">F. Effects of Image Segmentation Architecture (Apparatus) and Integrated Circuit</p>
<p id="p-0139" num="0157"><figref idref="DRAWINGS">FIG. 22</figref> shows a result obtained when a simulator of an image segmentation architecture based on <figref idref="DRAWINGS">FIGS. 4</figref>, <b>7</b> and <b>8</b> has been created in the Java and C languages, to measure the image segmentation time in simulation. A method which realizes high-speed processing shown in <figref idref="DRAWINGS">FIG. 12A</figref> has been used on image segmentation cells. In the simulation, a plurality of sample images have been given as input data, to measure a square root (which indicates the length of one side of the image) and the maximum and minimum processing times required in image segmentation. Further, to estimate the worst case processing time by a calculation equation, such an image segmentation time also is shown in the graph as to be expected when an image of interest is regular and consist of black-and-white lattices in a very rare case of natural images where there are many regions subject to image segmentation.</p>
<p id="p-0140" num="0158">The results indicate that, if it is supposed that processing can be performed in a cycle of 10 ns (at a frequency of 100 MHz), very high-speed image segmentation is possible by which an image consisting of 160,000 (400×400) pixels can be processed in an average of 50 μs or less or, even in the worst case, 300 μs or less. Therefore, real time processing is sufficiently possible even taking into account input/output overheads.</p>
<p id="p-0141" num="0159">An image segmentation integrated circuit based on the image segmentation architecture of the present embodiment has been designed using a hardware description language. In the hardware description, a method realizing high-speed processing shown in <figref idref="DRAWINGS">FIG. 12A</figref> has been used on image segmentation cells. In this case, the image segmentation cells are given in about 100 lines, the horizontal and vertical coupling weight registers are each given in about 100 lines, and the other peripheral circuits are given in about 300 lines.</p>
<p id="p-0142" num="0160">Since the image segmentation architecture of the present embodiment has an array-shaped regular configuration as shown in <figref idref="DRAWINGS">FIGS. 7 and 8</figref>, a generator has been created in the C language which automatically generates an overall cell network. The cell network generator has about 400 lines. When this generator is used to generate a cell network consisting of 16×16 pixels, the entire description is created in the hardware description language over about 3,500 lines and the simulation description, about 600 lines.</p>
<p id="p-0143" num="0161">The hardware description thus created has been realized in an LSI using three-layered metal wiring CMOS technologies based on a design rule of 0.35 μm. To roughly calculate the number of image segmentation cells that can be put on the chip, logic syntheses with a commercial software have been performed using a standard-cell library to estimate an area. As a result of the logic syntheses, the image segmentation cell has an area A<sub>pi </sub>of 26,495 μm<sup>2 </sup>and the coupling weight register has an area A<sub>WR</sub><sub>k </sub>of 8,873 μm<sup>2</sup>. In a case where the image is a square, if each side has N number of pixels, the area A<sub>total </sub>of the entire cell network can be estimated by the following equation:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>A</i><sub>total</sub><i>=A</i><sub>pi</sub><i>×N</i><sup>2</sup><i>+A</i><sub>WRk</sub>×(<i>N</i><sup>2</sup>+2)  (4)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0144" num="0162">Thus, if the cells are to be put on a chip of 9 mm×9 mm (area of 81 mm<sup>2</sup>), about 45×45 pixels can be mounted as viewed from an estimate of the obtained cell area. If, further, it is supposed that the number of transistors and the layout area can be halved by full-custom designing, the area of the image segmentation cells and that of the coupling weight registers can both be reduced to about ¼, thereby installing about 67×67 pixels.</p>
<p id="p-0145" num="0163">The areas can be further reduced by substituting a serial adder/subtractor (<figref idref="DRAWINGS">FIG. 12B</figref>) which performs processing serially for the adder which calculates a total sum of the weights (S<sub>i</sub>=Σ<sub>k∈N(i) </sub>(W<sub>ik</sub>×x<sub>k</sub>(t)) in order to decide the self-excitable state in the image segmentation cell.</p>
<p id="p-0146" num="0164">In this case, decision processing requires nine cycles for execution instead of one cycle, so that the total processing time increases as much as about nine times. The processing of image segmentation by use of the circuit of the present embodiment is very speedy and has no effects on real time processing, so that it is possible to process an image consisting of 160,000 (400×400) pixels in 2.7 ms or less even in the worst case estimate and in 450 μs on average. In this case, the area Ap<sub>i </sub>of the image segmentation cell is decreased to 13,953 μm<sup>2</sup>, so that it is estimated that about 84×84 pixels can be installed on a 9 mm×9 mm chip using MOS technologies based on a design rule of 0.35 μm in the case of full custom designing, and about 162×162 pixels can be installed on a 9 mm×9 mm chip using CMOS technologies based on a design rule of 0.18 μm.</p>
<p id="p-0147" num="0165">Table 1 shows estimated values of the number of mountable pixels in a case where they are installed in full custom designing using CMOS technologies based on design rules of 0.35 μm, 0.18 μm, and 0.09 μm. Data of the chip areas and the technologies is referred from ITRS 2000Update Road Map (Reference: “ITRS 2000 Update: The International Technology Roadmap for Semiconductors 2000 Update”, URL http://public.itrs.net/(2000)). Based on this reference, it can be estimated that if CMOS technologies based on a design rule of 0.09 μm which become a standard in 2004 are used, about 972×972 pixels can be realized on one chip (area: 356 mm<sup>2</sup>) for high performance applications.</p>
<p id="p-0148" num="0166">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="center"/>
<thead>
<row>
<entry namest="1" nameend="1" rowsep="1">TABLE 1</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry>Estimates of the number of pixels that can be processed</entry>
</row>
<row>
<entry>by one chip (in the case of full custom designing)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="49pt" align="left"/>
<colspec colname="1" colwidth="168pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry>Technology</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="4">
<colspec colname="offset" colwidth="49pt" align="left"/>
<colspec colname="1" colwidth="49pt" align="left"/>
<colspec colname="2" colwidth="63pt" align="left"/>
<colspec colname="3" colwidth="56pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry/>
<entry>Number of pixels</entry>
<entry>Number of pixels</entry>
</row>
<row>
<entry/>
<entry/>
<entry>that can be</entry>
<entry>that can be</entry>
</row>
<row>
<entry/>
<entry/>
<entry>processed in the</entry>
<entry>processed in the</entry>
</row>
<row>
<entry/>
<entry/>
<entry>case of parallel</entry>
<entry>case of serial</entry>
</row>
<row>
<entry/>
<entry>Chip area</entry>
<entry>adder/subtractor</entry>
<entry>adder/subtractor</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="3" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="4">
<colspec colname="1" colwidth="49pt" align="left"/>
<colspec colname="2" colwidth="49pt" align="left"/>
<colspec colname="3" colwidth="63pt" align="left"/>
<colspec colname="4" colwidth="56pt" align="left"/>
<tbody valign="top">
<row>
<entry>0.35 μm</entry>
<entry>Standard</entry>
<entry>138 × 138</entry>
<entry>171 × 171</entry>
</row>
<row>
<entry/>
<entry>size of 170</entry>
<entry>(19,044)</entry>
<entry>(29241)</entry>
</row>
<row>
<entry/>
<entry>[mm<sup>2</sup>]</entry>
</row>
<row>
<entry/>
<entry>High</entry>
<entry>186 × 186</entry>
<entry>232 × 232</entry>
</row>
<row>
<entry/>
<entry>performance</entry>
<entry>(34,596)</entry>
<entry>(53,824)</entry>
</row>
<row>
<entry/>
<entry>size of 310</entry>
</row>
<row>
<entry/>
<entry>[mm<sup>2</sup>]</entry>
</row>
<row>
<entry>0.18 μm</entry>
<entry>Standard</entry>
<entry>270 × 270</entry>
<entry>336 × 336</entry>
</row>
<row>
<entry>(1999)</entry>
<entry>size of 170</entry>
<entry>(72,900)</entry>
<entry>(112,896)</entry>
</row>
<row>
<entry/>
<entry>[mm<sup>2 </sup>]</entry>
</row>
<row>
<entry/>
<entry>High</entry>
<entry>363 × 363</entry>
<entry>452 × 452</entry>
</row>
<row>
<entry/>
<entry>performance</entry>
<entry>(131,769)</entry>
<entry>(204,304)</entry>
</row>
<row>
<entry/>
<entry>size of 310</entry>
</row>
<row>
<entry/>
<entry>[mm<sup>2</sup>]</entry>
</row>
<row>
<entry>0.09 μm</entry>
<entry>Standard</entry>
<entry>578 × 578</entry>
<entry>718 × 718</entry>
</row>
<row>
<entry>(2004)</entry>
<entry>size of 195</entry>
<entry>(334,084)</entry>
<entry>(515,524)</entry>
</row>
<row>
<entry/>
<entry>[mm<sup>2</sup>]</entry>
</row>
<row>
<entry/>
<entry>High</entry>
<entry>780 × 780</entry>
<entry>972 × 972</entry>
</row>
<row>
<entry/>
<entry>performance</entry>
<entry>(608,400)</entry>
<entry>(944,784)</entry>
</row>
<row>
<entry/>
<entry>size of 356</entry>
</row>
<row>
<entry/>
<entry>[mm<sup>2</sup>]</entry>
</row>
<row>
<entry namest="1" nameend="4" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0149" num="0167">G. Key Points of Embodiments Related to the Invention</p>
<p id="p-0150" num="0168">As described above, according to the method or apparatus for image segmentation based on the image segmentation algorithm and the architecture of the embodiments, real time image segmentation of color and grayscale natural images can be executed on all pixels of an input image in parallel, thereby realizing real time processing, which has been difficult using conventional image segmentation methods based on software. Further, the algorithm and the architecture make it possible to realize a real time image processing method, a real time image processing apparatus, and an image processing integrated circuit. The following will enumerate characteristics of the embodiments.</p>
<p id="p-0151" num="0169">(1) A simple and high speed image segmentation algorithm can be realized not only by software, but also by a digital circuit. This algorithm expresses the cell states by a digital variable and so can be realized as a digital circuit. Therefore, by using present-day CAD techniques, it is possible to design a circuit which accommodates restrictions by automatic processing if the conditions in designing are not stringent. As a result, it is possible to design the circuit by state-of-the-art manufacturing technology relatively easily, giving an expectation of an improvement in integration density and operating speed. Further, the image segmentation algorithm is a very simple method and so can increase the processing speed of image segmentation, even in the conventional processor-based image segmentation system, by means of software.</p>
<p id="p-0152" num="0170">(2) As the image segmentation architecture, there are alternately arranged in an array state the image segmentation cells (<figref idref="DRAWINGS">FIG. 12</figref>) which correspond to pixels and the two kinds of vertical and horizontal coupling weight registers (<figref idref="DRAWINGS">FIG. 9</figref>), in a realized form of the image segmentation cell network (<figref idref="DRAWINGS">FIGS. 7 and 8</figref>). Such a two-dimensional array structure accompanied even by realization of a smaller area can be extremely easily installed into an integrated circuit.</p>
<p id="p-0153" num="0171">(3) The image segmentation cells can be realized both in a case where the adder/subtractor is used in parallel processing with importance placed on an increase in processing speed, and in a case where the adder/subtractor is used in serial processing with importance placed on a decrease in area (<figref idref="DRAWINGS">FIG. 12</figref>). This makes it possible to select the high speed processing and the compacting of the apparatus in accordance with service conditions.</p>
<p id="p-0154" num="0172">(4) Image segmentation is realized by pipeline processing as shown in <figref idref="DRAWINGS">FIG. 4</figref>. This makes it possible to segment the pixels in parallel with each other by a simple configuration.</p>
<p id="p-0155" num="0173">(5) By the algorithm and the architecture, cell state transition is made using the coupling weights between the adjacent cells (pixels), so that only by changing the coupling weights, it is possible to use the same algorithm and cell network for a color image and a grayscale image. Further, a portion which is different, in calculation of the coupling weight, between the color and gray scale images can be separated as a coupling weight calculation circuit from the cell network so that the calculation can be performed by pipeline processing. As a result, the area can be reduced.</p>
<p id="p-0156" num="0174">Additional advantages and modifications will readily occur to those skilled in the art. Therefore, the invention in its broader aspects is not limited to the specific details and representative embodiments shown and described herein. Accordingly, various modifications may be made without departing from the spirit or scope of the general invention concept as defined by the appended claims and their equivalents.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image segmentation method which pinpoints one of regions from an input image belonging to a same category and identifies the one region as an image segmentation region, said method comprising:
<claim-text>a preparation step including,
<claim-text>an initialization step of putting, into a non-excitation state, a cell which is an individual image segmentation unit corresponding to pixels of the input image,</claim-text>
<claim-text>a taking step of pixel values of the pixels corresponding to the cell, and calculating each coupling weight between a plurality of adjacent cells, and</claim-text>
<claim-text>a determination step of determining leader cells based on each calculation result in the taking step;</claim-text>
</claim-text>
<claim-text>a self-excitable cell detection step of selecting one of the leader cells determined by the determination step to detect the one leader cell as a self-excitable cell;</claim-text>
<claim-text>a self-excitation step of putting, into an excitation state, the self-excitable cell detected in the self-excitable cell detection step;</claim-text>
<claim-text>an excitable cell detection step of detecting an excitable cell from adjacent cells based on said coupling weights between cells in the excitation state including the leader cells and the adjacent cells;</claim-text>
<claim-text>an excitation step of putting, into an excitation state, the excitable cell detected in the excitable cell detection step; and</claim-text>
<claim-text>an inhibition step of putting, into an inhibition state, a cell in the excitation state if no cell is detected in the excitable cell detection step, wherein:</claim-text>
<claim-text>image segmentation of one region is completed by repeating the excitation step until no cell is detected any more in the excitable cell detection step; and</claim-text>
<claim-text>the image segmentation of all the regions is completed by repeating the respective steps until no leader cell in the non-excitation state is detected any more in the self-excitable cell detection step,</claim-text>
<claim-text>wherein I<sub>i </sub>is a pixel value of the cell i (i indicates a cell number) which is an individual image segmentation unit corresponding to the pixels of the input image, x<sub>i </sub>is a variable which indicates whether the cell i is in the excitation or non-excitation state, p<sub>i </sub>is a variable which indicates whether the self-excitation is permitted or not, W<sub>ik </sub>is the coupling weight between the adjacent cells i and k, φ<sub>p </sub>is a threshold value which decides whether the self-excitation is permitted or not, φ<sub>z </sub>is a threshold value which decides whether the self-excitation is permitted or not, z<sub>i </sub>is a variable which indicates whether the state of cell i is changed or not, and z is a variable of a global suppressor which decides whether are cells having changed to the excitation state based on a logical sum of the values z<sub>i</sub>'s of all the cells;</claim-text>
<claim-text>in the preparation step, the variable x<sub>i </sub>of the image segmentation cell i is set to 0 (x<sub>i</sub>=0: non-excitation), the pixel values I<sub>i </sub>corresponding to the cells i are taken in to calculate the coupling weight W<sub>ik </sub>between the adjacent plural cells i and k, so that if a total sum of calculation results is larger than the threshold value φ<sub>p</sub>, p<sub>i</sub>=1 (self-excitable state) is set and if the total sum is equal to or smaller than the threshold value φ<sub>p</sub>, p<sub>i</sub>=0 (non-self-excitable state) is set for initialization, and z=0 where the variable z is the global suppressor is set for initialization;</claim-text>
<claim-text>in each self-excitable cell detection step, at least one non-excited leader cell is selected from among the leader cells of p<sub>i</sub>=1 determined in the determination step to detect the selected cells as the self-excitable cells;</claim-text>
<claim-text>in each self-excitation step, the variables x<sub>i </sub>and z<sub>i </sub>of the self-excitable cells i detected in the self-excitable cell detection step are set to 1 (x<sub>i</sub>=1: self-excitation, z<sub>i</sub>=1: changed state), respectively;</claim-text>
<claim-text>in the excitable cell detection step, if a total sum of the coupling weights W<sub>ik </sub>between the excited cells k (x<sub>k</sub>=1) adjacent to the cells i in the non-excitation state is larger than the threshold value φ<sub>z </sub>the cells i are detected to be the excitable cells;</claim-text>
<claim-text>in each excitation step, the variables x<sub>i </sub>and z<sub>i </sub>of all the cells i detected in the excitable cell detection step are set to 1 (x<sub>i</sub>=1: excitation state, z<sub>i</sub>=1: changed state), respectively, and the variable z<sub>i </sub>of the cells i already in the excitation state (x<sub>i</sub>=1 and z<sub>i</sub>=1) is set to 0 (z<sub>i</sub>=0: unchanged state); and</claim-text>
<claim-text>in each inhibition step, if no cell is detected in the excitable cell detection step, the cells of x<sub>i</sub>=1 (excitation state) are set to x<sub>i</sub>=0 (non-excitation state) and z<sub>i</sub>=0 (unchanged state), and if p<sub>i</sub>=1, the cells are set to p<sub>i</sub>=0 (inhibition state).</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The image segmentation method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>when the input image is a grayscale image, a brightness value is used as the pixel value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The image segmentation method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>when the input image is a color image, color information is used as the pixel value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. An image segmentation apparatus which pinpoints one of regions from an input image belonging to a same category and identifies the one region as an image segmentation region to selectively output an image of the arbitrary image segmentation region, said apparatus comprising:
<claim-text>an input image memory which stores pixel values of the input image;</claim-text>
<claim-text>a coupling weight calculation circuit which reads out the pixel values from the input image memory to calculate a coupling weight between each image segmentation cell corresponding to each pixel and an adjacent cell;</claim-text>
<claim-text>a leader cell determination circuit which determines, based on the coupling weights calculated by the coupling weight calculation circuit, as a leader cell, the cell in which a total sum of the coupling weights with the adjacent cells is in excess of a reference value;</claim-text>
<claim-text>an image segmentation cell network having decision means in which there are alternately arranged in an array state the image segmentation cells which transit over a non-excitation state, a self-excitable state and an excitation state in accordance with each pixel of the input image and coupling weight registers which hold the inter-cell coupling weights obtained by the coupling weight calculation circuit, the decision means deciding whether each cell is excitable or not based on values held in the coupling weight registers in which the cells are arranged adjacent to each other, the decision means putting, into the excitation state, the leader cell determined by the leader cell determination circuit and putting, into the excitation state, an excitable cell selected from the adjacent cells to expand an excitation region, thereby deciding the image segmentation region;</claim-text>
<claim-text>a segmentation region storage circuit which stores information of all the cells in the image segmentation region decided by the image segmentation cell network; and</claim-text>
<claim-text>an output image memory which stores the pixel value corresponding to each cell in an arbitrary image segmentation region based on contents stored in the segmentation region storage circuit,</claim-text>
<claim-text>wherein the coupling weight calculation circuit takes in the pixel values corresponding to the cells from the input image memory, to calculate the coupling weights between the adjacent cells in column direction by parallel processing and to calculate the coupling weights between the adjacent cells in row direction by pipeline processing.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The image segmentation apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein:
<claim-text>the coupling weight calculation circuit is provided with an encoder which reduces a number of bits of a calculation result of the coupling weights.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The image segmentation apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein:
<claim-text>each row of the image segmentation cell network is provided with a bus which transfers data to all the cells and the coupling weight registers.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The image segmentation apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein:
<claim-text>the coupling weight register reduces a number of bits of the coupling weight data from the coupling weight calculation circuit to a permitted number of bits and stores the reduced data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The image segmentation apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein:
<claim-text>the cells of the image segmentation cell network carry out additions and subtractions required in a decision of the excitable state, serially at k number of adder/subtractors (k is an integer number smaller than the number of the adjacent cells) and at the corresponding registers.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The image segmentation apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein:
<claim-text>a brightness value is used as the pixel value if the input image is a grayscale image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The image segmentation apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein:
<claim-text>color information is used as the pixel value if the input image is a color image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. An image segmentation apparatus which pinpoints one of regions from an input image belonging to a same category and identifies the one region as an image segmentation region to selectively output an image of the arbitrary image segmentation region, said apparatus comprising:
<claim-text>an input image memory which stores pixel values of the input image;</claim-text>
<claim-text>a coupling weight calculation circuit which reads out the pixel values from the input image memory to calculate a coupling weight between each image segmentation cell corresponding to each pixel and an adjacent cell by pipeline processing;</claim-text>
<claim-text>a leader cell determination circuit which determines, based on the coupling weights calculated by the coupling weight calculation circuit, as a leader cell, the cell in which a total sum of the coupling weights with the adjacent cells is in excess of a reference value;</claim-text>
<claim-text>an image segmentation cell network having decision means in which there are alternately arranged in an array state the image segmentation cells which transit over a non-excitation state, a self-excitable state and an excitation state in accordance with each pixel of the input image and coupling weight registers which hold the inter-cell coupling weights obtained by the coupling weight calculation circuit, the decision means deciding whether each cell is excitable or not based on values held in the coupling weight registers in which the cells are arranged adjacent to each other, the decision means putting, into the excitation state, the leader cell determined by the leader cell determination circuit and putting, into the excitation state, an excitable cell selected from the adjacent cells to expand an excitation region, thereby deciding the image segmentation region;</claim-text>
<claim-text>a segmentation region storage circuit which stores information of all the cells in the image segmentation region decided by the image segmentation cell network; and</claim-text>
<claim-text>an output image memory which stores the pixel value corresponding to each cell in an arbitrary image segmentation region based on contents stored in the segmentation region storage circuit, wherein:</claim-text>
<claim-text>the leader cell determination circuit takes in the coupling weights corresponding to the cells from the coupling weight calculation circuit, to sequentially determine the leader cells by column-parallel pipeline processing.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. An image segmentation apparatus which pinpoints one of regions from an input image belonging to a same category and identifies the one region as an image segmentation region to selectively output an image of the arbitrary image segmentation region, said apparatus comprising:
<claim-text>an input image memory which stores pixel values of the input image;</claim-text>
<claim-text>a coupling weight calculation circuit which reads out the pixel values from the input image memory to calculate a coupling weight between each image segmentation cell corresponding to each pixel and an adjacent cell by pipeline processing;</claim-text>
<claim-text>a leader cell determination circuit which determines, based on the coupling weights calculated by the coupling weight calculation circuit, as a leader cell, the cell in which a total sum of the coupling weights with the adjacent cells is in excess of a reference value;</claim-text>
<claim-text>an image segmentation cell network having decision means in which there are alternately arranged in an array state the image segmentation cells which transit over a non-excitation state, a self-excitable state and an excitation state in accordance with each pixel of the input image and coupling weight registers which hold the inter-cell coupling weights obtained by the coupling weight calculation circuit, the decision means deciding whether each cell is excitable or not based on values held in the coupling weight registers in which the cells are arranged adjacent to each other, the decision means putting, into the excitation state, the leader cell determined by the leader cell determination circuit and putting, into the excitation state, an excitable cell selected from the adjacent cells to expand an excitation region, thereby deciding the image segmentation region;</claim-text>
<claim-text>a segmentation region storage circuit which stores information of all the cells in the image segmentation region decided by the image segmentation cell network; and</claim-text>
<claim-text>an output image memory which stores the pixel value corresponding to each cell in an arbitrary image segmentation region based on contents stored in the segmentation region storage circuit, wherein:</claim-text>
<claim-text>each row of the image segmentation cell network is provided with a shift register which transfers data to all the cells and the coupling weight registers.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. An image segmentation apparatus which pinpoints one of regions from an input image belonging to a same category and identifies the one region as an image segmentation region to selectively output an image of the arbitrary image segmentation region, said apparatus comprising:
<claim-text>an input image memory which stores pixel values of the input image;</claim-text>
<claim-text>a coupling weight calculation circuit which reads out the pixel values from the input image memory to calculate a coupling weight between each image segmentation cell corresponding to each pixel and an adjacent cell by pipeline processing;</claim-text>
<claim-text>a leader cell determination circuit which determines, based on the coupling weights calculated by the coupling weight calculation circuit, as a leader cell, the cell in which a total sum of the coupling weights with the adjacent cells is in excess of a reference value;</claim-text>
<claim-text>an image segmentation cell network having decision means in which there are alternately arranged in an array state the image segmentation cells which transit over a non-excitation state, a self-excitable state and an excitation state in accordance with each pixel of the input image and coupling weight registers which hold the inter-cell coupling weights obtained by the coupling weight calculation circuit, the decision means deciding whether each cell is excitable or not based on values held in the coupling weight registers in which the cells are arranged adjacent to each other, the decision means putting, into the excitation state, the leader cell determined by the leader cell determination circuit and putting, into the excitation state, an excitable cell selected from the adjacent cells to expand an excitation region, thereby deciding the image segmentation region;</claim-text>
<claim-text>a segmentation region storage circuit which stores information of all the cells in the image segmentation region decided by the image segmentation cell network; and</claim-text>
<claim-text>an output image memory which stores the pixel value corresponding to each cell in an arbitrary image segmentation region based on contents stored in the segmentation region storage circuit, wherein:</claim-text>
<claim-text>the image segmentation cell network is provided, as the coupling weight registers, with a vertical coupling weight register which stores the coupling weight between vertical and diagonal cells and a horizontal coupling weight register which stores the coupling weight between horizontal and diagonal cells, in which the vertical coupling weight registers and the horizontal coupling weight registers are alternately arranged between the cells so that the same coupling weight can be shared between the adjacent cells.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. An image segmentation apparatus which pinpoints one of regions from an input image belonging to a same category and identifies the one region as an image segmentation region to selectively output an image of the arbitrary image segmentation region, said apparatus comprising:
<claim-text>an input image memory which stores pixel values of the input image;</claim-text>
<claim-text>a coupling weight calculation circuit which reads out the pixel values from the input image memory to calculate a coupling weight between each image segmentation cell corresponding to each pixel and an adjacent cell by pipeline processing;</claim-text>
<claim-text>a leader cell determination circuit which determines, based on the coupling weights calculated by the coupling weight calculation circuit, as a leader cell, the cell in which a total sum of the coupling weights with the adjacent cells is in excess of a reference value;</claim-text>
<claim-text>an image segmentation cell network having decision means in which there are alternately arranged in an array state the image segmentation cells which transit over a non-excitation state, a self-excitable state and an excitation state in accordance with each pixel of the input image and coupling weight registers which hold the inter-cell coupling weights obtained by the coupling weight calculation circuit, the decision means deciding whether each cell is excitable or not based on values held in the coupling weight registers in which the cells are arranged adjacent to each other, the decision means putting, into the excitation state, the leader cell determined by the leader cell determination circuit and putting, into the excitation state, an excitable cell selected from the adjacent cells to expand an excitation region, thereby deciding the image segmentation region;</claim-text>
<claim-text>a segmentation region storage circuit which stores information of all the cells in the image segmentation region decided by the image segmentation cell network; and</claim-text>
<claim-text>an output image memory which stores the pixel value corresponding to each cell in an arbitrary image segmentation region based on contents stored in the segmentation region storage circuit, wherein:</claim-text>
<claim-text>the cells of the image segmentation cell network carry out additions and subtractions required in the decision of the excitable state, in parallel with each other as many adders, provided individually for each cell, as the number of the adjacent cells and one subtractor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. An image segmentation apparatus which pinpoints one of regions from an input image belonging to a same category and identifies the one region as an image segmentation region to selectively output an image of the arbitrary image segmentation region, said apparatus comprising:
<claim-text>an input image memory which stores pixel values of the input image;</claim-text>
<claim-text>a coupling weight calculation circuit which reads out the pixel values from the input image memory to calculate a coupling weight between each image segmentation cell corresponding to each pixel and an adjacent cell by pipeline processing;</claim-text>
<claim-text>a leader cell determination circuit which determines, based on the coupling weights calculated by the coupling weight calculation circuit, as a leader cell, the cell in which a total sum of the coupling weights with the adjacent cells is in excess of a reference value;</claim-text>
<claim-text>an image segmentation cell network having decision means in which there are alternately arranged in an array state the image segmentation cells which transit over a non-excitation state, a self-excitable state and an excitation state in accordance with each pixel of the input image and coupling weight registers which hold the inter-cell coupling weights obtained by the coupling weight calculation circuit, the decision means deciding whether each cell is excitable or not based on values held in the coupling weight registers in which the cells are arranged adjacent to each other, the decision means putting, into the excitation state, the leader cell determined by the leader cell determination circuit and putting, into the excitation state, an excitable cell selected from the adjacent cells to expand an excitation region, thereby deciding the image segmentation region;</claim-text>
<claim-text>a segmentation region storage circuit which stores information of all the cells in the image segmentation region decided by the image segmentation cell network; and</claim-text>
<claim-text>an output image memory which stores the pixel value corresponding to each cell in an arbitrary image segmentation region based on contents stored in the segmentation region storage circuit, wherein:</claim-text>
<claim-text>the image segmentation cell network comprises:</claim-text>
<claim-text>self-excitation means for putting into the excitation state the leader cell determined by the leader cell determination circuit;</claim-text>
<claim-text>excitable cell detection means for detecting the excitable cell from the adjacent cells based on the coupling weights between the cell in the excitation state and the cells adjacent to the cell in the excitation state;</claim-text>
<claim-text>excitation means for putting into the excitation state the cells detected by the excitable cell detection means; and</claim-text>
<claim-text>inhibition means for putting into the inhibition state the cells in the excitation state in a case where no cell is detected by the excitable cell detection means;</claim-text>
<claim-text>wherein the image segmentation of one region is completed by performing repeated processing of the excitation means concurrently on the cells detected by the excitable cell detection means until no cell is detected anymore by the excitable cell detection means, so that the image segmentation of all the regions is completed by sequentially performing the processing of the respective self-excitation, excitable cell detection, excitation and inhibition means on the cells and leader cells in the non-excitation state and not in the inhibition state.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. An image processing method including an image segmentation which pinpoints one of regions from an input image belonging to a same category and identifies the one region as an image segmentation region, said method comprising:
<claim-text>a preparation step including,
<claim-text>an initialization step of putting, into a non-excitation state, a cell which is an individual image segmentation unit corresponding to pixels of the input image,</claim-text>
<claim-text>a taking step of pixel values of the pixels corresponding to the cell, and calculating each coupling weight between a plurality of adjacent cells, and</claim-text>
<claim-text>a determination step of determining leader cells based on each calculation result in the taking step;</claim-text>
</claim-text>
<claim-text>a self-excitable cell detection step of selecting one of the leader cells determined by the determination step to detect the one leader cell as a self-excitable cell;</claim-text>
<claim-text>a self-excitation step of putting, into an excitation state, the self-excitable cell detected in the self-excitable cell detection step;</claim-text>
<claim-text>an excitable cell detection step of detecting an excitable cell from adjacent cells based on said coupling weights between cells in the excitation state including the leader cells and the adjacent cells;</claim-text>
<claim-text>an excitation step of putting, into an excitation state, the excitable cell detected in the excitable cell detection step; and</claim-text>
<claim-text>an inhibition step of putting, into an inhibition state, a cell in the excitation state if no cell is detected in the excitable cell detection step, wherein:</claim-text>
<claim-text>image segmentation of one region is completed by repeating the excitation step until no cell is detected any more in the excitable cell detection step; and</claim-text>
<claim-text>the image segmentation of all the regions is completed by repeating the respective steps until no leader cell in the non-excitation state is detected any more in the self-excitable cell detection step,</claim-text>
<claim-text>wherein I<sub>i </sub>is a pixel value of the cell i (i indicates a cell number) which is an individual image segmentation unit corresponding to the pixels of the input image, x<sub>i </sub>is a variable which indicates whether the cell i is in the excitation or non-excitation stat, p<sub>i </sub>is a variable which indicates whether the self-excitation is permitted or not, W<sub>ik </sub>is the coupling weight between the adjacent cells i and k, φ<sub>p </sub>is a threshold value which decides whether the self-excitation is permitted or not, φ<sub>z </sub>is a threshold value which decides whether the self-excitation is permitted or not, z<sub>i </sub>is a variable which indicates whether the state of cell i is changed or not, and z is a variable of a global suppressor which decides whether are cells having changed to the excitation state based on a logical sum of the values z<sub>i</sub>'s of all the cells;</claim-text>
<claim-text>in the preparation step, the variable x<sub>i </sub>of the image segmentation cell i is set to 0 (x<sub>i</sub>=0: non-excitation), the pixel values I<sub>i </sub>corresponding to the cells i are taken in to calculate the coupling weight W<sub>ik </sub>between the adjacent plural cells i and k, so that if a total sum of calculation results is larger than the threshold value φ<sub>p</sub>, p<sub>i</sub>=1 (self-excitable state) is set and if the total sum is equal to or smaller than the threshold value φ<sub>p</sub>, p<sub>i</sub>=0 (non-self-excitable state) is set for initialization, and z=0 where the variable z is the global suppressor is set for initialization;</claim-text>
<claim-text>in each self-excitable cell detection step, at least one non-excited leader cell is selected from among the leader cells of p<sub>i</sub>=1 determined in the determination step to detect the selected cells as the self-excitable cells;</claim-text>
<claim-text>in each self-excitation step, the variables x<sub>i </sub>and z<sub>i </sub>of the self-excitable cells i detected in the self-excitable cell detection step are set to 1 (x<sub>i</sub>=1: self-excitation, z<sub>i</sub>=1: changed state), respectively;</claim-text>
<claim-text>in the excitable cell detection step, if a total sum of the coupling weights W<sub>ik </sub>between the excited cells k (x<sub>k</sub>=1) adjacent to the cells i in the non-excitation state is larger than the threshold value φ<sub>z</sub>, the cells i are detected to be the excitable cells;</claim-text>
<claim-text>in each excitation step, the variables x<sub>i </sub>and z<sub>i </sub>of all the cells i detected in the excitable cell detection step are set to 1 (x<sub>i</sub>=1: excitation state, z<sub>i</sub>=1: changed state), respectively, and the variable z<sub>i </sub>of the cells i already in the excitation state (x<sub>i</sub>=1 and z<sub>i</sub>=1) is set to 0 (z<sub>i</sub>=0: unchanged state); and</claim-text>
<claim-text>in each inhibition step, if no cell is detected in the excitable cell detection step, the cells of x<sub>i</sub>=1 (excitation state) are set to x<sub>i</sub>=0 (non-excitation state) and z<sub>i</sub>=0 (unchanged state), and if p<sub>i</sub>=1, the cells are set to p<sub>i</sub>=0 (inhibition state).</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. An image processing apparatus integrated circuit apparatus for processing an image including an image segmentation which pinpoints one of regions from an input image belonging to a same category and identifies the one region as an image segmentation region to selectively output an image of the arbitrary image segmentation region, said apparatus comprising:
<claim-text>an input image memory which stores pixel values of the input image;</claim-text>
<claim-text>a coupling weight calculation circuit which reads out the pixel values from the input image memory to calculate a coupling weight between each image segmentation cell corresponding to each pixel and an adjacent cell;</claim-text>
<claim-text>a leader cell determination circuit which determines, based on the coupling weights calculated by the coupling weight calculation circuit, as a leader cell, the cell in which a total sum of the coupling weights with the adjacent cells is in excess of a reference value;</claim-text>
<claim-text>an image segmentation cell network having decision means in which there are alternately arranged in an array state the image segmentation cells which transit over a non-excitation state, a self-excitable state and an excitation state in accordance with each pixel of the input image and coupling weight registers which hold the inter-cell coupling weights obtained by the coupling weight calculation circuit, the decision means deciding whether each cell is excitable or not based on values held in the coupling weight registers in which the cells are arranged adjacent to each other, the decision means putting, into the excitation state, the leader cell determined by the leader cell determination circuit and putting, into the excitation state, an excitable cell selected from the adjacent cells to expand an excitation region, thereby deciding the image segmentation region;</claim-text>
<claim-text>a segmentation region storage circuit which stores information of all the cells in the image segmentation region decided by the image segmentation cell network; and</claim-text>
<claim-text>an output image memory which stores the pixel value corresponding to each cell in an arbitrary image segmentation region based on contents stored in the segmentation region storage circuit,</claim-text>
<claim-text>wherein the coupling weight calculation circuit takes in the pixel values corresponding to the cells from the input image memory, to calculate the coupling weights between the adjacent cells in a column direction by parallel processing and to calculate the coupling weights between the adjacent cells in a row direction by pipeline processing.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. An image segmentation apparatus which pinpoints one of regions from an input image belonging to a same category and identifies the one region as an image segmentation region to selectively output an image of the arbitrary image segmentation region, said apparatus comprising:
<claim-text>an input image memory which stores pixel values of the input image;</claim-text>
<claim-text>a coupling weight calculation circuit which reads out the pixel values from the input image memory to calculate a coupling weight between each image segmentation cell corresponding to each pixel and an adjacent cell;</claim-text>
<claim-text>a leader cell determination circuit which determines, based on the coupling weights calculated by the coupling weight calculation circuit, as a leader cell, the cell in which a total sum of the coupling weights with the adjacent cells is in excess of a reference value;</claim-text>
<claim-text>an image segmentation cell network having decision means in which there are alternately arranged in an array state the image segmentation cells which transit over a non-excitation state, a self-excitable state and an excitation state in accordance with each pixel of the input image and coupling weight registers which hold the inter-cell coupling weights obtained by the coupling weight calculation circuit, the decision means deciding whether each cell is excitable or not based on values held in the coupling weight registers in which the cells are arranged adjacent to each other, the decision means putting, into the excitation state, the leader cell determined by the leader cell determination circuit and putting, into the excitation state, an excitable cell selected from the adjacent cells to expand an excitation region, thereby deciding the image segmentation region;</claim-text>
<claim-text>a segmentation region storage circuit which stores information of all the cells in the image segmentation region decided by the image segmentation cell network; and</claim-text>
<claim-text>an output image memory which stores the pixel value corresponding to each cell in an arbitrary image segmentation region based on contents stored in the segmentation region storage circuit,</claim-text>
<claim-text>wherein the coupling weight calculation circuit takes in the pixel values corresponding to the cells from the input image memory, to calculate the coupling weights between the adjacent cells by parallel processing and to calculate the coupling weights between the adjacent cells in row direction by pipeline processing.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The image segmentation apparatus according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein:
<claim-text>the coupling weight calculation circuit is provided with an encoder which reduces a number of bits of a calculation result of the coupling weights.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The image segmentation apparatus according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein:
<claim-text>each row of the image segmentation cell network is provided with a bus which transfers data to all the cells and the coupling weight registers.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The image segmentation apparatus according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein:
<claim-text>the coupling weight register reduces a number of bits of the coupling weight data from the coupling weight calculation circuit to a permitted number of bits and stores the reduced data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The image segmentation apparatus according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein:
<claim-text>the cells of the image segmentation cell network carry out additions and subtractions required in decision of the excitable state, serially at k number of adder/subtractors (k is an integer number smaller than the number of the adjacent cells) and at the corresponding registers.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The image segmentation apparatus according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein:
<claim-text>a brightness value is used as the pixel value if the input image is a grayscale image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The image segmentation apparatus according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein:
<claim-text>color information is used as the pixel value if the input image is a color image.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
