<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298372-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298372</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10961810</doc-number>
<date>20041008</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>467</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>T</subclass>
<main-group>17</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>345424</main-classification>
</classification-national>
<invention-title id="d0e53">Sample rate adaptive filtering for volume rendering</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5847711</doc-number>
<kind>A</kind>
<name>Kaufman et al.</name>
<date>19981200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345424</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6664961</doc-number>
<kind>B2</kind>
<name>Ray et al.</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345424</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6674430</doc-number>
<kind>B1</kind>
<name>Kaufman et al.</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345419</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7133041</doc-number>
<kind>B2</kind>
<name>Kaufman et al.</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345419</main-classification></classification-national>
</citation>
<citation>
<nplcit num="00005">
<othercit>Lee Westover, “Footprint Evaluation for Volume Rendering,” Aug. 1990, ACM SIGGRAPH Computer Graphics, vol. 24, No. 4, p. 367-376.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00006">
<othercit>Klaus Mueller, Roni Yagel, “Fast Perspective Volume Rendering with Splatting by Utilizing a Ray-Driven Approach,” Oct. 28, 1996, Proceedings of the 7th Conference on Visualization '96, p. 65-72, 468.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00007">
<othercit>Klaus Mueller, Naeem Shareef, Jian Huang, Roger Crawfis, “High-Quality Splatting On Rectilinear Grids With Efficient Culling Of Occluded Voxels,” Apr. 1999, IEEE Transactions on Visualization and Computer Graphics, vol. 5, No. 2, p. 116-134.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00008">
<othercit>Matthias Zwicker, Hanspeter Pfister, Jeroen van Baar, and Markus Gross, “EWA Volume Splatting,” Oct. 21, 2001, Proceedings of the Conference on Visualization '01, p. 29-36.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00009">
<othercit>Daqing Xue, Roger Crawfis, “Efficient Splatting Using Modern Graphics Hardware,” 2003, Journal of Graphics Tools, vol. 8, No. 3, p. 1-21.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00010">
<othercit>S. Roettger, S. Guthe, D. Weiskopf, T. Ertl, and W. Strasser. Smart hardware-accelerated volume rendering. In <i>Eurographics/IEEE TCVG Symposium on Visualization 2003</i>, 2003.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00011">
<othercit>C. P. Botha and F. H. Post. Shellsplatting: Interactive rendering of anisotropic volumes. In <i>Proceedings of 2003 Joint Eurographics—IEEE TCVG Symposium on Visualization</i>, May 2003.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00012">
<othercit>M. Botsch and L. Kobbelt. High-quality point-based rendering on modern GPUs. In <i>Proceedings of the 2003 Pacific Graphics Conference</i>, pp. 335-343, 2003.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00013">
<othercit>K. Engel, M. Kraus, and T. Ertl. High-quality pre-integrated volume rendering using hardware-accelerated pixel shading. In <i>Proceedings of the 2001 ACM SIGGRAPH/Eurographics Workshop on Graphics hardware</i>, pp. 9-16. ACM Press, 2001.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00014">
<othercit>J. Huang, R. Crawfis, and D. Stredney. Edge preservation in volume rendering using splatting. In <i>Proceedings of the 1998 IEEE symposium on Volume visualization</i>, pp. 63-69, NC, USA, 1998.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00015">
<othercit>J. Huang, K. Mueller, N. Shareef, and R. Crawfis. Fastsplats: Optimized splatting on rectilinear grids. In <i>Proceedings of the 2000 IEEE Visualization Conference</i>, pp. 219-227, USA, Oct. 2000.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00016">
<othercit>L. Lippert and M. Gross. Fast wavelet based volume rendering by accumulation of transparent texture maps. In <i>Proceedings of Eurographics 1995</i>, pp. 431-443, Sep. 1995.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00017">
<othercit>K. Mueller and R. Crawfis. Eliminating popping artifacts in sheet buffer-based splatting. In <i>Proceedings of the 1998 IEEE Visualization Conference</i>, pp. 239-246, Ottawa, Canada, Oct. 1998.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00018">
<othercit>K. Mueller, T. Moeller, and R. Crawfis. Splatting without the blur. In <i>Proceedings of the 1999 IEEE Visualization Conference</i>, pp. 363-370, San Francisco, CA, USA, Oct. 1999.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00019">
<othercit>K. Mueller, T. Moeller, J.E. Swan, R. Crawfis, N. Shareef, and R. Yagel. Splatting errors and antialiasing. <i>IEEE Transactions on Visualization and Computer Graphics</i>, 4(2):178-191, Apr.-Jun. 1998.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>12</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>345424</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>3</number-of-drawing-sheets>
<number-of-figures>3</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20060077204</doc-number>
<kind>A1</kind>
<date>20060413</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Pfister</last-name>
<first-name>Hanspeter</first-name>
<address>
<city>Arlington</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Zwicker</last-name>
<first-name>Matthias B.</first-name>
<address>
<city>Gerlikon</city>
<country>CH</country>
</address>
</addressbook>
<nationality>
<country>CH</country>
</nationality>
<residence>
<country>CH</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Chen</last-name>
<first-name>Wei</first-name>
<address>
<city>Hangzhou</city>
<country>CN</country>
</address>
</addressbook>
<nationality>
<country>CN</country>
</nationality>
<residence>
<country>CN</country>
</residence>
</applicant>
<applicant sequence="004" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Ren</last-name>
<first-name>Liu</first-name>
<address>
<city>Pittsburgh</city>
<state>PA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Brinkman</last-name>
<first-name>Dirk</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Mueller</last-name>
<first-name>Clifton D.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="03" rep-type="attorney">
<addressbook>
<last-name>Vinokur</last-name>
<first-name>Gene V.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Mitsubishi Electric Research Laboratories, Inc.</orgname>
<role>02</role>
<address>
<city>Cambridge</city>
<state>MA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Chauhan</last-name>
<first-name>Ulka J.</first-name>
<department>2628</department>
</primary-examiner>
<assistant-examiner>
<last-name>Repko</last-name>
<first-name>Jason M</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method renders a volume data set including a plurality of voxels. A sampling rate for each voxel in a volume data set is determined. Each voxel is filtered according to the sampling rate and pixels for an output image are generated from the filtered voxels.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="157.99mm" wi="234.53mm" file="US07298372-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="237.57mm" wi="172.38mm" orientation="landscape" file="US07298372-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="222.67mm" wi="171.45mm" orientation="landscape" file="US07298372-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="188.47mm" wi="154.94mm" orientation="landscape" file="US07298372-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION </heading>
<p id="p-0002" num="0001">The present invention relates generally to computer graphics, and more particularly to rendering three-dimensional graphics data by splatting.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION </heading>
<p id="p-0003" num="0002">Hardware-accelerated volume rendering methods for rectilinear grids include ray casting, texture slicing, shear-warp and shear-image rendering, and splatting, see, Roettger et al. “<i>Smart hardware</i>-<i>accelerated volume rendering</i>,” Eurographics/IEEE TCVG Symposium on Visualization, 2003, texture slicing, see, Rezk-Salama, et al., “<i>Interactive volume on standard pc graphics hardware using multi</i>-<i>textures and multi</i>-<i>stage rasterization</i>,” Proceedings of the ACM SIGGRAPH/EUROGRAPHICS workshop on Graphics hardware, pages 109-118, ACM Press, 2000, Engel, et al., “<i>High</i>-<i>quality pre</i>-<i>integrated volume rendering using hardware</i>-<i>accelerated pixel shading</i>,” Proceedings of the 2001 ACM SIGGRAPH/Eurographics Workshop on Graphics hardware, pages 9-16. ACM Press, 2001, Pfister et al., “<i>The VolumePro real</i>-<i>time ray</i>-<i>casting system</i>,” Proceedings of ACM SIGGRAPH 1999, pages 251-260. ACM Press, 1999, Wu, et al., “<i>Shear</i>-<i>image order ray casting volume rendering</i>,” ACM Symposium on Interactive 3D Graphics, pages 152-162, June, 2003, and Pfister, “<i>The Visualization Handbook</i>,” chapter Hardware-Accelerated Volume Rendering, Chris Johnson and Chuck Hansen (Editors), Academic Press, 2004.</p>
<p id="p-0004" num="0003">Splatting reconstructs a continuous function by sampling a scalar field of values using 3D reconstruction kernels associated with each scalar value. For volume rendering, the continuous function is mapped to screen space as a superposition of pre-integrated 3D kernels, which are called 2D footprints, see, Westover, “<i>Footprint evaluation for volume rendering</i>,” Proceedings of ACM SIGGRAPH 1990, pages 367-376, August 1990. Splatting offers flexibility in terms of volume grids, including non-rectilinear, and mixing with point-sampled geometry, see Mao, “<i>Splatting of non rectilinear volumes through stochastic resampling</i>,” IEEE Transactions on Visualization and Computer Graphics, 2(2):156-170, 1996, and Zwicker, et al., “<i>Ewa volume splatting</i>,” IEEE Visualization 2001, pages 29-36, 2001.</p>
<p id="p-0005" num="0004">Zwicker et al. describe a method for aliasing-free splatting. However, achieving interactive high quality EWA splatting is still difficult due to the computational complexity of EWA filtering.</p>
<p id="p-0006" num="0005">Splatting benefits from the use of pre-integrated reconstruction kernels. Since Westover's original work, see above, and Westover, “<i>Interactive volume rendering</i>,” C. Upson, editor, Proceedings of the Chapel Hill Workshop on Volume Visualization, pages 9-16, May 1989, most volume splatting methods focus on improving image quality, including ray-driven perspective splatting, edge preservation, eliminating popping and blur, and image-aligned splatting, see, Mueller, et al., “<i>Fast perspective volume rendering with splatting by utilizing a ray driven approach</i>,” Proceedings of the 1996 IEEE Visualization Conference, pages 65-72, October 1996, Huang et al, “<i>Edge preservation in volume rendering using splatting</i>,” Proceedings of the 1998 IEEE symposium on Volume visualization, pages 63-69, 1998, Mueller et al., “<i>Eliminating popping artifacts in sheet buffer</i>-<i>based splatting</i>,” Proceedings of the 1998 IEEE Visualization Conference, pages 239-246, October 1998, Mueller et al., “<i>Splatting without the blur</i>,” Proceedings of the 1999 IEEE Visualization Conference, pages 363-370, October 1999, and Mueller et al., “<i>High</i>-<i>quality splatting on rectilinear grids with efficient culling of occluded voxels</i>,” IEEE Transactions on Visualization and Computer Graphics, 5(2):116-134, 1999.</p>
<p id="p-0007" num="0006">With splatting, the volume data are interpreted according to 3D reconstruction kernels, one kernel for each particle, discrete sample point, or voxel. Each 3D reconstruction kernel has the effect of absorbing and emitting light. Integrals are predetermined separately across each 3D kernel, resulting in ‘footprint’ functions. Each footprint function ‘spreads’ the contribution of each point over nearby pixels in an output image. Typically, the span of the footprint is in the order of two to five pixels. The ‘smeared’ contributions of each voxel in the 3D volume are composited, i.e., accumulated, in a front-to-back or back-to-front order to produce the pixels of the output image.</p>
<p id="p-0008" num="0007">Aliasing problems in volume splatting is described by Swan et al., “<i>An anti</i>-<i>aliasing technique for splatting</i>,” Proceedings of the 1997 IEEE Visualization Conference, pages 197-204, October, 1997, and Mueller, et al., “<i>Splatting errors and antialiasing</i>,” IEEE Transactions on Visualization and Computer Graphics, 4(2):178-191, April-June 1998. There, a distance-dependent stretch of the footprints was used to make the footprints act as low-pass filters.</p>
<p id="p-0009" num="0008">Heckbert, in “Fundamentals in Texture Mapping and Image Warping” Master's Thesis, University of California at Berkeley, Department of Electrical Engineering and Computer Science, 1989, describes a rendering method that uses elliptical weighted average (EWA) filters to avoid aliasing of surface textures. However, that method only operates on regularly sampled 2D texture. In other words, that method cannot be used directly with irregular point samples or volume data sets.</p>
<p id="p-0010" num="0009">Zwicker et al., extended Heckbert's method to represent and render texture functions on irregularly point-sampled surfaces, and to volume splatting, see Zwicker et al., “<i>Surface splatting,” Proceedings of A CM SIGGRAPH </i>2001, pages 371-378, July 2001, Zwicker et al., “<i>Ewa splatting</i>,” IEEE Transactions on Visualization and Computer Graphics, 8(3):223-238, 2002, and Zwicker et al., “<i>Ewa volume splatting</i>,” IEEE Visualization 2001, pages 29-36, 2001.</p>
<p id="p-0011" num="0010">Point-based models have been successfully rendered on a graphics processing unit (GPU), see, Rusinkiewicz et al., “<i>Qsplat: A multiresolution point rendering system for large meshes</i>,” Proceedings of ACM SIGGRAPH 2000, pages 343-352, July 2000, Botsch et al., “<i>High</i>-<i>quality point</i>-<i>based rendering on modern GPUs</i>,” Proceedings of the 2003 Pacific Graphics Conference, pages 335-343, 2003, and Guennebaud et al., “<i>Efficient screen space approach for hardware accelerated surfel rendering</i>,” Proceedings of the 2003 Vision, Modeling and Visualization Conference, pages 1-10, November 2003.</p>
<p id="p-0012" num="0011">Ren, et al., in “<i>Object</i>-<i>space ewa surface splatting: A hardware accelerated approach to high quality point rendering</i>,” Proceedings of Eurographics 2002, pages 461-470, September 2002, described an object space formulation for EWA surface splats and an efficient implementation of the formulation on graphics hardware. For each point in object space, quadrilaterals, which were texture-mapped with a Gaussian texture, were deformed to result in a correct screen-space EWA splat after projection.</p>
<p id="p-0013" num="0012">Other prior art method includes opacity-based culling, fast splat rasterization, hierarchical splatting, object and image space coherence, shell splatting, 3D adjacency data structure, and post-convolved splatting, see, Mueller et al., “<i>High</i>-<i>quality splatting on rectilinear grids with efficient culling of occluded voxels</i>,” IEEE Transactions on Visualization and Computer Graphics, 5(2):116-134, 1999, Huang et al., “<i>Fastsplats: Optimized splatting on rectilinear grids</i>,” Proceedings of the 2000 IEEE Visualization Conference, pages 219-227, October 2000, Laur et al., “<i>Hierarchical splatting: A progressive refinement algorithm for volume rendering</i>,” Proceedings of ACM SIGGRAPH 1991, pages 285-288, August 1991, Ihm et al., “<i>On enhancing the speed of splatting with indexing</i>,” Proceedings of the 1995 IEEE Visualization Conference, pages 69-76, 1995, Botha et al., “<i>Shellsplatting: Interactive rendering of anisotropic volumes</i>,” Proceedings of 2003 Joint Eurographics—IEEE TCVG Symposium on Visualization, May 2003, Orchard et al., “<i>Accelerated splatting using a </i>3<i>d adjacency data structure</i>,” Proceedings of Graphics Interface 2001, pages 191-200, September 2001, and Neophytou et al., “<i>Post</i>-<i>convolved splatting</i>,” Proceedings of the symposium on Data visualisation 2003, pages 223-230, Eurographics Association, 2003.</p>
<p id="p-0014" num="0013">Lippert et al., in “<i>Fast wavelet based volume rendering by accumulation of transparent texture maps</i>,” Proceedings of Eurographics 1995, pages 431-443, September 1995, described a splatting method that directly uses a wavelet representation of the volume data. A hierarchical and frequency sensitive splatting method is based on wavelet transformations and pre-computed splat primitives, which accomplished view-dependent and transfer function-dependent splatting, Welsh, et al., in “<i>A frequency</i>-<i>sensitive point hierarchy for images and volumes</i>,” Proceedings of the 2003 IEEE Visualization Conference, Seattle, USA, October 2003. None of those methods have been implemented completely on a GPU.</p>
<p id="p-0015" num="0014">Some GPU-accelerated splatting methods use texture mapping hardware for the projection and scan-conversion of footprints, see Crawfis et al., “<i>Texture splats for </i>3<i>d scalar and vector field visualization</i>,” Proceedings of the 1993 IEEE Visualization Conference, pages 261-266, 1993, and Botha, et al., above.</p>
<p id="p-0016" num="0015">EWA Volume Splatting</p>
<p id="p-0017" num="0016">Volume splatting interprets volume data as a set of particles that are absorbing and emitting light. To render the data, line integrals are precomputed separately across each particle, resulting in 2D footprint functions or splats in the image plane. The splats are composited back-to-front to determine the output image. Particles are represented by 3D reconstruction kernels A common choice is 3D elliptical Gaussian kernels. The notation G<sub>v</sub>(t−p) represents an elliptical Gaussian kernel centered at a 3D point p with a 3×3 variance matrix V:</p>
<p id="p-0018" num="0017">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <msub>
            <mi>G</mi>
            <mi>V</mi>
          </msub>
          <mo>⁡</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mi>t</mi>
              <mo>-</mo>
              <mi>p</mi>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <mfrac>
            <mn>1</mn>
            <mrow>
              <msup>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <mn>2</mn>
                    <mo>⁢</mo>
                    <mi>π</mi>
                  </mrow>
                  <mo>)</mo>
                </mrow>
                <mrow>
                  <mn>3</mn>
                  <mo>/</mo>
                  <mn>2</mn>
                </mrow>
              </msup>
              <mo>⁢</mo>
              <msup>
                <mrow>
                  <mo></mo>
                  <mi>V</mi>
                  <mo></mo>
                </mrow>
                <mrow>
                  <mn>1</mn>
                  <mo>/</mo>
                  <mn>2</mn>
                </mrow>
              </msup>
            </mrow>
          </mfrac>
          <mo>⁢</mo>
          <mrow>
            <msup>
              <mi>ⅇ</mi>
              <mrow>
                <mrow>
                  <mo>-</mo>
                  <mfrac>
                    <mn>1</mn>
                    <mn>2</mn>
                  </mfrac>
                </mrow>
                <mo>⁢</mo>
                <msup>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <mi>t</mi>
                      <mo>-</mo>
                      <mi>p</mi>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                  <mi>T</mi>
                </msup>
                <mo>⁢</mo>
                <mrow>
                  <msup>
                    <mi>V</mi>
                    <mrow>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                  </msup>
                  <mo>⁡</mo>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <mi>t</mi>
                      <mo>-</mo>
                      <mi>p</mi>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mrow>
            </msup>
            <mo>.</mo>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>1</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0019" num="0018">In theory, Gaussian kernels have infinite support. In practice, the kernels are truncated to a given cutoff radius r, i.e., the kernels are evaluated only in a range
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(<i>t−p</i>)<sup>T</sup><i>V</i><sup>−1</sup>(<i>t−p</i>)≦<i>r</i><sup>2</sup>,  (2)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where usually 1≦r≦3. Furthermore, the choice of Gaussians as 3D kernels guarantees a closed-form footprint function after integration along viewing rays.
</p>
<p id="p-0020" num="0019">However, during perspective rendering, the splatting process usually results in aliasing artifacts due to a changing of sampling rate along the viewing rays while rendering. EWA volume splatting minimizes the artifacts by convolving the footprint function with a 2D low-pass filter, which yields an aliasing-free footprint function called the EWA volume resampling filter.</p>
<p id="p-0021" num="0020">Zwicker, et al., in “<i>Ewa volume splatting</i>,” IEEE Visualization 2001, pages 29-36, 2001, described a closed-form representation of the EWA volume resampling filter that is based on the following two assumptions. First, the low-pass filter takes the form of a 2D Gaussian reconstruction kernel function. Second, a non-linear perspective transformation, which maps reconstruction kernels to image space, is linearly approximated using a Jacobian matrix.</p>
<p id="p-0022" num="0021">To summarize the derivation of the EWA volume resampling filter, a rotational part of the viewing transformation that maps object space to camera space coordinates is given by a 3×3 matrix W. Denote camera space coordinates by u=(u<sub>0</sub>, u<sub>1</sub>, u<sub>2</sub>). Normalized, the origin of the camera space u=0 is at a center of projection and an image plane is a plane at a distance u<sub>2</sub>=1. Camera space coordinates of a voxel k are given by u<sub>k</sub>. Image space coordinates are denoted by x, and the image space position of voxel k is x<sub>k</sub>. Further, the Jacobian matrix of the perspective projection at a point u<sub>k </sub>in camera space to image space is a 3×3 matrix J<sub>u</sub><sub><sub2>k</sub2></sub>:</p>
<p id="p-0023" num="0022">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <msub>
          <mi>J</mi>
          <msub>
            <mi>u</mi>
            <mi>k</mi>
          </msub>
        </msub>
        <mo>=</mo>
        <mrow>
          <mrow>
            <mo>(</mo>
            <mtable>
              <mtr>
                <mtd>
                  <mfrac>
                    <mn>1</mn>
                    <msub>
                      <mi>u</mi>
                      <msub>
                        <mi>k</mi>
                        <mn>2</mn>
                      </msub>
                    </msub>
                  </mfrac>
                </mtd>
                <mtd>
                  <mn>0</mn>
                </mtd>
                <mtd>
                  <mrow>
                    <mo>-</mo>
                    <mfrac>
                      <msub>
                        <mi>u</mi>
                        <msub>
                          <mi>k</mi>
                          <mn>0</mn>
                        </msub>
                      </msub>
                      <msubsup>
                        <mi>u</mi>
                        <msub>
                          <mi>k</mi>
                          <mn>2</mn>
                        </msub>
                        <mn>2</mn>
                      </msubsup>
                    </mfrac>
                  </mrow>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>0</mn>
                </mtd>
                <mtd>
                  <mfrac>
                    <mn>1</mn>
                    <msub>
                      <mi>u</mi>
                      <msub>
                        <mi>k</mi>
                        <mn>2</mn>
                      </msub>
                    </msub>
                  </mfrac>
                </mtd>
                <mtd>
                  <mrow>
                    <mo>-</mo>
                    <mfrac>
                      <msub>
                        <mi>u</mi>
                        <msub>
                          <mi>k</mi>
                          <mn>1</mn>
                        </msub>
                      </msub>
                      <msubsup>
                        <mi>u</mi>
                        <msub>
                          <mi>k</mi>
                          <mn>2</mn>
                        </msub>
                        <mn>2</mn>
                      </msubsup>
                    </mfrac>
                  </mrow>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mfrac>
                    <msub>
                      <mi>u</mi>
                      <msub>
                        <mi>k</mi>
                        <mn>0</mn>
                      </msub>
                    </msub>
                    <mrow>
                      <mo></mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <msub>
                            <mi>u</mi>
                            <msub>
                              <mi>k</mi>
                              <mn>0</mn>
                            </msub>
                          </msub>
                          <mo>,</mo>
                          <msub>
                            <mi>u</mi>
                            <msub>
                              <mi>k</mi>
                              <mn>1</mn>
                            </msub>
                          </msub>
                          <mo>,</mo>
                          <msub>
                            <mi>u</mi>
                            <msub>
                              <mi>k</mi>
                              <mn>2</mn>
                            </msub>
                          </msub>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                      <mo></mo>
                    </mrow>
                  </mfrac>
                </mtd>
                <mtd>
                  <mfrac>
                    <msub>
                      <mi>u</mi>
                      <msub>
                        <mi>k</mi>
                        <mn>1</mn>
                      </msub>
                    </msub>
                    <mrow>
                      <mo></mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <msub>
                            <mi>u</mi>
                            <msub>
                              <mi>k</mi>
                              <mn>0</mn>
                            </msub>
                          </msub>
                          <mo>,</mo>
                          <msub>
                            <mi>u</mi>
                            <msub>
                              <mi>k</mi>
                              <mn>1</mn>
                            </msub>
                          </msub>
                          <mo>,</mo>
                          <msub>
                            <mi>u</mi>
                            <msub>
                              <mi>k</mi>
                              <mn>2</mn>
                            </msub>
                          </msub>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                      <mo></mo>
                    </mrow>
                  </mfrac>
                </mtd>
                <mtd>
                  <mfrac>
                    <msub>
                      <mi>u</mi>
                      <msub>
                        <mi>k</mi>
                        <mn>2</mn>
                      </msub>
                    </msub>
                    <mrow>
                      <mo></mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <msub>
                            <mi>u</mi>
                            <msub>
                              <mi>k</mi>
                              <mn>0</mn>
                            </msub>
                          </msub>
                          <mo>,</mo>
                          <msub>
                            <mi>u</mi>
                            <msub>
                              <mi>k</mi>
                              <mn>1</mn>
                            </msub>
                          </msub>
                          <mo>,</mo>
                          <msub>
                            <mi>u</mi>
                            <msub>
                              <mi>k</mi>
                              <mn>2</mn>
                            </msub>
                          </msub>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                      <mo></mo>
                    </mrow>
                  </mfrac>
                </mtd>
              </mtr>
            </mtable>
            <mo>)</mo>
          </mrow>
          <mo>.</mo>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>3</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0024" num="0023">Given the 3×3 variance matrix V<sub>k</sub>″ of a reconstruction kernel k in object space, its transformation through camera space to image space is V<sub>k</sub>=J<sub>u</sub><sub><sub2>k</sub2></sub>WV<sub>k</sub>″W<sup>T</sup>J<sub>u</sub><sub><sub2>k</sub2></sub><sup>T</sup>.</p>
<p id="p-0025" num="0024">The EWA volume resampling filter ρ<sub>k</sub>(x) is obtained by integrating the reconstruction kernel in image space along viewing rays. The reconstruction kernel is convolved with the Gaussian low-pass filter, which, as shown by Zwicker et al, above, yields the 2D footprint function</p>
<p id="p-0026" num="0025">
<maths id="MATH-US-00003" num="00003">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mrow>
            <msub>
              <mi>ρ</mi>
              <mi>k</mi>
            </msub>
            <mo>⁡</mo>
            <mrow>
              <mo>(</mo>
              <mi>x</mi>
              <mo>)</mo>
            </mrow>
          </mrow>
          <mo>=</mo>
          <mrow>
            <mfrac>
              <mn>1</mn>
              <mrow>
                <mn>2</mn>
                <mo>⁢</mo>
                <mi>π</mi>
                <mo>⁢</mo>
                <mrow>
                  <mo></mo>
                  <msubsup>
                    <mi>J</mi>
                    <msub>
                      <mi>u</mi>
                      <mi>k</mi>
                    </msub>
                    <mrow>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                  </msubsup>
                  <mo></mo>
                </mrow>
                <mo>⁢</mo>
                <mrow>
                  <mo></mo>
                  <msup>
                    <mi>W</mi>
                    <mrow>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                  </msup>
                  <mo></mo>
                </mrow>
                <mo>⁢</mo>
                <msup>
                  <mrow>
                    <mo></mo>
                    <mrow>
                      <msub>
                        <mover>
                          <mi>V</mi>
                          <mo>^</mo>
                        </mover>
                        <mi>k</mi>
                      </msub>
                      <mo>+</mo>
                      <msub>
                        <mi>V</mi>
                        <mi>h</mi>
                      </msub>
                    </mrow>
                    <mo></mo>
                  </mrow>
                  <mfrac>
                    <mn>1</mn>
                    <mn>2</mn>
                  </mfrac>
                </msup>
              </mrow>
            </mfrac>
            <mo>⁢</mo>
            <msup>
              <mi>ⅇ</mi>
              <mrow>
                <mrow>
                  <mo>-</mo>
                  <mfrac>
                    <mn>1</mn>
                    <mn>2</mn>
                  </mfrac>
                </mrow>
                <mo>⁢</mo>
                <msup>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <mi>x</mi>
                      <mo>-</mo>
                      <msub>
                        <mi>x</mi>
                        <mi>k</mi>
                      </msub>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                  <mi>T</mi>
                </msup>
                <mo>⁢</mo>
                <mrow>
                  <msub>
                    <mi>M</mi>
                    <mi>k</mi>
                  </msub>
                  <mo>⁡</mo>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <mi>x</mi>
                      <mo>-</mo>
                      <msub>
                        <mi>x</mi>
                        <mi>k</mi>
                      </msub>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mrow>
            </msup>
          </mrow>
        </mrow>
        <mo>,</mo>
        <mstyle>
          <mtext>
</mtext>
        </mstyle>
        <mo>⁢</mo>
        <mi>where</mi>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>4</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <msub>
          <mi>M</mi>
          <mi>k</mi>
        </msub>
        <mo>=</mo>
        <mrow>
          <msup>
            <mrow>
              <mo>(</mo>
              <mrow>
                <msub>
                  <mover>
                    <mi>V</mi>
                    <mo>^</mo>
                  </mover>
                  <mi>k</mi>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>V</mi>
                  <mi>h</mi>
                </msub>
              </mrow>
              <mo>)</mo>
            </mrow>
            <mrow>
              <mo>-</mo>
              <mn>1</mn>
            </mrow>
          </msup>
          <mo>.</mo>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>5</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0027" num="0026">There, V<sub>h </sub>is a 2×2 variance matrix of the Gaussian low-pass filter, which is usually chosen to be the identity matrix. The 2×2 variance matrix {circumflex over (V)}<sub>k </sub>is obtained by skipping the third row and column of V<sub>k</sub><sup>1</sup>. A matrix with a hat symbol, ‘^’, denotes the result of skipping its third row and column.</p>
<p id="p-0028" num="0027">The problem with the prior art filtering is that after a particular filter is selected, the same filter is used for the entire volume data set, without considering how the volume voxels were generated, and without considering how the data set is sampled along the viewing rays during the generation of the output image.</p>
<p id="p-0029" num="0028">It is desired to solve this problem.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION </heading>
<p id="p-0030" num="0029">The invention provides a hardware-accelerated adaptive elliptical weighted average (EWA) volume splatting method that uses adaptive filtering. The EWA splatting method combines a Gaussian reconstruction kernel with a low-pass image filter to render high quality images without aliasing artifacts or excessive blurring.</p>
<p id="p-0031" num="0030">The adaptive filtering reduces the number of operations required in EWA splatting, and can be implemented efficiently on conventional graphics processing units (GPUs). The method includes interactive pre-classification. To accelerate rendering, splat geometry and 3D volume data are stored locally in a memory of the GPU.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS </heading>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of sample rate adaptive filtering according to the invention;</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic of sample rate adaptive filtering according to the invention; and</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram of data structures according to the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT </heading>
<p id="p-0035" num="0034">Introduction</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 1</figref> shows a system and method for rendering <b>100</b> according to our invention. A volume data set includes voxels. The voxels can be generated using a constant sampling rate. In which case, the volume data set is said to be regular. If a varying sampling rate is used during the generation, then the volume date set is irregular. For the purpose of this description, we call the rate at which the voxels are generated the first sampling rate.</p>
<p id="p-0037" num="0036">During rendering, the voxels in the data set are sampled along viewing rays to generate pixels in an output image. For the purpose of this description, we call the rate at which the voxels are sampled the second sampling rate. This second sampling rate can also be regular or irregular.</p>
<p id="p-0038" num="0037">According to the invention, we filter the voxels adaptively during the rendering either according to the first rate, the second rate, or both the first and second rates.</p>
<p id="p-0039" num="0038">Volume Rendering</p>
<p id="p-0040" num="0039">As shown in <figref idref="DRAWINGS">FIG. 1</figref>, voxels <b>102</b> of a 3D volume data set <b>101</b> are transformed <b>110</b> from object space to camera space <b>111</b> and classified <b>120</b> according to a sampling rate classification, as described above.</p>
<p id="p-0041" num="0040">The classifying step <b>120</b> assigns a type of filtering <b>130</b> to be performed on each classified voxel <b>121</b>. Each classified voxel is filtered <b>130</b> according to the classification <b>120</b>. Filtered voxels <b>135</b> are projected <b>300</b> to image space to produce an output image <b>331</b>.</p>
<p id="p-0042" num="0041">The classification <b>120</b> determines whether the voxels <b>121</b> are filtered <b>130</b> using a reconstruction filter <b>131</b>, a low-pass filter <b>132</b>, or an EWA volume resampling filter <b>133</b>.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 2</figref> is used to describe some of the details of our rate adaptive filtering. Voxels <b>102</b> of the volume data set <b>101</b> are transformed <b>110</b> to camera space between an image plane <b>220</b> and a view-point <b>201</b>. The transformed voxels <b>111</b> are classified <b>120</b> as being sampled at a low rate <b>211</b>, a normal rate <b>212</b>, or a high rate <b>213</b>, relative to each other.</p>
<p id="p-0044" num="0043">In the case of perspective rendering, the second sampling rate corresponds to a distance from the view-point <b>201</b> due to the diverging <b>230</b> viewing rays <b>215</b>. Note, the first sampling rate of the volume data set is fixed in this case. In perspective rendering, viewing rays originating at the view-point diverge. This is in contrast to orthogonal or rectilinear rendering, where viewing rays originate from multiple view-points and are parallel to each other and the second sampling rate is usually fixed.</p>
<p id="p-0045" num="0044">However, the same principals still hold, in case the data set itself is irregular due to the a varying first sample rate. For example, in an irregularly sampled data set, it is the local first sampling rate that determines the classification of the voxels, and the selection of the corresponding filters.</p>
<p id="p-0046" num="0045">At low sampling rate distance <b>211</b>, i.e., far from the viewpoint, the second sampling rate along the diverging viewing rays in camera space is less than the first sampling rate of the volume data set. If an EWA volume resampling filter is applied to the voxels at the far distance <b>211</b>, prefiltering is required to reduce high frequency components in the volume data to avoid aliasing artifacts. In this case, the low-pass filter convolved with the reconstruction filter in an EWA volume resampling filter dominates the EWA filter. Therefore, the EWA volume resampling filter is approximated with a low-pass filter <b>132</b> when the sampling rate, (first or second) is low. The invention applies a low-pass filter <b>132</b> to voxels <b>111</b> classified <b>120</b> at the rate <b>211</b>. This avoids the complex EWA computations of the prior art, while maintaining the quality of the output image <b>331</b>.</p>
<p id="p-0047" num="0046">When the volume data are classified <b>120</b> as being at a high sampling rate distance, i.e., near the view point, the second sampling rate along the diverging viewing rays <b>215</b> is relatively higher than the first sampling rate of the volume data set. The low-pass filter convolved with an EWA filter, though not a dominant component in the EWA filter, can degrade the output image due to blurring.</p>
<p id="p-0048" num="0047">Therefore, approximating the EWA resampling filter by applying the reconstruction filter alone, without the convolution with the low-pass filter in an EWA volume resampling filter, reduces the number of required operations, and yields a better output image. Therefore, the invention applies only the reconstruction filter <b>131</b> to the voxels <b>213</b>.</p>
<p id="p-0049" num="0048">In the intermediate distance <b>212</b> between the two far and near distances <b>211</b> and <b>213</b>, the second sampling rate is determined to be approximately comparable to the first sampling rate of the volume data set. Therefore, the invention applies the EWA filtering <b>133</b> to voxels <b>111</b> classified <b>120</b> as being at the middle distance <b>212</b> to the view-point <b>201</b>.</p>
<p id="p-0050" num="0049">As a consequence, in our adaptive EWA splatting approach, we classify each voxel <b>102</b> into one of the above three sampling rate categories <b>211</b>-<b>213</b> for efficient determination of footprint functions while preserving high image quality of EWA splatting.</p>
<p id="p-0051" num="0050">Sampling Rate Dependent Classification</p>
<p id="p-0052" num="0051">We now describe our sampling rate dependent classification criteria for adaptive EWA volume splatting based on an analysis of the EWA filter described with respect to equation (4).</p>
<p id="p-0053" num="0052">The 2×2 variance matrix M<sub>k</sub>(x) of equation (5) determines the size and shape of the footprint, which is an ellipse. Because matrices W, V<sub>k</sub>″ and V<sub>h </sub>are the same for all voxels in one view, the footprint of each voxel depends only on the Jacobian matrix J<sub>u</sub><sub><sub2>k</sub2></sub>.</p>
<p id="p-0054" num="0053">If the variance matrix V<sub>k</sub>″ is symmetric and the cutoff radii, see equation (2), of the reconstruction and the low-pass filters are respectively r<sub>k </sub>and r<sub>h</sub>, then the matrix {circumflex over (V)}<sub>k </sub>is symmetric and the minor and major radii of the ellipse can be derived from equation 4 as follows:</p>
<p id="p-0055" num="0054">
<maths id="MATH-US-00004" num="00004">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <msub>
            <mi>r</mi>
            <mn>0</mn>
          </msub>
          <mo>=</mo>
          <msqrt>
            <mrow>
              <mfrac>
                <msubsup>
                  <mi>r</mi>
                  <mi>k</mi>
                  <mn>2</mn>
                </msubsup>
                <msubsup>
                  <mi>u</mi>
                  <msub>
                    <mi>k</mi>
                    <mn>2</mn>
                  </msub>
                  <mn>2</mn>
                </msubsup>
              </mfrac>
              <mo>+</mo>
              <msubsup>
                <mi>r</mi>
                <mi>h</mi>
                <mn>2</mn>
              </msubsup>
            </mrow>
          </msqrt>
        </mrow>
        <mo>,</mo>
        <mrow>
          <msub>
            <mi>r</mi>
            <mn>1</mn>
          </msub>
          <mo>=</mo>
          <mrow>
            <msqrt>
              <mrow>
                <mfrac>
                  <mrow>
                    <msubsup>
                      <mi>r</mi>
                      <mi>k</mi>
                      <mn>2</mn>
                    </msubsup>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <msubsup>
                          <mi>u</mi>
                          <msub>
                            <mi>k</mi>
                            <mn>0</mn>
                          </msub>
                          <mn>2</mn>
                        </msubsup>
                        <mo>+</mo>
                        <msubsup>
                          <mi>u</mi>
                          <msub>
                            <mi>k</mi>
                            <mn>1</mn>
                          </msub>
                          <mn>2</mn>
                        </msubsup>
                        <mo>+</mo>
                        <msubsup>
                          <mi>u</mi>
                          <msub>
                            <mi>k</mi>
                            <mn>2</mn>
                          </msub>
                          <mn>2</mn>
                        </msubsup>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <msubsup>
                    <mi>u</mi>
                    <msub>
                      <mi>k</mi>
                      <mn>2</mn>
                    </msub>
                    <mn>4</mn>
                  </msubsup>
                </mfrac>
                <mo>+</mo>
                <msubsup>
                  <mi>r</mi>
                  <mi>h</mi>
                  <mn>2</mn>
                </msubsup>
              </mrow>
            </msqrt>
            <mo>.</mo>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>6</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0056" num="0055">A depth of a voxel in camera space u<sub>k</sub><sub><sub2>2 </sub2></sub>largely determines the ellipse radii as can be seen in equation 6 above. The distance between the view-point <b>201</b> and the image plane <b>220</b> is normalized to 1.0. It can be shown that u<sub>k</sub><sub><sub2>0</sub2></sub>/u<sub>k</sub><sub><sub2>2 </sub2></sub>and u<sub>k</sub><sub><sub2>1</sub2></sub>/u<sub>k</sub><sub><sub2>2 </sub2></sub>range from −tan(fov/2) to tan(fov/2), where fov is a view angle <b>230</b>. Hence, the maximum value of (u<sub>k</sub><sub><sub2>0</sub2></sub><sup>2</sup>+u<sub>k</sub><sub><sub2>1</sub2></sub><sup>2</sup>+u<sub>k</sub><sub><sub2>2</sub2></sub><sup>2</sup>)/u<sub>k</sub><sub><sub2>2</sub2></sub><sup>2 </sup>is +(2.0×tan(fov/2)<sup>2)</sup>).</p>
<p id="p-0057" num="0056">Therefore, conservative adaptive criteria can be determined by only considering a voxel camera space coordinate u<sub>k</sub><sub><sub2>2</sub2></sub>.</p>
<p id="p-0058" num="0057">To determine the radius r<sub>0</sub>, the radius r<sub>h </sub>is discarded, given that r<sub>k</sub>/u<sub>k</sub><sub><sub2>2 </sub2></sub>is much larger than r<sub>h</sub>. In this case, r<sub>h </sub>can be discarded for the determination of r<sub>1 </sub>as well. On the other hand, if r<sub>k</sub>×(1.0+(2.0×tan(fov/2)<sup>2)</sup>)/u<sub>k</sub><sub><sub2>2 </sub2></sub>is smaller then r<sub>h</sub>, the radius r<sub>1 </sub>can be approximated by r<sub>h</sub>.</p>
<p id="p-0059" num="0058">From the above analysis, we derive the following adaptive filtering classifications H<sub>k</sub>(x) with two controlling parameters c<sub>min </sub>and c<sub>max</sub>:</p>
<p id="p-0060" num="0059">
<maths id="MATH-US-00005" num="00005">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mo>(</mo>
          <mtable>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <mrow>
                      <msub>
                        <mi>H</mi>
                        <mi>k</mi>
                      </msub>
                      <mo>⁡</mo>
                      <mrow>
                        <mo>(</mo>
                        <mi>x</mi>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                    <mo>=</mo>
                    <mrow>
                      <msup>
                        <mi>x</mi>
                        <mi>T</mi>
                      </msup>
                      <mo>·</mo>
                      <msubsup>
                        <mover>
                          <mi>V</mi>
                          <mo>^</mo>
                        </mover>
                        <mi>k</mi>
                        <mrow>
                          <mo>-</mo>
                          <mn>1</mn>
                        </mrow>
                      </msubsup>
                      <mo>·</mo>
                      <mi>x</mi>
                    </mrow>
                  </mrow>
                  <mo>,</mo>
                </mrow>
              </mtd>
              <mtd>
                <mrow>
                  <mrow>
                    <mi>if</mi>
                    <mo>⁢</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>⁢</mo>
                    <msub>
                      <mi>u</mi>
                      <msub>
                        <mi>k</mi>
                        <mn>2</mn>
                      </msub>
                    </msub>
                  </mrow>
                  <mo>&lt;</mo>
                  <mrow>
                    <mfrac>
                      <msub>
                        <mi>r</mi>
                        <mi>k</mi>
                      </msub>
                      <msub>
                        <mi>r</mi>
                        <mi>h</mi>
                      </msub>
                    </mfrac>
                    <mo>×</mo>
                    <msub>
                      <mi>c</mi>
                      <mi>min</mi>
                    </msub>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <mrow>
                      <msub>
                        <mi>H</mi>
                        <mi>k</mi>
                      </msub>
                      <mo>⁡</mo>
                      <mrow>
                        <mo>(</mo>
                        <mi>x</mi>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                    <mo>=</mo>
                    <mrow>
                      <msup>
                        <mi>x</mi>
                        <mi>T</mi>
                      </msup>
                      <mo>·</mo>
                      <msubsup>
                        <mi>V</mi>
                        <mi>h</mi>
                        <mrow>
                          <mo>-</mo>
                          <mn>1</mn>
                        </mrow>
                      </msubsup>
                      <mo>·</mo>
                      <mi>x</mi>
                    </mrow>
                  </mrow>
                  <mo>,</mo>
                </mrow>
              </mtd>
              <mtd>
                <mrow>
                  <mrow>
                    <mi>if</mi>
                    <mo>⁢</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"/>
                    </mstyle>
                    <mo>⁢</mo>
                    <msub>
                      <mi>u</mi>
                      <msub>
                        <mi>k</mi>
                        <mn>2</mn>
                      </msub>
                    </msub>
                  </mrow>
                  <mo>&gt;</mo>
                  <mrow>
                    <mfrac>
                      <msub>
                        <mi>r</mi>
                        <mi>k</mi>
                      </msub>
                      <msub>
                        <mi>r</mi>
                        <mi>h</mi>
                      </msub>
                    </mfrac>
                    <mo>×</mo>
                    <msub>
                      <mi>c</mi>
                      <mi>max</mi>
                    </msub>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <mrow>
                      <msub>
                        <mi>H</mi>
                        <mi>k</mi>
                      </msub>
                      <mo>⁡</mo>
                      <mrow>
                        <mo>(</mo>
                        <mi>x</mi>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                    <mo>=</mo>
                    <mrow>
                      <mi>x</mi>
                      <mo>·</mo>
                      <msup>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <msub>
                              <mover>
                                <mi>V</mi>
                                <mo>^</mo>
                              </mover>
                              <mi>k</mi>
                            </msub>
                            <mo>+</mo>
                            <msub>
                              <mi>V</mi>
                              <mi>h</mi>
                            </msub>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                        <mrow>
                          <mo>-</mo>
                          <mn>1</mn>
                        </mrow>
                      </msup>
                      <mo>·</mo>
                      <mi>x</mi>
                    </mrow>
                  </mrow>
                  <mo>,</mo>
                </mrow>
              </mtd>
              <mtd>
                <mi>otherwise</mi>
              </mtd>
            </mtr>
          </mtable>
          <mo>)</mo>
        </mrow>
        <mo>.</mo>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>7</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0061" num="0060">Based on the above criteria, our adaptive filtering selects one of the resampling filters <b>131</b>-<b>133</b> to be used for efficient interactive rendering. In equations (7), magnification criteria for selecting the reconstruction filter <b>131</b> is listed first, minification criteria for selecting the low-pass filter <b>132</b> is second, and criteria for selecting the EWA volume resampling filter <b>133</b> is third.</p>
<p id="p-0062" num="0061">The parameters c<sub>min </sub>and c<sub>max </sub>can be adjusted to achieve a desired balance between efficiency of operation and quality of image according to user preference and application need.</p>
<p id="p-0063" num="0062">Our adaptive rendering based on sampling rates can work with regular, rectilinear and irregular volume data sets. It can also be incorporated in prior art splatting systems.</p>
<p id="p-0064" num="0063">To reduce the additional operations required by the classification <b>130</b>, the volume data are organized as local neighborhoods or patches in a spatial data structure, described below in detail with respect to <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0065" num="0064">The voxels are classified on a per patch basis, and the same filter is applied to all voxels in a patch that has the same classification. This is strictly for expediency. In an ideal system, each voxel is classified and filtered accordingly.</p>
<p id="p-0066" num="0065">Hardware Accelerated Rendering</p>
<p id="p-0067" num="0066">We can implement our adaptive EWA filtering in a hardware-accelerated volume splatting framework for rendering regular or rectilinear volume data sets.</p>
<p id="p-0068" num="0067">Our framework is based on an axis-aligned volume splatting scheme with three traversal orders along the three major axes.</p>
<p id="p-0069" num="0068">Adaptive Splatting</p>
<p id="p-0070" num="0069">In the preferred embodiment, we perform volume splatting using a patch-based classification scheme.</p>
<p id="p-0071" num="0070">As shown in <figref idref="DRAWINGS">FIG. 3</figref>, voxels <b>102</b> of the volume data set <b>101</b> can be organized as slices <b>310</b>, and the voxels <b>102</b> of each slice <b>310</b> are grouped into uniform rectangular patches <b>315</b>. For the sample rate classification <b>120</b>, we determine the camera space coordinate u<sub>k</sub><sub><sub2>2 </sub2></sub>of each of the four corner voxels, i.e., vertices, <b>311</b>-<b>314</b> of each patch, and evaluate the criteria given in Equation 7.</p>
<p id="p-0072" num="0071">If all four vertices of the patch meet the magnification criterion, the reconstruction filter <b>131</b> is used as the footprint function.</p>
<p id="p-0073" num="0072">If all four vertices of a patch meet the minification criterion, the low-pass filter <b>132</b> is used as the footprint function.</p>
<p id="p-0074" num="0073">Otherwise, the full EWA resampling filter is applied <b>133</b>.</p>
<p id="p-0075" num="0074">We set c<sub>min </sub>and c<sub>max </sub>in Equation 7 to 0.3, and 2.0×(1.0+(2.0×tan(fov/2)<sup>2</sup>)) respectively for all examples herein.</p>
<p id="p-0076" num="0075">Our splatting method relies on proxy geometry, i.e., textured quadrilaterals, as rendering primitives that represent the footprint functions. The texture on each quad encodes a 2D unit Gaussian function. Note that the geometry of the quad is deformed to stretch and scale the unit Gaussian texture, such that a projection of the quad to the image plane matches the footprint function. This is achieved using programmable vertex shaders.</p>
<p id="p-0077" num="0076">A textured quadrilateral representing a splat is associated with each voxel. Splats are processed in two stages. In the first stage, the contributions from splats in one slice are added in a buffer. Then, back-to-front or front-to-back composition of each slice is performed to yield the output image. We call this composition method slice-by-slice composition.</p>
<p id="p-0078" num="0077">Optionally, composition can be performed directly, without using the buffer. We call this simple composition method splat-every-sample composition.</p>
<p id="p-0079" num="0078">In particular, the geometry of the quadrilateral can be derived by analyzing the EWA resampling filter. In our adaptive scheme, we implement a different filter for each of the cases in Equation 7, and we select the appropriate filter based on our per-patch evaluation described above. During rasterization of the proxy quads, the filter weight, the color and the illumination components of each pixel are based on voxel attributes in the volume texture.</p>
<p id="p-0080" num="0079">Interactive Opacity Culling</p>
<p id="p-0081" num="0080">Interactive opacity culling as described herein is a useful pre-processing step for interactive exploration of volume data. In the prior art, all of the voxels of the volume data set are rendered, which is not efficient because transparent voxels are not culled. Unnecessary rendering of transparent voxels can be avoided using our interactive opacity culling. Here, only non-transparent voxels are rendered, which typically account only for 5%-20% of all voxels in the volume data set.</p>
<p id="p-0082" num="0081">However, in our retained-mode hardware implementation, opacity culling requires collecting indices of the vertices for those non-transparent voxels and loading an index buffer to the graphics hardware whenever a user selected transfer function for determining which voxels are not transparent is changed. Because the construction of the index buffer is time-consuming and loading it to graphics memory involves a significant amount of data transfer between the processor and GPU, changes of the transfer function cannot be rendered at interactive rates.</p>
<p id="p-0083" num="0082">Referring back to <figref idref="DRAWINGS">FIG. 3</figref>, we solve this problem by constructing an auxiliary data structure in an optional pre-processing step. The basic idea uses a list-based splatting method, where a single iso-value list is constructed for the entire volume data set.</p>
<p id="p-0084" num="0083">We bucket sort <b>320</b> the voxels <b>102</b> of each slice <b>310</b> based on intensity values of the voxels. The sorting produces iso-value lists <b>321</b> for each slice, where each list includes voxels having the same intensity values. Note that when describing volume data, the term density is interchangeable with intensity.</p>
<p id="p-0085" num="0084">Indices of proxy geometry corresponding to the iso-value lists are sorted accordingly, and arranged into iso-value index buffers <b>330</b>. The index buffers, which are pre-loaded in graphics hardware before interactive rendering, span <b>256</b> intervals of iso-value voxels. Practically, the index buffers are placed in video memory or AGP memory, depending on index buffer size.</p>
<p id="p-0086" num="0085">Pointers to the start of each iso-value index are maintained in main memory. When the transfer function is interactively changed from a first range of intensity values to a second range of intensity values, the pointers to voxels having intensity values in the second range according to the changed transfer function are determined. The voxels indicated by the pointers are visible voxels which are transformed into camera space and classified by our rendering method <b>100</b>.</p>
<p id="p-0087" num="0086">Although the invention has been described by way of examples of preferred embodiments, it is to be understood that various other adaptations and modifications may be made within the spirit and scope of the invention. Therefore, it is the object of the appended claims to cover all such variations and modifications as come within the true spirit and scope of the invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US07298372-20071120-M00001.NB">
<img id="EMI-M00001" he="7.03mm" wi="76.20mm" file="US07298372-20071120-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US07298372-20071120-M00002.NB">
<img id="EMI-M00002" he="23.28mm" wi="76.20mm" file="US07298372-20071120-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00003" nb-file="US07298372-20071120-M00003.NB">
<img id="EMI-M00003" he="20.49mm" wi="76.20mm" file="US07298372-20071120-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00004" nb-file="US07298372-20071120-M00004.NB">
<img id="EMI-M00004" he="11.26mm" wi="76.20mm" file="US07298372-20071120-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00005" nb-file="US07298372-20071120-M00005.NB">
<img id="EMI-M00005" he="18.37mm" wi="76.20mm" file="US07298372-20071120-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>We claim:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A computer-implemented method for rendering a volume data set including a plurality of voxels using a graphic processor unit, comprising the steps of:
<claim-text>determining a sampling rate for each voxel in a volume data set stored in a memory of a graphics processing unit;</claim-text>
<claim-text>transforming the plurality of voxels from an object space to a camera space;</claim-text>
<claim-text>organizing the transformed voxels in slices;</claim-text>
<claim-text>grouping the transformed voxels in each slice into a plurality of patches;</claim-text>
<claim-text>determining, for each corner voxel of a patch, a sampling rate of the corner voxel in camera space;</claim-text>
<claim-text>classifying the patch as at a particular sampling rate if all of the corner voxels are at the particular sampling rate;</claim-text>
<claim-text>filtering each voxel in the patch according to the classification according to the sampling rate;</claim-text>
<claim-text>generating an output image from the filtered voxels; and rendering the output image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, in which the voxels in the volume data set are generated at a first sampling rate, and the filtering is according to the first sampling rate.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of claim method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, in which the pixels of the output image are generated at a second sampling rate, and the filtering is according to the second sampling rate.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, in which a first sampling rate is determined while generating the volume data set and a second sampling rate is determined while rendering, and the filtering each voxel is according to the first and second sampling rate.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, in which the first sampling rate is constant.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, in which the first sampling rate is varying.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, in which the second sampling rate is constant.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref> in which the second sampling rate is varying.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, in which the filtering is low-pass filtering at a low sampling rate.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, in which the filtering is elliptical weighted average filtering at a normal sampling rate.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, in which the filtering is reconstruction filtering at a high sampling rate.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>organizing the plurality of voxels of the volume data set into slices;</claim-text>
<claim-text>sorting the voxels in each slice into a lists according to intensity values of the voxels;</claim-text>
<claim-text>storing each list as an index in an index buffer;</claim-text>
<claim-text>transforming, from an object space to a view-independent camera space. for each slice, only voxels in index buffers having a predetermined intensity value.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
