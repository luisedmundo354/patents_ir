<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298914-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298914</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11604347</doc-number>
<date>20061127</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2002-149220</doc-number>
<date>20020523</date>
</priority-claim>
</priority-claims>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>36</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>N</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382245</main-classification>
</classification-national>
<invention-title id="d0e61">Image processing device, method and recording medium for compressing image data using repeatability of data patterns</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4803735</doc-number>
<kind>A</kind>
<name>Nishidi et al.</name>
<date>19890200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>4972499</doc-number>
<kind>A</kind>
<name>Kurosawa</name>
<date>19901100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382227</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5373567</doc-number>
<kind>A</kind>
<name>Takahashi et al.</name>
<date>19941200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382216</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5455680</doc-number>
<kind>A</kind>
<name>Shin</name>
<date>19951000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5883672</doc-number>
<kind>A</kind>
<name>Suzuki et al.</name>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5995665</doc-number>
<kind>A</kind>
<name>Maeda</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6236755</doc-number>
<kind>B1</kind>
<name>Kashiwazaki</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6597815</doc-number>
<kind>B1</kind>
<name>Satoh et al.</name>
<date>20030700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6657564</doc-number>
<kind>B2</kind>
<name>Malik</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6658148</doc-number>
<kind>B1</kind>
<name>Fung et al.</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382209</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6697525</doc-number>
<kind>B1</kind>
<name>Sadeh</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>6731814</doc-number>
<kind>B2</kind>
<name>Zeck et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>6804401</doc-number>
<kind>B2</kind>
<name>Nelson et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>6898313</doc-number>
<kind>B2</kind>
<name>Li et al.</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>7010171</doc-number>
<kind>B2</kind>
<name>Buckley</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382243</main-classification></classification-national>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>7158683</doc-number>
<kind>B2</kind>
<name>Yokose</name>
<date>20070100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382245</main-classification></classification-national>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2003/0219161</doc-number>
<kind>A1</kind>
<name>Yokose</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2007/0065031</doc-number>
<kind>A1</kind>
<name>Yokose</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382238</main-classification></classification-national>
</citation>
<citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>2007/0071340</doc-number>
<kind>A1</kind>
<name>Yokose</name>
<date>20070300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382243</main-classification></classification-national>
</citation>
<citation>
<patcit num="00020">
<document-id>
<country>JP</country>
<doc-number>A-03-035678</doc-number>
<date>19910200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00021">
<document-id>
<country>JP</country>
<doc-number>A 7-236062</doc-number>
<date>19950900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00022">
<document-id>
<country>JP</country>
<doc-number>A-08-331391</doc-number>
<date>19961200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00023">
<document-id>
<country>JP</country>
<doc-number>A-08-331392</doc-number>
<date>19961200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00024">
<document-id>
<country>JP</country>
<doc-number>A-09-022462</doc-number>
<date>19970100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00025">
<document-id>
<country>JP</country>
<doc-number>A-11-055528</doc-number>
<date>19990200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00026">
<document-id>
<country>JP</country>
<doc-number>A 11-168633</doc-number>
<date>19990600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00027">
<document-id>
<country>JP</country>
<doc-number>A-2000-261812</doc-number>
<date>20000900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00028">
<othercit>Japanese Office Action drafted on Jul. 25, 2006, mailed on Aug. 1, 2006 in Japanese Patent Application No. 2002-149220 filed May 23, 2002.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>5</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382164</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382173</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382176</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382181</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382232</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382233</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382234</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382239</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382243</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382245</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382250</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>341 50</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>341 51</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>341 63</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>341 67</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>341 74</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>341 87</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>37524003</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>37524004</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3752401</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3752402</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>7</number-of-figures>
</figures>
<us-related-documents>
<division>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>10376608</doc-number>
<kind>00</kind>
<date>20030303</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7158683</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>11604347</doc-number>
</document-id>
</child-doc>
</relation>
</division>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20070071340</doc-number>
<kind>A1</kind>
<date>20070329</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Yokose</last-name>
<first-name>Taro</first-name>
<address>
<city>Ashigarakami-gun</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Oliff &amp; Berridge, PLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Fuji Xerox Co., Ltd.</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Alavi</last-name>
<first-name>Amir</first-name>
<department>2624</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An image processing device for compressing image data using conversion to spatial frequency components may include a dividing section that divides the image data into a plurality of pixel blocks and computes spatial frequency components of each pixel block; a segmenting section that computes an intensity of predetermined high frequency components from information of the spatial frequency components and segments the image data into a first plane formed by including a pixel block having an intensity which is less than a predetermined threshold value and into a second plane formed by including a pixel block having an intensity which is equal to or greater than the threshold value; a compression section that executes compression for the first plane image data by applying quantization and entropy coding using the spatial frequency components information; and a run length compression section that executes run length compression of the second plane image data.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="75.35mm" wi="170.01mm" file="US07298914-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="183.22mm" wi="150.88mm" file="US07298914-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="75.86mm" wi="171.53mm" file="US07298914-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="235.37mm" wi="172.13mm" file="US07298914-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="188.64mm" wi="147.24mm" file="US07298914-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="180.17mm" wi="174.24mm" file="US07298914-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<p id="p-0002" num="0001">This is a Division of application Ser. No. 10/376,608 filed Mar. 3, 2003 now U.S. Pat. No. 7,158,683. The disclosure of the prior application is hereby incorporated by reference herein in its entirety.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to an image processing device for compressing image data.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">In devices for handling image data, it is common practice to compress image data in order to reduce data transfer load and lower data storage requirements. In order to compress image data efficiently, it is important to select the compression method and compression parameters to match the characteristics of the image data. For example, in the case of an image having comparatively low frequency spatial frequency components, such as a natural image, a JPEG (Joint Picture Experts Group) compression method is applied, while run length compression is applied to sections having consecutive characters or the like.</p>
<p id="p-0007" num="0006">Most images are not made up of sections having only one characteristic, such just natural images or just text, and are in fact normally a combination of natural images and text. For this reason, if the same compression is carried out for all of the data, compression efficiency is lowered and quality is degraded. For example, if image data containing natural images and text is compressed using JPEG, it is possible to carry out appropriate compression for the natural image section, but the quality of the text section is degraded and compression efficiency is lowered.</p>
<p id="p-0008" num="0007">There are therefore techniques to segment image data into natural image section planes and text section planes and apply appropriate compression, for each plane. In this case, segmentation into planes discriminates text regions using edge detection or presence or absence of restricted colour. Examples of such techniques are disclosed in Japanese Patent Laid-open No. Hei. 7-236062. A technique for segmenting into planes based on results of encoding is also disclosed in Japanese Patent Laid-open No. Hei. 11-168633.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0009" num="0008">However, with the above described image processing techniques, overall processing load is increased because processing that is unrelated to the compression is used when segmenting into planes, and encoding processing is reiterated. Also, segmentation processing does not always bring about an appropriate result, which means that the increase in load is not sufficiently compensated for by the extent of improvement in compression.</p>
<p id="p-0010" num="0009">The present invention has been conceived in view of the above described situation, and an advantage of the present invention is that it provides an image processing device that can sufficiently improve compression with a low processing load.</p>
<p id="p-0011" num="0010">In order to achieve the above described advantage, the present invention provides an image processing device, for performing compression of image data using multistage processing, comprising segmenting means for segmenting image data into a plurality of planes using results of pre-processing, and means for carrying out respective post-processing using results of pre-processing for the image data segmented into planes.</p>
<p id="p-0012" num="0011">Here, the means for carrying out post-processing can selectively apply different processing for each plane. Also, the means for carrying out post-processing may apply processing using different processing parameters for each plane.</p>
<p id="p-0013" num="0012">According to the present invention, there is also provided an image processing device for performing compression of image data using prediction encoding, comprising means for sequentially selecting noted pixels from image data that was subject of compression, and determining whether or not the noted pixel can be predicted from information for other pixels, segmenting means for segmenting the image data into a first plane including a set of pixels determined to be predictable, and a second plane including a set of pixels determined not to be predictable, and means for applying compression using prediction encoding for image data of the first plane.</p>
<p id="p-0014" num="0013">According to the present invention there is also provided an image processing device for carrying out compression of image data using conversion to spatial frequency components, comprising means for converting image data to spatial frequency components, segmenting means for segmenting image data into a plurality of planes based on results of the conversion to spatial frequency components, and means for applying compression to at least one of the plurality of planes using the results of the conversion to spatial frequency components.</p>
<p id="p-0015" num="0014">According to another aspect of the present invention, there is also provided an image processing device for compressing image data using repeatability of data patterns, comprising means for executing pattern matching for image data, segmenting means for segmenting image data into a plurality of planes based on results of the pattern matching, and means for applying compression to at least one of the plurality of planes using pattern repeatability.</p>
<p id="p-0016" num="0015">In order to solve the above described problems, the present invention also provides an image data generating method, for generating image data compressed using multistage processing, comprising a step of segmenting image data into a plurality of planes using results of pre-processing, and a step of carrying out respective post-processing for the image data segmented into planes using results of the pre-processing.</p>
<p id="p-0017" num="0016">In order to solve the above described problems of the related art, the present invention also provides a program for carrying out compression of image data through multistage processing using a computer, for causing execution on the computer of a procedure for segmenting image data into a plurality of planes using results of pre-processing, and a procedure for carrying out respective post-processing for the image data segmented into planes using results of the pre-processing.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 1</figref> is a structural block diagram of an image processing device of an embodiment of the present invention.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 2</figref> is a functional block diagram showing an overview of an image compression program executed by a CPU <b>1</b>.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 3</figref> is a functional block diagram showing one example of an image compression program executed by a CPU <b>1</b>.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart showing one example of specific processing content for a decision section.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 5</figref> is an explanatory drawing showing an overview of image data of each plane and mask image data appearing during processing of the image processing device of the present invention.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 6</figref> is a functional block diagram showing another example of an image compression program executed by a CPU <b>1</b>.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 7</figref> is a functional block diagram showing yet another example of an image compression program executed by a CPU <b>1</b>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0025" num="0024">An embodiment of the present invention will now be described with reference to the drawings. An image processor of the embodiment of the present invention is a general computer, and as shown in <figref idref="DRAWINGS">FIG. 1</figref>, comprises a CPU <b>1</b>, a memory section <b>2</b>, a hard disk <b>3</b> and an input/output interface <b>4</b>. The CPU <b>1</b> executes programs stored on the hard disk <b>3</b>, and implements the various means of the present invention. Specific processing contents for this CPU <b>1</b>—will be described in detail later. The memory section <b>2</b> acts as working memory for the CPU <b>1</b>. The hard disk <b>3</b> stores programs executed by the CPU <b>1</b>. The input/output interface <b>4</b> outputs image data and user instructions input from the outside to the CPU <b>1</b>. Also, image data that has been subjected to compression is output to the outside in accordance with instructions input from the CPU <b>1</b>.</p>
<p id="p-0026" num="0025">Next, an image processing program stored on the hard disk <b>3</b> and executed by the CPU will be described. As shown in <figref idref="DRAWINGS">FIG. 2</figref>, for example, this image processing program is basically made up of an image segmenting section <b>11</b> and a compression section <b>12</b>, and the compression section <b>12</b> includes a pre-processing section <b>13</b> and a post-processing section <b>14</b>. The pre-processing section <b>13</b> executes processing for the previous stage of compression for input image data, and the results are output to the image segmenting section <b>11</b>. The image segmenting section <b>11</b> segments the input image data into a plurality of planes, generates image data for each plane and outputs the data to the post-processing section <b>14</b> of the compression section <b>12</b>. The post-processing section <b>14</b> executes specified processing on image data of the input plurality of planes to generate compressed image data. It is not necessary to perform compression for image data of all the planes, and it is possible to perform compression for image data of at least one plane.</p>
<p id="p-0027" num="0026">In this embodiment, it is possible to use various compression methods for this compression. In the following, the case of using prediction encoding will be described as a specific example.</p>
<p id="h-0005" num="0000">[Compression Program Using Prediction Encoding]</p>
<p id="p-0028" num="0027">A compression program using prediction encoding is shown as a functional block diagram in <figref idref="DRAWINGS">FIG. 3</figref>, and includes a compression expansion interpolation section <b>21</b>, a pixel value prediction section <b>22</b>, a decision section <b>23</b>, an image segmenting section <b>24</b>, a reduction processing section <b>25</b>, a JPEG encoding section <b>26</b>, a prediction encoding section <b>27</b>, and a code output section <b>28</b>. Here, processing carried out by the compression expansion interpolation section <b>21</b> and the pixel value prediction section <b>22</b> is equivalent to the pre-processing of the present invention, while processing carried out by the reduction processing section <b>25</b> and JPEG encoding section <b>26</b>, and the prediction encoding section <b>27</b> is equivalent to the post-processing of the present invention.</p>
<p id="p-0029" num="0028">The compression expansion interpolation section <b>21</b> receives input of image data that is the subject of processing, carries out compression or expansion processing on the image data to convert the resolution, obtains a value for each pixel of the image data after resolution conversion using a 4-point linear interpolation method (bi-linear interpolation method) and outputs the values as interpolated image data. The pixel value prediction section <b>22</b> receives input of image data that is the subject of processing, sequentially selects each pixel of the image data as noted pixels, and determines whether prediction possible for each of the selected noted pixels. Information as to whether prediction is predictable for each pixel constituting the image data is then output as prediction evaluation information. Here, as prediction evaluations there are determination results as to whether or not it is possible to predict values for the noted pixels from values of pixels around the noted pixels. In more detail, it is respectively determined whether or not it is possible to predict a noted pixel (is predictable) from already selected pixels (as previous noted pixels) among pixels around the noted pixel, and whether or not it is possible to predict the noted pixel from pixels selected after that (selected as a noted pixel later on) (is Backward Predictable), and then prediction evaluation information is obtained for these “is predictable” and “is backward predictable” conditions.</p>
<p id="p-0030" num="0029">The decision section <b>23</b> receives input of each pixel value of image data after resolution conversion, and prediction evaluation information for each pixel, from the compression expansion interpolation section <b>21</b> and the pixel value prediction section <b>22</b> respectively, and generates information for determining planes to which each pixel will belong (plane designation information) using specified conditions based on these input values. Specific examples of the specified conditions used here will be given later. Also, plane designation information output by the decision section <b>23</b> represents whether the pixel belongs to a first plane to be subjected to JPEG encoding later, or a second plane to be subjected to prediction encoding, and is, for example, mask image data with the same size as the image data and a depth (number of bits per single pixel) of “1”, or mask image data such that pixels equivalent to pixels to belong to the first plane become “1” while pixels equivalent to pixels to belong to the second plane become “0”.</p>
<p id="p-0031" num="0030">The image segmenting section <b>24</b> selectively outputs each pixel constituting image data to either the reduction processing section <b>25</b> or the prediction encoding section <b>27</b> based on plane designation information output by the decision section <b>23</b>. Specifically, this image segmenting section <b>24</b> respectively generates, in the following order, image data to be processed by the prediction encoding section <b>27</b> (first plane image data) and image data to be processed by the reduction processing section <b>25</b> (second plane image data).</p>
<p id="p-0032" num="0031">That is, the image segmenting section <b>24</b> ensures that there are two regions for storing image data of the same size as the input image data. One of these two regions is the first plane image data and the other is the second plane image data. The image segmenting section <b>24</b> therefore sequentially selects each pixel of the input image data and acquires the value of the selected pixel as a set value. Values of pixels in the mask image data, corresponding to the pixels, are then referenced. When the value is “0”, a value of a corresponding pixel in the first plane image data is made the set value. Also, if a corresponding pixel in the mask image data is “1”, the value of a corresponding pixel in the second plane image data is set to the set value. Accordingly, of the pixels included in the first plane image data, parts equivalent to a region where pixel values in mask image data become “1” are kept at a value initially set when ensuring the region. These parts are called “don't care” in the following. Of pixels included in the second plane image data, those located in parts equivalent to a region where pixel values in mask image data become “0” are similar called “don't care”.</p>
<p id="p-0033" num="0032">In this way, the first plane image data formed by including the image portion equivalent to a region where values of pixels in the mask image data are “0”, and the second plane image data formed by including the image portion equivalent to a region where values of pixels in the mask image data are “1”, are generated, and these data are respectively used by the reduction processing section <b>25</b> and the prediction encoding section <b>27</b>.</p>
<p id="p-0034" num="0033">The reduction processing section <b>25</b> performs compression of the second plane image data and carries out resolution conversion. Reduction processing carried out here is the same as reduction processing carried out in the compression expansion interpolation section <b>21</b>. The JPEG encoding section <b>26</b> carries out JPEG encoding processing for the image data that has been subjected to reduction processing, performs compression on the image data and outputs the resultant data.</p>
<p id="p-0035" num="0034">The prediction encoding section <b>27</b> performs compression of the first plane image data using prediction encoding, and outputs results of the compression. The code output section <b>28</b> generates compression image data made up including results of compression input from the JPEG encoding section <b>26</b> and results of compression input from the prediction encoding section <b>27</b>, writes the data to the hard disk <b>3</b> or outputs the data to the outside via the input output interface <b>4</b>. Processing for each of these sections is actually executed by the CPU <b>1</b>.</p>
<p id="p-0036" num="0035">An example of specific conditions when determining the plane to which each pixel belongs in the decision section <b>23</b> will now be described. The decision section <b>23</b> is realized by the processing as shown in <figref idref="DRAWINGS">FIG. 4</figref>, and the planes are determined by this processing. If the CPU <b>1</b> commences this processing for the decision section <b>23</b>, first of all information (immediately previous information) representing what plane the pixel processed immediately previous belongs to is initialized, and set to a predetermined value (for example, “first plane”) (S<b>1</b>). Also, mask image data having the same size as the input image data and a depth of 1 is generated and stored in the memory section <b>2</b>. Next, pixels are sequentially selected from the input image data (S<b>2</b>). The order for selection of pixels here is the same as the order for selecting noted pixels in the processing for the pixel value prediction section <b>22</b>.</p>
<p id="p-0037" num="0036">Next the CPU <b>1</b> compares the values of the selected pixels with values of corresponding pixels in the interpolated image data, and Boolean values representing whether or not a difference between the two is less than a predetermined threshold value are generated as gap information (isGap) (S<b>3</b>). It is then determined whether or not information (immediately previous information) stored as the plane to which the pixel processed immediately before belongs is the “first plane” or the “second plane” (S<b>4</b>), and if it is the “first plane” a Boolean value for isPredictable || (isGap &amp;&amp; isBackwardPredictable) is calculated using the gap information (isGap) generated in process S<b>3</b>, and isPredictable and isBackwardPredictable for the selected pixels, as the above described specified conditions, and it is checked whether this Boolean value is true or false (S<b>5</b>). Here, the symbol “||” means “OR” and the symbol “&amp;&amp;” means “AND”, and the content inside brackets is calculated first. Notation with these symbols is widely used in notation such as the C language.</p>
<p id="p-0038" num="0037">If the Boolean value calculated in processing of S<b>5</b> is true, the CPU <b>1</b> determines that the plane to which the selected pixel belongs is “first plane”, sets the corresponding pixel of the mask image data to “1” and sets the immediately previous information to “first plane” (S<b>6</b>). If the Boolean value calculated in the processing of S<b>5</b> is false, it is determined that the plane to which the selected pixel belongs is the “second plane”, the corresponding pixel of the mask image data is set to “0” and sets the immediately previous information to “second plane” (S<b>7</b>). After the plane to which the selected pixel belongs has been decided in process S<b>6</b> or process S<b>7</b>, it is checked whether or not there are unselected pixels (S<b>8</b>), and if there are unselected pixels (Yes), processing returns to S<b>2</b> so as to select the pixels (B). On the other hand, if there are no unselected pixels (N<b>0</b>), the mask image data stored in the memory section <b>2</b> is output as plane designation information and processing terminates.</p>
<p id="p-0039" num="0038">In process S<b>4</b>, if the immediately previous information is “second plane”, the CPU <b>1</b> calculates a Boolean value for isGap &amp;&amp; (ispredictable || isBackwardPredictable) using the gap information (isGap) generated in process S<b>3</b>, and ispredictable and isBackwardPredictable for the selected pixels, as the above described specified conditions, and it is checked whether this Boolean value is true or false (S<b>9</b>). If this value is true, processing moves to the process S<b>6</b>. If the value is false in S<b>9</b>, processing moves to S<b>7</b> (A).</p>
<p id="p-0040" num="0039">If the pixel processed immediately previously belongs to the second plane, the processing for the decision section <b>23</b> of this embodiment determines that the pixel belongs to the first plane if there is predictability, even if the gap information is true (this is equivalent to the case where the pixel in the image data is equivalent to an edge portion), and determines that the pixel belongs to the second plane if there is no predictability, even if the gap information is true. Also, if the pixel processed immediately previously belongs to the first plane, if there is predictability it is determined that the pixel belongs to the first plane based on the already processed pixels (among those, they can be made to belong to the first plane), and if, with the gap information true, and based on pixels processed afterwards, there is predictability, it is determined that the pixel belongs in the first plane. The latter is done because it is determined that the pixel is located at the end (upper left end) of a pixel set belonging to the first plane. Logical operations carried out in processes S<b>5</b> and S<b>9</b> shown here, and Boolean values appearing in these processes, are only working examples, and it is also possible to use other values an operations.</p>
<p id="p-0041" num="0040">A characteristic of the processing of the decision section <b>23</b> of this embodiment is that decision results for the immediately previous pixel are used. This means that the bad practice of there being multiple isolated points in the mask image data thus reducing compression efficiency of the mask image data is prevented.</p>
<p id="h-0006" num="0000">[Further Example of Conditions for Determination in the Decision Section <b>23</b>]</p>
<p id="p-0042" num="0041">Here, the plane to which each pixel belongs is determined using not only gap information calculated based on interpolated image data input from the compression expansion interpolation section <b>21</b> and input image data, but also using information about whether prediction is possible. However, it is also possible to carry out simplified processing where only the gap information is used and it is determined that the pixel belongs in the first plane if the gap information is greater than or equal to a predetermined threshold value, and it is determined that the pixel belongs in the second plane if the gap information less than the threshold value. This is decision processing using prediction encoding for cases where degradation due to compression expansion interpolation is large. Similarly, it is possible to determine the plane to which each pixel belongs using only predictability.
<br/>
[Operation]
</p>
<p id="p-0043" num="0042">Next, operation of an image processing device of this embodiment will be described. The CPU <b>1</b> executes compression expansion interpolation processing for the input image data and stores the interpolated image data in the memory section <b>2</b>. The CPU also checks whether or not each pixel can be forwardly or backward predicted with respect to input image data, and for each pixel, associated information related to forward predictability and backward predictability is stored in the memory section <b>2</b>.</p>
<p id="p-0044" num="0043">The CPU <b>1</b> executes the processing shown in <figref idref="DRAWINGS">FIG. 4</figref> to generate plane designation information indicating which of the first plane or the second plane each pixel belongs to and stores this information in the memory section <b>2</b>. This plane designation information is implemented as, for example, mask image data. The CPU <b>1</b> applies mask image data to the input image data, segments into first plane image data, made up of an input image data pixel set corresponding to pixels in the mask image data that are “1”, and second plane image data, made up of an input image data pixel set corresponding to pixels in the mask image data that are “0”, and stores the respective image data in the memory section <b>2</b>.</p>
<p id="p-0045" num="0044">Specifically, as shown in <figref idref="DRAWINGS">FIG. 5</figref>, first plane image data P<b>1</b> to be subjected to prediction encoding, second plane image data P<b>2</b> to be subjected to JPEG encoding and mask image data M representing which plane each pixel belongs to are generated from input image data IN including a natural image portion N and a text image portion T. Normally, the mask image data M shown in <figref idref="DRAWINGS">FIG. 5</figref> is black (<b>0</b>) only for a region enclosed by the outline of the natural image, but as a result of the above described processing, by determining which plane a pixel belongs to a black (<b>0</b>) region continues further to the upper right side of the drawing (pixel scanning direction) from the outline corresponding to use of the state of the immediately previous pixel.</p>
<p id="p-0046" num="0045">The CPU <b>1</b> then executes prediction encoding processing for the first plane image data and stores the results in the memory section <b>2</b>. On the other hand, reduction processing is carried out for the second plane image data, followed by JPEG encoding, and the results are stored in the memory section <b>2</b>. In this way the CPU combines and outputs the prediction encoded image data, the image data after JPEG encoding and the mask image data. It is also possible to carry out compression such as run length compression for the mask image data.</p>
<p id="p-0047" num="0046">Here, the compression expansion interpolation processing and processing to check whether or not prediction is possible are respectively compression processing, that is post-processing, and processing to acquire information used when carrying out prediction encoding processing. With this embodiment, since results of originally required processing are used in processing to segment the image data into planes, increase in overall load of image compression processing is only slight, and it is possible to achieve segmentation into planes and to sufficiently improve compression. It is also possible to use results of compression expansion interpolation processing in the processing of the reduction processing section <b>25</b>, and to use processing results of the pixel value prediction section <b>22</b> in the processing of the prediction encoding section <b>27</b>.</p>
<p id="p-0048" num="0047">For image data that has been subjected to compression in this way, decoding processing is carried out corresponding to the prediction encoding for the section where first plane image data has been compressed, and decoding processing corresponding to JPEG encoding and expansion processing corresponding to the compression is carried out for the section where second plane image data has been compressed. Decoded image data for each plane is combined using mask image data (using decoding when this has been encoded), and the original image data is reproduced.</p>
<p id="h-0007" num="0000">[Processing Before Prediction Encoding]</p>
<p id="p-0049" num="0048">As processing for the prediction enclosing section <b>27</b> carried out by the CPU <b>1</b>, it is possible to carry out the following processing before prediction encoding. Specifically, in order to carry out prediction encoding of the first plane image data, if a difference in value between a previously selected pixel and the currently selected pixel, when each pixel of the image data is being selected, is smaller than a specified threshold value, the CPU <b>1</b> makes the value of the currently selected pixel to the same value as the previously selected pixel. In this case, it is possible to carry out processing such as MTF (Move-to-Front) estimation (estimation for compressing depending on how long before a pixel of the same value was processed) or error diffusion in order to prevent image quality degradation, to simplify processing this processing is not absolutely necessary.</p>
<p id="h-0008" num="0000">[Compression Program Using Conversion to Spatial Frequency Components]</p>
<p id="p-0050" num="0049">So far the case of using prediction encoding has been given as an example of a compression method, but as well as this it is also possible to carry out similar processing in the case where conversion to spatial frequency components is used or where repeatability of data patterns is used, so these type of situations will be described in the following.</p>
<p id="p-0051" num="0050">First of all, the case of using conversion to spatial frequency components will be described. As shown in <figref idref="DRAWINGS">FIG. 6</figref>, a program to be executed by the CPU <b>1</b> in this case includes a DCT processing section <b>31</b>, a decision section <b>32</b>, an image segmenting section <b>33</b>, a JPEG encoding section <b>34</b>, an LZ (Lampel-Ziv) encoding section <b>35</b> and a code output section <b>36</b>.</p>
<p id="p-0052" num="0051">The DCT (discrete cosine transform) processing section <b>31</b> divides input image data up into, for example, pixel blocks of 8×8, and calculates a spatial frequency component for each pixel block. The decision section <b>32</b> calculates strength of a specified high frequency component from information of the spatial frequency components input from the DCT processing section <b>31</b>, plane designation information is generated such that if this strength is smaller than a predetermined threshold value the pixels belonging to that pixel block are set as belonging to the first plane, while otherwise pixels belonging to that pixel block are set as belonging to the second plane, and this information is output to the image segmenting section <b>33</b>.</p>
<p id="p-0053" num="0052">The image segmenting section <b>33</b> receives input of plane designation information from the decision section <b>32</b>, and selectively outputs each pixel of the input image data to either the JPEG encoding section <b>34</b> or the LZ encoding section <b>35</b> based on this plane designation information. Specifically, image data (first plane image data) made up from a subset of pixels belonging to the first plane are output to the JPEG encoding section <b>34</b>, and image data (second plane image data) made up from a subset of pixels belonging to the second plane are output to the LZ encoding section <b>35</b>.</p>
<p id="p-0054" num="0053">The JPEG encoding section <b>34</b> executes JPEG compression for the first plane image data and outputs the results to the code output section <b>36</b>. The LZ encoding section <b>35</b> executes LZ compression for the second plane image data and outputs the results to the code output section <b>36</b>. Here, LZ compression is carried out using repeatability of data patterns included in the image data, and the actual content is widely known and so will not be described in detail. The code output section <b>36</b> generates data including JPEG compressed image data and LZ compressed image data, and outputs this as image data of the compression result.</p>
<p id="p-0055" num="0054">The JPEG encoding section <b>34</b> also uses information of the spatial frequency components generated in the DCT processing section <b>31</b> to perform quantization and entropy coding processing. Specifically, calculation results from the DCT processing section are used in both the segmentation processing by the decision section <b>32</b> and the image segmenting section <b>33</b>, and the JPEG compression by the JPEG encoding section <b>34</b>. Here, processing by the DCT processing section <b>31</b> is equivalent to pre-processing, and processing by the JPEG encoding section <b>34</b> is equivalent to post-processing.</p>
<p id="h-0009" num="0000">[Compression Program Using Repeatability of Data Patterns]</p>
<p id="p-0056" num="0055">A case of using repeatability of data patterns will also be described. A program to be executed by the CPU <b>1</b> in this case comprises a pattern matching section <b>41</b>, a decision section <b>42</b>, an image segmenting section <b>43</b>, a JPEG encoding section <b>44</b>, an LZ encoding section <b>45</b> and a code output section <b>46</b>, as shown in <figref idref="DRAWINGS">FIG. 7</figref>.</p>
<p id="p-0057" num="0056">The pattern matching section <b>41</b> divides the input image data up into, for example, 8×8 pixel blocks, checks pixels in each pixel block while selectively selecting pixels, and checks whether or not there is a string of pixels appearing repeatedly as a pattern in the pixel block. Here, if there is a string of pixels appearing repeatedly as a pattern information specifying the pattern and information specifying the position where the pattern appears are output.</p>
<p id="p-0058" num="0057">The decision section <b>42</b> generates plane designation information such that if a string of pixel values appearing repeatedly as a pattern is found by the pattern matching section <b>41</b>, (if the pattern matching section <b>41</b> outputs information specifying a pattern etc.) the pixels in the pixel block are set as pixels belonging to the first plane, and otherwise sets the pixels in the pixel block as belonging to the second plane, and outputs the plane designation information to the image segmenting section <b>43</b>.</p>
<p id="p-0059" num="0058">The image segmenting section <b>43</b> receives input of the plane designation pattern from the decision section <b>42</b>, and selectively outputs each pixel of the input image data to either the LZ encoding section <b>45</b> or the JPEG encoding section <b>44</b> based on this plane designation information. Specifically, image data made up from a subset of pixels belonging to the first plane (first plane image data) are output to the LZ encoding section <b>45</b>, and image data made up from a subset of pixels belonging to the second plane (second plane image data) are output to the JPEG encoding section <b>44</b>.</p>
<p id="p-0060" num="0059">The JPEG encoding section <b>44</b> executes JPEG compression for the second plane image data and outputs the results to the code output section <b>46</b>. The LZ encoding section <b>45</b> executes LZ compression for the first plane image data and outputs the results to the code output section <b>46</b>. The code output section <b>46</b> generates data made up to contain image data that has been subjected to JPEG compression and image data that has been subjected to LZ compression and outputs as compression result image data.</p>
<p id="p-0061" num="0060">Here, the LZ encoding section <b>45</b> carries out encoding using information specifying a pattern and information specifying the position where the pattern appears, output by the pattern matching section <b>41</b>. Specifically, here processing by the pattern matching section is equivalent to pre-processing and processing by the LZ encoding section is equivalent to post-processing.</p>
<p id="h-0010" num="0000">[Pixel Filling]</p>
<p id="p-0062" num="0061">As has already been described, void (don't care) pixels are included in the first plane image data and the second plane image data generated by the image segmenting sections <b>24</b>, <b>33</b> and <b>43</b>. These void pixels can either be left as they are or set to a predetermined value, but in any case, it is possible to set to a suitable value by carrying out the following processing.</p>
<p id="p-0063" num="0062">Specifically, the image segmenting sections <b>24</b>, <b>33</b> and <b>43</b> set values of void pixels of the image data in each plane depending on the compression method for image data of each plane. For example, in the case of using prediction encoding, void pixels in the image data of the plane subjected to prediction encoding are set to the same value as pixels processed immediately previously. In this way, it is possible to improve encoding efficiency using prediction encoding. Also, in the case of using JPEG encoding, values of void pixels are set to an average value of values of pixels surrounding the pixels. In this way it is possible to improve the efficiency of JPEG encoding.</p>
<p id="p-0064" num="0063">According to the present invention, compression pre-processing is executed for image data, the image data are segmented into a plurality of planes based on results of the pre-processing, and, among the image data of each segmented plane, at least one is subjected to compression (post processing) following on from the pre-processing executed before, and compressed image data is generated and output. Accordingly, segmentation of image data is made possible without additional processing, increase in processing load is restricted and it is possible to improve compression efficiency.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image processing device which compresses image data using repeatability of data patterns, comprising:
<claim-text>a pattern matching unit that executes pattern matching for image data;</claim-text>
<claim-text>a segmenting unit that segments image data into a first plane which includes pixels repeatedly appearing as a pattern and a second plane which does not include pixels repeatedly appearing as a pattern, based on results of the pattern matching; and</claim-text>
<claim-text>a compression processor that applies compression to the first plane using pattern repeatability.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The image processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>the pattern matching unit executes the pattern matching by dividing the image data into a plurality of pixel blocks and checking, for each pixel block, whether or not there is a string of pixel values which repeatedly appears in the pixel block as a pattern; and</claim-text>
<claim-text>the first plane includes a set of pixel blocks which includes the pixels repeatedly appearing as a pattern and the second plane includes a set of pixel blocks having no pixel repeatedly appearing as a pattern.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The image processing device according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein
<claim-text>the compression processor applies compression using the pattern repeatability by executing run length encoding with respect to the first plane and applies JPEG compression with respect to the second plane.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A computer readable recording medium storing a program causing a computer to execute a process for compressing image data using repeatability of data patterns, the process comprising:
<claim-text>executing pattern matching for image data;</claim-text>
<claim-text>segmenting the image data into a first plane which includes pixels repeatedly appearing as a pattern and a second plane which does not include pixels repeatedly appearing as a pattern, based on results of the pattern matching; and</claim-text>
<claim-text>applying compression to the first plane using pattern repeatability.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A method for compressing image data using repeatability of data patterns, the method comprising:
<claim-text>executing pattern matching for image data;</claim-text>
<claim-text>segmenting the image data into a first plane which includes pixels repeatedly appearing as a pattern and a second plane which does not include pixels repeatedly appearing as a pattern, based on results of the pattern matching; and</claim-text>
<claim-text>applying compression to the first plane using pattern repeatability.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
