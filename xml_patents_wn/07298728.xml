<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298728-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298728</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10328613</doc-number>
<date>20021223</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>1109</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>B</subclass>
<main-group>7</main-group>
<subgroup>212</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>370347</main-classification>
<further-classification>370337</further-classification>
</classification-national>
<invention-title id="d0e53">Scheduling system and method for a burst switch</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5499238</doc-number>
<kind>A</kind>
<name>Shon</name>
<date>19960300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5838681</doc-number>
<kind>A</kind>
<name>Bonomi et al.</name>
<date>19981100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37039541</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6052751</doc-number>
<kind>A</kind>
<name>Runaldue et al.</name>
<date>20000400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710107</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6260090</doc-number>
<kind>B1</kind>
<name>Fuhs et al.</name>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710107</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6269077</doc-number>
<kind>B1</kind>
<name>Matsumura et al.</name>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370218</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6529503</doc-number>
<kind>B1</kind>
<name>Chiang et al.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370363</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6681270</doc-number>
<kind>B1</kind>
<name>Agarwala et al.</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710 40</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6742046</doc-number>
<kind>B2</kind>
<name>Yamamoto et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709240</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>7114026</doc-number>
<kind>B1</kind>
<name>Khanna</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711108</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2003/0026287</doc-number>
<kind>A1</kind>
<name>Mullendore et al.</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370442</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>EP</country>
<doc-number>1 158 699</doc-number>
<kind>A2</kind>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>EP</country>
<doc-number>1 168 664</doc-number>
<kind>A2</kind>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00013">
<othercit>McKeown, N.; Fast Switched Backplane for a Gigabit Switched Router: White Paper, pp. 1-25.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00014">
<othercit>McKeown, et al.; A Quantitative Comparison of Iterative Scheduling Algtorithms for Input-Queued Switches; Computer Networks and ISDN Systems; 1998; pp. 2309-2326; vol. 30, No. 24.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00015">
<othercit>McKeown, N.; The ISLIP Scheduling Algorithm for Input-queued Switches; IEEE/ACM Transactions on Networking; Apr. 1999; vol. 7, No. 2; pp. 188-201.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00016">
<othercit>McKeown, et al.; Achieving 100% Throughput in an input-Queued Switch; Proceedings IEEE INFOCOM '96; Fifteenth Annual Joint Conference of the IEEE Computer Societies; Networking the Next Generation: Mar. 1996; vol. 1, pp. 296-302.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00017">
<othercit>Chao, et al.; Saturn: A Terabit Packet Switch Using Dual Round-Robin: IEEE Communications Magazine; Dec. 2000; pp. 78-84.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>370321</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370337</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370345</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370336</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370347</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370349</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3703954</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>37039542</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370442</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370473-474</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3703957-39572</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370412-418</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>12</number-of-drawing-sheets>
<number-of-figures>12</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20040120276</doc-number>
<kind>A1</kind>
<date>20040624</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Golla</last-name>
<first-name>Prasad N.</first-name>
<address>
<city>Plano</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Blanton</last-name>
<first-name>John</first-name>
<address>
<city>Dallas</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Damm</last-name>
<first-name>Gerard</first-name>
<address>
<city>Ottawa</city>
<country>CA</country>
</address>
</addressbook>
<nationality>
<country>CA</country>
</nationality>
<residence>
<country>CA</country>
</residence>
</applicant>
<applicant sequence="004" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Verchere</last-name>
<first-name>Dominique</first-name>
<address>
<city>Chauffailles</city>
<country>FR</country>
</address>
</addressbook>
<nationality>
<country>FR</country>
</nationality>
<residence>
<country>FR</country>
</residence>
</applicant>
<applicant sequence="005" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Haardt</last-name>
<first-name>Céline</first-name>
<address>
<city>Bouloc</city>
<country>FR</country>
</address>
</addressbook>
<nationality>
<country>FR</country>
</nationality>
<residence>
<country>FR</country>
</residence>
</applicant>
<applicant sequence="006" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Farahmand</last-name>
<first-name>Farid</first-name>
<address>
<city>Plano</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Danamraj &amp; Emanuelson, P.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Smith</last-name>
<first-name>Jessica W.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Alcatel Lucent</orgname>
<role>03</role>
<address>
<city>Paris</city>
<country>FR</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Pham</last-name>
<first-name>Chi</first-name>
<department>2616</department>
</primary-examiner>
<assistant-examiner>
<last-name>Hoang</last-name>
<first-name>Thai</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A scheduling system and method operable with a burst switching element wherein control information is provided to the switching element via a separate Burst Header that precedes data bursts on ingress data channels. In one embodiment, a series of scheduling determinations are made in a select order such that packet treatment (i.e., processing for transmission, buffering, or packet dropping) is optimized with respect to packet loss and available buffer space. In another embodiment, control information received in the Burst Headers is utilized to reserve output data channel bandwidth to future incoming data packets in a forward-looking scheduling mechanism.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="162.48mm" wi="214.29mm" file="US07298728-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="133.86mm" wi="154.18mm" file="US07298728-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="229.36mm" wi="117.18mm" orientation="landscape" file="US07298728-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="171.53mm" wi="149.35mm" orientation="landscape" file="US07298728-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="148.08mm" wi="135.04mm" file="US07298728-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="175.09mm" wi="144.36mm" orientation="landscape" file="US07298728-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="130.30mm" wi="140.72mm" file="US07298728-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="214.88mm" wi="163.49mm" orientation="landscape" file="US07298728-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="157.65mm" wi="73.91mm" orientation="landscape" file="US07298728-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="179.49mm" wi="152.32mm" orientation="landscape" file="US07298728-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="231.06mm" wi="167.64mm" orientation="landscape" file="US07298728-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="221.49mm" wi="160.87mm" file="US07298728-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="215.22mm" wi="158.07mm" orientation="landscape" file="US07298728-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION(S)</heading>
<p id="p-0002" num="0001">This application discloses subject matter related to the subject matter disclosed in the following commonly owned co-pending patent application(s): (i) “Multiserver Scheduling System And Method For A Fast Switching Element,” application Ser. No.: 10/059,641, filed Jan. 28, 2002, in the names of: Prasad Golla, Gerard Damm, John Blanton, Mei Yang, Dominique Verchere, Hakki Candan Cankaya, and Yijun Xiong; (ii) “Look-Up Table Arbitration System And Method For A Fast Switching Element,” application Ser. No.: 10/075,176, filed Feb. 14, 2002, in the names of: Prasad Golla, Gerard Damm, John Blanton, and Dominique Verchere; (iii) “Binary Tree Arbitration System And Method,” application Ser. No.: 10/109,423, filed Mar. 28, 2002, in the names of: Prasad Golla, Gerard Damm, Timucin Ozugur, John Blanton, and Dominique Verchere; and (iv) “Look-Ahead Contention Resolution Method For A Burst Switching Network, application Ser. No.: 10/328,354, Dec. 23, 2002 filed , in the name(s) of Farid Farahmand, John Blanton, and Dominique Verchere.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Technical Field of the Invention</p>
<p id="p-0004" num="0003">The present invention generally relates to scheduling techniques. More particularly, and not by way of any limitation, the present invention is directed to a scheduling system and method for a switching element operable with data bursts.</p>
<p id="p-0005" num="0004">2. Description of Related Art</p>
<p id="p-0006" num="0005">Scheduling is well-known as a resolution mechanism among a plurality of units contending for a common resource. For example, servers associated with input and output ports of a network element must first compete in order to establish appropriate traffic paths across a switching fabric before data can be transported between a selected input port and an output port. Since arbitration times can take a significant portion of a scheduling process, it is desirable to implement an efficient scheme where high throughput rates are required. Further, where available buffer space is limited or none at all, packet loss due to port congestion should be minimized as much as possible, especially where high quality services are to be provisioned. These concerns assume particular significance where data is aggregated at the input side of a switching system as a plurality of data bursts, or where scheduling functionality is distributed in disjoint entities (i.e., multi-level scheduling).</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0007" num="0006">Accordingly, the present invention advantageously provides an innovative scheduling system and method operable with a burst switching element wherein control information is provided to the switching element via a separate Burst Header (e.g., as a separate control channel) that precedes data bursts on ingress data channels. In one embodiment, a series of scheduling determinations are made in a select order such that packet treatment (i.e., processing for transmission, buffering, or packet dropping) is optimized with respect to packet loss and available buffer space. In another embodiment, control information received in the Burst Headers is utilized to reserve output data channel bandwidth to future incoming data packets in a forward-looking scheduling mechanism.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0008" num="0007">A more complete understanding of the present invention may be had by reference to the following Detailed Description when taken in conjunction with the accompanying drawings wherein:</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 1</figref> depicts an exemplary satellite-based Radio Burst Switch (RBS) system wherein the teachings of the present invention may be employed;</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 2</figref> depicts an exemplary channelized beaming scheme implemented in the RBS system shown in <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 3A</figref> depicts a functional block diagram of an embodiment of the RBS system architecture wherein a plurality of delay buffers are associated with the ingress ports;</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 3B</figref> depicts an architectural topology of the switching functionality associated with the RBS embodiment shown in <figref idref="DRAWINGS">FIG. 3A</figref>;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 4A</figref> depicts a functional block diagram of another embodiment of the RBS system architecture wherein a plurality of delay buffers are associated with the egress ports;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 4B</figref> depicts an architectural topology of the switching functionality associated with the RBS embodiment shown in <figref idref="DRAWINGS">FIG. 3B</figref>;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 5</figref> is a flow chart of the various operations involved in an embodiment of the scheduling methodology provided in accordance with the teachings of the present invention;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 6</figref> depicts a graphical representation of a data channel and associated control channel, wherein the control channel includes control information used in effectuating an allocation-based scheduling mechanism for data bursts to be received at a switch element, e.g., the RBS system shown in <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 7</figref> depicts a memory-mapped channel reservation scheme used for scheduling incoming data bursts to be received by the switch element;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 8</figref> depicts an exemplary scheduling operation using the memory-mapped channel reservation scheme provided in accordance with the teachings of the present invention;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 9</figref> is a flow chart of the various operations involved in another embodiment of the scheduling methodology provided in accordance with the teachings of the present invention; and</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 10</figref> depicts an exemplary multicast scheduling operation using the memory-mapped channel reservation scheme provided in accordance with the teachings of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0021" num="0020">In the drawings, like or similar elements are designated with identical reference numerals throughout the several views thereof, and the various elements depicted are not necessarily drawn to scale. Referring now to <figref idref="DRAWINGS">FIG. 1</figref>, depicted therein is an exemplary satellite-based Radio Burst Switch (RBS) system <b>100</b> wherein the teachings of the present invention may be advantageously employed for purposes of scheduling traffic. At the outset, it should be recognized that although the present invention's scheduling methodology will be particularly described in the context of the satellite-based RBS system <b>100</b>, the teachings hereof can be practiced in other scheduling applications as well where packet loss requirements and/or buffering capacities are stringent. Accordingly, the term “switch element” will be used in the present application with a view to cover both RBS elements as well as terrestrial-based communications network elements employing scheduling techniques (e.g., switches, routers, et cetera).</p>
<p id="p-0022" num="0021">Continuing to refer to <figref idref="DRAWINGS">FIG. 1</figref>, a plurality of ground stations <b>102</b>-<b>1</b> through <b>102</b>-M are operably disposed in the RBS system <b>100</b> for communication via a relay satellite <b>106</b> that employs an embodiment of the scheduling methodology of the present invention as will be described in detail hereinbelow. Each ground station is provided with a ground line access mechanism that operates as a concentration point for the data packets received (i.e., as in an ingress node with respect to the RBS system) or transmitted (i.e., as in an egress node with respect to the RBS system) on the terrestrial network links coupled thereto. Reference numerals <b>104</b>-<b>1</b> through <b>104</b>-M refer to M service access points associated with the corresponding ground stations for providing such ground line access.</p>
<p id="p-0023" num="0022">The RBS system <b>100</b> is operable to switch data between a plurality of ports, e.g., M virtual full duplex ports provided with the relay satellite <b>100</b>, using the scheduling scheme of the present invention, wherein each port represents a separate ground station. A separate beam covers each ground station, and each beam carries a number of frequency-multiplexed data channels (Data Channel Group or DCG). Packets received through ground links at a ground station's access point are aggregated into data bursts for transmission to the satellite via uplink beams, which include a Control Channel (CC) for carrying a Burst Header Packet (BHP) sent in advance of each data burst. Also, the CC's BHPs may be provided as in-band or out-of-band control information with respect to the data bursts. By way of illustration, reference numeral <b>108</b> refers to an exemplary uplink beam having the data channels and BHP channel transmitted by the ground station-<b>1</b> <b>102</b>-<b>1</b>. An ingress beam-forming system (not shown) at the satellite <b>106</b> resolves the signals from the separate ground stations into different beams, and a demultiplexing system extracts the separate data channels from each beam.</p>
<p id="p-0024" num="0023">In one exemplary implementation, the data bursts are preferably segmented into slots of equal size that correspond to the time slots of the relay satellite's switching matrix. Further, as will be described in additional detail hereinbelow, the scheduling system provided with the satellite element <b>106</b> preferably switches only during the guard band interval between the time slots. After an appropriate forwarding decision is implemented with respect to the incoming data packets as well as any buffered packets, a channel multiplexer aggregates the separate channels associated with an output port into a single signal. An egress beam-forming system then focuses the output port signals onto separate ground stations via downlink beams which include a Telemetry Channel (TMC) carrying slot synchronization information, in addition to the data burst channels. Reference numeral <b>110</b> refers to an exemplary downlink beam having the data burst channels and TMC signal transmitted to the ground station-M <b>102</b>-M.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 2</figref> depicts an exemplary channelized beaming scheme <b>200</b> implemented in the RBS system <b>100</b> described above. As pointed out, local ground stations are associated with respective service access points for concentrating ground lines and, accordingly, a Level-1 (L1) scheduler block <b>204</b> is provided to be operable with a ground station's uplink port <b>202</b> for forming data bursts (for example, incoming IP packets are aggregated into a “super packet,” created on the basis of duration and/or length and having the same egress port and Class of Service (CoS) requirements) and corresponding BHPs. A queuing management system of the ground station is operable to enqueue the data bursts and BHPs into channel-specific queues for uplink transmission towards the satellite node of the PBS system. It should be appreciated that various known and novel queuing/scheduling techniques may be employed by the ground station for purposes of data enqueuing and local buffering. Reference numerals <b>206</b>-<b>1</b> to <b>206</b>-<b>4</b> refer to four exemplary data queues associated with four corresponding data channels <b>208</b>-<b>1</b> through <b>208</b>-<b>4</b>. A Control Channel <b>210</b>, either in-band or out-of-band, is operable to carry the BHPs associated with the data bursts ahead of their transmission on the data channels. For instance, data bursts <b>220</b>-<b>1</b> to <b>220</b>-<b>5</b> exemplify a plurality of data bursts transmitted on data channel <b>208</b>-<b>1</b>. As illustrated in <figref idref="DRAWINGS">FIG. 2</figref>, BHP <b>222</b>-<b>1</b> is associated with data burst <b>220</b>-<b>1</b>, BHP <b>222</b>-<b>2</b> is associated with data burst <b>220</b>-<b>2</b>, and BHP <b>222</b>-<b>3</b> is associated with data burst <b>220</b>-<b>3</b>. Likewise, the data bursts of the other data channels are associated with corresponding BHPs on Control Channel <b>210</b>. As will be described below, each BHP is transmitted ahead of its data burst by a predetermined time offset, and includes necessary control information used in setting up the satellite's on-board burst switching apparatus <b>212</b>. A Level-2 (L2) scheduler <b>214</b> is operable to receive the BHP information which, in response thereto, resolves the BHP requests for determining a forwarding decision. A forwarding switching station <b>216</b> is operable responsive to the output of the L2 scheduler <b>214</b> for configuring its switching matrix, whereby the outgoing data packets are directed to the downlink ports of the satellite.</p>
<p id="p-0026" num="0025">Although buffer capacity that can be provided with the switching station of the RBS system is severely curtailed because of the tight satellite environment, a small amount of memory may nevertheless be available for purposes of supporting some delay in the packets that cannot be immediately processed for scheduling through the satellite node. This condition is particularly useful in providing services where guaranteed packet delivery is deemed important. The delay buffers may be associated with the switching system's ingress ports (for buffering input channels), egress ports (for buffering output channels), or both, depending on the architectural requirements, for implementing a plurality of delay paths within the system. Since the RBS system is operable to switch among N virtual full duplex ports (i.e., for switching, theoretically, between N ingress ports and N egress ports, each port supporting P data channels), a switching station capable of switching (N×P) channels will be necessary. Further, where K delay buffers are provided, each supporting a delay loop path with respect to the switching station, the switching matrix needs to be dimensioned (N×P+K) by (N×P+K), which may be partitioned in different ways based on the buffer architecture, among others. <figref idref="DRAWINGS">FIG. 3A</figref> depicts a functional block diagram of an embodiment of the RBS system architecture <b>300</b>A wherein a delay buffer block <b>306</b> having a plurality of delay buffers is associated with the input data channels. A channel switch <b>304</b> is operable to receive incoming data burst packets (after beam-separated and demultiplexed) via a plurality of ingress ports <b>302</b>-<b>1</b> through <b>302</b>-N, each having P data channels. In this configuration, a packet entering on a data channel of one ingress port is assigned to an available channel on a designated output port. If no channel is available on the output port, then the packet may be assigned to one of the delay buffers of the delay block <b>306</b>. A plurality of port switches <b>308</b>-<b>1</b> to <b>308</b>-P, each corresponding to an egress data channel group, are operably coupled to the channel switch <b>304</b>. Control signals <b>305</b>, <b>309</b> provided by the forwarding decision block of the switching/scheduling system determine the configuration of the channel and port switches, respectively. The output of the port switches is provided to a multiplex combiner <b>310</b> that combines the P output channels of a particular egress port <b>312</b>. As will be explained in detail hereinbelow, an elaborate packet forwarding methodology may be implemented for effectuating a scheduling scheme in accordance with the teachings of the present invention.</p>
<p id="p-0027" num="0026">The functional architecture described above can be cast as a switching problem having an architectural topology <b>300</b>B shown in <figref idref="DRAWINGS">FIG. 3B</figref>. The partitioned switching functionality of the RBS embodiment <b>300</b>A is combined into a single switching block <b>350</b> that receives a plurality of data channels associated with each ingress port <b>352</b>. Reference numerals <b>356</b>-<b>1</b> to <b>356</b>-K refer to K delay buffers of the delay block <b>306</b> shown in <figref idref="DRAWINGS">FIG. 3A</figref>. Output ports <b>354</b>-<b>1</b> to <b>354</b>-N exemplify the N egress ports of the RBS system.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 4A</figref> depicts a functional block diagram of another embodiment of the RBS system architecture <b>400</b>A wherein the delay buffers are associated with the output ports. Again, N ingress ports <b>302</b>-<b>1</b> to <b>302</b>-N provide the incoming data packets to a channel switch <b>402</b> that is coupled to P port switches <b>404</b>-<b>1</b> to <b>404</b>-P. Each port switch is provided with a delay block having a set (K) of memory buffers. Reference numerals <b>406</b>-<b>1</b> to <b>406</b>-P refer to the P delay blocks that correspond to P port switches. The outputs of the P port switches are combined on a port-by-port basis such that all output channels of a particular egress port <b>312</b> are frequency-multiplexed into a single signal.</p>
<p id="p-0029" num="0028">Similar to <figref idref="DRAWINGS">FIG. 3B</figref>, <figref idref="DRAWINGS">FIG. 4B</figref> depicts an architectural topology <b>400</b>B associated with the RBS system embodiment <b>400</b>A described above. A generic switching block <b>450</b>, which exemplifies the separate channel and port switching structures shown in <figref idref="DRAWINGS">FIG. 4A</figref>, is operably coupled to the ingress ports <b>302</b>-<b>1</b> to <b>302</b>-N for receiving demultiplexed data packets on individual input data channels. A plurality of delay buffers <b>452</b>-<b>1</b> to <b>452</b>-K are associated with the P output channels of a single port, e.g., egress port <b>312</b>. When a packet arrives at an input port, the scheduling mechanism determines the assigned egress port and searches for an available data channel associated therewith. If no channels or buffers are available, the packet may be dropped.</p>
<p id="p-0030" num="0029">As alluded to hereinabove, the buffering capacity associated with the burst switching apparatus can be extremely limited. However, the packet dropping mechanism should be one such that not only a minimal amount is dropped but it should also be one that allows for judicious utilization of resources. Thus, in accordance with the teachings of the present invention, the scheduling methodology comprises a scheme for choosing which packet to drop among two or more candidates based on their position within the processing flow of the RBS system. Moreover, the methodology provides for randomizing the order of service to the multiple data channels arriving at the switch in order to avoid preferential treatment for one or more data flows.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 5</figref> is a flow chart of the various operations involved in an embodiment of the scheduling methodology of the present invention which can be implemented with either of the architectural topologies described above, wherein at least a portion of the scheduling mechanism may comprise software/firmware instructions on a computer-accessible medium. For each time slot, a determination is made if there are packets previously buffered in the delay buffers that can be transmitted from an output port (block <b>502</b>). In other words, the determination seeks to find if there are enough data channels available on the designated output ports that can be used for transmitting the previously buffered data packets. If so, such previously buffered packets are scheduled for transmission from the output ports before considering any other packets (block <b>503</b>). Thereafter, another determination is made if there are ingress packets at the burst switching apparatus which are part of a previously accepted data burst (block <b>504</b>). In the context of the present invention, a previously accepted burst is one for which one or more data packets have already been accepted by the RBS system, that is, the prior data packets have been scheduled for transmission or accepted for delay buffering, but not dropped. If so, such packets of previously accepted data bursts are processed before processing any of the newly arriving packets at the switch. Accordingly, these packets are scheduled for transmission immediately (in the current time slot), or buffered if necessary (block <b>506</b>). Thereafter, yet another determination is made whether the initial packets of any newly arriving bursts can be transmitted or buffered (block <b>508</b>). If so, such initial packets of the newly arrived data bursts are processed accordingly, depending upon the availability of output data channels on the destination egress ports and/or the availability of free delay buffers (block <b>510</b>). Otherwise, a packet drop policy may then be applied with respect to the initial packets at the switch (block <b>512</b>). In one exemplary application, if a packet of a particular data burst is dropped, all remaining packets associated with that data burst are also dropped, including any currently buffered packets.</p>
<p id="p-0032" num="0031">In terms of implementation of the above-described scheduling mechanism, the switching apparatus may be required to write a new packet into a delay buffer while another packet is being transmitted from that buffer. This can be effectuated by servicing the buffers before servicing the input data channels. Accordingly, when an input data channel is processed, all delay buffers that were serviced in the same time slot (also known as slot cycle) are seen as empty and available. At the start of each slot cycle, therefore, all the delay buffers are examined to determine which ones have packets stored and available for routing to the output ports. Buffered packets that cannot be sent on output data channels may be held over to the next slot cycle. This process may be referred to as a “buffer kickback” scheme, and a ceiling on the number of cycles for which a buffered packet can be kicked back (i.e., held back) may be implemented based on design constraints. In one configuration, a numerical sequence may be established for all delay buffers in the switch, based on the buffer number and the port number, which can take the form of S<sub>i,j</sub>, S<sub>i,j+1</sub>, S<sub>i,j+2</sub>, . . . , S<sub>i+1,j</sub>, S<sub>i+1,j+1</sub>, S<sub>i+1,j+2</sub>, . . . where i is the port number (i→1, 2, . . . , N) and j is the buffer number (j→1, 2, . . . , K). Delay buffers may be serviced in a cyclic numerical order, first by buffer number and then by port number. To prevent starting each service cycle at the same point for a slot, a pointer mechanism may be implemented such that the service starting point is advanced in an unpredictable way during the scheduling process. The mechanism used to advance the pointer can be keyed to certain events driven by the incoming traffic.</p>
<p id="p-0033" num="0032">As pointed out previously, the packets of existing data bursts are serviced after the delay buffers are serviced. For single-slot bursts this has no meaning, but for multi-slot bursts, slot number <b>2</b> and beyond of a data burst are serviced before any initial packets (i.e., slot number <b>1</b> packets) of a newly arrived burst. The intent is to preserve the accomplishment of scheduling previous slots of a multi-slot burst, since dropping a subsequent slot of the burst can result in discarding the slots that have already been transmitted to a ground station. If a slot cannot be allocated to an output data channel, then an attempt is made to store it one of the delay buffers associated with the port. On other hand, if the slot cannot be transmitted or stored, the whole data burst is dropped. Whenever a burst is dropped, the scheduler of the present invention searches through the delay buffers and discards any other slot packets associated with the dropped burst. In addition, the remaining packets of the burst that are yet to be received may be marked to be dropped as well.</p>
<p id="p-0034" num="0033">To ensure that the processing of the channels does not consistently start with the same channel for each time slot (i.e., follow any fixed pattern), the service starting point may be randomized similar to the delay buffer service process described above. Pointers may be established with respect to the channel and port combination to start with, wherein the channel pointer may be advanced cyclically each time a packet is transmitted from a channel and the port pointer is advanced cyclically each time a new burst arrives at the switch. Again, the pointer advance mechanism may be keyed to the incoming traffic.</p>
<p id="p-0035" num="0034">After the packets of existing bursts are processed, the scheduler processes packets of the newly arrived bursts. Whereas these are slot number <b>1</b> packets for multi-slot bursts as mentioned above, they comprise the sole packets for single-slot bursts. Other than that, their processing is similar to the scheduling mechanism set forth for the existing data bursts. Once again, the service starting point (channel and port combination) is randomized to prevent any fixed patterns.</p>
<p id="p-0036" num="0035">The rationale for giving priority to subsequent slot packets may be illustrated as follows. When a burst comprises more than slot packet, it may be that the first packet must be dropped. Then, in order to conserve switch resources, the remaining packets of the burst are dropped. If the first packet is transmitted, it is important not to drop the subsequent packets of the burst, because this will result in loss of the previously transmitted packets also. Even in the absence of buffering (or, with limited buffering), it is possible to prevent loss of subsequent slot packets by the simple scheme of processing initial packets after all the previous bursts are processed.</p>
<p id="p-0037" num="0036">As a further implementational variation, any statistical variation in traffic load on each channel and/or among a group of channels may be eliminated by requiring the switch's link partners (i.e., uplink and downlink ports) to use a burst initiating scheme that allows for generating a more deterministic traffic. Whereas such a scheme may require synchronization between the link partners, it imposes only a minimal collaboration among the various link partners since such synchronization is already required and no further collaboration is necessary to maintain the burst initiation timing.</p>
<p id="p-0038" num="0037">Pseudocode relating to the above-described scheduling methodology, as applied in the two architectural topologies, is set forth below.</p>
<p id="h-0006" num="0000">Case A: Delay Buffers Associated with Input Ports</p>
<p id="p-0039" num="0038">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="14pt" align="left"/>
<colspec colname="1" colwidth="203pt" align="left"/>
<thead>
<row>
<entry/>
<entry namest="offset" nameend="1" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry/>
<entry>Initially, all burst_status<sub>i,j </sub>are set to EMPTY.</entry>
</row>
<row>
<entry/>
<entry>When a new burst arrives at channel<sub>i,j </sub>its burst_status is set to</entry>
</row>
<row>
<entry/>
<entry>NEW.</entry>
</row>
<row>
<entry/>
<entry> for each buffer i</entry>
</row>
<row>
<entry/>
<entry>  for each input port j</entry>
</row>
<row>
<entry/>
<entry>   if buffer<sub>i,j </sub>is occupied</entry>
</row>
<row>
<entry/>
<entry>     if an output channel is available for the packet</entry>
</row>
<row>
<entry/>
<entry>      Switch the packet to the channel.</entry>
</row>
<row>
<entry/>
<entry>      Show the buffer as unoccupied.</entry>
</row>
<row>
<entry/>
<entry>    end if</entry>
</row>
<row>
<entry/>
<entry>   end if</entry>
</row>
<row>
<entry/>
<entry>  end for</entry>
</row>
<row>
<entry/>
<entry> end for</entry>
</row>
<row>
<entry/>
<entry> for each input channel i</entry>
</row>
<row>
<entry/>
<entry>  for each input port j</entry>
</row>
<row>
<entry/>
<entry>   if burst_status<sub>i,j </sub>is OLD</entry>
</row>
<row>
<entry/>
<entry>    if an output channel is available for the packet</entry>
</row>
<row>
<entry/>
<entry>     Switch the packet to the channel.</entry>
</row>
<row>
<entry/>
<entry>    else</entry>
</row>
<row>
<entry/>
<entry>     if a buffer is available on port j</entry>
</row>
<row>
<entry/>
<entry>      Show the buffer as unavailable.</entry>
</row>
<row>
<entry/>
<entry>      Store the packet in the buffer.</entry>
</row>
<row>
<entry/>
<entry>     else</entry>
</row>
<row>
<entry/>
<entry>      Drop the packet.</entry>
</row>
<row>
<entry/>
<entry>      Delete from the buffers other packets of this</entry>
</row>
<row>
<entry/>
<entry> burst.</entry>
</row>
<row>
<entry/>
<entry>     end if</entry>
</row>
<row>
<entry/>
<entry>    end if</entry>
</row>
<row>
<entry/>
<entry>   end if</entry>
</row>
<row>
<entry/>
<entry>  end for</entry>
</row>
<row>
<entry/>
<entry> end for</entry>
</row>
<row>
<entry/>
<entry> for each input channel i</entry>
</row>
<row>
<entry/>
<entry>  for each input port j</entry>
</row>
<row>
<entry/>
<entry>   if burst_status<sub>i,j </sub>is NEW</entry>
</row>
<row>
<entry/>
<entry>    Cyclically advance the port start point.</entry>
</row>
<row>
<entry/>
<entry>    Set burst_status<sub>i,j </sub>to OLD.</entry>
</row>
<row>
<entry/>
<entry>    if an output channel is available for the packet</entry>
</row>
<row>
<entry/>
<entry>     Switch the packet to the channel.</entry>
</row>
<row>
<entry/>
<entry>     Cyclically advance the channel start point.</entry>
</row>
<row>
<entry/>
<entry>    else</entry>
</row>
<row>
<entry/>
<entry>     if a buffer is available on port j</entry>
</row>
<row>
<entry/>
<entry>      Show the buffer as unavailable.</entry>
</row>
<row>
<entry/>
<entry>      Store the packet in the buffer.</entry>
</row>
<row>
<entry/>
<entry>     else</entry>
</row>
<row>
<entry/>
<entry>      Drop the packet.</entry>
</row>
<row>
<entry/>
<entry>      Set burst_status<sub>i,j </sub>to EMPTY.</entry>
</row>
<row>
<entry/>
<entry>     end if</entry>
</row>
<row>
<entry/>
<entry>    end if</entry>
</row>
<row>
<entry/>
<entry>   end if</entry>
</row>
<row>
<entry/>
<entry>  end for</entry>
</row>
<row>
<entry/>
<entry> end for</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="1" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
<br/>
Case B: Delay Buffers Associated with Output Ports
</p>
<p id="p-0040" num="0039">
<tables id="TABLE-US-00002" num="00002">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="14pt" align="left"/>
<colspec colname="1" colwidth="203pt" align="left"/>
<thead>
<row>
<entry/>
<entry namest="offset" nameend="1" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry/>
<entry>Initially, all burst_status<sub>i,j </sub>are set to EMPTY.</entry>
</row>
<row>
<entry/>
<entry>When a new burst arrives at channel<sub>i,j </sub>its burst_status is set to</entry>
</row>
<row>
<entry/>
<entry>NEW.</entry>
</row>
<row>
<entry/>
<entry> for each buffer i</entry>
</row>
<row>
<entry/>
<entry>  for each output channel j</entry>
</row>
<row>
<entry/>
<entry>   if buffer<sub>i,j </sub>is occupied</entry>
</row>
<row>
<entry/>
<entry>    if an output channel is available for the packet</entry>
</row>
<row>
<entry/>
<entry>     Switch the packet to the channel.</entry>
</row>
<row>
<entry/>
<entry>     Show the buffer as unoccupied.</entry>
</row>
<row>
<entry/>
<entry>     Cyclically advance the buffer starting point.</entry>
</row>
<row>
<entry/>
<entry>    end if</entry>
</row>
<row>
<entry/>
<entry>   end if</entry>
</row>
<row>
<entry/>
<entry>  end for</entry>
</row>
<row>
<entry/>
<entry> end for</entry>
</row>
<row>
<entry/>
<entry> for each input channel i</entry>
</row>
<row>
<entry/>
<entry>  for each input port j</entry>
</row>
<row>
<entry/>
<entry>   if burst_status<sub>i,j </sub>is OLD</entry>
</row>
<row>
<entry/>
<entry>    if an output channel is available for the packet</entry>
</row>
<row>
<entry/>
<entry>     Switch the packet to the channel.</entry>
</row>
<row>
<entry/>
<entry>    else</entry>
</row>
<row>
<entry/>
<entry>     if there are channels with available buffers</entry>
</row>
<row>
<entry/>
<entry>      Select an output channel k with the most</entry>
</row>
<row>
<entry/>
<entry> available</entry>
</row>
<row>
<entry/>
<entry>       buffers.</entry>
</row>
<row>
<entry/>
<entry>      Select an available buffer from channel k.</entry>
</row>
<row>
<entry/>
<entry>      Show the buffer as unavailable.</entry>
</row>
<row>
<entry/>
<entry>      Store the packet in the buffer.</entry>
</row>
<row>
<entry/>
<entry>     else</entry>
</row>
<row>
<entry/>
<entry>      Drop the packet.</entry>
</row>
<row>
<entry/>
<entry>      Set burst_status<sub>i,j </sub>to EMPTY.</entry>
</row>
<row>
<entry/>
<entry>      Delete from the buffers other packets of this</entry>
</row>
<row>
<entry/>
<entry> burst.</entry>
</row>
<row>
<entry/>
<entry>     end if</entry>
</row>
<row>
<entry/>
<entry>    end if</entry>
</row>
<row>
<entry/>
<entry>   end if</entry>
</row>
<row>
<entry/>
<entry>  end for</entry>
</row>
<row>
<entry/>
<entry> end for</entry>
</row>
<row>
<entry/>
<entry> for each input channel i</entry>
</row>
<row>
<entry/>
<entry>  for each input port j</entry>
</row>
<row>
<entry/>
<entry>   if burst_status<sub>i,j </sub>is NEW</entry>
</row>
<row>
<entry/>
<entry>    Cyclically advance the port start point.</entry>
</row>
<row>
<entry/>
<entry>    if an output channel is available for the packet</entry>
</row>
<row>
<entry/>
<entry>     Switch the packet to the channel.</entry>
</row>
<row>
<entry/>
<entry>     Cyclically advance the channel start point.</entry>
</row>
<row>
<entry/>
<entry>    else</entry>
</row>
<row>
<entry/>
<entry>     if there are channels with available buffers</entry>
</row>
<row>
<entry/>
<entry>      Select an output channel k with the most</entry>
</row>
<row>
<entry/>
<entry> available</entry>
</row>
<row>
<entry/>
<entry>       buffers.</entry>
</row>
<row>
<entry/>
<entry>      Select an available buffer from channel k.</entry>
</row>
<row>
<entry/>
<entry>      Show the buffer as unavailable.</entry>
</row>
<row>
<entry/>
<entry>      Store the packet in the buffer.</entry>
</row>
<row>
<entry/>
<entry>     else</entry>
</row>
<row>
<entry/>
<entry>      Drop the packet.</entry>
</row>
<row>
<entry/>
<entry>      Set burst_status<sub>i,j </sub>to EMPTY.</entry>
</row>
<row>
<entry/>
<entry>     end if</entry>
</row>
<row>
<entry/>
<entry>    end if</entry>
</row>
<row>
<entry/>
<entry>   end if</entry>
</row>
<row>
<entry/>
<entry>  end for</entry>
</row>
<row>
<entry/>
<entry> end for</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="1" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0041" num="0040">Favorable results have been obtained by way of experimental simulation involving the foregoing implementations of the present invention's scheduling methodology. Furthermore, although the scheduler processes the data channels in sequence (thereby sacrificing some performance that may be available in schemes incorporating parallel operations), it has been observed that adequate throughput and negligible packet loss are possible in the switch configurations tested via simulation. Additionally, in situations where the packet forwarding computations cannot be computed within one slot time (due to, for example, sequential processing of the channels and delay buffers), the scheduling methodology can still be implemented using multiple processors, each of which computes the packet forwarding solution for a separate time slot. This is possible because the BHPs precede the data bursts with enough time delay to allow the solution to be computed by the time the bursts actually arrive at the switch. Accordingly, such a scheme is operable to perform what may be referred to as “anticipatory” packet scheduling for effectuating forwarding decisions that are to be implemented at future time slots. The BHPs carried on the uplink Control Channels can be packed with appropriate information that can be utilized by the scheduler for “allocating” yet-to-arrive ingress data packets to output data channels and/or the delay buffers.</p>
<p id="p-0042" num="0041">Referring now to <figref idref="DRAWINGS">FIG. 6</figref>, depicted therein is a graphical representation of an exemplary data channel <b>602</b> and associated Control Channel <b>604</b>, wherein a plurality of BHPs include control information used in effectuating a forward-looking scheduling mechanism alluded to in the foregoing. The data channel <b>602</b> is exemplified with three data bursts <b>606</b>-<b>1</b> through <b>606</b>-<b>3</b>, each of which is preceded by a corresponding BHP. By way of illustration, BHP <b>608</b>-<b>1</b> precedes the data burst <b>606</b>-<b>1</b> associated therewith. Likewise, BHPs <b>608</b>-<b>2</b> and <b>608</b>-<b>3</b> are associated with data bursts <b>606</b>-<b>2</b> and <b>606</b>-<b>3</b>, respectively. Each data burst is temporally separated from its BHP by a system-wide constant, e.g., delay (♦) <b>610</b>, which can span a predetermined number of time slots, e.g., 4 slots, 5 slots, etc. As will be described in detail below, the forward-looking scheduler of the present invention is operable to implement an arbitration arrangement to “reserve” output data channels on a slot-by-slot basis using a memory-mapped channel scheme. In the context of the present invention, the BHPs can be packed with the following information:
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0042">Multicast Bit: This bit is set depending on whether the associated data burst is destined to one output port only (unicast) or towards multiple ports (multicast/broadcast). An “ON” multicast bit may be followed by a list of destination port numbers. Alternatively, a group of ports could be provided, wherein a group number is operable to indicate a pre-assigned list of output ports.</li>
        <li id="ul0002-0002" num="0043">Group Bit: When this bit is set to “ON” condition, the list of destination numbers provided is treated as a single group, not as a collection of individual ports. It should be appreciated that referring to group entities rather than individual port numbers may reduce the size of the BHP considerably.</li>
        <li id="ul0002-0003" num="0044">Destination Field Number(s): These numbers identify a list of ports or a group of ports the burst is destined to in case the multicast bit is set. If the multicast bit is not set, then the burst is identified for unicast service. When the multicast bit is set but the group bit is not set, then the destination port numbers are individually listed. If both the group and multicast bits are set, then the list of destination numbers refers to groups of ports.</li>
        <li id="ul0002-0004" num="0045">Offset: This field indicates the time in time slot (TS) increments after which the burst will arrive at the forwarding switch. The number of bits in the offset field will depend on the maximum allowable time slots between the BHP's arrival and the arrival of the data burst. As pointed out before, this offset may be provided as a system-wide constant, (♦); but it may also be variable. If X time slots are necessary for the scheduler to perform forward-looking channel allocations, setting of the switching matrices, etc., then a delay of X time slots between the BHPs and associated data bursts will be needed. If everything is properly slotted and synchronized, this delay may be treated as a constant (i.e., exactly X time slots between each BHP-burst pair). Also, as will be described below, the scheduler needs to be implemented in a pipeline organization having X instances, each scheduler instance executing independently for finding a matching solution (which pre-allocates incoming data packets to memory-mapped outgoing data channels and/or delay buffers) for its corresponding time slot.</li>
        <li id="ul0002-0005" num="0046">Burst Length: This field provides the burst length as the number of time slots a data burst occupies. In general, a data burst occupies at least one time slot. Appropriate padding may be provided where slot boundaries and burst boundaries are not aligned.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0043" num="0047">Additionally, depending on the Control Channel organization (i.e., merged Control Channels), the input channel and the input port information could also be included in the BHP fields.</p>
<p id="p-0044" num="0048">A forward-looking scheduling mechanism for channel reservation can now be described using the BHP information set forth above. Referring to <figref idref="DRAWINGS">FIG. 7</figref>, depicted therein is an exemplary memory-mapped channel reservation scheme <b>700</b> used for scheduling future data bursts to be received in a switching element. A scheduler <b>702</b> is operable to receive the BHPs via a Control Channel <b>704</b>, which BHPs include control information such as delay ♦, burst length, multicast indicators, et cetera. A memory block <b>706</b> associated with scheduler <b>702</b> is operable to contain a port-associated mapping wherein a plurality of memory locations are associated with output data channels and delay buffers on a time slot basis. By way of illustration, a single port <b>708</b> having four output data channels (CH-<b>1</b> through CH-<b>4</b>) and a delay buffer block <b>710</b> having three buffers (DELAY-<b>1</b> through DELAY-<b>3</b>) are memory-mapped from the current time slot (TS) through a plurality of future time slots (TS-1, TS-2, et cetera). A slot pointer <b>707</b> points to the data packet assignment that is current for each time slot. The assignment map at TS (i.e., the current slot) is forwarded to the switch configuration controller (not shown) for setting the packet switching/forwarding paths for the current slot cycle.</p>
<p id="p-0045" num="0049">Forward-looking packet assignment for channel reservation is accomplished based on the BHP information. As the incoming BHPs continuously provide information regarding the follow-on data bursts on the ingress data channels, a channel allocation mechanism (which can be based on arbitration, e.g., a round-robin arbitration (RRA) mechanism, or a simple counter-based mechanism) resolves the BHP requests such that the slot-mapped memory locations contain indications of which future packets are assigned to which output data channels and/or delay buffers on a per-slot basis. For instance, reference numerals <b>712</b>-<b>1</b> through <b>712</b>-<b>4</b> refer to the indications associated with four data packets that are scheduled for transmission on the output port's four channels, CH-<b>1</b> through CH-<b>4</b>, in the current TS. By way of example, indication <b>712</b>-<b>1</b> may be associated with a packet on incoming port x<b>1</b>, data channel y<b>1</b>; indication <b>712</b>-<b>2</b> with a packet on incoming port x<b>2</b>, data channel y<b>1</b>; indication <b>712</b>-<b>3</b> with a packet on incoming port x<b>1</b>, data channel y<b>2</b>; and indication <b>712</b>-<b>4</b> with a packet on incoming port x<b>3</b>, data channel y<b>3</b>. Likewise, reference numerals <b>714</b>-<b>1</b> and <b>714</b>-<b>2</b> refer to the indications associated with two data packets that are to be buffered in DELAY-<b>1</b> and DELAY-<b>2</b>, respectively, in the current TS. It should be apparent that these indications may simply comprise ordered pairs of {port; channel} associated with packets that have been selected based on a scheduling/arbitration mechanism.</p>
<p id="p-0046" num="0050">Continuing to refer to <figref idref="DRAWINGS">FIG. 7</figref>, reference numeral <b>716</b>-<b>1</b> refers to an indication that an incoming data packet associated with a {port; channel} pair is to be scheduled for transmission on the output port's CH-<b>4</b> in the next slot (i.e., TS-1). In similar manner, reference numerals <b>716</b>-<b>2</b> to <b>716</b>-<b>5</b> refer to the indications (or, “channel reservations”) of future data packets to be scheduled in TS-2 slot (i.e., two slots behind the current slot); reference numerals <b>716</b>-<b>6</b> and <b>714</b>-<b>3</b> refer to the future channel reservations in TS-3 slot; and reference numeral <b>716</b>-<b>7</b> refers to the channel reservation by a packet in TS-4 slot. The delay buffer block is likewise slot-mapped to indicate which future data packets may be buffered in which buffers. Reference numerals <b>718</b>-<b>1</b> to <b>718</b>-<b>3</b> refer to the indications associated with three packets (as identified by their {port; channel} combinations) that are to be buffered in TS-2 slot. Similarly, reference numeral <b>718</b>-<b>4</b> refers to the indication of a future packet to be buffered in TS-3 slot.</p>
<p id="p-0047" num="0051">It should be recognized that a buffer kickback mechanism may also be implemented in the forward-looking scheduling scheme set forth above. For example, an arbitration associated with TS-2 may result in a determination to hold a buffer reservation indication over for another time slot, as all the TS-2 memory locations associated with the channels for the particular output port are full. Such a buffer kickback is exemplified by an arrow from TS-2 to TS-3 in the buffer mapping. A variety of rules may be implemented with respect to the kickback scheme. For example, kickback may not be possible when the number of times a packet indication is kicked back reaches a predetermined maximum. In this case, the affected packet indication is “dropped,” that is, the packet will not be able to obtain an output data channel or a buffer when it actually arrives at the switch.</p>
<p id="p-0048" num="0052">In terms of an exemplary implementation, <figref idref="DRAWINGS">FIG. 8</figref> depicts a 2-output port, 4-channel forward-looking allocation scheme <b>800</b> of the present invention. Data channels of output port A <b>803</b>A and output port B <b>803</b>B are mapped to respective memory locations that are slot-mapped as described above. By way of illustration, reference numerals <b>805</b>-<b>1</b> through <b>805</b>-<b>4</b> refer to the four data channels of the output port A <b>803</b>A provided as a memory-mapped portion <b>807</b>A. Likewise, reference numeral <b>807</b>B refers to the memory-mapped portion associated with the output port B <b>803</b>B. Reference numeral <b>812</b> refers to the current slot packet assignment (i.e., at TS) that is forwarded for configuring the switching path matrix of the network element.</p>
<p id="p-0049" num="0053">Each time slot is associated with an arbiter/counter that allocates packet indications, one channel at a time, based on the look-ahead BHP requests received by the scheduler. The number of arbiters/counters needed is determined, at least in part, by the offset between the BHPs and the associated data bursts because of systemwide constraints. If the maximum and minimum offset values are ♦<sub>max </sub>and ♦<sub>min</sub>, respectively, the number of arbiters/counters would be approximately ♦<sub>max</sub>-♦<sub>min </sub>However, in terms of memory allocation, it is preferred that registers to store the scheduling allocation for all the ♦<sub>max </sub>slots be present.</p>
<p id="p-0050" num="0054">Continuing to refer to <figref idref="DRAWINGS">FIG. 8</figref>, reference numeral <b>808</b> refers to a block of arbiters/counters that are associated with each port's slot-mapped memory allocation portion wherein each time slot is provided with an arbiter/counter. For instance, 12 arbiter/counters are illustrated for each of the output ports; arbiter/counter <b>810</b>-<b>1</b> is associated with TS-1 (i.e., one slot behind the current slot), arbiter/counter <b>810</b>-<b>2</b> is associated with TS-2 (i.e., two slots behind the current slot), and so on. Each arbiter/counter operates to fill the memory-mapped channels with packet indications, on a slot-by-slot basis, based on any known or heretofore unknown arbitration mechanism or simple counting. For example, when a BHP <b>804</b> corresponding to a 3-packet data burst <b>802</b> is transmitted to the switching element, arbiter/counter <b>810</b>-<b>8</b> fills channel <b>2</b> of output port A <b>803</b>A with the packet indication associated with packet <b>806</b>-<b>1</b> for the TS-8 slot. Likewise, indications for subsequent packets <b>806</b>-<b>2</b> and <b>806</b>-<b>3</b> are filled in TS-9 and TS-10 slots, using corresponding arbiters/counters (hereinafter, collectively “arbiters”).</p>
<p id="p-0051" num="0055">An exemplary packet drop policy in the context of the forward-looking scheduling allocation mechanism is set forth below. Any BHP that indicates an arrival of a burst longer than ♦ slots is discarded and, accordingly, the burst will be ignored when it is sent to the switch. In view of the buffer kickback scheme described above, a packet indication will be dropped when it cannot be kicked back by a slot. Apart from the limitation on the number of kickbacks allowed, kickback may also be limited by the condition where, at any given time slot, the maximum available delay loops have been exhausted. Associated with each time slot there may be a register that signifies how many packets (i.e., their indications) are destined to be sent to the delay loops in that particular time slot.</p>
<p id="p-0052" num="0056">Also, when a packet indication is “dropped” for whatever reason, indications associated with the whole burst will also be dropped, much like the condition where actual packets are dropped. If a Quality of Service (QoS) program is implemented whereby the traffic is assigned multiple priorities, high priority packets can preempt low priority packets. In such a situation, an entire low priority burst may have to be preempted as well.</p>
<p id="p-0053" num="0057"><figref idref="DRAWINGS">FIG. 9</figref> is a flow chart of the various operations involved in an exemplary forward-looking scheduler mechanism of the present invention. A determination is made if a BHP indicates arrival of a future burst that is longer than the system's burst delay parameter (block <b>902</b>). If so, that burst is ignored for purposes of scheduling an output channel (block <b>904</b>). Another determination is made if kickback in delay buffers is possible for any packet (i.e., their indications) (block <b>906</b>). If kickback is not possible, packet indication assignment is dropped in the scheduler's memory allocation space (block <b>908</b>). On the other hand, if kickback is allowed, packet indications may be mapped to different assignments in subsequent time slots (block <b>910</b>). If all available delay buffers have been exhausted and no data channel assignment is possible (block <b>912</b>), a packet drop policy may be applied as described above (block <b>914</b>). Otherwise, packet indications regarding future packets are assigned to output port channels based on an arbitration/counter mechanism, on a slot-by-slot basis (block <b>916</b>) Where per-slot arbitration is utilized for resolving the BHP requests, a variety of schemes may be implemented including, e.g., Round-Robin Arbitration (RRA), Binary Tree Arbitration (BTA), Prioritized BTA, Look-Up Table Arbitration, and other modifications described in the following commonly owned co-pending patent application(s): (i) “Multiserver Scheduling System And Method For A Fast Switching Element,” application Ser. No. 10/059,641, filed Jan. 28, 2002, in the names of: Prasad Golla, Gerard Damm, John Blanton, Mei Yang, Dominique Verchere, Hakki Candan Cankaya, and Yijun Xiong; (ii) “Look-Up Table Arbitration System And Method For A Fast Switching Element,” application Ser. No. 10/075,176, filed Feb. 14, 2002, in the names of: Prasad Golla, Gerard Damm, John Blanton, and Dominique Verchere; and (iii) “Binary Tree Arbitration System And Method,” application Ser. No. 10/109,423, filed Mar. 28, 2002, in the names of: Prasad Golla, Gerard Damm, Timucin Ozugur, John Blanton, and Dominique Verchere, which is (are) hereby incorporated by reference.</p>
<p id="p-0054" num="0058">Implementational aspects of an exemplary forward-looking scheduler mechanism of the present invention are set forth as below. First, output data channels are mapped to a memory block (i.e., a mapped-memory structure) associated with the scheduler, wherein the memory can comprise any conventional type, e.g., non-volatile RAM, EPROM, Flash memory, and the like. Each data channel is mapped to a plurality of memory locations that are organized into a number of sections corresponding to a predetermined number of future time slots (i.e., the “look-ahead horizon”). The memory-mapped channels are also organized on per-port basis. A corresponding number of “arbiters” (including mechanisms that involve request-grant-accept (RGA) or request-grant (RG) arbitrations as well as mechanisms employing simple counting) are provisioned such that each future time slot of an output port is associated with an arbiter that computes or otherwise determines assignment of future data packets with respect to that particular slot/port combination. In other words, a determination is made with respect to each future time slot, based on the control information received via the BHPs, as to which future data packets can be sent on which output data channels. As explained in detail hereinabove, packet indications relating to the allocated future data packets are stored in appropriate memory locations on per-channel and per-slot basis to provide a slot-by-slot channel assignment map. As the current time slot of the switching matrix is incremented, a corresponding channel assignment map is forwarded to the matrix for transmitting data packets on output data channels in accordance with the map. In a further variation, delay buffer mapping may also be included as described above.</p>
<p id="p-0055" num="0059">The forward-looking scheduling mechanism of the present invention can be practiced with multicast service as well. <figref idref="DRAWINGS">FIG. 10</figref> depicts an exemplary channel-reservation-based multicast scheduling scheme <b>1000</b> provided in accordance with the teachings of the present invention. Based on the control information (i.e., multicast bit, group bit and destination port list information) provided in a BHP <b>1006</b> corresponding to a 3-packet data burst <b>1002</b>, the packet indications relating to the three packets are assigned to a 3-slot window associated with each destination port's memory map. Reference numerals <b>1004</b>-<b>1</b> to <b>1004</b>-<b>3</b> refer to the three data packets of the burst <b>1002</b>, whose indications are assigned slot-by-slot with respect to a plurality of output ports <b>1010</b>-<b>1</b> to <b>1010</b>-N in 3-slot windows <b>1008</b>-<b>1</b> to <b>1008</b>-N associated therewith. Data channels of the output ports are memory-mapped as described hereinabove. Accordingly, slot-based memory map channels <b>1011</b>-<b>1</b> to <b>1011</b>-N correspond to the N output ports, wherein the package indications can be assigned based on the BHP requests. In a multicast service, the package indications are allocated on a per-port basis and, as a consequence, the package indication assignments may not be identical across the ports, as illustrated in this FIG. Moreover, the package indications for a destination port may be partially buffered for the slot window associated therewith.</p>
<p id="p-0056" num="0060">Based on the foregoing, those skilled in the art should appreciate that the present invention provides an innovative scheduling mechanism operable with a burst switching environment wherein stringent buffering capacity and packet drop conditions are typically encountered. By processing data packets in accordance with the scheduling principles set forth in this patent application, not only are the switch resources judiciously conserved but the throughput is maintained with minimal packet loss as well. In a further aspect, the forward-looking scheduling mechanism of the present invention provides a more advanced implementation that determines packet forwarding strategies based on the advance control information received on control channels.</p>
<p id="p-0057" num="0061">It is believed that the operation and construction of the present invention will be apparent from the Detailed Description set forth hereinabove. While the exemplary embodiments of the invention shown and described have been characterized as being preferred, it should be readily understood that various changes and modifications could be made therein without departing from the scope of the present invention as set forth in the following claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A scheduling method for use with a switch element operating to switch at least one input data channel of an input port to an output port, said at least one input data channel including data bursts of a plurality of packets each, comprising the steps:
<claim-text>for each time slot associated with said switch element, determining whether a buffer structure provided with said switch element contains previously received data packets that can be transmitted from said output port on an output data channel;</claim-text>
<claim-text>if so, forwarding said previously received data packets for transmission on said output data channel;</claim-text>
<claim-text>determining whether a currently received data packet on said at least one input data channel is part of a data burst previously accepted by said switch element for transmission;</claim-text>
<claim-text>if so, processing said currently received data packet on said at least one input data channel;</claim-text>
<claim-text>determining whether a currently received initial data packet of a new data burst on said at least one input data channel can be processed for scheduling by said switch element; and</claim-text>
<claim-text>if so, processing said currently received initial data packet for scheduling by said switch element.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The scheduling method for use with a switch element as set forth in <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step of applying a packet drop policy with respect to at least one of said currently received data packet and said currently received initial data packet if said switch element is unable to process said data packets.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The scheduling method for use with a switch element as set forth in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said step of processing said currently received data packet on said at least one input data channel comprises forwarding said currently received data packet for transmission on an output data channel associated with said output port.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The scheduling method for use with a switch element as set forth in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said step of processing said currently received data packet on said at least one input data channel comprises storing said currently received data packet in said buffer structure.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The scheduling method for use with a switch element as set forth in <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein said buffer structure is associated with said input port.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The scheduling method for use with a switch element as set forth in <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein said buffer structure is associated with said output port.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The scheduling method for use with a switch element as set forth in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said step of processing said currently received initial data packet of a new data burst on said at least one input data channel comprises forwarding said currently received initial data packet for transmission on an output data channel associated with said output port.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The scheduling method for use with a switch element as set forth in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said step of processing said currently received initial data packet of a new data burst on said at least one input data channel comprises storing said currently received initial data packet in said buffer structure.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The scheduling method for use with a switch element as set forth in <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said buffer structure is associated with at least one of said input port and said output port.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The scheduling method for use with a switch element as set forth in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said previously received data packets contained in said buffer structure are forwarded based on a numerical sequential order established for a plurality of buffer elements that form said buffer structure.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A scheduling system for use with a switch element operating to switch at least one input data channel of an input port to an output port, said at least one input data channel including data bursts of a plurality of packets each, said system comprising:
<claim-text>means for forwarding data packets that are stored in a buffer structure provided with said switch element upon determining that there exists an output data channel available on said output port for transmitting said data packets;</claim-text>
<claim-text>means for processing a currently received data packet on said at least one input data channel upon determining that said currently received data packet is part of a data burst previously accepted by said switch element for processing; and</claim-text>
<claim-text>means for processing a currently received initial data packet of a new data burst upon determining that said currently received initial data packet of a new data burst can be processed for scheduling by said switch element.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The scheduling system for use with a switch element as set forth in <claim-ref idref="CLM-00011">claim 11</claim-ref>, further including means for applying a packet drop policy with respect to at least one of said currently received data packet and said currently received initial data packet if said switch element is unable to process said data packets.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The scheduling system for use with a switch element as set forth in <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein said means for processing said currently received data packet on said at least one input data channel comprises means for forwarding said currently received data packet for transmission on an output data channel associated with said output port.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The scheduling system for use with a switch element as set forth in <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein said means for processing said currently received data packet on said at least one input data channel comprises means for determining whether said currently received data packet needs to be stored in said buffer structure.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The scheduling system for use with a switch element as set forth in <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein said buffer structure is associated with said input port.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The scheduling system for use with a switch element as set forth in <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein said buffer structure is associated with said output port.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The scheduling system for use with a switch element as set forth in <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein said means for processing said currently received initial data packet of a new data burst comprises means for forwarding said currently received initial data packet for transmission on an output data channel associated with said output port.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The scheduling system for use with a switch element as set forth in <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein said means for processing said currently received initial data packet of a new data burst comprises means for determining whether said currently received initial data packet needs to be stored in said buffer structure.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The scheduling system for use with a switch element as set forth in <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein said buffer structure is associated with at least one of said input port and said output port.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The scheduling system for use with a switch element as set forth in <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein said data packets stored in said buffer structure are forwarded based on a numerical sequential order established for a plurality of buffer elements that form said buffer structure.</claim-text>
</claim>
</claims>
</us-patent-grant>
