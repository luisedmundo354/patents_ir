<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298884-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298884</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11054090</doc-number>
<date>20050209</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>FR</country>
<doc-number>04 05524</doc-number>
<date>20040521</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>276</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>62</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382132</main-classification>
<further-classification>382224</further-classification>
<further-classification>378 37</further-classification>
</classification-national>
<invention-title id="d0e71">Method and apparatus for classification of pixels in medical imaging</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5003979</doc-number>
<kind>A</kind>
<name>Merickel et al.</name>
<date>19910400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5133020</doc-number>
<kind>A</kind>
<name>Giger et al.</name>
<date>19920700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382128</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5544219</doc-number>
<kind>A</kind>
<name>Muller et al.</name>
<date>19960800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>378210</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5579360</doc-number>
<kind>A</kind>
<name>Abdel-Mottaleb</name>
<date>19961100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>378 37</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5832103</doc-number>
<kind>A</kind>
<name>Giger et al.</name>
<date>19981100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5984870</doc-number>
<kind>A</kind>
<name>Giger et al.</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600443</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6058322</doc-number>
<kind>A</kind>
<name>Nishikawa et al.</name>
<date>20000500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600408</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6246782</doc-number>
<kind>B1</kind>
<name>Shapiro et al.</name>
<date>20010600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382128</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6317617</doc-number>
<kind>B1</kind>
<name>Gilhuijs et al.</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600408</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6427082</doc-number>
<kind>B1</kind>
<name>Modell et al.</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6970587</doc-number>
<kind>B1</kind>
<name>Rogers</name>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382132</main-classification></classification-national>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2002/0003861</doc-number>
<kind>A1</kind>
<name>Rick et al.</name>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>378 9812</main-classification></classification-national>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2002/0159565</doc-number>
<kind>A1</kind>
<name>Muller et al.</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>2002/0165837</doc-number>
<kind>A1</kind>
<name>Zhang et al.</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>706 16</main-classification></classification-national>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>2003/0194050</doc-number>
<kind>A1</kind>
<name>Abdalmajeid</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>2003/0194121</doc-number>
<kind>A1</kind>
<name>Abdalmajeid</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>2003/0231790</doc-number>
<kind>A1</kind>
<name>Bottema</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382128</main-classification></classification-national>
</citation>
<citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>2005/0027188</doc-number>
<kind>A1</kind>
<name>Metaxas et al.</name>
<date>20050200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600410</main-classification></classification-national>
</citation>
<citation>
<patcit num="00019">
<document-id>
<country>WO</country>
<doc-number>WO 00/05677</doc-number>
<kind>A</kind>
<date>20000200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00020">
<othercit>Marx, C., et al., Contrast-enhanced digital mammography (CDEM): phantom experiment and first clinical results, Proc. SPIE, vol. 4682, pp. 174-181, 2002.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>25</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>2</number-of-drawing-sheets>
<number-of-figures>4</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20050259857</doc-number>
<kind>A1</kind>
<date>20051124</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Jeunehomme</last-name>
<first-name>Fanny</first-name>
<address>
<city>Versailles</city>
<country>FR</country>
</address>
</addressbook>
<nationality>
<country>FR</country>
</nationality>
<residence>
<country>FR</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Muller</last-name>
<first-name>Serge</first-name>
<address>
<city>Guyancourt</city>
<country>FR</country>
</address>
</addressbook>
<nationality>
<country>FR</country>
</nationality>
<residence>
<country>FR</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Iordache</last-name>
<first-name>Razvan</first-name>
<address>
<city>Paris</city>
<country>FR</country>
</address>
</addressbook>
<nationality>
<country>FR</country>
</nationality>
<residence>
<country>FR</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Cantor Colburn LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>General Electric Company</orgname>
<role>02</role>
<address>
<city>Schenectady</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Werner</last-name>
<first-name>Brian P.</first-name>
<department>2624</department>
</primary-examiner>
<assistant-examiner>
<last-name>Park</last-name>
<first-name>Edward</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An apparatus and method for medical imaging, particularly for mammography, wherein a body organ, such as a breast, is exposed to X-rays and the X-rays are collected after attenuation through the object. The recorded attenuations are processed and displaying a result of this processing in the form of a representation of an image of the object. The processing of the recorded attenuations form includes automatic classification of zones of the breast into pathological or non-pathological classes. The automatic classification takes into account at least one classification input into the apparatus in advance in association with data that can be collected by the apparatus, and using this prior classification as a reference in order to produce a classification of the same type if there is similarity between the collected data and the data associated with this reference classification.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="69.26mm" wi="110.07mm" file="US07298884-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="175.94mm" wi="115.06mm" file="US07298884-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="191.43mm" wi="132.33mm" file="US07298884-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application claims the benefit of a priority under 35 USC 119(a)-(d) to-French Patent Application 04 05524 filed May 21, 2004, the entire contents of which are hereby incorporated by reference.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">An embodiment of the invention relates to a method and apparatus for medical imaging and in particular to a method and apparatus for the classification of pixels in medical imaging. An embodiment of the invention relates to Contrast Medium-enhanced Mammography (CMM) by X-rays and the injection of a contrast medium.</p>
<p id="p-0004" num="0003">Mammography is medical imaging intended particularly for the detection of tumors by examination of successive images taken to reveal the variation with time of impregnation of the contrast medium and its gradual disappearance. In mammography the contrast medium tends to attenuate X-rays significantly more than a non-impregnated tissue, and thus reveals particularly vascularised zones such as tumors. But the variation of contrast within the breast itself provides an important indication about whether or not tumors are present, by the rate at which this contrast appears and disappears.</p>
<p id="p-0005" num="0004">At present, contrast medium-enhanced mammography is practiced within the context of MRI, a technique that comprises making molecules composing the examined organ vibrate. Within this context, the variation of contrast in the breast is displayed on the screen in the form of a sequence of images that the practitioner interprets based on experience, as revealing or not revealing the presence of a tumor.</p>
<p id="p-0006" num="0005">Marx et al., “Contrast-enhanced digital mammography (CEDM): phantom experiment and first clinical results”, Proc. SPIE—International Soc. for Optical Engineering, vol. 4682, pp. 174-181, 2002, proposes to produce maps representing the distribution of some parameters in the breast. These parameters are measurements illustrating some kinetic aspects of contrast variation obtained from a sequence of X-ray images.</p>
<p id="p-0007" num="0006">However, the diagnosis work to be done by the practitioner is still considerable.</p>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE INVENTION</heading>
<p id="p-0008" num="0007">According to an embodiment of the invention, an apparatus comprises means for exposing an object, such as a body organ, e.g., the breast, to a source of radiation, such as an X-ray beam; means for collecting the radiation after attenuation through the object; means for processing recorded attenuations and means for displaying the result of this processing in the form of a representation on an image of the object. The means for processing the recorded attenuations form means for automatic classification of zones of the object into pathological classes The means for automatic classification is suitable for taking account of at least one classification input into the apparatus in advance in association with data that can be collected by the apparatus, and using this prior classification as a reference in order to produce a classification of the same type if there is similarity between the collected data and the data associated with this reference classification.</p>
<p id="p-0009" num="0008">An embodiment of the invention is a method for medical imaging, particularly for mammography, comprising exposing an object, such as a body organ, e.g., a breast, to radiation; collecting the radiation after attenuation through the object; processing recorded attenuations and displaying the result of this processing in the form of a representation on an image of the breast, the processing of the recorded attenuations comprises automatically classifying zones of the object into pathological classes, the automatic classification taking into account at least one prior classification input in association with data that can is collected, and using this prior classification as a reference in order to produce a classification of the same type if there is similarity between the collected data and the data associated with this reference classification.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0010" num="0009">Other characteristics, purposes and advantages of the invention will become clear after reading the detailed description given below with reference to the attached figures among which:</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 1</figref> shows a time axis representing different instants at which images are taken during impregnation/deimpregnation of a contrast medium;</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 2</figref> shows the variation of a grey level measured during impregnation/deimpregnation of a breast by the contrast medium;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram showing a distribution of points in a several dimensional space used for identification of a classification of a local zone of the breast; and</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 4</figref> is a time axis illustrating the use of two photos with two different energies in an embodiment of the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0015" num="0014">An embodiment of the invention is to improve the way in which the practitioner is assisted in using X-rays for contrast medium enhanced mammography, in diagnosing the presence of a particular pathology, and particularly for identification of the presence of malignant tumors</p>
<p id="p-0016" num="0015">In this description, the term “grey level” will denote a value representing as possible the attenuation recorded in the presence of the contrast medium. In practice, these values are obtained after application of a logarithm to the attenuation actually recorded, since in the known manner the attenuation induced by the presence of a contrast medium, typically a product containing iodine, is exponential to the local concentration of the product. The logarithm thus applied outputs a value approximately proportional to the attenuation due to the product containing iodine after passing through the breast, in other words the thickness actually impregnated by the product containing iodine.</p>
<p id="p-0017" num="0016">In a first variant, each point on the image (or pixel) of the examined breast is associated with a vector in n dimensions, in which each dimension corresponds to a different observation instant of this same pixel. In other words, this vector associated with each pixel represents the rate at which the contrast appears in this particular pixel.</p>
<p id="p-0018" num="0017">Thus, for each point located at the same location in each successive image during impregnation/disappearance of the contract medium, there is a vector X<sub>i,j </sub>associated with this point for which each of the components G<sub>n</sub>(i,j) correspond to the grey level recorded at each successive instant. N is the number of successive sequences, and i,j are the coordinates of the same pixel in each successive image in the sequence of images.</p>
<p id="p-0019" num="0018">The result is thus a vector X<sub>i,j </sub>defined as follows:</p>
<p id="p-0020" num="0019">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mrow>
  <msub>
    <mi>X</mi>
    <mrow>
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
    </mrow>
  </msub>
  <mo>=</mo>
  <mrow>
    <mo>{</mo>
    <mtable>
      <mtr>
        <mtd>
          <mrow>
            <msub>
              <mi>G</mi>
              <mn>1</mn>
            </msub>
            <mo>⁡</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>i</mi>
                <mo>,</mo>
                <mi>j</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mtd>
      </mtr>
      <mtr>
        <mtd>
          <mrow>
            <mi>⋮</mi>
            <mo>⁢</mo>
            <mstyle>
              <mspace width="0.8em" height="0.8ex"/>
            </mstyle>
            <mo>⁢</mo>
            <mn>10</mn>
          </mrow>
        </mtd>
      </mtr>
      <mtr>
        <mtd>
          <mrow>
            <msub>
              <mi>G</mi>
              <mi>n</mi>
            </msub>
            <mo>⁡</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>i</mi>
                <mo>,</mo>
                <mi>j</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mtd>
      </mtr>
    </mtable>
    <mo>}</mo>
  </mrow>
</mrow>
</math>
</maths>
</p>
<p id="p-0021" num="0020">Therefore the coefficients of this vector are distributed from G<sub>1 </sub>to G<sub>n</sub>(i,j) and are representative of grey levels obtained in instants t<sub>1 </sub>to t<sub>n</sub>.</p>
<p id="p-0022" num="0021">The first variant uses these vectors X<sub>i,j </sub>to identify a similarity between them and vectors representing a typical variation in contrast with time in the presence of a specific pathology. More generally, the objective is to sort the different vectors corresponding to different points into classes that could reveal the existence of some pathologies.</p>
<p id="p-0023" num="0022">In one embodiment, these various vectors are classified into four categories. A first category comprises vectors that could reveal the presence of a malignant tumor at the pixel i,j considered. A second category comprises the vectors that could indicate the presence of a benign tumor at the pixel i,j considered. A third category comprises vectors that could indicate the presence of healthy tissue (parenchyma) at the pixel i,j considered. A fourth category comprises vectors that could indicate the presence of a blood vessel at the pixel i,j considered.</p>
<p id="p-0024" num="0023">In another embodiment, with the purpose of detecting tumors, the first and second classification categories (malignant tumors and benign tumors) may be coincident.</p>
<p id="p-0025" num="0024">The various categories may also be distributed into vessels, tumors, and normal tissue, for detection purposes.</p>
<p id="p-0026" num="0025">The following processing can be applied in order to determine which of these categories is applicable.</p>
<p id="p-0027" num="0026">Each vector may be considered to belong to an n dimensional space, in which each dimension represents a given instant. The position of the point according to this dimension then represents the value of the grey level observed at the instant corresponding to this dimension. This type of space is shown in <figref idref="DRAWINGS">FIG. 3</figref>, in two dimensions to simplify the illustration. Therefore, these two dimensions correspond to two images at two different instants. A vector X<sub>i,j </sub>will be located on a median at 45° if the values of the grey levels are the same at instants t<sub>1 </sub>and t<sub>2</sub>.</p>
<p id="p-0028" num="0027">In this case, the instant t<sub>1 </sub>was an image instant at which no contrast medium had yet been impregnated in the breast, and it can be understood that the point would belong to, the oblique line at 45° if the contrast medium were not present at instant t<sub>2 </sub>either. These points located on the oblique may also be located on zones of the breast in which vascularization is observed to be negligible or non-existent. The points thus positioned are classified as “parenchyma” in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0029" num="0028">Thus, <figref idref="DRAWINGS">FIG. 2</figref> shows the variation in the grey level as a function of time, depending on whether the point at which this grey level is observed forms part of a common tissue (parenchyma), a vessel, a malignant tumor or a benign tumor:</p>
<p id="p-0030" num="0029">On the other hand, a vector X<sub>i,j </sub>will be positioned further above this oblique when the impregnation at time t<sub>2 </sub>is greater.</p>
<p id="p-0031" num="0030">Two oblique bands <b>10</b> and <b>20</b> are shown, one band <b>10</b> close to the median passing through the origin, and the other <b>20</b> further towards the top. Therefore, the low band <b>10</b> represents a location in the breast in which the impregnation at time t<sub>2 </sub>is relatively low. Therefore, the highest band <b>20</b> represents locations within the breast at which impregnation are already very high at time t<sub>2</sub>.</p>
<p id="p-0032" num="0031">It is considered that points with low impregnation at time t<sub>2 </sub>(low band <b>10</b>) correspond to the presence of a tumor, while points with high impregnation at time t<sub>2 </sub>(high band <b>20</b>) correspond to the presence of a vessel at the point considered.</p>
<p id="p-0033" num="0032">It should be noted now that it is known that malignant lesions/tumors cause a very fast increase in the contrast, followed by a constant period, and then fast disappearance of the contrast. It should be noted also that benign lesions/tumors are marked by a gradual increase in the contrast. It should be noted also that vessels are obviously affected by fast contrast variations. Other tissues are less sensitive to contrast variations.</p>
<p id="p-0034" num="0033">When considering a number n of successive images, the same processing is performed but this time in a space with n dimensions. The zones corresponding to the different classification categories are then zones in this space with n dimensions.</p>
<p id="p-0035" num="0034">In one embodiment, the vectors thus localized on particular classification zones are preferably vectors obtained after preprocessing. One desirable preprocessing comprises subtracting using an initial vector corresponding to an image taken without the presence of a contrast medium (this initial image is called the mask). For example, another type of preprocessing may comprise noise elimination filtering.</p>
<p id="p-0036" num="0035">The classification may also be made on normalized data to compare image sequences acquired under different conditions. Data may be normalized to compensate for radiation conditions at different energies. Data may also be normalized to compensate for a variable breast thickness.</p>
<p id="p-0037" num="0036">Additional components may also be provided in the vector, such as the number of sign changes in recorded grey levels during the image sequence, or such as the patient's age, weight or any other data related to the patient's medical history. This data is also integrated in the n dimensional space, each time in the form of an additional dimension subsequently used for determining classifications.</p>
<p id="p-0038" num="0037">In one variant, the vector X<sub>i,j </sub>also includes the coordinates of the pixel considered in space. This embodiment can avoid incoherent classification variations such as sudden classification changes in nearby pixels.</p>
<p id="p-0039" num="0038">In another embodiment, the dimensions of the classification space do not necessarily correspond to a sequence of measurement instants. Each dimension is dedicated to positioning in this space of a value of a kinetic parameter calculated on the contrast variation. Thus, one of the dimensions can be dedicated to the maximum recorded value of the slope while determining the contrast at the pixel considered. Another dimension can represent the maximum value of the contrast recorded at the same pixel considered. Another dimension can represent the hold duration of the maximum contrast at the same pixel considered.</p>
<p id="p-0040" num="0039">In this variant, the m parameters thus represented in the n dimensional space can easily be compared with data from previous sequences of images, including when these images were taken at different times, in other words at different number of times t<sub>1 </sub>. . . t<sub>n </sub>or with a variable distribution in time.</p>
<p id="p-0041" num="0040">Thus, <figref idref="DRAWINGS">FIG. 1</figref> shows two image sequences (corresponding to the upper triangles and the lower triangles respectively) that can be compared more easily because these kinetic parameters have been produced, although the images were not taken at the same instants.</p>
<p id="p-0042" num="0041">According to a second embodiment of the invention, the space in which the vectors X<sub>i,j </sub>are shown is a two dimensional space, in which these two dimensions correspond to different radiation energies used at different times or at the same time. In this variant, the two instants are preferably very close to each other, in other words in practice as close as possible.</p>
<p id="p-0043" num="0042">This embodiment provoked a contrast difference between these two images, due either to a different reaction of the same dose of the contrast medium facing two different radiation energies. For example, one of the radiations is located at about 25 to 35 keV, while the other is about 40 to 49 keV. Thus advantage is taken that a contrast medium, typically a product containing iodine, has a capacity to attenuate X-rays that varies as a function of the energy in the rays passing through it.</p>
<p id="p-0044" num="0043">It is known that the attenuation coefficient p varies as a function of the energy of the X-rays according to a variation law by which the value of μ suddenly changes at a precisely determined energy, this sudden change currently being called the K-edge. Thus, when the two energies are located on the opposite sides of this K-edge, the difference in contrast is particular high between the two acquisitions.</p>
<p id="p-0045" num="0044">Consequently, at pixels in a position corresponding to a strong presence of a substance containing iodine, the contrast will be sensitive to the variation of energy between the two images. On the other hand, zones without this impregnation will only have a small reactivity to the energy variation.</p>
<p id="p-0046" num="0045">These two acquisitions, preferably very close, are more generally made at an optimum instant for observing such contrasts and their differences, after the injection of the contrast medium. Thus in this approach, the kinetic acquisition is replaced by a double energy acquisition, the two images being acquired at different radiation spectra (and therefore at different energies). One of the spectra advantageously corresponds to a normal energy level for a conventional mammographic examination, the other spectrum for example being a spectrum typically used in the context of an enhanced contrast method.</p>
<p id="p-0047" num="0046">The contrast for pixels with a low impregnation will be similar at times t<sub>1</sub>, and t<sub>2</sub>, and will produce vectors X<sub>i,j </sub>close to the oblique at 45° passing through the origin. Pixels i, j with strong impregnation will correspond to vectors X<sub>i,j </sub>well above the oblique.</p>
<p id="p-0048" num="0047">The variable height position of the vectors X<sub>i,j </sub>makes it possible to classify them in different zones depending on the classification category mentioned above to which they belong, if any. Consequently, images taken at instants t<sub>1 </sub>and t<sub>2 </sub>within the kinetic of the impregnation/deimpregnation reaction are particularly revealing of the different categories.</p>
<p id="p-0049" num="0048">In the above, we described the application of two radiations at different energies chosen to be on each side of the sudden change in the attenuation coefficient. However, this approach is also possible even if the two energies are not on opposite sides of the K-edge. Thus, a contrast difference can also be used when it is due to the continuous variation of the attenuation coefficient as a function of the radiation energy, in other words when the two energies chosen are located in the typical part of the variation of the attenuation coefficient, and not on opposite sides of the K-edge.</p>
<p id="p-0050" num="0049">Double energy acquisitions may be carried out many times while the contrast is increasing/reducing, and be analyzed in a space with 2n dimensions like the spaces mentioned above. Recommendations for spatial consistency, the use of data applicable to the patient, pre-processing of vectors, normalization of data, use of kinetic parameters derived from the variation in contrast differences, may also be applicable in this “double energy” variant.</p>
<p id="p-0051" num="0050">We will now describe the operation of a means for processing capable of making the classification in one of the spaces with two dimensions or n dimensions described above. This means for processing are means capable of acquiring reference data used subsequently for automatic production of the classification. To achieve this, this means (apart from conventional data processing equipment) could implement a network of neurons or a machine with support vectors. This means will use initial information input into the system as a reference result. This information is defined as reference information preferably contains vectors X<sub>i,j </sub>like those defined above that can be used in the classification space with n or with m dimensions. Therefore, mean for classification are intended to be able to input vectors that can be used according to any one of the disclosed embodiments, and take account in the device of the fact that these input vectors correspond to a pixel belonging to one of the classification categories.</p>
<p id="p-0052" num="0051">A first operating mode comprises learning or training in the means for processing by inputting a collection of test data with predefined and associated classifications, in a preliminary phase. Thus, in a first embodiment, there are distinct implementation steps for the apparatus and method performed at different times. One step comprises acquisition of learning data. Another step is how to use the apparatus, in other words, application of learning acquired on specific acquisitions.</p>
<p id="p-0053" num="0052">In the variant in which the means for processing use vectors comprising successive grey levels, the training vectors will comprise a series of successive grey levels at the pixels considered. Each of these vectors is associated with the data according to which the corresponding pixel belongs to one of the classification categories, in a predefined manner.</p>
<p id="p-0054" num="0053">A vector encountered afterwards will be categorized as belonging to the same class as one of the reference vectors if it is similar to this reference vector, for example, at a distance less than a predetermined threshold in the n dimensional space.</p>
<p id="p-0055" num="0054">The same approach will be applied in the case in which the vector comprises kinetic parameters derived from successive grey levels, in other words, parameters such as the slope or the maximum grey level.</p>
<p id="p-0056" num="0055">This learning is also applicable in the case of vectors representing double energy images. The reference vectors (in this case learning vectors) include the results of two contrast readings with different energy for examinations carried out later and the classification results assigned by a visual diagnosis made on these readings by a practitioner or by a laboratory analysis.</p>
<p id="p-0057" num="0056">According to one variant, means for automatically establishing a classification of zones encountered are provided, while remaining under the guidance of the practitioner. In this approach, the means for processing displays the sequence of images produced. The practitioner examines the sequence of images and identifies at least one zone representative of each class, by experience. The means for processing uses these manual identifications to compare the remainder of the image with the zones thus classified. If the image sequence reveals other zones that appear similar to those identified by the practitioner, then the method and apparatus classifies these zones in the same categories that the practitioner selected for the zones used as reference.</p>
<p id="p-0058" num="0057">This similarity is identified in the same way as described above, using vectors associated with pixels identified by the practitioner as reference data. The method and apparatus displays the zones considered as being similar and submits this result to the practitioner. In this case, the reference data defining the classes are at least partly defined directly by the practitioner.</p>
<p id="p-0059" num="0058">In another operating mode, the method and apparatus combined the two approaches mentioned above. In this case, the means for processing makes automatic classification starting from a learning done earlier. The result is displayed on the screen in the form of a map identifying the different zones corresponding to the different classes. In a further step, the user confirms or contradicts the classification made on these different zones. The means for processing takes into account this confirmation or contradiction made by the practitioner. The method and apparatus integrates data learned earlier and the information comprising data reclassified by the practitioner, when a new automatic classification is necessary.</p>
<p id="p-0060" num="0059">The processing may then be repeated on the same sequence starting from the learning thus updated. In other words, the means for learning means is reactivated after a first automatic classification to include additional learning data like those introduced by the practitioner in the form of confirmations or contradictions of the first result.</p>
<p id="p-0061" num="0060">The various means described above, for which a classification will be automatically output, may for example be used under the control of software capable of carrying out the various processing steps when it is implemented on an appropriate processor.</p>
<p id="p-0062" num="0061">Obviously, the various arrangements or processing described above, and others comprising improvements thereof, can be combined differently in each of the disclosed embodiments to achieve the same result.</p>
<p id="p-0063" num="0062">One skilled in the art may make or propose various modifications to the structure/way and/or function and/or results and/or steps of the disclosed embodiments and equivalents thereof without departing from the scope and extant of the invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US07298884-20071120-M00001.NB">
<img id="EMI-M00001" he="11.68mm" wi="76.20mm" file="US07298884-20071120-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An apparatus for medical imaging comprising:
<claim-text>means for exposing an object to radiation;</claim-text>
<claim-text>means for collecting the radiation after attenuation through the object;</claim-text>
<claim-text>means for processing recorded attenuations; and</claim-text>
<claim-text>means for displaying a result of the processing in the form of a representation on an image of the object;</claim-text>
<claim-text>wherein the means for processing the recorded attenuations forms means for automatic classification of zones of the object into pathological or non-pathological classes, the means for automatic classification taking account of at least one classification input into the apparatus in advance in association with data that can be collected by the apparatus, and using this prior classification as a reference in order to produce a classification of the same type if there is similarity between the collected data and the data associated with this reference classification; and</claim-text>
<claim-text>wherein the means for automatic classification makes a classification of pixels of an image of the object at the same location in a several dimensional space, the dimensions of this space each corresponding to the value of a grey level at a given instant of a contrast appearance rate at the pixel considered.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the several dimensional space further comprises dimensions that each represent a parameter among the maximum slope of a contrast variation, the value of a maximum contrast reached, a hold duration of the contrast at its maximum value, at the pixel considered.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref> wherein the several dimensional space further comprises at least two dimensions that each represent the measured signal for two different radiation energies at the pixel considered.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the several dimensional space further comprises at least two dimensions that each represent the measured signal for two different radiation energies at the pixel considered.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref> wherein the two different radiation energies are located on opposites sides of a sudden change in an attenuation coefficient of a contrast medium.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the means for automatic classification takes account of at least one manual classification of a current image zone of the object as reference classification; and
<claim-text>automatically establishes the same classification in case of similarity with other data collected on the same object.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the means for automatic classification includes means for learning; and
<claim-text>carrying out recording a collection of reference information comprising several reference classifications associated with data that can be collected by the apparatus.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> comprising:
<claim-text>means for enabling a user to confirm or contradict an automatic classification made by the apparatus; and</claim-text>
<claim-text>means for taking account of this confirmation or contradiction in order to incorporate the results of this confirmation or contradiction as a reference classification.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the means for classification identifies incoherent spatial variations in the classification, and modifying the classification of some locations in case of such incoherent spatial variations.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> comprising means for accounting of one item of data among the number of changes in the sign of the variation in grey levels, the age of the object, weight or medical data, when creating a classification.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the means for automatic classification records a vector corresponding to each pixel location in the image of the object, each vector comprising the dimensions of the several dimensional space that correspond to grey levels of the pixel at different times that correspond to an appearance and disappearance of a contrast medium.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. A method for medical imaging comprising:
<claim-text>exposing an object to radiation;</claim-text>
<claim-text>collecting the radiation after attenuation through the object;</claim-text>
<claim-text>processing recorded attenuations comprising automatic classifying of zones of the object into pathological or non-pathological classes, the automatic classification taking account of at least one classification input in advance in association with data that can be collected, and using this prior classification as a reference in order to produce a classification of the same type if there is similarity between the collected data and the data associated with this reference classification; and</claim-text>
<claim-text>displaying a result of the processing in the form of a representation on an image of the object the process;</claim-text>
<claim-text>wherein the automatic classification makes a classification of pixels of the image of the object at the same location in a several dimensional space, the dimensions of this space each corresponding to the value of a grey level at a given instant of a contrast appearance rate at the pixel considered.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein the several dimensional space further comprises dimensions that each represent a parameter among the maximum slope of a contrast variation, the value of a maximum contrast reached, a hold duration of the contrast at its maximum value, at the pixel considered.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref> wherein the several dimensional space further comprises at least two dimensions that each represent the measured signal for two different radiation energies at the pixel considered.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein the several dimensional space further comprises at least two dimensions that each represent the measured signal for two different radiation energies at the pixel considered.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method according to <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the two different radiation energies are located on opposites sides of a sudden change in an attenuation coefficient of a contrast medium.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein the automatic classification takes account of at least one manual classification of a current image zone of the object as reference classification; and
<claim-text>automatically establishes the same classification in case of similarity with other data collected on the same object.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein the automatic classification includes learning; and
<claim-text>carrying out recording a collection of reference information comprising several reference classifications associated with data that can be collected by the apparatus.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> comprising:
<claim-text>enabling a user to confirm or contradict an automatic classification; and</claim-text>
<claim-text>taking into account of this confirmation or contradiction in order to incorporate the results of this confirmation or contradiction as a reference classification.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein the classification identifies incoherent spatial variations in the classification, and modifying the classification of some locations in case of such incoherent spatial variations.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> comprising:
<claim-text>accounting for one item of data among the number of changes in the sign of the variation in grey levels, the age of the object, weight or medical data, when creating a classification.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. A computer program product comprising a computer readable medium having computer readable program code means embodied in the medium, the computer readable program code means implementing the method according to <claim-ref idref="CLM-00012">claim 12</claim-ref>.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. An article of manufacture for use with a computer system, the article of manufacture comprising a computer readable medium having computer readable program code means embodied in the medium, the program code means implementing of the method according to <claim-ref idref="CLM-00012">claim 12</claim-ref>.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. A program storage device readable by a computer tangibly embodying a program of instructions executable by the computer to perform the method according to <claim-ref idref="CLM-00012">claim 12</claim-ref>.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein the automatic classification records a vector corresponding to each pixel location in the image of the object, each vector comprising the dimensions of the several dimensional space that correspond to grey levels of the pixel at different times that correspond to an appearance and disappearance of a contrast medium.</claim-text>
</claim>
</claims>
</us-patent-grant>
