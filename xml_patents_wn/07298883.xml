<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298883-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298883</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10724395</doc-number>
<date>20031201</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>635</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382132</main-classification>
<further-classification>382170</further-classification>
<further-classification>382190</further-classification>
<further-classification>600443</further-classification>
</classification-national>
<invention-title id="d0e53">Automated method and system for advanced non-parametric classification of medical images and lesions</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5657362</doc-number>
<kind>A</kind>
<name>Giger et al.</name>
<date>19970800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>378 37</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5790690</doc-number>
<kind>A</kind>
<name>Doi et al.</name>
<date>19980800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382128</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5999639</doc-number>
<kind>A</kind>
<name>Rogers et al.</name>
<date>19991200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382132</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6058322</doc-number>
<kind>A</kind>
<name>Nishikawa et al.</name>
<date>20000500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600408</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6282305</doc-number>
<kind>B1</kind>
<name>Huo et al.</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382128</main-classification></classification-national>
</citation>
<citation>
<nplcit num="00006">
<othercit>U.S. Appl. No. 10/724,395, filed Dec. 1, 2003, Giger et al.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00007">
<othercit>U.S. Appl. No. 10/777,041, filed Feb. 13, 2004, Giger et al.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00008">
<othercit>U.S. Appl. No. 10/360,814, filed Feb. 10, 2003, Giger et al.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00009">
<othercit>U.S. Appl. No. 10/617,675, filed Jul. 14, 2003, Giger et al.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00010">
<othercit>Harald Ganster, et al. “Automated Melanoma Recognition”; IEEE Transactions on Medical Imaging; vol. 20, No. 3, Mar. 2001; pp. 233-239.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00011">
<othercit>Agness Schumann, Free University of Berlin, Geoinformatics, Germany, 12249 Berlin, Malteserstr, 74-100, Neural Networks Versus Statistics: a Comparing Study of Their Classification Performance on Well Log Data.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00012">
<othercit>Rudolf T. Suurmond, Erik Bergkvist, Working Paper, Artificial neural netrworks and statistical approaches to classifying remotely sensed data; WP-96-131, Nov. 1996; International Institute for Applied Systems Analysis, Laxenburg Austria.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00013">
<othercit>Rudolf T. Suurmond, Erik Bergkvist, “Different artificial neural network and statistical approaches in classifying remotely sensed data”, pp. 1-28.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>9</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382125</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382128</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382129</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382130</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382131</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382132</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382133</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382134</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382190</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382198</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382170</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>378  4</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>378 21</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>378 23</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>378 25</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>378 26</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>378 27</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>378 37</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>378901</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>600300</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>600411</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>600425</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>600427</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>600407</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>600410</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>128906</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>128915</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>128920</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>128922</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>25036304</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>11</number-of-drawing-sheets>
<number-of-figures>11</number-of-figures>
</figures>
<us-related-documents>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60429538</doc-number>
<kind>00</kind>
<date>20021129</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20040190763</doc-number>
<kind>A1</kind>
<date>20040930</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Giger</last-name>
<first-name>Maryellen L</first-name>
<address>
<city>Elmhurst</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Bonta</last-name>
<first-name>Dacian</first-name>
<address>
<city>Chicago</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Oblon, Spivak, McClelland, Maier &amp; Neustadt, P.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>University of Chicago</orgname>
<role>02</role>
<address>
<city>Chicago</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Ahmed</last-name>
<first-name>Samir</first-name>
<department>2624</department>
</primary-examiner>
<assistant-examiner>
<last-name>Tabatabai</last-name>
<first-name>Abolfazl</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A computer-aided diagnosis (CAD) scheme to aid in the detection, characterization, diagnosis, and/or assessment of normal and diseased states (including lesions and/or images). The scheme employs lesion features for characterizing the lesion and includes non-parametric classification, to aid in the development of CAD methods in a limited database scenario to distinguish between malignant and benign lesions. The non-parametric classification is robust to kernel size.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="141.73mm" wi="97.62mm" file="US07298883-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="160.53mm" wi="99.91mm" file="US07298883-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="182.80mm" wi="154.26mm" orientation="landscape" file="US07298883-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="159.60mm" wi="138.26mm" orientation="landscape" file="US07298883-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="182.46mm" wi="153.33mm" orientation="landscape" file="US07298883-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="175.01mm" wi="169.76mm" orientation="landscape" file="US07298883-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="160.53mm" wi="161.54mm" orientation="landscape" file="US07298883-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="218.10mm" wi="128.78mm" orientation="landscape" file="US07298883-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="220.13mm" wi="128.78mm" orientation="landscape" file="US07298883-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="222.08mm" wi="197.87mm" orientation="landscape" file="US07298883-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="225.47mm" wi="196.17mm" orientation="landscape" file="US07298883-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="207.35mm" wi="157.31mm" orientation="landscape" file="US07298883-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">The present application is related to and claims the benefit of provisional U.S. Patent Application No. 60/429,538, filed on Nov. 29, 2002, the entire contents of which are incorporated herein by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?GOVINT description="Government Interest" end="lead"?>
<p id="p-0003" num="0002">The present invention was made in part of U.S. Government support under NIH Grant ROI CA89452. The U.S. Government may have certain rights to this invention.</p>
<?GOVINT description="Government Interest" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">1. Field of the Invention</p>
<p id="p-0005" num="0004">The invention relates generally to the field of computer-aided diagnosis (CAD) including detection, characterization, diagnosis, and/or assessment of normal and diseased states (including lesions).</p>
<p id="p-0006" num="0005">The present invention also generally relates to computerized techniques for automated analysis of digital images, for example, as disclosed in one or more of U.S. Pat. Nos. 4,839,807; 4,841,555; 4,851,984; 4,875,165; 4,907,156; 4,918,534; 5,072,384; 5,133,020; 5,150,292; 5,224,177; 5,289,374; 5,319,549; 5,343,390; 5,359,513; 5,452,367; 5,463,548; 5,491,627; 5,537,485; 5,598,481; 5,622,171; 5,638,458; 5,657,362; 5,666,434; 5,673,332; 5,668,888; 5,732,697; 5,740,268; 5,790,690; 5,832,103; 5,873,824; 5,881,124; 5,931,780; 5,974,165; 5,982,915; 5,984,870; 5,987,345; 6,011,862; 6,058,322; 6,067,373; 6,075,878; 6,078,680; 6,088,473; 6,112,112; 6,138,045; 6,141,437; 6,185,320; 6,205,348; 6,240,201; 6,282,305; 6,282,307; 6,317,617; as well as U.S. patent applications Ser. Nos. 08/173,935; 08/398,307 (PCT Publication WO 96/27846); Ser. Nos. 08/536,149; 08/900,189; 09/027,468; 09/141,535; 09/471,088; 09/692,218; 09/716,335; 09/759,333; 09/760,854; 09/773,636; 09/816,217; 09/830,562; 09/818,831; 09/842,860; 09/860,574; 60/160,790; 60/176,304; 60/329,322; 09/990,311; 09/990,310; 60/332,005; and 60/331,995; as well as co-pending U.S. patent applications (listed by attorney docket number) 215752US-730-730-20, 216439US-730-730-20, and references identified in the following List of Non-Patent References by the author(s) and year of publication and cross referenced throughout the specification by reference to the respective number, in parentheses, of the reference:</p>
<p id="p-0007" num="0006">List of Non-Patent References
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0007">1. Feig S A: Decreased breast cancer mortality through mammographic screening: Results of clinical trials. Radiology 167:659-665, 1988.</li>
    <li id="ul0001-0002" num="0008">2. Tabar L, Fagerberg G, Duffy S W, Day N E, Gad A, Grontoft O: Update of the Swedish two-county program of mammographic screening for breast cancer. Radiol Clin North Am 30:187-210, 1992.</li>
    <li id="ul0001-0003" num="0009">3. Smart C R, Hendrick R E, Rutledge J H, Smith R A: Benefit of mammography screening in women ages 40 to 49 years: Current evidence from randomized controlled trials. Cancer 75:1619-26, 1995.</li>
    <li id="ul0001-0004" num="0010">4. Bassett L W, Gold R H: Breast Cancer Detection: Mammography and Other Methods in Breast Imaging New York: Grune and Stratton, 1987.</li>
    <li id="ul0001-0005" num="0011">5. Kopans DB: Breast Imaging. Philadelphia: JB Lippincott, 1989.</li>
    <li id="ul0001-0006" num="0012">6. Brown M L, Houn F, Sickles E A, Kessler L G: Screening mammography in community practice: positive predictive value of abnormal findings and yield of follow-up diagnostic procedures. AJR 165:1373-1377, 1995.</li>
    <li id="ul0001-0007" num="0013">7. Giger M L: Computer-aided diagnosis. In: Syllabus: A Categorical Course on the Technical Aspects of Breast Imaging, edited by Haus A, Yaffe M. Oak Brook, Ill.: RSNA Publications, 1993, pp. 272-298.</li>
    <li id="ul0001-0008" num="0014">8. Vyborny C J, Giger M L: Computer vision and artificial intelligence in mammography. AJR 162:699-708, 1994.</li>
    <li id="ul0001-0009" num="0015">9. Giger M L, Huo Z, Kupinski M A, Vyborny C J: “Computer-aided diagnosis in mammography”, In: Handbook of Medical Imaging, Volume 2. Medical Imaging Processing and Analysis, (Sonka M, Fitzpatrick M J, eds) SPIE, pp. 915-1004, 2000.</li>
    <li id="ul0001-0010" num="0016">10. D'Orsi C J, Bassett L W, Feig S A, Jackson V P, Kopans D B, Linver M N, Sickles E A, Stelling C B: Breast Imaging Reporting and Data System (BI-RADS). Reston, Va. (American College of Radiology), 1998.</li>
    <li id="ul0001-0011" num="0017">11. Getty D J, Pickett R M, D'Orsi C J, Swets J A: Enhanced interpretation of diagnostic images. Invest. Radiol. 23: 240-252, 1988.</li>
    <li id="ul0001-0012" num="0018">12. Swets J A, Getty D J, Pickett R M, D'Orsi C J, Seltzer S E, McNeil B J: Enhancing and evaluating diagnostic accuracy. Med Decis Making 11:9-18, 1991.</li>
    <li id="ul0001-0013" num="0019">13. Cook H M, Fox M D: Application of expert systems to mammographic image analysis. American Journal of Physiologic Imaging 4: 16-22, 1989.</li>
    <li id="ul0001-0014" num="0020">14. Gale A G, Roebuck E J, Riley P, Worthington B S, et al.: Computer aids to mammographic diagnosis. British Journal of Radiology 60: 887-891, 1987.</li>
    <li id="ul0001-0015" num="0021">15. Getty D J, Pickett R M, D'Orsi C J, Swets J A: Enhanced interpretation of diagnostic images. Invest. Radiol. 23: 240-252, 1988.</li>
    <li id="ul0001-0016" num="0022">16. Swett H A, Miller P A: ICON: A computer-based approach to differential diagnosis in radiology. Radiology 163: 555-558, 1987.</li>
    <li id="ul0001-0017" num="0023">17. Huo Z, Giger M L, Vyborny C J, Bick U, Lu P, Wolverton D E, Schmidt R A: Analysis of spiculation in the computerized classification of mammographic masses” Medical Physics 22:1569-1579, 1995.</li>
    <li id="ul0001-0018" num="0024">18. Jiang Y, Nishikawa R M, Wolverton D E, Giger M L, Doi K, Schmidt R A, Vyborny C J: Automated feature analysis and classification of malignant and benign clustered microcalcifications. Radiology 198(3):671-678, 1996.</li>
    <li id="ul0001-0019" num="0025">19. Ackerman L V, Gose E E: Breast lesion classification by computer and xeroradiography. Breast Cancer 30:1025-1035, 1972.</li>
    <li id="ul0001-0020" num="0026">20. Patrick E A, Moskowitz M, Mansukhani V T, Gruenstein E I: Expert learning system network for diagnosis of breast calcifications. Invest Radiol 16: 534-539, 1991.</li>
    <li id="ul0001-0021" num="0027">21. Huo Z, Giger M L, Vyborny C J, Wolverton D E, Schmidt R A, Doi K: Automated computerized classification of malignant and benign mass lesions on digitized mammograms. Academic Radiology 5: 155-168, 1998.</li>
    <li id="ul0001-0022" num="0028">22. Jiang Y, Nishikawa R M, Schmidt R A, Metz C E, Giger M L, Doi K: Improving breast cancer diagnosis with computer-aided diagnosis. Academic Radiology 6: 22-33, 1999.</li>
    <li id="ul0001-0023" num="0029">23. Huo Z, Giger M L, Metz C E: Effect of dominant features on neural network performance in the classification of mammographic lesions. PMB 44: 2579-2595, 1999.</li>
    <li id="ul0001-0024" num="0030">24. Huo Z, Giger M L, Vyborny C J, Wolverton D E, Metz C E: Computerized classification of benign and malignant masses on digitized mammograms: a robustness study. Academic Radiology 7:1077-1084 2000.</li>
    <li id="ul0001-0025" num="0031">25. American Cancer Society. Cancer facts and Figures—1998. New York, N.Y. 1998; p. 20.</li>
    <li id="ul0001-0026" num="0032">26. Metz C E. ROC methodology in radiologic imaging. Invest Radiol 1986; 21:720-733.</li>
    <li id="ul0001-0027" num="0033">27. Efromovich, Sam. “Nonparametric curve estimation: methods, theory and applications”. Springer, N.Y. 1999</li>
    <li id="ul0001-0028" num="0034">28. Silverman, B. W. “Density Estimation for Statistics and Data Analysis”, Chapman and Hall, London, N.Y., 1986.</li>
    <li id="ul0001-0029" num="0035">29. Zhou K H, Hall W J, Shapiro D E. “Smooth non-parametric receiver operating characteristic (ROC) curves for continuous diagnostic tests”. Stat Med., 1997, 16(19):2143-56.</li>
</ul>
</p>
<p id="p-0008" num="0036">The following patents and patent applications may be considered relevant to the field of the present invention:
<ul id="ul0002" list-style="none">
    <li id="ul0002-0001" num="0037">30. Doi K, Chan H-P, Giger M L: Automated systems for the detection of abnormal anatomic regions in a digital x-ray image. U.S. Pat. No. 4907156, March 1990.</li>
    <li id="ul0002-0002" num="0038">31. Giger M L, Doi K, Metz C E, Yin F-F: Automated method and system for the detection and classification of abnormal lesions and parenchymal distortions in digital medical images. U.S. Pat. No. 5133020, July 1992.</li>
    <li id="ul0002-0003" num="0039">32. Doi K, Matsumoto T, Giger M L, Kano A: Method and system for analysis of false positives produced by an automated scheme for the detection of lung nodules in digital chest radiographs. U.S. Pat. No. 5289374, February 1994.</li>
    <li id="ul0002-0004" num="0040">33. Nishikawa R M, Giger M L, Doi K: Method for computer-aided detection of clustered microcalcifications from digital mammograms. U.S. Pat. No. 5,537,485, July 1996.</li>
    <li id="ul0002-0005" num="0041">34. Giger M L, Doi K, Lu P, Huo Z: Automated method and system for improved computerized detection and classification of mass in mammograms. U.S. Pat. No. 5,832,103, November, 1998.</li>
    <li id="ul0002-0006" num="0042">35. Giger M L, Bae K, Doi K: Automated method and system for the detection of lesions in medical computed tomographic scans. U.S. Pat. No. 5,881,124, March, 1999.</li>
    <li id="ul0002-0007" num="0043">36. Bick U, Giger M L: Method and system for the detection of lesions in medical images. U.S. patent Allowed.</li>
    <li id="ul0002-0008" num="0044">37. Giger M L, Zhang M, Lu P: Method and system for the detection of lesions and parenchymal distortions in mammograms. U.S. Pat. No. 5,657,362, August, 1997.</li>
    <li id="ul0002-0009" num="0045">38. Giger M L, Kupinski M A: Automatic analysis of lesions in medical images. U.S. Pat. No. 6,138,045, Oct. 24, 2000.</li>
    <li id="ul0002-0010" num="0046">39. Huo Z, Giger M L: Method and system for the computerized assessment of breast cancer risk. U.S. Pat. No. 6,282,305, Aug. 28, 2001.</li>
    <li id="ul0002-0011" num="0047">40. Giger M L, Al-Hallaq H, Wolverton D E, Bick U: Method and system for the automated analysis of lesions in ultrasound images. U.S. Pat. No. 5,984,870, Nov. 16, 1999.</li>
    <li id="ul0002-0012" num="0048">41. Gilhuijs K, Giger M L, Bick U: Method and system for the automated analysis of lesions in magnetic resonance images. U.S. patent Ser. No. 08/900,188 allowed.</li>
    <li id="ul0002-0013" num="0049">42. Gilhuijs K, Giger M L, Bick U: Method and system for the assessment of tumor extent. U.S. patent Ser. No. 09/156,413, allowed;</li>
    <li id="ul0002-0014" num="0050">43. Armato S G, Giger M L, MacMahon H: Method, system and computer readable medium for the two-dimensional and three-dimensional detection of lesions in computed tomography scans. U.S. patent Pending;</li>
    <li id="ul0002-0015" num="0051">44. Giger M L, Vyborny C J, Huo Z, Lan L: Method, system and computer readable medium for an intelligent search workstation for computer assisted interpretation of medical images. U.S. patent pending, Ser. No. 09/773,636; and</li>
    <li id="ul0002-0016" num="0052">45. Drukker K, Giger M L, Horsch K, Vyborny C J: Automated method and system for the detection of abnormalities in sonographic images. U.S. patent Pending Ser. No. 60/332,005.</li>
</ul>
</p>
<p id="p-0009" num="0053">The contents of each of these references, including patents and patent applications, are incorporated herein by reference. The techniques disclosed in the patents, patent applications and other references can be utilized as part of the present invention.</p>
<heading id="h-0003" level="1">DISCUSSION OF THE BACKGROUND</heading>
<p id="p-0010" num="0054">The inventors' research, findings and analysis are discussed in this Background section along with that of others; accordingly, discussion in this section does not constitute an admission that the discussed material constitutes “prior art.”</p>
<p id="p-0011" num="0055">Breast cancer remains a disease without a cure unless it is found at a sufficiently early stage and subsequently surgically removed, irradiated, or eradicated with chemotherapy. Major research issues include those focused on genetic and molecular forms of detection and treatment, and those focused on anatomical levels of prevention, detection, and treatment. In these various areas, the role of the human interpreter (e.g., oncologist, radiologist, pathologist, surgeon, primary care physician) varies. However, the very presence of a human interpreter introduces subjective judgment into the decision-making process—whether it be in the initial detection (or miss) of a lesion on a mammogram or in the surgical decision regarding the type of incision. Thus, while ongoing research is needed in the biological aspects of cancer, in the physical aspects of instrumentation to better “see” the cancer, and in the biological/chemical/physical aspects of therapy, research is also needed for improving the role of the human in the overall management of the patient. Multi-modality and multi-disciplinary decision making on patient management, requiring inputs from oncologists, pathologists, radiologists, surgeons, and risk clinic physicians, can be quite subjective, as is often evident during case management conferences. Although “subjective” does not necessarily mean “poor judgement”, it does permit sub-optimal and inconsistent decision making.</p>
<p id="p-0012" num="0056">Breast cancer is the leading cause of death for women in developed countries. Detection of breast cancer in an early stage increases success of treatment dramatically, and hence screening for breast cancer of women over 40 years of age is generally recommended. Current methods for detecting and diagnosing breast cancer include mammography, sonography (also referred to as ultrasound), and magnetic resonance imaging (MRI).</p>
<p id="p-0013" num="0057">Mammography is the most effective method for the early detection of breast cancer, and it has been shown that periodic screening of asymptomatic women does reduce mortality (Refs. 1-6). Many breast cancers are detected and referred for surgical biopsy on the basis of a radiographically detected mass lesion or cluster of microcalcifications. Although general rules for the differentiation between benign and malignant mammographically identified breast lesions exist, considerable misclassification of lesions occurs with the current methods. On average, less than 30% of masses referred for surgical breast biopsy are actually malignant.</p>
<p id="p-0014" num="0058">Computerized analysis schemes are being developed to aid in distinguishing between malignant and benign lesions in order to improve both sensitivity (true positive rate) and specificity (true negative rate). Comprehensive summaries of investigations in the field of mammography CAD (computer aided diagnosis) have been published by Giger and colleagues (Refs. 7-9). Investigators have used computers to aid in the decision-making process regarding likelihood of malignancy and patient management using human-extracted features and BI-RADS (Refs. 10-13). Such methods are dependent on the subjective identification and interpretation of the mammographic data by human observers. Gale et al. (Ref. 14) and Getty et al. (Ref. 15) both developed computer-based classifiers, which take as input diagnostically-relevant features obtained from radiologists' readings of breast images. Getty et al. found that with the aid of the classifier, community radiologists performed as well as unaided expert mammographers in making benign-malignant decisions. Swett et al. (Ref. 16) developed an expert system to provide visual and cognitive feedback to the radiologist using a critiquing approach combined with an expert system. Other investigators have been developing methods based on computer-extracted features (Refs. 17-24). The benefit of using computer-extracted features is the objectivity and reproducibility of the result. Radiologists employ many radiographic image features, which they seem to extract and interpret simultaneously and instantaneously. Thus, the development of methods using computer-extracted features requires, besides the determination of which individual features are clinically significant, the computerized means for the extraction of each such feature. Spatial features, which are characteristic of lesions, have been shown to be extractable by a computer analysis of the mammograms and to be useful in distinguishing between malignant and benign. Most methods are evaluated in terms of their ability to distinguish between malignant and benign lesions, however, a few have been evaluated in terms of patient management (i.e., return to screening vs. biopsy). It is important to state that while one of the aims of computerized classification is to increase sensitivity (true positive rate), another aim of computerized classification is to reduce the number of benign cases sent for biopsy. Such a reduction will be clinically acceptable only if it does not result in unbiopsied malignant cases, however, since the “cost” of a missed cancer is much greater than misclassification of a benign case. Thus, computer classification schemes should be developed to improve specificity (true negative rate) but not at the loss of sensitivity (true positive rate). We have shown that the computerized analysis of mass lesions (Refs. 17, 21) and clustered microcalcifications (Refs. 18, 22) on digitized mammograms yields performances similar to an expert mammographer and significantly better than average radiologists in the task of distinguishing between malignant and benign lesions.</p>
<p id="p-0015" num="0059">We are investigating the potential usefulness of computer-aided diagnosis as an aid to radiologists in the characterization and classification of mass lesions in mammography. Observer studies have shown that such a system can aid in increasing the diagnostic accuracy of radiologists both in terms of sensitivity (true positive rate) and specificity (true negative rate). Our mass classification method includes three components: 1) automated segmentation of mass regions, 2) automated feature-extraction, and 3) automated classification. The method was initially trained with 95 mammograms containing masses from 65 patients. Features related to the margin, shape, and density of each mass are extracted automatically from the image data and merged into an estimate of the likelihood of malignancy (Refs. 17, 21, 23, 24). These features include a spiculation measure (<figref idref="DRAWINGS">FIG. 1</figref>), a margin definition feature (<figref idref="DRAWINGS">FIG. 2</figref>), and two density measures. The round-robin performance of the computer in distinguishing between benign and malignant masses was evaluated by receiver operating characteristic (ROC) analysis (Ref. 21). Our computer classification scheme yielded an Az value of 0.94, similar to that of an experienced mammographer (Az=0.91) and statistically significantly higher than the average performance of five radiologists with less mammographic experience (Az=0.81) (<figref idref="DRAWINGS">FIG. 3</figref>). With the database we used, the computer scheme achieved, at 100% sensitivity, a positive predictive value of 83%, which was 12% higher than that of the experienced mammographer and 21% higher than that of the average performance of the less experienced mammographers at a p-value of less than 0.001 (Ref. 21).</p>
<p id="p-0016" num="0060">The computerized mass classification method was independently evaluated on a 110-case database consisting of 50 malignant and 60 benign cases (Ref. 24). The effects of variations in both case mix and in film digitization technique on the performance of the method were assessed. Categorization of lesions as malignant or benign using the computer achieved an Az value (area under the receiver operating characteristic (ROC) curve) of 0.90 on the prior training database (Fuji scanner digitization) in a round-robin evaluation, and Az values of 0.82 and 0.81 on the independent database for Konica and Lumisys digitization formats, respectively. However, in the statistical comparison of these performances, we failed to show a statistical significant difference between the performance on the training database and that on the independent validation database (p-values&gt;0.10). Thus, our computer-based method for the classification of lesions on mammograms was shown to be robust to variations in case mix and film digitization technique (Ref. 24).</p>
<p id="p-0017" num="0061">Subsequently we have developed advanced classifiers for the merging of features—characteristics of the lesion or image—into a probability or status of disease. These classifiers have potential to aid in the development of CAD methods in a limited database scenario.</p>
<heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0018" num="0062">Accordingly, an object of this invention is to provide a method and system that classifies images using non-parametric classification.</p>
<p id="p-0019" num="0063">Accordingly, an object of this invention is to provide a method and system that classifies lesions using non-parametric classification.</p>
<p id="p-0020" num="0064">Accordingly, an object of this invention is to provide a method and system that classifies disease status using non-parametric classification.</p>
<p id="p-0021" num="0065">Another object of this invention to provide a method and system that perform computerized differential diagnosis of medical images using non-parametric classification.</p>
<p id="p-0022" num="0066">These and other objects are achieved according to the invention by providing a new automated method and system that classifies lesions or medical images in which the analysis method involves non-parametric classification.</p>
<p id="p-0023" num="0067">Preferred embodiments of the present invention provide a method and system that employ a lesion characterization module. A specific embodiment is a computerized method for the characterization of mammographic lesions combined with a computerized method for the classification of the lesions using non-parametric classification.</p>
<p id="p-0024" num="0068">According to other aspects of the present invention, there are provided novel systems implementing the methods of this invention, and novel computer program products that upon execution cause the computer system to perform the method of the invention.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0025" num="0069">A more complete appreciation of the invention and many of the attendant advantages thereof will be readily obtained as the same becomes better understood by reference to the following detailed description when considered in connection with the accompanying drawings, in which like reference numerals refer to identical or corresponding parts throughout the several views, and in which:</p>
<p id="p-0026" num="0070"><figref idref="DRAWINGS">FIG. 1</figref> is an illustration showing the overall methods for the computerized analysis of image data in CAD. These include detection, segmentation, characterization, and classification;</p>
<p id="p-0027" num="0071"><figref idref="DRAWINGS">FIG. 2(</figref><i>a</i>) is an illustration defining the radial angle as the angle between the direction of the maximum gradient and its radial direction; <figref idref="DRAWINGS">FIG. 2(</figref><i>b</i>) and <b>2</b>(<i>c</i>) are illustrations showing normalized cumulated edge-gradient distributions for spiculated masses; and circular masses, respectively;</p>
<p id="p-0028" num="0072"><figref idref="DRAWINGS">FIG. 3</figref> shows the relationship between measures of spiculation and margin definition for malignant and benign mammographic masses;</p>
<p id="p-0029" num="0073"><figref idref="DRAWINGS">FIG. 4</figref> illustrates results of a test using an embodiment of the present invention;</p>
<p id="p-0030" num="0074"><figref idref="DRAWINGS">FIG. 5</figref> illustrates estimation results for various features;</p>
<p id="p-0031" num="0075"><figref idref="DRAWINGS">FIG. 6</figref> illustrates the effect of varying kernel size in the present invention;</p>
<p id="p-0032" num="0076"><figref idref="DRAWINGS">FIG. 7</figref> illustrates results of a test of one embodiment of the present invention;</p>
<p id="p-0033" num="0077"><figref idref="DRAWINGS">FIG. 8</figref> illustrates corresponding test result distribution; and</p>
<p id="p-0034" num="0078"><figref idref="DRAWINGS">FIG. 9</figref> illustrates the effect of kernel size or performance of various embodiments of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0035" num="0079">In describing preferred embodiments of the present invention illustrated in the drawings, specific terminology is employed for the sake of clarity. However, the invention is not intended to be limited to the specific terminology so selected, and it is to be understood that each specific element includes all technical equivalents that operate in a similar manner to accomplish a similar purpose.</p>
<p id="p-0036" num="0080"><figref idref="DRAWINGS">FIG. 1</figref> schematically shows the overall method for computer-aided diagnosis indicating the role of non-parametric classification.</p>
<p id="p-0037" num="0081">Classifiers such as linear discriminant analysis or artificial neural networks have limitations especially in a limited training database situation. Linear discriminant analysis may fail such as in the XOR problem. Artificial neural networks tend to be complex and difficult to model. Non-parametric classification can be applied to the various tasks in CAD to improve the use of computerized image analysis in medical imaging by optimizing the computer output.</p>
<p id="p-0038" num="0082">While the inventors have investigated various computer-extracted features of lesions (and their relationship to likelihood of malignancy), it is novel to combine such features using non-parametric classifiers in order to improve characterization of the lesion, image, and/or disease status, especially when limited databases for training are available. A particular example is given here using non-parametric classification in the task of distinguishing between malignant and benign mammographic lesions.</p>
<p id="p-0039" num="0083">Radiographically, mass lesions can be characterized (Refs. 7, 9) by, for example:
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0000">
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0084">Lesion Feature 1: degree of spiculation (spiked versus rounded),</li>
        <li id="ul0004-0002" num="0085">Lesion Feature 2: margin definition (margin sharpness),</li>
        <li id="ul0004-0003" num="0086">Lesion Feature 3: shape,</li>
        <li id="ul0004-0004" num="0087">Lesion Feature 4: density (determined using average gray level, contrast, texture),</li>
        <li id="ul0004-0005" num="0088">Lesion Feature 5: homogeneity (texture),</li>
        <li id="ul0004-0006" num="0089">Lesion Feature 6: asymmetry,</li>
        <li id="ul0004-0007" num="0090">Lesion Feature 7: temporal stability,</li>
        <li id="ul0004-0008" num="0091">and so forth.
<br/>
Mass lesions from mammograms may be characterized using the inventors' earlier work (Refs. 17, 21, 23, 24) in which a characterization scheme based on the degree of spiculation is determined from a cumulative edge gradient histogram analysis in which the gradient is analyzed relative to the radial angle (<figref idref="DRAWINGS">FIG. 2</figref>). The mass is first extracted from the anatomic background of the mammogram using automatic region-growing techniques (Ref. 17). Features extracted are then obtained using cumulative edge gradient histogram analysis. In the cumulative edge-gradient analysis, the maximum gradient and angle of this gradient relative to the radial direction is calculated.
</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0040" num="0092"><figref idref="DRAWINGS">FIG. 2</figref> illustrates the calculation of the FWHM (full width at half max) from the cumulative gradient orientation histogram for a spiculated mass and a smooth mass. Note that here the spiculation feature (based on the radial direction) is used in distinguishing between spiculated lesions and round lesions. Also, the average gradient along the margin of a mass will be calculated to describe the sharpness of the margin. Higher values indicate a sharper margin and thus a higher likelihood that the lesion is benign.</p>
<p id="p-0041" num="0093">In addition, a radial gradient index (normalized radial gradient) (Refs. 21, 69) that describes the circularity and density characteristics of a lesion is used and is given by</p>
<p id="p-0042" num="0094">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mrow>
  <mi>RGI</mi>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <munderover>
        <mo>∑</mo>
        <mrow>
          <mi>P</mi>
          <mo>∈</mo>
          <mi>L</mi>
        </mrow>
        <mstyle>
          <mspace width="0.3em" height="0.3ex"/>
        </mstyle>
      </munderover>
      <mo>⁢</mo>
      <mstyle>
        <mspace width="0.3em" height="0.3ex"/>
      </mstyle>
      <mo>⁢</mo>
      <mrow>
        <mi>cos</mi>
        <mo>⁢</mo>
        <mstyle>
          <mspace width="0.3em" height="0.3ex"/>
        </mstyle>
        <mo>⁢</mo>
        <mi>φ</mi>
        <mo>⁢</mo>
        <msqrt>
          <mrow>
            <msubsup>
              <mi>D</mi>
              <mi>x</mi>
              <mn>2</mn>
            </msubsup>
            <mo>+</mo>
            <msubsup>
              <mi>D</mi>
              <mi>y</mi>
              <mn>2</mn>
            </msubsup>
          </mrow>
        </msqrt>
      </mrow>
    </mrow>
    <mrow>
      <munderover>
        <mo>∑</mo>
        <mrow>
          <mi>P</mi>
          <mo>∈</mo>
          <mi>L</mi>
        </mrow>
        <mstyle>
          <mspace width="0.3em" height="0.3ex"/>
        </mstyle>
      </munderover>
      <mo>⁢</mo>
      <msqrt>
        <mrow>
          <msubsup>
            <mi>D</mi>
            <mi>x</mi>
            <mn>2</mn>
          </msubsup>
          <mo>+</mo>
          <msubsup>
            <mi>D</mi>
            <mi>y</mi>
            <mn>2</mn>
          </msubsup>
        </mrow>
      </msqrt>
    </mrow>
  </mfrac>
</mrow>
</math>
</maths>
<br/>
where:
<ul id="ul0005" list-style="none">
    <li id="ul0005-0001" num="0000">
    <ul id="ul0006" list-style="none">
        <li id="ul0006-0001" num="0095">RGI is a radial gradient index that is normalized to take on values between −1 and +1,</li>
        <li id="ul0006-0002" num="0096">P is an image point,</li>
        <li id="ul0006-0003" num="0097">L is the detected lesion excluding the center part,</li>
        <li id="ul0006-0004" num="0098">D<sub>x </sub>is the gradient in the x-direction,</li>
        <li id="ul0006-0005" num="0099">D<sub>y </sub>is the gradient in the y-direction, and</li>
        <li id="ul0006-0006" num="0100">φ is the angle between gradient vector and connection line from center point to neighbor point.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0043" num="0101">Although the radiographic density of a mass may not be by itself as powerful a predictor in distinguishing between benign and malignant masses as its margin features, taken with these features, density assessment can be extremely useful. The evaluation of the density of a mass is of particular importance in diagnosing circumscribed, lobulated, indistinct, or obscured masses that are not spiculated.</p>
<p id="p-0044" num="0102">In order to assess the density of a mass radiographically, the present invention uses three density-related measures (average gray level, contrast, and texture measure) that characterize different aspects of the density of a mass. These measures are similar to those used intuitively by radiologists. Average gray level is obtained by averaging the gray level values of each point within the grown region of a mass. Contrast is the difference between the average gray level of the grown mass and the average gray level of the surrounding fatty areas (areas with gray-level values in the lower 20% of the histogram for the total surrounding area). Texture is defined here as the standard deviation of the average gradient within a mass and it is used to quantify patterns arising from veins, trabeculae, and other structures that may be visible through a low-density mass, but not through a high-density mass. A mass of low radiographic density should have low values of average gray level and contrast, and a high value of the texture measure, whereas a mass of high radiographic density should have high values of average gray level and contrast, and a low value of the texture measure.</p>
<p id="p-0045" num="0103"><figref idref="DRAWINGS">FIG. 3</figref> shows the relationship between measures of spiculation and margin definition for malignant and benign mammographic masses.</p>
<p id="p-0046" num="0104">Non-parametric methods have been used for curve fitting in statistical analysis (Refs. 27-29). In the present invention however non-parametric classifiers are used to merge features (i.e., characteristics of the lesion or image) into a probability or status of disease. These classifiers are used to aid in the development of CAD methods in a limited database scenario.</p>
<p id="p-0047" num="0105">A signal/noise classifier based on the ratio of density probabilities at the observed point produces the maximal area under the ROC curve, being in this sense the “best” classifier possible. Such a classifier is created by (1) constructing estimators of the signal and noise densities and (2) classifying observations based on the ratio of the estimated probability densities. Non-parametric density methods may also be used to estimate probability densities of unknown functional forms. Non-parametric estimates are unbiased in the large number limit. One embodiment of the invention is the application of the approach outlined above for the classification of breast lesions detected on mammography, using a database of breast lesions (malignant or benign) which already have been analyzed by a computer system yielding computer-extracted lesion features. The non-parametric density estimate is the product of ‘blurring’ the observations (treated as Dirac ‘delta’ functions) with a suitably chosen kernel. A number of blurring kernels are available to construct the probability density estimates. Parabolic kernels of fixed size (1-x<sup>2 </sup>and (1-x<sup>2</sup>)<sup>2</sup>, for |x|&lt;1) are optimal in some cases. Alternatively, the Gaussian kernel may be used as it produce smooth, unbounded, density estimates (closer to our perception of what the “true” probability density should be). The kernel may be of fixed size, or it can be adaptative (wider in regions where data are more sparse, narrower in regions where data are more dense). In some cases adaptative kernels offer faster convergence, but fixed-size kernels are preferable as they are more robust to implement. In addition, the size of a fixed kernel can be found based on theoretical criteria.</p>
<p id="p-0048" num="0106">The probability densities in the feature space for benign and malignant lesions in a database can be estimated by summing up the blurring kernels centered in the observations, thus yielding the likelihood ratios. In the evaluation, lesions from an independent database can be classified based on the ratio of the estimated probability densities. The quality of fit will be estimated by the area beneath the corresponding ROC curve.</p>
<p id="p-0049" num="0107"><figref idref="DRAWINGS">FIG. 4</figref> shows an example for implementing non-parametric classification in CAD according to the present invention. The examples are given using a training database of 92 malignant (cancerous) lesion images and 110 benign lesion images and an independent testing database of 68 malignant lesion images and 38 benign lesion images.</p>
<p id="p-0050" num="0108">The present invention uses a non-parametric method for classifying mammographic lesions in order to estimate the probability density function (PDF) of malignant and benign lesions in the feature space. The feature space can consist of various features including the limited list above that are extracted by the computer to characterize the lesions. The present invention uses non-parametric smoothing with a kernel, K, to estimate the PDFs. Finally, a ratio of probability densities (i.e., the likelihood ratio) is used to classify the lesions.</p>
<p id="p-0051" num="0109">The PDF Estimator (i.e. the estimate of the PDF) is obtained by the following</p>
<p id="p-0052" num="0110">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mrow>
  <mrow>
    <mi>PDF</mi>
    <mo>⁡</mo>
    <mrow>
      <mo>(</mo>
      <mover>
        <mi>x</mi>
        <mo>-&gt;</mo>
      </mover>
      <mo>)</mo>
    </mrow>
  </mrow>
  <mo>=</mo>
  <mrow>
    <mo>∑</mo>
    <mrow>
      <mrow>
        <munder>
          <mi>K</mi>
          <mi>i</mi>
        </munder>
        <mo>⁡</mo>
        <mrow>
          <mo>(</mo>
          <mrow>
            <mover>
              <mi>x</mi>
              <mo>-&gt;</mo>
            </mover>
            <mo>-</mo>
            <msub>
              <mover>
                <mi>x</mi>
                <mo>-&gt;</mo>
              </mover>
              <mi>i</mi>
            </msub>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mrow>
      <mo>.</mo>
    </mrow>
  </mrow>
</mrow>
</math>
</maths>
<br/>
Where the kernel K may be paraboloid, Gaussian, Lorentzian or other forms.
</p>
<p id="p-0053" num="0111"><figref idref="DRAWINGS">FIG. 5</figref> schematically shows the estimation of the probability density function of a given feature. The dot symbols indicate the feature values for seven potential malignant lesions. Each region is spread (blurred) using a specific kernel (size and shape) and then summed to yield the estimated PDF for that particular feature. Note that the kernel size and shape can be made adaptive to the denseness (or inversely to the sparcity) of the feature data points. This process is repeated for each feature type for the malignant lesions and for the benign lesions.</p>
<p id="p-0054" num="0112">Ultimately one obtains the PDFs for the malignant lesions (PDF<sub>malignant</sub>) and for the benign lesions (PDF<sub>benign</sub>). The estimate of the likelihood ratio is calculated from the estimates of PDF<sub>malignant </sub>and PDF<sub>benign </sub>for all features values in the training database.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>LR (<i>x</i>)=PDF<sub>malignant</sub>(<i>x</i>)/PDF<sub>benign</sub>(<i>x</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0055" num="0113">The LR(x<sub>j</sub>) is then used to classify lesion j in the testing database, or any unknown lesion (or known lesion).</p>
<p id="p-0056" num="0114">In a test of this invention, each lesion image was characterized by 5 computer-extracted features: radial gradient of margin, spiculation, margin sharpness, texture, and I average gray value. Then, the lesions were classified using combinations of features, two at a time using the non-parametric classification method. The kernel was a Gaussian kernel with the kernel width for a specific feature being a percentage of the range of the values for that feature over all the lesions. Note that for a given feature, the kernel width was kept fixed in determining the PDF. In an alternative embodiment the width could be varied to be, for example, larger when less data points are available. This is schematically illustrated in <figref idref="DRAWINGS">FIG. 6</figref> in which the width of the kernel for the sparser-spaced data is larger.</p>
<p id="p-0057" num="0115"><figref idref="DRAWINGS">FIG. 7</figref> demonstrates for the test performed the 2-dimensional distribution of the two features (spiculation and radial gradient along the margin) for malignant and benign lesions in the training database (i.e., a consistency result). In this test, a Gaussian kernel size of 10% of the feature range was employed. The separation line, indicated by the zero notation, yields an area under the ROC curve of 0.86 for the two-feature, non-parametric classifier in the task of distinguishing between malignant and benign lesions.</p>
<p id="p-0058" num="0116"><figref idref="DRAWINGS">FIG. 8</figref> demonstrates the corresponding 2-dimensional distribution for the independent testing database (i.e., a validation result). The separation line, indicated by the zero notation, yields an area under the ROC curve of 0.81 for the two-feature, non-parametric classifier in the task of distinguishing between malignant and benign lesions.</p>
<p id="p-0059" num="0117"><figref idref="DRAWINGS">FIG. 9</figref> illustrates the effect of kernel size on the performance of the classifier in the task of distinguishing between malignant and benign lesion. Note that the classifier is quite robust over a range of kernel sizes.</p>
<p id="p-0060" num="0118">The table below gives performance results for the non-parametric classifier in which features were merged two at a time. The method can be extended to merge more than two features, as the database increases. Here ROC analysis (Ref. 26) was used to determine the performance of the combined features sets in the task of classifying lesions as malignant or benign. The validation result is given.</p>
<p id="p-0061" num="0119">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="center"/>
<thead>
<row>
<entry namest="1" nameend="1" rowsep="1">TABLE 1</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry>Area under Receiver Operating</entry>
</row>
<row>
<entry>Characteristic (ROC) •curve</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="5">
<colspec colname="offset" colwidth="49pt" align="left"/>
<colspec colname="1" colwidth="49pt" align="center"/>
<colspec colname="2" colwidth="42pt" align="center"/>
<colspec colname="3" colwidth="35pt" align="center"/>
<colspec colname="4" colwidth="42pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry/>
<entry>Margin</entry>
<entry/>
<entry>Average</entry>
</row>
<row>
<entry/>
<entry>Spiculation</entry>
<entry>sharpness</entry>
<entry>Texture</entry>
<entry>gray level</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="4" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="5">
<colspec colname="1" colwidth="49pt" align="left"/>
<colspec colname="2" colwidth="49pt" align="center"/>
<colspec colname="3" colwidth="42pt" align="center"/>
<colspec colname="4" colwidth="35pt" align="center"/>
<colspec colname="5" colwidth="42pt" align="center"/>
<tbody valign="top">
<row>
<entry>RadGrad</entry>
<entry>0.83</entry>
<entry>0.79</entry>
<entry>0.73</entry>
<entry>0.76</entry>
</row>
<row>
<entry>Spiculation</entry>
<entry/>
<entry>0/79</entry>
<entry>0.74</entry>
<entry>0.78</entry>
</row>
<row>
<entry>Margin</entry>
<entry/>
<entry/>
<entry>0.51</entry>
<entry>0.54</entry>
</row>
<row>
<entry>Sharpness</entry>
</row>
<row>
<entry>Texture</entry>
<entry/>
<entry/>
<entry/>
<entry>0.53</entry>
</row>
<row>
<entry namest="1" nameend="5" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0062" num="0120">It is evident from this testing that use of a non-parametric classifier can contribute to the classification of mass lesions by a computer, and likewise, can be expected to improve diagnoses. In addition, use of an adaptive kernel size dependent on the sparseness of feature data can be expected to improve the classification, especially when a limited database is used in training.</p>
<p id="p-0063" num="0121">Although the method has been presented on mammographic breast image data sets, the inventive non-paramatric CAD analysis method can be implemented on other breast images (such as sonograms) in which a computerized image analysis is performed with respect to some disease state, or it can be implemented on other medical images (such chest radiographs or CT scans) with respect to some disease state or state of risk.</p>
<p id="p-0064" num="0122">Numerous modifications and variations of the present invention are possible in light of the above teachings. It is therefore to be understood that within the scope of the appended claims and their equivalents, the invention may be practiced otherwise than as specifically described herein.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US07298883-20071120-M00001.NB">
<img id="EMI-M00001" he="15.16mm" wi="76.20mm" file="US07298883-20071120-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US07298883-20071120-M00002.NB">
<img id="EMI-M00002" he="6.01mm" wi="76.20mm" file="US07298883-20071120-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>What is claimed as new and desired to be secured by Letters Patent of the United States is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of analyzing a medical image to determine information concerning a disease that may be evidenced by a lesion in the medical image, the method comprising:
<claim-text>extracting data corresponding to at least one feature of the lesion from the medical image; and</claim-text>
<claim-text>determining the information concerning the disease, based on non-parametric smoothing of the extracted data over a database of previously stored feature data with one of a fixed or adaptive kernel, K, the adaptive kernel being wider in a region where the extracted data are more sparse, narrower in a region where the extracted data are more dense.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the information comprises at least one from a group including:
<claim-text>a decision on whether a lesion is present in the medical image;</claim-text>
<claim-text>a characterization of a likelihood that the lesion is malignant;</claim-text>
<claim-text>a characterization of a stage of cancer of the lesion;</claim-text>
<claim-text>a characterization of the lesion as being malignant or benign; and</claim-text>
<claim-text>a characterization of a likelihood that a malignancy will develop in the future.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the extracting data step comprises:
<claim-text>analyzing a surrounding environment of the lesion.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the analyzing step comprises:
<claim-text>assessing a parenchymal pattern surrounding the lesion in human breast tissue in a mammogram constituting the medical image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the extracting data step comprises:
<claim-text>determining at least one feature from a group of features comprising:
<claim-text>skewness of gray-values,</claim-text>
<claim-text>spiculation,</claim-text>
<claim-text>margin definition,</claim-text>
<claim-text>shape,</claim-text>
<claim-text>density,</claim-text>
<claim-text>homogeneity,</claim-text>
<claim-text>texture,</claim-text>
<claim-text>asymmetry, and</claim-text>
<claim-text>temporal stability.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where K is a paraboloid, Gaussian, or Lorentzian kernel.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the information comprises an estimate of a probability density function (PDF) of a distribution of the at least one lesion feature over the database, and the PDF is calculated by the mathematical equation
<claim-text>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>PDF(<i>{right arrow over (x)}</i>)=Σ<sub>i</sub><sup>K</sup>(<i>{right arrow over (x)}−{right arrow over (x)}</i><sub>i</sub>)<?in-line-formulae description="In-line Formulae" end="tail"?>
</claim-text>
<claim-text>where {right arrow over (x)} represents the extracted data, and {right arrow over (x)}<sub>i </sub>represents previously stored feature data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A system, comprising:
<claim-text>a data extraction device configured to extract data corresponding to at least one feature of the lesion from a medical image; and</claim-text>
<claim-text>a processor configured to determine the information concerning the disease, based on non-parametric smoothing of the extracted data over a database of previously stored feature data with one of a fixed or adaptive kernel, K, the adaptive kernel being wider in a region where the extracted data are more sparse, narrower in a region where the extracted data are more dense.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A computer readable storage medium containing instructions configured to cause a computing device to execute a method comprising:
<claim-text>extracting data corresponding to at least one feature of the lesion from the medical image; and</claim-text>
<claim-text>determining the information concerning the disease, based on non-parametric smoothing of the extracted data over a database of previously stored feature data with one of a fixed or adaptive kernel, K, the adaptive kernel being wider in a region where the extracted data are more sparse, narrower in a region where the extracted data are more dense.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
