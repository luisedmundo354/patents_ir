<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298889-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298889</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10276914</doc-number>
<date>20010523</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>DE</country>
<doc-number>100 25 922</doc-number>
<date>20000527</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>754</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382154</main-classification>
</classification-national>
<invention-title id="d0e71">Method and assembly for the photogrammetric detection of the 3-D shape of an object</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>3510210</doc-number>
<kind>A</kind>
<name>Haney</name>
<date>19700500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>352 39</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>4745290</doc-number>
<kind>A</kind>
<name>Frankel et al.</name>
<date>19880500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>25055917</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5828770</doc-number>
<kind>A</kind>
<name>Leis et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382103</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5889879</doc-number>
<kind>A</kind>
<name>Tsai et al.</name>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382123</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6363169</doc-number>
<kind>B1</kind>
<name>Ritter et al.</name>
<date>20020300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382154</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6434278</doc-number>
<kind>B1</kind>
<name>Hashimoto</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382285</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6580821</doc-number>
<kind>B1</kind>
<name>Roy</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382154</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6724930</doc-number>
<kind>B1</kind>
<name>Kosaka et al.</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382154</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2003/0012408</doc-number>
<kind>A1</kind>
<name>Bouguet et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382103</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>EP</country>
<doc-number>0 760 622</doc-number>
<kind>B1</kind>
<date>19970300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>25</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>6</number-of-drawing-sheets>
<number-of-figures>7</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20030137510</doc-number>
<kind>A1</kind>
<date>20030724</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Massen</last-name>
<first-name>Robert</first-name>
<address>
<city>Ohningen-Wangen</city>
<country>DE</country>
</address>
</addressbook>
<nationality>
<country>DE</country>
</nationality>
<residence>
<country>DE</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Friedman</last-name>
<first-name>Stuart J.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>corpus.e AG</orgname>
<role>03</role>
<address>
<city>Stuttgart</city>
<country>DE</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Bella</last-name>
<first-name>Matthew C.</first-name>
<department>2624</department>
</primary-examiner>
<assistant-examiner>
<last-name>Liew</last-name>
<first-name>Alex</first-name>
</assistant-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/EP01/05935</doc-number>
<kind>00</kind>
<date>20010523</date>
</document-id>
<us-371c124-date>
<date>20021120</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO01/92824</doc-number>
<kind>A </kind>
<date>20011206</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">For an automatic detection of the 3D shape of objects by photogrammetry, the background of the photogrammetric point markers is characterized by area markers which comprise a plurality of point markers and have a characteristic optical configuration that is expressed, e.g., in the color, shape, texture, or gray level of the surface area of the area marker. During the image processing of the photogrammetric images taken of an object, first the area markers and then the point markers present in the respective area markers are referenced in relation to one another. Instead of using area markers, a further embodiment uses constellation-type point marker arrangements, which are first referenced before the individual point markers forming the constellations are referenced. The method is particularly useful for the 3D detection of body parts which have been clad with an envelope marked in accordance with the invention, prior to the photogrammetric evaluation.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="210.65mm" wi="137.08mm" file="US07298889-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="104.82mm" wi="119.04mm" file="US07298889-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="213.19mm" wi="139.62mm" file="US07298889-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="223.27mm" wi="147.57mm" file="US07298889-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="221.91mm" wi="184.74mm" file="US07298889-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="217.25mm" wi="146.81mm" file="US07298889-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="119.46mm" wi="166.29mm" file="US07298889-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<p id="p-0002" num="0001">The invention relates to methods and arrangements for the photogrammetric detection of the 3D shape of an object.</p>
<p id="p-0003" num="0002">Contactless detection of the 3D shape of bodies and objects such as motor vehicle bodies, human body parts and the like is an important measuring method in quality control, in reverse engineering, in the generation of numerical 3D models of physically existing bodies, etc.</p>
<p id="p-0004" num="0003">A number of different methods are known in literature and on the market, which are based either on stripe projection, laser line projection, laser transit time measurement, or photogrammetry, and some are based on a combination of different methods.</p>
<p id="p-0005" num="0004">The so-called passive methods of short-range photogrammetry are especially cost-effective since merely calibrated cameras or digital cameras are needed here, but no expensive projection units or precisely calibrated mechanical structures are required.</p>
<p id="p-0006" num="0005">One typical representative of this group is the “PhotoModeler” software of the EOS company (see the Internet website www.photomodeler.com). This software allows to develop the numerical 3D model of an object from different images of the object which overlap as far as the captured parts of the object are concerned. In doing so, however, the positions of markers stuck onto the body to be measured or of distinct features such as corners or lines of such body need to be manually marked on the screen on the different 2D photographs by the user using a mouse and need to be referenced in pairs, that is, corresponding markers need to be associated with each other manually in the different photographs. Where a dense sequence of XYZ coordinate values is required, several hundred to thousand such assignment processes need to be carried out manually. This is not only extremely tedious, but also prone to errors, since it is almost impossible to assign without errors many markers that look the same.</p>
<p id="p-0007" num="0006">It is further known from photogrammetry to use markers with encoded point numbers (encoded point markers) which bear a pattern with an encoded point number. For this purpose, point encodings are used that are distributed on a line or ring or over an area and that are arranged around the measuring point proper. The identity of the encoded point markers can be recognized automatically by an image processing unit, whereupon the points in the images can then be associated in pairs automatically.</p>
<p id="p-0008" num="0007">These encoded point markers, however, need to be fairly large in order to accommodate a code such as, e.g., a radial bar code, a two-dimensional point code or the like. As a rule, each marker requires an individual code. This in turn prevents this method from being applied in the case of small bodies requiring many markers since due to the restricted spatial conditions, these point markers can no longer be applied in sufficient numbers.</p>
<p id="p-0009" num="0008">Further known are photogrammetric methods which can do without encoded markers and iteratively determine the association of markers that look the same. But these methods require accurately calibrated cameras, are very lengthy, and demand of the user good knowledge of the photogrammetric boundary conditions, in particular the appropriate imaging positions and the necessary amount of overlap, for the iterative solution methods to converge.</p>
<p id="p-0010" num="0009">Patent specification EP 0 760 622, “Sensing Process and Arrangement for the Three-Dimensional Shape in Space of Bodies or Body Parts”, Inventor and Applicant: Robert Massen, describes a method and an arrangement by means of which body parts to be digitized can be marked in a simple and cost-effective way by covering the body part with a tight-fitting elastic envelope featuring markers adapted to be evaluated photogrammetrically. As an example, this patent specification discusses the marking of a human foot to generate 3D models for the production of prostheses or made-to-measure shoes. This method allows, in a simple and cost-effective way, to apply a large number of markers and thereby to provide the basis for obtaining dense XYZ coordinates by photogrammetry. This, however, does not yet solve the problem of simple automatic registration of markers from the overlapping regions of the different images.</p>
<p id="p-0011" num="0010">The object of the present invention is to provide methods and arrangements for the photogrammetric detection of the 3D shape of an object, which are suitable for automatic referencing of photogrammetric markers and for high-resolution digitizing of objects, bodies or body parts, and which more particularly overcome the above-mentioned drawbacks occurring in photogrammetric methods that use encoded point markers.</p>
<p id="p-0012" num="0011">This object is attained by a method of detecting the 3D shape of an object by photogrammetry, comprising the steps of providing point markers and one or more area markers on the surface of the object, each area marker comprising a plurality of point markers, forming a background of the point markers, and having a surface area having a characteristic optical configuration; taking a plurality of photogrammetric images of the object from respective different views; performing an image processing of the images, in which first the area markers respectively corresponding in the images are associated with one another using their characteristic optical configuration, and then the point markers comprised by the area markers and respectively corresponding in the images are associated with one another with the aid of the area marker association; and, using the point marker association, determining the 3D shape of the object by means of a photogrammetric evaluation process.</p>
<p id="p-0013" num="0012">Furthermore, this object is attained by a method of detecting the 3D shape of an object by photogrammetry, comprising the steps of providing point markers on the surface of the object in such a manner that groups of a plurality of point markers are formed, the point markers in a group being arranged in relation to one another such that a characteristic point marker arrangement is produced; taking a plurality of photogrammetric images of the object from respective different views; performing an image processing of the images, in which first the characteristic point marker arrangements respectively corresponding in the images are associated with one another and then, with the aid of such association, the point markers comprised by the characteristic point marker arrangements and respectively corresponding in the images are associated with one another; and, using the point marker association, determining the 3D shape of the object by means of a photogrammetric evaluation process.</p>
<p id="p-0014" num="0013">In addition, the object of the invention is attained by an arrangement for detecting the 3D shape of an object by photogrammetry, comprising an imaging system for obtaining photogrammetric images of different views of the object and a system for measuring and evaluating the images and for determining the 3D shape of the object, which is characterized in that the arrangement further includes point markers and one or more area markers provided on the surface of the object, each area marker comprising a plurality of point markers, forming a background of the point markers, and having a surface area having a characteristic optical configuration.</p>
<p id="p-0015" num="0014">Finally, the object is attained in accordance with the invention by an arrangement for detecting the 3D shape of an object by photogrammetry, comprising an imaging system for obtaining photogrammetric images of different views of the object and a system for measuring and evaluating the images and for determining the 3D shape of the object, which is characterized in that the arrangement further includes point markers which are provided on the surface of the object in such a manner that groups of a plurality of point markers are formed, the point markers in a group being arranged in relation to one another such that a characteristic point marker arrangement is produced.</p>
<p id="p-0016" num="0015">The methods and arrangements in accordance with the invention result in the following advantageous effect:</p>
<p id="p-0017" num="0016">The inclusion of characteristically configured background areas behind the point markers for referencing, and the combination of noncoded point markers to form characteristic superordinate point marker arrangements allows a convenient and precise automated referencing of points even when the object whose 3D shape is to be determined by photogrammetry is small and/or requires a multitude of point markers for a sufficient determination of the 3D shape by means of photogrammetric methods.</p>
<p id="p-0018" num="0017">Advantageous further developments of the invention are characterized in the dependent claims.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<p id="p-0019" num="0018">Further features and advantages of the invention will be apparent from the following description of an embodiment with reference to the drawings, in which:</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 1</figref> shows two different encoded point markers that are part of the prior art;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 2</figref> illustrates an embodiment of the invention in the case of a human foot that is covered by an envelope provided with point markers and colored area markers;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIGS. 3</figref>, <b>4</b> and <b>5</b> are diagrammatic illustrations showing how the photogrammetric evaluation is effected with the aid of the point and area markers illustrated in <figref idref="DRAWINGS">FIG. 2</figref>;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 6</figref> shows a further embodiment of the invention, in which the point markers are combined in groups having characteristic point marker arrangements in the form of a constellation;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 7</figref> is a diagrammatic view of point markers, as are used in a preferred embodiment of the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 1</figref> shows two possible embodiments of the encoded point markers mentioned in the introduction to the specification, that are part of the prior art.</p>
<p id="p-0026" num="0025">The invention will now be explained by way of example, but not in a limiting sense, with reference to the employment of optical detection of the 3D shape of a human foot for obtaining the 3D data required for an automated selection of shapes of shoes that fit or suitable shoe lasts.</p>
<p id="p-0027" num="0026">It is assumed here, likewise by way of example, but not in a limiting sense, that the foot is clad in a tight-fitting, elastic envelope according to the above-mentioned patent EP 0 760 622, which has on its surface noncoded point markers that look the same, in the form of small crosses.</p>
<p id="p-0028" num="0027">As an example, the idea underlying a preferred embodiment of the invention will be discussed, that is, the idea of background marking involving a coloration, carried out region by region, of the background of the point markers. Since it is not possible to print color pictures in patent specifications, the different coloration is represented in the Figures by different black-and-white textures.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 2</figref> shows a human foot <b>1</b>, which is clad in a tight-fitting, elastic envelope <b>2</b>. The envelope <b>2</b> has on its surface a large number of identically looking photogrammetric point markers <b>3</b> in the form of small crosses.</p>
<p id="p-0030" num="0029">The intersection point of the two lines of the point markers represents an XY coordinate in the particular image observed, that can be determined using methods of two-dimensional image processing and can also be exactly determined as a two-dimensional coordinate in relation to the coordinate system of the particular image even in the case of different imaging angles, perspective distortions or the like. When digital cameras are used for image taking, for example, the coordinate system on which each image is based is dictated by the line and column structure of the sensor array and by the piercing point of the optical axis.</p>
<p id="p-0031" num="0030">As an example, only three regions, R<b>1</b>, R<b>2</b> and R<b>3</b> with the different background colors RED, GREEN and YELLOW are reproduced in <figref idref="DRAWINGS">FIG. 1</figref>. It is known to a person of ordinary skill in the art of image processing that color cameras can be used for automatic segmenting of such color regions with the aid of the colors occurring, which the system has been previously trained to recognize, i.e. such color regions can be automatically recognized and distinguished from each other. Methods of this type are described, for example, in German Patent DE 36 39 636 C2, “Automatic Inspection of Lengths of Textile Fabric”, Inventor and Applicant: Robert Massen.</p>
<p id="p-0032" num="0031">It is further known that such color segmenting can be made to be especially robust and independent of the viewing angle if color classifiers are employed that are independent of the brightness (which is dependent on the viewing angle). This can be done by, e.g., classification of each pixel using the color tone following conversion of the RGB color signals to the HSI color range (hue, saturation, intensity).</p>
<p id="p-0033" num="0032">As is shown clearly in <figref idref="DRAWINGS">FIG. 3</figref>, as an example it is assumed that images are taken of the surface of the body to be digitized as defined by the three regions R<b>1</b>, R<b>2</b> and R<b>3</b> from three different imaging positions, A<b>1</b>, A<b>2</b> and A<b>3</b>, using a digital camera <b>4</b>. The respective three two-dimensional images, B<b>1</b>, B<b>2</b> and B<b>3</b>, each show overlapping sectors of the body surface.</p>
<p id="p-0034" num="0033">By a pixel-by-pixel color classification of all three images into the colors RED, GREEN and YELLOW, each of the three images, B<b>1</b>, B<b>2</b> and B<b>3</b>, can be automatically decomposed into three so-called color class images <b>5</b> (in <figref idref="DRAWINGS">FIG. 4</figref>),</p>
<p id="p-0035" num="0034">B<b>1</b>-&gt; B<b>1</b>RED,B<b>1</b>GREEN,B<b>1</b>YELLOW</p>
<p id="p-0036" num="0035">B<b>2</b>-&gt; B<b>2</b>RED,B<b>2</b>GREEN,B<b>2</b>YELLOW</p>
<p id="p-0037" num="0036">B<b>3</b>-&gt; B<b>3</b>RED,B<b>3</b>GREEN,B<b>3</b>YELLOW,</p>
<p id="p-0038" num="0037">as is shown in <figref idref="DRAWINGS">FIG. 4</figref> using the region B<b>2</b> as an example. Accordingly, an automatic association of all regions that match in pairs has now already occurred, that is, while the photogrammetric markers have not yet been referenced, the background regions, R<b>1</b>, R<b>2</b>, and R<b>3</b> of these markers have already been referenced.</p>
<p id="p-0039" num="0038">The background regions, each of which comprises a plurality of point markers, will also be referred to as areas markers below because of their planar configuration, by analogy with the known point markers.</p>
<p id="p-0040" num="0039">According to the invention, the point markers within two referenced regions (area markers) are automatically associated with each other by a comparison of their positions in relation to the region boundaries and/or by an evaluation of the distinguishable figures formed by a plurality of point markers and/or by minor alterations of their shapes.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 5</figref> shows, by way of example, how the photogrammetric point markers situated directly at the region boundaries can be associated with each other based on the information contained in the color class images about these boundaries and the corners formed by regions.</p>
<p id="p-0042" num="0041">As an example, one side of the triangular red region R<b>1</b> is assumed to adjoin the likewise triangular yellow region R<b>3</b> and the green region R<b>2</b> having the form of a parallelogram.</p>
<p id="p-0043" num="0042">Forming along the lateral edge <b>6</b> observed is furthermore a “boundary between three countries”, i.e. a distinct point <b>7</b> where three area markers (regions) marked with three different colors meet. This point may be easily found by comparing all color class images with a neighborhood operator in the two overlapping images B<b>1</b> and B<b>2</b>. One of ordinary skill in the art of color image processing is familiar with such methods. Once the coordinate of this point in the two images B<b>1</b> and B<b>2</b> observed has been established, the noncoded photogrammetric point markers, shown here by the small black-and-white crosses <b>8</b> and <b>9</b> as an example, can easily be associated with one another using classical search methods, beginning at this starting point, parallel to the color region boundary and within the corresponding regions.</p>
<p id="p-0044" num="0043">A further advantage of the color-coded regions is the possibility to check automatically after each image is taken whether the degree of overlap of two images taken is sufficiently large. The degree of overlap results from the number of pixels with the identical color in each image.</p>
<p id="p-0045" num="0044">In addition to the area marking of the background regions by color, texture or similar features, the shape of the background region may also be made to bear information that facilitates automated referencing. For instance, owing to their pointed corners, triangular regions are suited to be easily recognized and associated by means of methods of 2D image processing.</p>
<p id="p-0046" num="0045">Aside from the automated referencing of the photogrammetric point markers based on their position in relation to the region boundaries, other features of these noncoded point markers may also be used. As shown in <figref idref="DRAWINGS">FIG. 6</figref>, according to the invention the photogrammetric point markers are for example grouped to form characteristic point marker arrangements similar to “constellations”, i.e. the relative position of several noncoded point markers within a region is selected such that automatically identifiable geometric shapes are formed, such as triangles, parallelepipeds, oblong structures, etc. In particular, those structures are of advantage which are invariant with respect to affine image transformations such as translation, rotation, elongation, extension, perspective distortion. Such image distortions are always produced when an image sector is taken from two different imaging positions. Such group arrangements are always possible since the position of the photogrammetric markers may be freely selected within limits, in particular in the case of bodies having continuously curved surfaces.</p>
<p id="p-0047" num="0046">It is further possible to make the photogrammetric point markers within one region identifiable by slightly modifying their shapes. This may be done, for example, by varying the length or appearance of the bars, as shown in <figref idref="DRAWINGS">FIG. 7</figref>. This type of encoding differs substantially from the known methods of encoding by means of bar codes or the like. In the method according to the invention, only the point markers within one region are marked differently; it is not necessary for all point markers covering the entire body to be identifiable. The coding may therefore be very simple and only needs to distinguish between few marker patterns. For this reason, small markings may be used.</p>
<p id="p-0048" num="0047">By combining the individual methods of referencing the photogrammetric point markers within an area marker (region), the markers contained in identical regions from two or more overlapping images may be easily associated with one another using methods of two-dimensional image processing and pattern recognition, even in the case of larger color regions.</p>
<p id="p-0049" num="0048">Accordingly, the two method steps of</p>
<p id="p-0050" num="0049">(a) referencing the background regions associated with one another on the basis of planar features, such as color, texture, degree of polarization, NIR reflection, degree of polarization, and the like,</p>
<p id="p-0051" num="0050">(b) referencing the noncoded photogrammetric point markers within one region on the basis of their positions in relation to the regions, their grouping structures, and simple features of shape</p>
<p id="p-0052" num="0051">allow to perform a complete automatic photogrammetric evaluation of a body or body part marked in accordance with the invention.</p>
<p id="p-0053" num="0052">It is, of course, also possible according to the invention to combine the method as described with conventionally encoded photogrammetric point markers, as are illustrated, e.g., in <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0054" num="0053">In the embodiment of the invention using the area markers, various modifications are conceivable. What is always important is that the area markers exhibit a particular optical configuration, so that different area markers can be distinguished from one another in image processing. This optical configuration may consist in, e.g., a characteristic shape, a characteristic color, a characteristic gray level, a characteristic texture, i.e. a characteristic pattern or a characteristic structure, a characteristic gloss, a surface coating applied to the surface of the area markers and having a characteristic degree of polarization, or a characteristic combination of the above-listed optical configuration features. The area markers may furthermore be characterized in their optical configuration in that they emit radiation either in the visible or in the invisible part of the spectrum.</p>
<p id="p-0055" num="0054">Also, the area markers need not necessarily be applied to an envelope. They can just as well be provided directly on the object. Moreover, self-adhesive films may, for example, be attached to the object, the films having the point and area markers applied thereon. Finally, it is also conceivable that the point and area markers are projected onto the surface of the object. The same applies of course to the point markers in the case of the embodiment involving the constellation-type point marker arrangements.</p>
<p id="p-0056" num="0055">The point markers may also have different shapes, and they do not necessarily need to consist of crosses. Instead, they may, e.g., consist of the intersection points of a net.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of detecting and for high-resolution digitizing of the 3D shape of an object, by photogrammetry using a multitude of point markers on said object, comprising the steps of:
<claim-text>applying at least two area markers on the surface of the object, each of said area markers having a surface with a characteristic optical configuration different from the other area markers;</claim-text>
<claim-text>providing a plurality of said point markers in each area marker, whereby said characteristic optical configuration of said area markers forms a background for the point markers;</claim-text>
<claim-text>taking a plurality of photogrammetric images of the object from respective different views;</claim-text>
<claim-text>performing an image processing of the images, in which
<claim-text>first the area markers in the images are automatically recognized by their respective characteristic optical configuration:</claim-text>
<claim-text>then, the area markers respectively corresponding in the images are automatically associated with one another using their characteristic optical configuration, and</claim-text>
<claim-text>for each set of associated area markers, automatically associating the point markers provided within each of said associated area markers and respectively corresponding in the images with one another</claim-text>
<claim-text>determining the 2D coordinates for each of the associated point markers: and</claim-text>
</claim-text>
<claim-text>performing a photogrammetric evaluation process for determining the 3D shape of the object using the said 2D coordinates of the multitude of associated point markers.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the characteristic optical configuration of the surface area of the area markers consists in a characteristic shape, a characteristic color, a characteristic gray level, a characteristic texture, i.e. a characteristic pattern or a characteristic structure, a characteristic gloss, a surface coating applied to the surface of the area markers and having a characteristic degree of polarization, or a characteristic combination of the above-listed optical configuration features.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the area markers are characterized in their optical configuration in that they emit radiation either in the visible or in the invisible part of the spectrum.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the point and area markers are provided on the object by pulling an elastic envelope having the point and area markers applied thereto over the object.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method as claimed in any of <claim-ref idref="CLM-00001">claims 1</claim-ref> to <claim-ref idref="CLM-00003">3</claim-ref>, wherein the point and area markers are provided on the object by sticking self-adhesive films having the point and area markers applied thereto onto the surface of the object.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method as claimed in any of <claim-ref idref="CLM-00001">claims 1</claim-ref> to <claim-ref idref="CLM-00003">3</claim-ref>, wherein the point and area markers are provided on the object by projecting the point and area markers onto the surface of the object.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the point markers comprised by an area marker are provided in a specific arrangement in relation to one another and to the peripheral line of the surface area of the area marker.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method as claimed in <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the point marker association is performed with the aid of the area marker association in such a way that the point markers appearing in different images are associated with one another using their geometric position in relation to the peripheral lines of the areas formed by the area markers and/or using characteristic point marker arrangements formed by the point markers within the area markers.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A method of detecting and for high-resolution digitizing of the 3D shape of an object by photogrammetry using a multitude of point markers on said object, comprising the steps of:
<claim-text>applying said multitude of point markers on the surface of the object;</claim-text>
<claim-text>said point markers forming groups of a plurality of said point markers;</claim-text>
<claim-text>in each of said groups, arranging said point markers within a group in relation to one another for producing a characteristic point marker arrangement different from the characteristic point marker arrangement of the other groups;</claim-text>
<claim-text>taking a plurality of photogrammetric images of the object from respective different views;</claim-text>
<claim-text>performing an image processing of the images, in which
<claim-text>first, said groups of a plurality of said point markers in the images are automatically recognized by their respective characteristic arrangement;</claim-text>
<claim-text>then, the groups respectively corresponding in the images are automatically associated with one another using their characteristic point marker arrangements;</claim-text>
</claim-text>
<claim-text>for each set of said associated groups, automatically associating the point markers comprised by the associated characteristic point marker arrangements and respectively corresponding in the images with one another;
<claim-text>determining the 2D coordinates for each of the associated point markers; and</claim-text>
</claim-text>
<claim-text>performing a photogrammetric evaluation process for determining the 3D shape of the object using the said 2D coordinates of the multitude of associated point markers.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method as claimed in <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the point markers are provided on the object by pulling an elastic envelope having the point markers applied thereto over the object.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method as claimed in <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the point markers are provided on the object by sticking self-adhesive films having the point markers applied thereto onto the surface of the object.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method as claimed in <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the point markers are provided on the object by projecting them onto the surface of the object.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the point markers are noncoded.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the point markers consist of crosses.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the point markers consist of the intersection points of a net.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. An arrangement for detecting and for high-resolution digitizing the 3D shape of an object by photogrammetry using a multitude of point markers on said object, comprising:
<claim-text>an imaging system for obtaining photogrammetric images of different views of the object; and</claim-text>
<claim-text>a system for measuring and evaluating the images and for determining the 3D shape of the object, wherein the arrangement further includes</claim-text>
<claim-text>at least two area markers on the surface of the object, each of said area markers having a surface with a characteristic optical configuration different from the other area markers; and</claim-text>
<claim-text>a plurality of said point markers comprised in each area marker, said characteristic optical configuration of said area markers forming a background for said point markers;</claim-text>
<claim-text>the system being configured for performing an image processing of the images, in which
<claim-text>first the area markers in the images are automatically recognized by their respective characteristic optical configuration;</claim-text>
<claim-text>then, the area markers respectively corresponding in the images are automatically associated with one another using their characteristic optical configuration, and p<b>2</b> for each set of associated area markers, the point markers provided within each of said associated area markers and respectively corresponding in the images are automatically associated with one another;</claim-text>
<claim-text>the 2D coordinates for each of the associated point markers are determined: and</claim-text>
</claim-text>
<claim-text>a photogrammetric evaluation process for determining the 3D shape of the object using said 2D coordinates of the multitude of associated point markers is performed.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The arrangement as claimed in <claim-ref idref="CLM-00016">claim 16</claim-ref>, further including an elastic envelope having the point markers and the one area marker or the plurality of area markers applied thereto and being designed such that it can be pulled over the object, adapting to the shape of the object.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The arrangement as claimed in <claim-ref idref="CLM-00016">claim 16</claim-ref>, further including one or more self-adhesive films having the point markers and the one area marker or the plurality of area markers applied thereto and being designed such that when stuck on the surface of the object, they are in tight-fitting contact with the object.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The arrangement as claimed in <claim-ref idref="CLM-00016">claim 16</claim-ref>, further comprising a projection system designed to be used for projecting the point markers and the one area marker or the plurality of area markers onto the object.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. An arrangement for detecting and for high-resolution digitizing of the 3D shape of an object by photogrammetry using a multitude of point markers on said object, comprising
<claim-text>an imaging system for obtaining photogrammetric images of different views of the object; and</claim-text>
<claim-text>a system for measuring and evaluating the images and for determining the 3D shape of the object, wherein the arrangement further includes groups of said point markers, each group being formed by a plurality of said point markers;</claim-text>
<claim-text>in each of said groups, said point markers within a group are arranged in relation to one another for producing a characteristic point marker arrangement different from the characteristic point marker arrangement of the other groups;</claim-text>
<claim-text>the system being configured for performing an image processing of the images, in which
<claim-text>first said groups of a. plurality of said point markers in the images are automatically recognized by their respective characteristic arrangement:</claim-text>
</claim-text>
<claim-text>then, the groups respectively corresponding in the images are automatically associated with one another using their characteristic point marker arrangements:
<claim-text>for each set of said set of said associated groups, the point markers comprised by the associated characteristic point marker arrangements and respectively corresponding in the images are automatically associated with one another;</claim-text>
<claim-text>the 2D coordinates for each of the associated point markers is determined; and</claim-text>
</claim-text>
<claim-text>a photogrammetric evaluation process is performed for determining the 3D shape of the object using said 2D coordinates of the multitude of associated point markers.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The arrangement as claimed in <claim-ref idref="CLM-00020">claim 20</claim-ref>, further including an elastic envelope having the point markers applied thereto and being designed such that it can be pulled over the object, adapting to the shape of the object.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The arrangement as claimed in <claim-ref idref="CLM-00020">claim 20</claim-ref>, further including one or more self-adhesive films having the point markers applied thereto and being designed such that when stuck on the surface of the object, they are in tight-fitting contact with the object.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The arrangement as claimed in <claim-ref idref="CLM-00020">claim 20</claim-ref>, further comprising a projection system designed to be used for projecting the point markers onto the object.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the object is a body part of a human being.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The arrangement as claimed in <claim-ref idref="CLM-00016">claims 16</claim-ref> or <claim-ref idref="CLM-00020">20</claim-ref>, wherein the object is a body part of a human being.</claim-text>
</claim>
</claims>
</us-patent-grant>
