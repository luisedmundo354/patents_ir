<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07299282-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07299282</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10828776</doc-number>
<date>20040420</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>746</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>15</main-group>
<subgroup>16</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>709224</main-classification>
<further-classification>712223</further-classification>
<further-classification>370469</further-classification>
</classification-national>
<invention-title id="d0e53">State processor for pattern matching in a network monitor device</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>3949369</doc-number>
<kind>A</kind>
<name>Churchill, Jr.</name>
<date>19760400</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>711128</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>4458310</doc-number>
<kind>A</kind>
<name>Chang</name>
<date>19840700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>711119</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>4504907</doc-number>
<kind>A</kind>
<name>Manning et al.</name>
<date>19850300</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>364200</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>4559618</doc-number>
<kind>A</kind>
<name>Houseman et al.</name>
<date>19851200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>365 49</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>4736320</doc-number>
<kind>A</kind>
<name>Bristol</name>
<date>19880400</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>364300</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>4891639</doc-number>
<kind>A</kind>
<name>Nakamura</name>
<date>19900100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>3408255</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>4910668</doc-number>
<kind>A</kind>
<name>Okamoto et al.</name>
<date>19900300</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>711207</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>4972453</doc-number>
<kind>A</kind>
<name>Daniel, III et al.</name>
<date>19901100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>379 10</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5043873</doc-number>
<kind>A</kind>
<name>Muramatsu et al.</name>
<date>19910800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711119</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>5060143</doc-number>
<kind>A</kind>
<name>Lee</name>
<date>19911000</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>364200</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>5101402</doc-number>
<kind>A</kind>
<name>Chui et al.</name>
<date>19920300</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370 17</main-classification></classification-national>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>5247517</doc-number>
<kind>A</kind>
<name>Ross et al.</name>
<date>19930900</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370 855</main-classification></classification-national>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>5247693</doc-number>
<kind>A</kind>
<name>Bristol</name>
<date>19930900</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>395800</main-classification></classification-national>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>5249282</doc-number>
<kind>A</kind>
<name>Segers</name>
<date>19930900</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>395425</main-classification></classification-national>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>5315580</doc-number>
<kind>A</kind>
<name>Phaal</name>
<date>19940500</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370 13</main-classification></classification-national>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>5339268</doc-number>
<kind>A</kind>
<name>Machida</name>
<date>19940800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>365 49</main-classification></classification-national>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>5351243</doc-number>
<kind>A</kind>
<name>Kalkunte et al.</name>
<date>19940900</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370 92</main-classification></classification-national>
</citation>
<citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>5365514</doc-number>
<kind>A</kind>
<name>Hershey et al.</name>
<date>19941100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370 17</main-classification></classification-national>
</citation>
<citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>5369605</doc-number>
<kind>A</kind>
<name>Parks</name>
<date>19941100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>36471509</main-classification></classification-national>
</citation>
<citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>5375070</doc-number>
<kind>A</kind>
<name>Hershey et al.</name>
<date>19941200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>364550</main-classification></classification-national>
</citation>
<citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>5394394</doc-number>
<kind>A</kind>
<name>Crowther et al.</name>
<date>19950200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370 60</main-classification></classification-national>
</citation>
<citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>5414650</doc-number>
<kind>A</kind>
<name>Hekhuis</name>
<date>19950500</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>36471502</main-classification></classification-national>
</citation>
<citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>5414704</doc-number>
<kind>A</kind>
<name>Spinney</name>
<date>19950500</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370 60</main-classification></classification-national>
</citation>
<citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>5422626</doc-number>
<kind>A</kind>
<name>Fish</name>
<date>19950600</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>34053917</main-classification></classification-national>
</citation>
<citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>5430709</doc-number>
<kind>A</kind>
<name>Galloway</name>
<date>19950700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370 13</main-classification></classification-national>
</citation>
<citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>5432776</doc-number>
<kind>A</kind>
<name>Harper</name>
<date>19950700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370 17</main-classification></classification-national>
</citation>
<citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>5493689</doc-number>
<kind>A</kind>
<name>Waclawsky et al.</name>
<date>19960200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>395821</main-classification></classification-national>
</citation>
<citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>5500855</doc-number>
<kind>A</kind>
<name>Hershey et al.</name>
<date>19960300</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370 17</main-classification></classification-national>
</citation>
<citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>5511215</doc-number>
<kind>A</kind>
<name>Terasaka et al.</name>
<date>19960400</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>395800</main-classification></classification-national>
</citation>
<citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>5530834</doc-number>
<kind>A</kind>
<name>Colloff et al.</name>
<date>19960600</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>711136</main-classification></classification-national>
</citation>
<citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>5530958</doc-number>
<kind>A</kind>
<name>Agarwal et al.</name>
<date>19960600</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>711  3</main-classification></classification-national>
</citation>
<citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>5535338</doc-number>
<kind>A</kind>
<name>Krause et al.</name>
<date>19960700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>3952002</main-classification></classification-national>
</citation>
<citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>5568471</doc-number>
<kind>A</kind>
<name>Hershey et al.</name>
<date>19961000</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370 17</main-classification></classification-national>
</citation>
<citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>5574875</doc-number>
<kind>A</kind>
<name>Stansfield et al.</name>
<date>19961100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>395403</main-classification></classification-national>
</citation>
<citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>5586266</doc-number>
<kind>A</kind>
<name>Hershey et al.</name>
<date>19961200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39520011</main-classification></classification-national>
</citation>
<citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>5586288</doc-number>
<kind>A</kind>
<name>Dahlberg</name>
<date>19961200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>395435</main-classification></classification-national>
</citation>
<citation>
<patcit num="00037">
<document-id>
<country>US</country>
<doc-number>5598410</doc-number>
<kind>A</kind>
<name>Stone</name>
<date>19970100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370469</main-classification></classification-national>
</citation>
<citation>
<patcit num="00038">
<document-id>
<country>US</country>
<doc-number>5606668</doc-number>
<kind>A</kind>
<name>Shwed</name>
<date>19970200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39520011</main-classification></classification-national>
</citation>
<citation>
<patcit num="00039">
<document-id>
<country>US</country>
<doc-number>5608662</doc-number>
<kind>A</kind>
<name>Large et al.</name>
<date>19970300</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>36472401</main-classification></classification-national>
</citation>
<citation>
<patcit num="00040">
<document-id>
<country>US</country>
<doc-number>5634009</doc-number>
<kind>A</kind>
<name>Iddon et al.</name>
<date>19970500</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39520011</main-classification></classification-national>
</citation>
<citation>
<patcit num="00041">
<document-id>
<country>US</country>
<doc-number>5651002</doc-number>
<kind>A</kind>
<name>Van Seters et al.</name>
<date>19970700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370392</main-classification></classification-national>
</citation>
<citation>
<patcit num="00042">
<document-id>
<country>US</country>
<doc-number>5680585</doc-number>
<kind>A</kind>
<name>Bruell</name>
<date>19971000</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>703 26</main-classification></classification-national>
</citation>
<citation>
<patcit num="00043">
<document-id>
<country>US</country>
<doc-number>5684954</doc-number>
<kind>A</kind>
<name>Kaiserswerth et al.</name>
<date>19971100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>3952002</main-classification></classification-national>
</citation>
<citation>
<patcit num="00044">
<document-id>
<country>US</country>
<doc-number>5703877</doc-number>
<kind>A</kind>
<name>Nuber et al.</name>
<date>19971200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370395</main-classification></classification-national>
</citation>
<citation>
<patcit num="00045">
<document-id>
<country>US</country>
<doc-number>5717916</doc-number>
<kind>A</kind>
<name>Verma</name>
<date>19980200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>395607</main-classification></classification-national>
</citation>
<citation>
<patcit num="00046">
<document-id>
<country>US</country>
<doc-number>5720032</doc-number>
<kind>A</kind>
<name>Picazo, Jr. et al.</name>
<date>19980200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>3952002</main-classification></classification-national>
</citation>
<citation>
<patcit num="00047">
<document-id>
<country>US</country>
<doc-number>5721827</doc-number>
<kind>A</kind>
<name>Logan et al.</name>
<date>19980200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709217</main-classification></classification-national>
</citation>
<citation>
<patcit num="00048">
<document-id>
<country>US</country>
<doc-number>5732213</doc-number>
<kind>A</kind>
<name>Gessel et al.</name>
<date>19980300</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39520011</main-classification></classification-national>
</citation>
<citation>
<patcit num="00049">
<document-id>
<country>US</country>
<doc-number>5740355</doc-number>
<kind>A</kind>
<name>Watanabe et al.</name>
<date>19980400</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39518321</main-classification></classification-national>
</citation>
<citation>
<patcit num="00050">
<document-id>
<country>US</country>
<doc-number>5749087</doc-number>
<kind>A</kind>
<name>Hoover et al.</name>
<date>19980500</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>711108</main-classification></classification-national>
</citation>
<citation>
<patcit num="00051">
<document-id>
<country>US</country>
<doc-number>5761424</doc-number>
<kind>A</kind>
<name>Adams et al.</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39520047</main-classification></classification-national>
</citation>
<citation>
<patcit num="00052">
<document-id>
<country>US</country>
<doc-number>5761429</doc-number>
<kind>A</kind>
<name>Thompson</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</citation>
<citation>
<patcit num="00053">
<document-id>
<country>US</country>
<doc-number>5764638</doc-number>
<kind>A</kind>
<name>Ketchum</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370401</main-classification></classification-national>
</citation>
<citation>
<patcit num="00054">
<document-id>
<country>US</country>
<doc-number>5781735</doc-number>
<kind>A</kind>
<name>Southard</name>
<date>19980700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39520054</main-classification></classification-national>
</citation>
<citation>
<patcit num="00055">
<document-id>
<country>US</country>
<doc-number>5784298</doc-number>
<kind>A</kind>
<name>Hershey et al.</name>
<date>19980700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>364557</main-classification></classification-national>
</citation>
<citation>
<patcit num="00056">
<document-id>
<country>US</country>
<doc-number>5787253</doc-number>
<kind>A</kind>
<name>McCreery et al.</name>
<date>19980700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39520061</main-classification></classification-national>
</citation>
<citation>
<patcit num="00057">
<document-id>
<country>US</country>
<doc-number>5793954</doc-number>
<kind>A</kind>
<name>Baker et al.</name>
<date>19980800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>3952008</main-classification></classification-national>
</citation>
<citation>
<patcit num="00058">
<document-id>
<country>US</country>
<doc-number>5799154</doc-number>
<kind>A</kind>
<name>Kuriyan</name>
<date>19980800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709223</main-classification></classification-national>
</citation>
<citation>
<patcit num="00059">
<document-id>
<country>US</country>
<doc-number>5802054</doc-number>
<kind>A</kind>
<name>Bellenger</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370401</main-classification></classification-national>
</citation>
<citation>
<patcit num="00060">
<document-id>
<country>US</country>
<doc-number>5805808</doc-number>
<kind>A</kind>
<name>Hasani et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>3952002</main-classification></classification-national>
</citation>
<citation>
<patcit num="00061">
<document-id>
<country>US</country>
<doc-number>5812529</doc-number>
<kind>A</kind>
<name>Czarnik et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370245</main-classification></classification-national>
</citation>
<citation>
<patcit num="00062">
<document-id>
<country>US</country>
<doc-number>5819028</doc-number>
<kind>A</kind>
<name>Manghirmalani et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>3951851</main-classification></classification-national>
</citation>
<citation>
<patcit num="00063">
<document-id>
<country>US</country>
<doc-number>5825774</doc-number>
<kind>A</kind>
<name>Ready et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370401</main-classification></classification-national>
</citation>
<citation>
<patcit num="00064">
<document-id>
<country>US</country>
<doc-number>5826096</doc-number>
<kind>A</kind>
<name>Baxter</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39580024</main-classification></classification-national>
</citation>
<citation>
<patcit num="00065">
<document-id>
<country>US</country>
<doc-number>5835726</doc-number>
<kind>A</kind>
<name>Shwed et al.</name>
<date>19981100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39520059</main-classification></classification-national>
</citation>
<citation>
<patcit num="00066">
<document-id>
<country>US</country>
<doc-number>5838919</doc-number>
<kind>A</kind>
<name>Schwaller et al.</name>
<date>19981100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39520054</main-classification></classification-national>
</citation>
<citation>
<patcit num="00067">
<document-id>
<country>US</country>
<doc-number>5841895</doc-number>
<kind>A</kind>
<name>Huffman</name>
<date>19981100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382155</main-classification></classification-national>
</citation>
<citation>
<patcit num="00068">
<document-id>
<country>US</country>
<doc-number>5850386</doc-number>
<kind>A</kind>
<name>Anderson et al.</name>
<date>19981200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370241</main-classification></classification-national>
</citation>
<citation>
<patcit num="00069">
<document-id>
<country>US</country>
<doc-number>5850388</doc-number>
<kind>A</kind>
<name>Anderson et al.</name>
<date>19981200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification> 37252</main-classification></classification-national>
</citation>
<citation>
<patcit num="00070">
<document-id>
<country>US</country>
<doc-number>5862335</doc-number>
<kind>A</kind>
<name>Welch, Jr. et al.</name>
<date>19990100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>39520054</main-classification></classification-national>
</citation>
<citation>
<patcit num="00071">
<document-id>
<country>US</country>
<doc-number>5878420</doc-number>
<kind>A</kind>
<name>de la Salle</name>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>707 10</main-classification></classification-national>
</citation>
<citation>
<patcit num="00072">
<document-id>
<country>US</country>
<doc-number>5893155</doc-number>
<kind>A</kind>
<name>Cheriton</name>
<date>19990400</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>711144</main-classification></classification-national>
</citation>
<citation>
<patcit num="00073">
<document-id>
<country>US</country>
<doc-number>5903754</doc-number>
<kind>A</kind>
<name>Pearson</name>
<date>19990500</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>395680</main-classification></classification-national>
</citation>
<citation>
<patcit num="00074">
<document-id>
<country>US</country>
<doc-number>5917821</doc-number>
<kind>A</kind>
<name>Gobuyan et al.</name>
<date>19990600</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370392</main-classification></classification-national>
</citation>
<citation>
<patcit num="00075">
<document-id>
<country>US</country>
<doc-number>6003123</doc-number>
<kind>A</kind>
<name>Carter et al.</name>
<date>19991200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>711207</main-classification></classification-national>
</citation>
<citation>
<patcit num="00076">
<document-id>
<country>US</country>
<doc-number>6014380</doc-number>
<kind>A</kind>
<name>Hendel et al.</name>
<date>20000100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370392</main-classification></classification-national>
</citation>
<citation>
<patcit num="00077">
<document-id>
<country>US</country>
<doc-number>6047304</doc-number>
<kind>A</kind>
<name>Ladwig et al.</name>
<date>20000400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>708530</main-classification></classification-national>
</citation>
<citation>
<patcit num="00078">
<document-id>
<country>US</country>
<doc-number>6097699</doc-number>
<kind>A</kind>
<name>Chen et al.</name>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370231</main-classification></classification-national>
</citation>
<citation>
<patcit num="00079">
<document-id>
<country>US</country>
<doc-number>6101554</doc-number>
<kind>A</kind>
<name>Creedon et al.</name>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709253</main-classification></classification-national>
</citation>
<citation>
<patcit num="00080">
<document-id>
<country>US</country>
<doc-number>6115393</doc-number>
<kind>A</kind>
<name>Engel et al.</name>
<date>20000900</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370469</main-classification></classification-national>
</citation>
<citation>
<patcit num="00081">
<document-id>
<country>US</country>
<doc-number>6172990</doc-number>
<kind>B1</kind>
<name>Deb et al.</name>
<date>20010100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370474</main-classification></classification-national>
</citation>
<citation>
<patcit num="00082">
<document-id>
<country>US</country>
<doc-number>6226265</doc-number>
<kind>B1</kind>
<name>Nakamichi et al.</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370235</main-classification></classification-national>
</citation>
<citation>
<patcit num="00083">
<document-id>
<country>US</country>
<doc-number>6226267</doc-number>
<kind>B1</kind>
<name>Spinney et al.</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370235</main-classification></classification-national>
</citation>
<citation>
<patcit num="00084">
<document-id>
<country>US</country>
<doc-number>6269330</doc-number>
<kind>B1</kind>
<name>Cidon et al.</name>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>704 43</main-classification></classification-national>
</citation>
<citation>
<patcit num="00085">
<document-id>
<country>US</country>
<doc-number>6272151</doc-number>
<kind>B1</kind>
<name>Gupta et al.</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370489</main-classification></classification-national>
</citation>
<citation>
<patcit num="00086">
<document-id>
<country>US</country>
<doc-number>6279113</doc-number>
<kind>B1</kind>
<name>Vaidya</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>713201</main-classification></classification-national>
</citation>
<citation>
<patcit num="00087">
<document-id>
<country>US</country>
<doc-number>6282570</doc-number>
<kind>B1</kind>
<name>Leung et al.</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</citation>
<citation>
<patcit num="00088">
<document-id>
<country>US</country>
<doc-number>6330226</doc-number>
<kind>B1</kind>
<name>Chapman et al.</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370232</main-classification></classification-national>
</citation>
<citation>
<patcit num="00089">
<document-id>
<country>US</country>
<doc-number>6363056</doc-number>
<kind>B1</kind>
<name>Beigi et al.</name>
<date>20020300</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370252</main-classification></classification-national>
</citation>
<citation>
<patcit num="00090">
<document-id>
<country>US</country>
<doc-number>6381306</doc-number>
<kind>B1</kind>
<name>Lawson et al.</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>379 32</main-classification></classification-national>
</citation>
<citation>
<patcit num="00091">
<document-id>
<country>US</country>
<doc-number>6424624</doc-number>
<kind>B1</kind>
<name>Galand et al.</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370231</main-classification></classification-national>
</citation>
<citation>
<patcit num="00092">
<document-id>
<country>US</country>
<doc-number>6430184</doc-number>
<kind>B1</kind>
<name>Robins et al.</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370392</main-classification></classification-national>
</citation>
<citation>
<patcit num="00093">
<document-id>
<country>US</country>
<doc-number>6430409</doc-number>
<kind>B1</kind>
<name>Rossmann</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>4554221</main-classification></classification-national>
</citation>
<citation>
<patcit num="00094">
<document-id>
<country>US</country>
<doc-number>6453345</doc-number>
<kind>B2</kind>
<name>Trcka et al.</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</citation>
<citation>
<patcit num="00095">
<document-id>
<country>US</country>
<doc-number>6516337</doc-number>
<kind>B1</kind>
<name>Tripp et al.</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709202</main-classification></classification-national>
</citation>
<citation>
<patcit num="00096">
<document-id>
<country>US</country>
<doc-number>6519568</doc-number>
<kind>B1</kind>
<name>Harvey et al.</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>705  1</main-classification></classification-national>
</citation>
<citation>
<patcit num="00097">
<document-id>
<country>US</country>
<doc-number>6625657</doc-number>
<kind>B1</kind>
<name>Bullard</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709237</main-classification></classification-national>
</citation>
<citation>
<patcit num="00098">
<document-id>
<country>US</country>
<doc-number>6651099</doc-number>
<kind>B1</kind>
<name>Dietz et al.</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</citation>
<citation>
<patcit num="00099">
<document-id>
<country>US</country>
<doc-number>6690668</doc-number>
<kind>B1</kind>
<name>Szczepanek et al.</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370392</main-classification></classification-national>
</citation>
<citation>
<patcit num="00100">
<document-id>
<country>JP</country>
<doc-number>2003-44510</doc-number>
<kind>A</kind>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00101">
<othercit>“Technical Note: the Narus System,” Downloaded Apr. 29, 1999 from www.narus.com, Narus Corporation, Redwood City California.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00102">
<othercit>R. Periakaruppam and E. Nemeth. “GTrace-A Graphical Traceroute Tool.” 1999 Usenix LISA. Available on www.caida.org, URL: http://www.caida.org/outreach/papers/1999/GTrace/GTrace.pdf.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00103">
<othercit>W. Stallings, “Packet Filtering in the SNMP Remote Monitor.” Nov. 1994. Available on www.ddj.com, URL: http://www.ddj.com/documents/s=1013/ddj9411h/9411h.htm.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00104">
<othercit>Advanced Methods for Storage and Retrieval in Image; http://www.cs.tulane.edu/ww/Prototype/proposal.html; 1998.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00105">
<othercit>Measurement and Analysis of the Digital DECT Propagation Channel; IEEE; 1998.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00106">
<othercit>“NetFlow Services and Applications,” Cisco White Paper, Mar. 1999, pp. 1-27, Cisco Systems, Inc. San Jose, CA.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00107">
<othercit>N. Brownlee, C. Mills and G. Ruth “Traffic Flow Measurement: Architecture,” IETF Standard-Working-Draft, Internet Engineering Task Force, IETF, CH, vol. RTFM, No. 7, Jun. 1999.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00108">
<othercit>Rona J. Prufer, “Network Advisor Protocol Analysis: Decodes,” Hewlett-Packard Journal, Hewlett-Packard Co. Palo Alto, CA, vol. 43, No. 5, Oct. 1, 1992, pp. 34-40.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00109">
<othercit>Walter Gora, “Universal Network Monitoring based on FAN.1,” Raviv J. International Council For Computer Communication, Computer Communication Technologies For The 90's, Tel Aviv, Oct. 30-Nov. 3, 1988, Proc. Of The International Conference On Computer Communication, Amsterdam, Elsevier, NL, conf. 9, Oct. 30, 1988, pp. 104-114.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00110">
<othercit>G. Giacolone, R. Busch, F. Creed, A. Davidovich, S. Divakaruni, C. Drake, C. Ematrudo, J. Fifield, M. Hodges, W. Howell, P. Jenkins, M. Kozyrczak, C. Miller, T. Obremski, C. Reed, G. Rohrbaugh, M. Vincent, T. von Reyn and J. Zimmermann, “A 1MB, 100MHz Integrated L2 Cache Memory with 128b Interface and ECC Protection,” Solid-State Circuits Conference, 1996. Digest of Technical Papers, 42<sup>nd </sup>ISSCC., 1996 IEEE International, San Francisco, CA, Feb. 8-10, 1996, New York, NY, IEEE, US, Feb. 8, 1996, pp. 370-371, 475.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00111">
<othercit>David C. Feldmeier, “Improving Gateway Performance With A Routing-Table Cache,” Networks: Evolution Or Revolution? New Orleans, Mar. 27-31, 1988, Proceedings of the Annual Joint Conference of the Computer and Communications Societies. (Infocom), New York, IEEE, US, conf. 7, Mar. 27, 1988, pp. 306-307.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00112">
<othercit>J.K. Peir, W.W. Hsu, H. Young and S. Ong, “Fast Cache Access with Full-Map Block Directory,” Proceedings of the 1997 IEEE International Conference on Computer Design: VLSI In Computers and Processors, 1997, ICCD '97, Austin, TX, Oct. 12-15, 1997, Los Alamitos, CA, IEEE Computer Society, Oct. 12, 1997, pp. 578-579.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00113">
<othercit>J.H. Park and K.M. George. “Efficient Parallel Hardware Algorithms For String Matching,” Microprocessors and Microsystems, IPC Business Press Ltd., London, GB, vol. 23, No. 3, Oct. 1, 1999, pp. 155-168.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00114">
<othercit>Andrew S. Tanenbaum, “Computer Networks” Third Edition, Prentice-Hall, Inc. 1996, section 1.4, pp. 28-44.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>4</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>709200-202</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709213</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709220-224</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709230</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709238</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709250</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>712  1</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>712208</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>712223</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370392</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370469</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>23</number-of-drawing-sheets>
<number-of-figures>27</number-of-figures>
</figures>
<us-related-documents>
<division>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>09608267</doc-number>
<kind>00</kind>
<date>20000630</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>6789116</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>10828776</doc-number>
</document-id>
</child-doc>
</relation>
</division>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60141903</doc-number>
<kind>00</kind>
<date>19990630</date>
</document-id>
</us-provisional-application>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20040199630</doc-number>
<kind>A1</kind>
<date>20041007</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Sarkissian</last-name>
<first-name>Haig A.</first-name>
<address>
<city>San Antonio</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Dietz</last-name>
<first-name>Russell S.</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Koppenhaver</last-name>
<first-name>Andrew A.</first-name>
<address>
<city>Littleton</city>
<state>CO</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Rosenfeld</last-name>
<first-name>Dov</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<orgname>Inventek</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Hi/fn Inc.</orgname>
<role>02</role>
<address>
<city>Los Gatos</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Meky</last-name>
<first-name>Moustafa</first-name>
<department>2157</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A processor for processing contents of packets passing through a connection point on a computer network. The processor includes a searching apparatus having one or more comparators for searching for a reference string in the contents of a packet, and processes contents of all packets passing through the connection point in real time. In one implementation, the processor is programmable and has an instruction set that includes an instruction for invoking the searching apparatus to search for a specified reference string in the packet starting at an unknown location within a range of the packet.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="167.98mm" wi="221.06mm" file="US07299282-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="200.41mm" wi="164.59mm" file="US07299282-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="240.37mm" wi="175.01mm" orientation="landscape" file="US07299282-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="259.76mm" wi="191.52mm" orientation="landscape" file="US07299282-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="237.24mm" wi="171.53mm" file="US07299282-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="210.40mm" wi="168.06mm" file="US07299282-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="201.17mm" wi="148.59mm" file="US07299282-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="183.22mm" wi="149.18mm" file="US07299282-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="234.36mm" wi="173.82mm" file="US07299282-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="247.23mm" wi="178.31mm" file="US07299282-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="233.60mm" wi="178.90mm" file="US07299282-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="206.59mm" wi="195.07mm" file="US07299282-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="230.63mm" wi="151.64mm" file="US07299282-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="225.64mm" wi="150.54mm" file="US07299282-20071120-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="254.76mm" wi="188.04mm" orientation="landscape" file="US07299282-20071120-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="244.69mm" wi="161.04mm" orientation="landscape" file="US07299282-20071120-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="118.36mm" wi="119.13mm" file="US07299282-20071120-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="242.15mm" wi="169.16mm" file="US07299282-20071120-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="213.87mm" wi="149.78mm" file="US07299282-20071120-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="223.10mm" wi="169.76mm" orientation="landscape" file="US07299282-20071120-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="254.51mm" wi="185.67mm" orientation="landscape" file="US07299282-20071120-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00021" num="00021">
<img id="EMI-D00021" he="252.14mm" wi="166.96mm" file="US07299282-20071120-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00022" num="00022">
<img id="EMI-D00022" he="231.90mm" wi="159.43mm" orientation="landscape" file="US07299282-20071120-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00023" num="00023">
<img id="EMI-D00023" he="254.76mm" wi="160.87mm" orientation="landscape" file="US07299282-20071120-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading>
<p id="p-0002" num="0001">This application is a division of U.S. application Ser. No. 09/608,267 for STATE PROCESSOR FOR PATTERN MATCHING IN A NETWORK MONITOR DEVICE to inventors Sarkissian, et al., filed Jun. 30, 2000 now U.S. Pat. No. 6,789,116.</p>
<p id="p-0003" num="0002">U.S. application Ser. No. 09/608,267 claims the benefit of U.S. Provisional Patent Application Ser. No.: 60/141,903 for METHOD AND APPARATUS FOR MONITORING TRAFFIC IN A NETWORK to inventors Dietz, et al., filed Jun. 30, 1999, the contents of which are incorporated herein by reference.</p>
<p id="p-0004" num="0003">U.S. application Ser. No. 09/608,267 is related to the following U.S. patent applications, each filed concurrently with that application and each assigned to Apptitude, Inc., the assignee of the present invention:</p>
<p id="p-0005" num="0004">U.S. patent application Ser. No. 09/608,237 for METHOD AND APPARATUS FOR MONITORING TRAFFIC IN A NETWORK, to inventors Dietz, et al., filed Jun. 30, 2000, and incorporated herein by reference.</p>
<p id="p-0006" num="0005">U.S. patent application Ser. No. 09/609,179 for PROCESSING PROTOCOL SPECIFIC INFORMATION IN PACKETS SPECIFIED BY A PROTOCOL DESCRIPTION LANGUAGE, to inventors Koppenhaver, et al., filed Jun. 30, 2000, and incorporated herein by reference.</p>
<p id="p-0007" num="0006">U.S. patent application Ser. No. 09/608,126 for RE-USING INFORMATION FROM DATA TRANSACTIONS FOR MAINTAINING STATISTICS IN NETWORK MONITORING, to inventors Dietz, et al., filed Jun. 30, 2000, and incorporated herein by reference.</p>
<p id="p-0008" num="0007">U.S. patent application Ser. No. 09/608,266 for ASSOCIATIVE CACHE STRUCTURE FOR LOOKUPS AND UPDATES OF FLOW RECORDS IN A NETWORK MONITOR, to inventors Sarkissian, et al., filed Jun. 30, 2000, and incorporated herein by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF INVENTION</heading>
<p id="p-0009" num="0008">The present invention relates to computer networks, specifically to the real-time elucidation of packets communicated within a data network, including classification according to protocol and application program.</p>
<heading id="h-0003" level="1">BACKGROUND</heading>
<p id="p-0010" num="0009">There has long been a need for network activity monitors. This need has become especially acute, however, given the recent popularity of the Internet and other interconnected networks. In particular, there is a need for a real-time network monitor that can provide details as to the application programs being used. Such a monitor should enable non-intrusive, remote detection, characterization, analysis, and capture of all information passing through any point on the network (i.e., of all packets and packet streams passing through any location in the network). Not only should all the packets be detected and analyzed, but for each of these packets the network monitor should determine the protocol (e.g., http, ftp, H.323, VPN, etc.), the application/use within the protocol (e.g., voice, video, data, real-time data, etc.), and an end user's pattern of use within each application or the application context (e.g., options selected, service delivered, duration, time of day, data requested, etc.). Also, the network monitor should not be reliant upon server resident information such as log files. Rather, it should allow a user such as a network administrator or an Internet service provider (ISP) the means to measure and analyze network activity objectively; to customize the type of data that is collected and analyzed; to undertake real time analysis; and to receive timely notification of network problems.</p>
<p id="p-0011" num="0010">Related and incorporated by reference U.S. patent application Ser. No. 09/608,237 for METHOD AND APPARATUS FOR MONITORING TRAFFIC INA NETWORK, to inventors Dietz, et al, describes a network monitor that includes carrying out protocol specific operations on individual packets including extracting information from header fields in the packet to use for building a signature for identifying the conversational flow of the packet and for recognizing future packets as belonging to a previously encountered flow. A parser subsystem includes a parser for recognizing different patterns in the packet that identify the protocols used. For each protocol recognized, a slicer extracts important packet elements from the packet. These form a signature (i.e., key) for the packet. The slicer also preferably generates a hash for rapidly identifying a flow that may have this signature from a database of known flows.</p>
<p id="p-0012" num="0011">The flow signature of the packet, the hash and at least some of the payload are passed to an analyzer subsystem. In a hardware embodiment, the analyzer subsystem includes a unified flow key buffer (UFKB) for receiving parts of packets from the parser subsystem and for storing signatures in process, a lookup/update engine (LUE) to lookup a database of flow records for previously encountered conversational flows to determine whether a signature is from an existing flow, a state processor (SP) for performing state processing, a flow insertion and deletion engine (FIDE) for inserting new flows into the database of flows, a memory for storing the database of flows, and a cache for speeding up access to the memory containing the flow database. The LUE, SP, and FIDE are all coupled to the UFKB, and to the cache.</p>
<p id="p-0013" num="0012">Each flow-entry includes one or more statistical measures, e.g., the packet count related to the flow, the time of arrival of a packet, the time differential.</p>
<p id="p-0014" num="0013">In the preferred hardware embodiment, each of the LUE, state processor, and FIDE operate independently from the other two engines. The state processor performs one or more operations specific to the state of the flow.</p>
<p id="p-0015" num="0014">The state processor analyzes both new and existing flows in order to classify them by application. It does this by proceeding from state to state based on rules defined by the engineer. A rule is a test followed by the next state to proceed to if the test is true. The state processor goes through each rule until the test is true or there are no more tests to perform. The state processor starts the process by using the last protocol recognized by parser subsystem as an offset into a jump table (the jump vector). The jump table takes us to the instructions to use for that protocol. Most instructions test something in the unified flow key buffer or the flow-entry if it exists. The state processor may have to test bits, do comparisons, add or subtract to perform the test.</p>
<p id="p-0016" num="0015">One of the common operations that may be require of a state processor is to search the contents of a packet for the existence of one of a set of known strings. Such identification may be useful for furthering the process of identifying the application content of a conversational flow. For example, it may be desired to search for the uniform resource locator (URL) of packets related to the http protocol, or there may be a need to search for particular strings that identify protocols or aspects of protocols, for example, the strings “port”, “get”, “post,” and so forth. Any of these strings may be in a packet, and which string and wherein the packet the string resides is often unknown.</p>
<p id="p-0017" num="0016">In most common processing systems, the set of instructions implemented are general purpose in nature. All processing systems have a typical set of instructions related to the analysis and manipulation of the Instruction and program counters. These instructions include Jump, Call and Return. In addition, these same processing systems contain the appropriate instructions to analyze and manipulate registers and memory locations. These instructions include Increment, Decrement and Move, Compare and Logical manipulation.</p>
<p id="p-0018" num="0017">While a state processor can includes such a basic set of standard instructions, implementing searches for known for one or more known strings in a target data stream may take too long using such a set of standard instructions in order to accommodate the high speed of packet arrival. It is therefore desirable to have a processor that can perform some specific search functions that are required to evaluate the content of and data within packets on networks extremely rapidly.</p>
<p id="p-0019" num="0018">Specifically, there is a need for a searching apparatus that may be part of the state processor and that can rapidly search a target data stream for a specified reference string. Furthermore, there is a need for a programmable processor that includes instructions that invoke the searching apparatus to perform such a search.</p>
<p id="p-0020" num="0019">Using such a processor in a network monitor enables the monitor to scale and meet any network speed requirements.</p>
<heading id="h-0004" level="1">SUMMARY</heading>
<p id="p-0021" num="0020">Disclosed herein is a processor for processing contents of packets passing through a connection point on a computer network. The processor includes a searching apparatus having one or more comparators for searching for a reference string in the contents of a packet, and processes contents of all packets passing through the connection point in real time. In one implementation, the processor is programmable and has an instruction set that includes an instruction for invoking the searching apparatus to search for a specified reference string in the packet starting at an unknown location within a range of the packet.</p>
<p id="p-0022" num="0021">Embodiments of searching apparatus that can be used in the processor also are disclosed. The searching apparatus is configured to search for a reference string of N<sub>R </sub>units in target data starting from any of a set of starting positions within the target data. The searching apparatus includes a reference register configured to receive the N<sub>R </sub>units of a reference string, one or more target data registers coupled in series to receive the target data; and, a plurality of comparator sets, one comparator set corresponding to each of the starting positions. The comparator set of a particular starting position is coupled to each unit of the reference register and to N<sub>R </sub>units of the target data registers starting from the particular starting position and comparing the reference register contents to corresponding contents of N<sub>R </sub>contiguous units of the target data registers starting from the particular starting position. Each comparator set indicates if there is a match of the first reference string in the target data starting from its corresponding different starting position. The first plurality of comparator sets indicates in parallel if the first reference string is contained in the target data registers starting at any of the starting positions.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0023" num="0022">Although the present invention is better understood by referring to the detailed preferred embodiments, these should not be taken to limit the present invention to any specific embodiment because such embodiments are provided only for the purposes of explanation. The embodiments, in turn, are explained with the aid of the following figures.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 1</figref> is a functional block diagram of a network embodiment of the present invention in which a monitor is connected to analyze packets passing at a connection point.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram representing an example of some of the packets and their formats that might be exchanged in starting, as an illustrative example, a conversational flow between a client and server on a network being monitored and analyzed. A pair of flow signatures particular to this example and to embodiments of the present invention is also illustrated. This represents some of the possible flow signatures that can be generated and used in the process of analyzing packets and of recognizing the particular server applications that produce the discrete application packet exchanges.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 3</figref> is a functional block diagram of a process embodiment of the present invention that can operate as the packet monitor shown in <figref idref="DRAWINGS">FIG. 1</figref>. This process may be implemented in software or hardware.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart of a high-level protocol language compiling and optimization process, which in one embodiment may be used to generate data for monitoring packets according to versions of the present invention.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart of a packet parsing process used as part of the parser in an embodiment of the inventive packet monitor.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart of a packet element extraction process that is used as part of the parser in an embodiment of the inventive packet monitor.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart of a flow-signature building process that is used as part of the parser in the inventive packet monitor.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart of a monitor lookup and update process that is used as part of the analyzer in an embodiment,of the inventive packet monitor.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart of an exemplary Sun Microsystems Remote Procedure Call application than may be recognized by the inventive packet monitor.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 10</figref> is a functional block diagram of a hardware parser subsystem including the pattern recognizer and extractor that can form part of the parser module in an embodiment of the inventive packet monitor.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 11</figref> is a functional block diagram of a hardware analyzer including a state processor that can form part of an embodiment of the inventive packet monitor.</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 12</figref> is a functional block diagram of a flow insertion and deletion engine process that can form part of the analyzer in an embodiment of the inventive packet monitor.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 13</figref> is a flowchart of a state processing process that can form part of the analyzer in an embodiment of the inventive packet monitor.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 14</figref> is a simple functional block diagram of a process embodiment of the present invention that can operate as the packet monitor shown in <figref idref="DRAWINGS">FIG. 1</figref>. This process may be implemented in software.</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 15</figref> is a functional block diagram of how the packet monitor of <figref idref="DRAWINGS">FIG. 3</figref> (and <figref idref="DRAWINGS">FIGS. 10 and 11</figref>) may operate on a network with a processor such as a microprocessor.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 16</figref> is an example of the top (MAC) layer of an Ethernet packet and some of the elements that may be extracted to form a signature according to one aspect of the invention.</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 17A</figref> is an example of the header of an Ethertype type of Ethernet packet of <figref idref="DRAWINGS">FIG. 16</figref> and some of the elements that may be extracted to form a signature according to one aspect of the invention.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 17B</figref> is an example of an IP packet, for example, of the Ethertype packet shown in <figref idref="DRAWINGS">FIGS. 16 and 17A</figref>, and some of the elements that may be extracted to form a signature according to one aspect of the invention.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 18A</figref> is a three dimensional structure that can be used to store elements of the pattern, parse and extraction database used by the parser subsystem in accordance to one embodiment of the invention.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 18B</figref> is an alternate form of storing elements of the pattern, parse and extraction database used by the parser subsystem in accordance to another embodiment of the invention.</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 19</figref> is a block diagram of the state processor component of the analyzer subsystem of <figref idref="DRAWINGS">FIG. 11</figref>.</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 20</figref> is a block diagram of the search engine component of the analyzer subsystem of <figref idref="DRAWINGS">FIG. 11</figref>.</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 21</figref> is a dataflow block diagram showing four individual search modules of the search engine.</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 22A</figref> is a block diagram of the search engine core; <figref idref="DRAWINGS">FIG. 22B</figref> shows a comparator component of the core that compares a plurality of inputs to another plurality of inputs.</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 23A</figref> shows an implementation of the input core in more detail; <figref idref="DRAWINGS">FIG. 23B</figref> shows a comparator component of the core.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0049" num="0048">Note that this document includes hardware diagrams and descriptions that may include signal names. In most cases, the names are sufficiently descriptive, in other cases however the signal names are not needed to understand the operation and practice of the invention.</p>
<p id="h-0007" num="0000">Operation in a Network</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 1</figref> represents a system embodiment of the present invention that is referred to herein by the general reference numeral <b>100</b>. The system <b>100</b> has a computer network <b>102</b> that communicates packets (e.g., IP datagrams) between various computers, for example between the clients <b>104</b>-<b>107</b> and servers <b>110</b> and <b>112</b>. The network is shown schematically as a cloud with several network nodes and links shown in the interior of the cloud. A monitor <b>108</b> examines the packets passing in either direction past its connection point <b>121</b> and, according to one aspect of the invention, can elucidate what application programs are associated with each packet. The monitor <b>108</b> is shown examining packets (i.e., datagrams) between the network interface <b>116</b> of the server <b>110</b> and the network. The monitor can also be placed at other points in the network, such as connection point <b>123</b> between the network <b>102</b> and the interface <b>118</b> of the client <b>104</b>, or some other location, as indicated schematically by connection point <b>125</b> somewhere in network <b>102</b>. Not shown is a network packet acquisition device at the location <b>123</b> on the network for converting the physical information on the network into packets for input into monitor <b>108</b>. Such packet acquisition devices are common.</p>
<p id="p-0051" num="0050">Various protocols may be employed by the network to establish and maintain the required communication, e.g., TCP/IP, etc. Any network activity—for example an application program run by the client <b>104</b> (CLIENT <b>1</b>) communicating with another running on the server <b>110</b> (SERVER <b>2</b>)—will produce an exchange of a sequence of packets over network <b>102</b> that is characteristic of the respective programs and of the network protocols. Such characteristics may not be completely revealing at the individual packet level. It may require the analyzing of many packets by the monitor <b>108</b> to have enough information needed to recognize particular application programs. The packets may need to be parsed then analyzed in the context of various protocols, for example, the transport through the application session layer protocols for packets of a type conforming to the ISO layered network model.</p>
<p id="p-0052" num="0051">Communication protocols are layered, which is also referred to as a protocol stack. The ISO (International Standardization Organization) has defined a general model that provides a framework for design of communication protocol layers. This model, shown in table from below, serves as a basic reference for understanding the functionality of existing communication protcols.</p>
<p id="p-0053" num="0052">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="1" colwidth="42pt" align="center"/>
<colspec colname="2" colwidth="56pt" align="left"/>
<colspec colname="3" colwidth="119pt" align="left"/>
<thead>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
<row>
<entry>Layer</entry>
<entry>Functionality</entry>
<entry>Example</entry>
</row>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry>7</entry>
<entry>Application</entry>
<entry>Telnet, NFS, Novell NCP, HTTP,</entry>
</row>
<row>
<entry/>
<entry/>
<entry>H.323</entry>
</row>
<row>
<entry>6</entry>
<entry>Presentation</entry>
<entry>XDR</entry>
</row>
<row>
<entry>5</entry>
<entry>Session</entry>
<entry>RPC, NETBIOS, SNMP, etc.</entry>
</row>
<row>
<entry>4</entry>
<entry>Transport</entry>
<entry>TCP, Novel SPX, UDP, etc.</entry>
</row>
<row>
<entry>3</entry>
<entry>Network</entry>
<entry>IP, Novell IPX, VIP, AppleTalk, etc.</entry>
</row>
<row>
<entry>2</entry>
<entry>Data Link</entry>
<entry>Network Interface Card (Hardware</entry>
</row>
<row>
<entry/>
<entry/>
<entry>Interface). MAC layer</entry>
</row>
<row>
<entry>1</entry>
<entry>Physical</entry>
<entry>Ethernet, Token Ring, Frame Relay,</entry>
</row>
<row>
<entry/>
<entry/>
<entry>ATM, T1 (Hardware Connection)</entry>
</row>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0054" num="0053">Different communication protocols employ different levels of the ISO model or may use a layered model that is similar to but which does not exactly conform to the ISO model. A protocol in a certain layer may not be visible to protocols employed at other layers. For example, an application (Level <b>7</b>) may not be able to identify the source computer for a communication attempt (Levels <b>2</b>-<b>3</b>).</p>
<p id="p-0055" num="0054">In some communication arts, the term “frame” generally refers to encapsulated data at OSI layer <b>2</b>, including a destination address, control bits for flow control, the data or payload, and CRC (cyclic redundancy check) data for error checking. The term “packet” generally refers to encapsulated data at OSI layer <b>3</b>. In the TCP/IP world, the term “datagram” is also used. In this specification, the term “packet” is intended to encompass packets, datagrams, frames, and cells. In general, a packet format or frame format refers to how data is encapsulated with various fields and headers for transmission across a network. For example, a data packet typically includes an address destination field, a length field, an error correcting code (ECC) field, or cyclic redundancy check (CRC) field, as well as headers and footers to identify the beginning and end of the packet. The terms “packet format” and “frame format,” also referred to as “cell format,” are generally synonymous.</p>
<p id="p-0056" num="0055">Monitor <b>108</b> looks at every packet passing the connection point <b>121</b> for analysis. However, not every packet carries the same information useful for recognizing all levels of the protocol. For example, in a conversational flow associated with a particular application, the application will cause the server to send a type-A packet, but so will another. If, though, the particular application program always follows a type-A packet with the sending of a type-B packet, and the other application program does not, then in order to recognize packets of that application's conversational flow, the monitor can be available to recognize packets that match the type-B packet to associate with the type-A packet. If such is recognized after a type-A packet, then the particular application program's conversational flow has started to reveal itself to the monitor <b>108</b>.</p>
<p id="p-0057" num="0056">Further packets may need to be examined before the conversational flow can be identified as being associated with the application program. Typically, monitor <b>108</b> is simultaneously also in partial completion of identifying other packet exchanges that are parts of conversational flows associated with other applications. One aspect of monitor <b>108</b> is its ability to maintain the state of a flow. The state of a flow is an indication of all previous events in the flow that lead to recognition of the content of all the protocol levels, e.g., the ISO model protocol levels. Another aspect of the invention is forming a signature of extracted characteristic portions of the packet that can be used to rapidly identify packets belonging to the same flow.</p>
<p id="p-0058" num="0057">In real-world uses of the monitor <b>108</b>, the number of packets on the network <b>102</b> passing by the monitor <b>108</b>'s connection point can exceed a million per second. Consequently, the monitor has very little time available to analyze and type each packet and identify and maintain the state of the flows passing through the connection point. The monitor <b>108</b> therefore masks out all the unimportant parts of each packet that will not contribute to its classification. However, the parts to mask-out will change with each packet depending on which flow it belongs to and depending on the state of the flow.</p>
<p id="p-0059" num="0058">The recognition of the packet type, and ultimately of the associated application programs according to the packets that their executions produce, is a multi-step process within the monitor <b>108</b>. At a first level, for example, several application programs will all produce a first kind of packet. A first “signature” is produced from selected parts of a packet that will allow monitor <b>108</b> to identify efficiently any packets that belong to the same flow. In some cases, that packet type may be sufficiently unique to enable the monitor to identify the application that generated such a packet in the conversational flow. The signature can then be used to efficiently identify all future packets generated in traffic related to that application.</p>
<p id="p-0060" num="0059">In other cases, that first packet only starts the process of analyzing the conversational flow, and more packets are necessary to identify the associated application program. In such a case, a subsequent packet of a second type—but that potentially belongs to the same conversational flow—is recognized by using the signature. At such a second level, then, only a few of those application programs will have conversational flows that can produce such a second packet type. At this level in the process of classification, all application programs that are not in the set of those that lead to such a sequence of packet types may be excluded in the process of classifying the conversational flow that includes these two packets. Based on the known patterns for the protocol and for the possible applications, a signature is produced that allows recognition of any future packets that may follow in the conversational flow.</p>
<p id="p-0061" num="0060">It may be that the application is now recognized, or recognition may need to proceed to a third level of analysis using the second level signature. For each packet, therefore, the monitor parses the packet and generates a signature to determine if this signature identified a previously encountered flow, or shall be used to recognize future packets belonging to the same conversational flow. In real time, the packet is further analyzed in the context of the sequence of previously encountered packets (the state), and of the possible future sequences such a past sequence may generate in conversational flows associated with different applications. A new signature for recognizing future packets may also be generated. This process of analysis continues until the applications are identified. The last generated signature may then be used to efficiently recognize future packets associated with the same conversational flow. Such an arrangement makes it possible for the monitor <b>108</b> to cope with millions of packets per second that must be inspected.</p>
<p id="p-0062" num="0061">Another aspect of the invention is adding Eavesdropping. In alternative embodiments of the present invention capable of eavesdropping, once the monitor <b>108</b> has recognized the executing application programs passing through some point in the network <b>102</b> (for example, because of execution of the applications by the client <b>105</b> or server <b>110</b>), the monitor sends a message to some general purpose processor on the network that can input the same packets from the same location on the network, and the processor then loads its own executable copy of the application program and uses it to read the content being exchanged over the network. In other words, once the monitor <b>108</b> has accomplished recognition of the application program, eavesdropping can commence.</p>
<p id="h-0008" num="0000">The Network Monitor</p>
<p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. 3</figref> shows a network packet monitor <b>300</b>, in an embodiment of the present invention that can be implemented with computer hardware and/or software. The system <b>300</b> is similar to monitor <b>108</b> in <figref idref="DRAWINGS">FIG. 1</figref>. A packet <b>302</b> is examined, e.g., from a packet acquisition device at the location <b>121</b> in network <b>102</b> (<figref idref="DRAWINGS">FIG. 1</figref>), and the packet evaluated, for example in an attempt to determine its characteristics, e.g., all the protocol information in a multilevel model, including what server application produced the packet.</p>
<p id="p-0064" num="0063">The packet acquisition device is a common interface that converts the physical signals and then decodes them into bits, and into packets, in accordance with the particular network (Ethernet, frame relay, ATM, etc.). The acquisition device indicates to the monitor <b>108</b> the type of network of the acquired packet or packets.</p>
<p id="p-0065" num="0064">Aspects shown here include: (1) the initialization of the monitor to generate what operations need to occur on packets of different types—accomplished by compiler and optimizer <b>310</b>, (2) the processing—parsing and extraction of selected portions—of packets to generate an identifying signature—accomplished by parser subsystem <b>301</b>, and (3) the analysis of the packets—accomplished by analyzer <b>303</b>.</p>
<p id="p-0066" num="0065">The purpose of compiler and optimizer <b>310</b> is to provide protocol specific information to parser subsystem <b>301</b> and to analyzer subsystem <b>303</b>. The initialization occurs prior to operation of the monitor, and only needs to re-occur when new protocols are to be added.</p>
<p id="p-0067" num="0066">A flow is a stream of packets being exchanged between any two addresses in the network. For each protocol there are known to be several fields, such as the destination (recipient), the source (the sender), and so forth, and these and other fields are used in monitor <b>300</b> to identify the flow. There are other fields not important for identifying the flow, such as checksums, and those parts are not used for identification.</p>
<p id="p-0068" num="0067">Parser subsystem <b>301</b> examines the packets using pattern recognition process <b>304</b> that parses the packet and determines the protocol types and associated headers for each protocol layer that exists in the packet <b>302</b>. An extraction process <b>306</b> in parser subsystem <b>301</b> extracts characteristic portions (signature information) from the packet <b>302</b>. Both the pattern information for parsing and the related extraction operations, e.g., extraction masks, are supplied from a parsing-pattern-structures and extraction-operations database (parsing/extractions database) <b>308</b> filled by the compiler and optimizer <b>310</b>.</p>
<p id="p-0069" num="0068">The protocol description language (PDL) files <b>336</b> describes both patterns and states of all protocols that an occur at any layer, including how to interpret header information, how to determine from the packet header information the protocols at the next layer, and what information to extract for the purpose of identifying a flow, and ultimately, applications and services. The layer selections database <b>338</b> describes the particular layering handled by the monitor. That is, what protocols run on top of what protocols at any layer level. Thus <b>336</b> and <b>338</b> combined describe how one would decode, analyze, and understand the information in packets, and, furthermore, how the information is layered. This information is input into compiler and optimizer <b>310</b>.</p>
<p id="p-0070" num="0069">When compiler and optimizer <b>310</b> executes, it generates two sets of internal data structures. The first is the set of parsing/extraction operations <b>308</b>. The pattern structures include parsing information and describe what will be recognized in the headers of packets; the extraction operations are what elements of a packet are to be extracted from the packets based on the patterns that get matched. Thus, database <b>308</b> of parsing/extraction operations includes information describing how to determine a set of one or more protocol dependent extraction operations from data in the packet that indicate a protocol used in the packet.</p>
<p id="p-0071" num="0070">The other internal data structure that is built by compiler <b>310</b> is the set of state patterns and processes <b>326</b>. These are the different states and state transitions that occur in different conversational flows, and the state operations that need to be performed (e.g., patterns that need to be examined and new signatures that need to be built) during any state of a conversational flow to further the task of analyzing the conversational flow.</p>
<p id="p-0072" num="0071">Thus, compiling the PDL files and layer selections provides monitor <b>300</b> with the information it needs to begin processing packets. In an alternate embodiment, the contents of one or more of databases <b>308</b> and <b>326</b> may be manually or otherwise generated. Note that in some embodiments the layering selections information is inherent rather than explicitly described. For example, since a PDL file for a protocol includes the child protocols, the parent protocols also may be determined.</p>
<p id="p-0073" num="0072">In the preferred embodiment, the packet <b>302</b> from the acquisition device is input into a packet buffer. The pattern recognition process <b>304</b> is carried out by a pattern analysis and recognition (PAR) engine that analyzes and recognizes patterns in the packets. In particular, the PAR locates the next protocol field in the header and determines the length of the header, and may perform certain other tasks for certain types of protocol headers. An example of this is type and length comparison to distinguish an IEEE 802.3 (Ethernet) packet from the older type 2 (or Version 2) Ethernet packet, also called a DIGITAL-Intel-Xerox (DIX) packet. The PAR also uses the pattern structures and extraction operations database <b>308</b> to identify the next protocol and parameters associated with that protocol that enables analysis of the next protocol layer. Once a pattern or a set of patterns has been identified, it/they will be associated with a set of none or more extraction operations. These extraction operations (in the form of commands and associated parameters) are passed to the extraction process <b>306</b> implemented by an extracting and information identifying (EII) engine that extracts selected parts of the packet, including identifying information from the packet as required for recognizing this packet as part of a flow. The extracted information is put in sequence and then processed in block <b>312</b> to build a unique flow signature (also called a “key”) for this flow. A flow signature depends on the protocols used in the packet. For some protocols, the extracted components may include source and destination addresses. For example, Ethernet frames have end-point addresses that are useful in building a better flow signature. Thus, the signature typically includes the client and server address pairs. The signature is used to recognize further packets that are or may be part of this flow.</p>
<p id="p-0074" num="0073">In the preferred embodiment, the building of the flow key includes generating a hash of the signature using a hash function. The purpose if using such a hash is conventional—to spread flow-entries identified by the signature across a database for efficient searching. The hash generated is preferably based on a hashing algorithm and such hash generation is known to those in the art.</p>
<p id="p-0075" num="0074">In one embodiment, the parser passes data from the packet—a parser record—that includes the signature (i.e., selected portions of the packet), the hash, and the packet itself to allow for any state processing that requires further data from the packet. An improved embodiment of the parser subsystem might generate a parser record that has some predefined structure and that includes the signature, the hash, some flags related to some of the fields in the parser record, and parts of the packet's payload that the parser subsystem has determined might be required for further processing, e.g., for state processing.</p>
<p id="p-0076" num="0075">Note that alternate embodiments may use some function other than concatenation of the selected portions of the packet to make the identifying signature. For example, some “digest function” of the concatenated selected portions may be used.</p>
<p id="p-0077" num="0076">The parser record is passed onto lookup process <b>314</b> which looks in an internal data store of records of known flows that the system has already encountered, and decides (in <b>316</b>) whether or not this particular packet belongs to a known flow as indicated by the presence of a flow-entry matching this flow in a database of known flows <b>324</b>. A record in database <b>324</b> is associated with each encountered flow.</p>
<p id="p-0078" num="0077">The parser record enters a buffer called the unified flow key buffer (UFKB). The UFKB stores the data on flows in a data structure that is similar to the parser record, but that includes a field that can be modified. In particular, one or the UFKB record fields stores the packet sequence number, and another is filled with state information in the form of a program counter for a state processor that implements state processing <b>328</b>.</p>
<p id="p-0079" num="0078">The determination (<b>316</b>) of whether a record with the same signature already exists is carried out by a lookup engine (LUE) that obtains new UFKB records and uses the hash in the UFKB record to lookup if there is a matching known flow. In the particular embodiment, the database of known flows <b>324</b> is in an external memory. A cache is associated with the database <b>324</b>. A lookup by the LUE for a known record is carried out by accessing the cache using the hash, and if the entry is not already present in the cache, the entry is looked up (again using the hash) in the external memory.</p>
<p id="p-0080" num="0079">The flow-entry database <b>324</b> stores flow-entries that include the unique flow-signature, state information, and extracted information from the packet for updating flows, and one or more statistical about the flow. Each entry completely describes a flow. Database <b>324</b> is organized into bins that contain a number, denoted N, of flow-entries (also called flow-entries, each a bucket), with N being 4 in the preferred embodiment. Buckets (i.e., flow-entries) are accessed via the hash of the packet from the parser subsystem <b>301</b> (i.e., the hash in the UFKB record). The hash spreads the flows across the database to allow for fast lookups of entries, allowing shallower buckets. The designer selects the bucket depth N based on the amount of memory attached to the monitor, and the number of bits of the hash data value used. For example, in one embodiment, each flow-entry is 128 bytes long, so for 128K flow-entries, 16 Mbytes are required. Using a 16-bit hash gives two flow-entries per bucket. Empirically, this has been shown to be more than adequate for the vast majority of cases. Note that another embodiment uses flow-entries that are 256 bytes long.</p>
<p id="p-0081" num="0080">Herein, whenever an access to database <b>324</b> is described, it is to be understood that the access is via the cache, unless otherwise stated or clear from the context.</p>
<p id="p-0082" num="0081">If there is no flow-entry found matching the signature, i.e., the signature is for a new flow, then a protocol and state identification process <b>318</b> further determines the state and protocol. That is, process <b>318</b> determines the protocols and where in the state sequence for a flow for this protocol's this packet belongs. Identification process <b>318</b> uses the extracted information and makes reference to the database <b>326</b> of state patterns and processes. Process <b>318</b> is then followed by any state operations that need to be executed on this packet by a state processor <b>328</b>.</p>
<p id="p-0083" num="0082">If the packet is found to have a matching flow-entry in the database <b>324</b> (e.g., in the cache), then a process <b>320</b> determines, from the looked-up flow-entry, if more classification by state processing of the flow signature is necessary. If not, a process <b>322</b> updates the flow-entry in the flow-entry database <b>324</b> (e.g., via the cache). Updating includes updating one or more statistical measures stored in the flow-entry. In our embodiment, the statistical measures are stored in counters in the flow-entry.</p>
<p id="p-0084" num="0083">If state processing is required, state process <b>328</b> is commenced. State processor <b>328</b> carries out any state operations specified for the state of the flow and updates the state to the next state according to a set of state instructions obtained form the state pattern and processes database <b>326</b>.</p>
<p id="p-0085" num="0084">The state processor <b>328</b> analyzes both new and existing flows in order to analyze all levels of the protocol stack, ultimately classifying the flows by application (level <b>7</b> in the ISO model). It does this by proceeding from state-to-state based on predefined state transition rules and state operations as specified in state processor instruction database <b>326</b>. A state transition rule is a rule typically containing a test followed by the next-state to proceed to if the test result is true. An operation is an operation to be performed while the state processor is in a particular state—for example, in order to evaluate a quantity needed to apply the state transition rule. The state processor goes through each rule and each state process until the test is true, or there are no more tests to perform.</p>
<p id="p-0086" num="0085">In general, the set of state operations may be none or more operations on a packet, and carrying out the operation or operations may leave one in a state that causes exiting the system prior to completing the identification, but possibly knowing more about what state and state processes are needed to execute next, i.e., when a next packet of this flow is encountered. As an example, a state process (set of state operations) at a particular state may build a new signature for future recognition packets of the next state.</p>
<p id="p-0087" num="0086">By maintaining the state of the flows and knowing that new flows may be set up using the information from previously encountered flows, the network traffic monitor <b>300</b> provides for (a) single-packet protocol recognition of flows, and (b) multiple-packet protocol recognition of flows. Monitor <b>300</b> can even recognize the application program from one or more disjointed sub-flows that occur in server announcement type flows. What may seem to prior art monitors to be some unassociated flow, may be recognized by the inventive monitor using the flow signature to be a sub-flow associated with a previously encountered sub-flow.</p>
<p id="p-0088" num="0087">Thus, state processor <b>328</b> applies the first state operation to the packet for this particular flow-entry. A process <b>330</b> decides if more operations need to be performed for this state. If so, the analyzer continues looping between block <b>330</b> and <b>328</b> applying additional state operations to this particular packet until all those operations are completed—that is, there are no more operations for this packet in this state. A process <b>332</b> decides if there are further states to be analyzed for this type of flow according to the state of the flow and the protocol, in order to fully characterize the flow. If not, the conversational flow has now been fully characterized and a process <b>334</b> finalizes the classification of the conversational flow for the flow.</p>
<p id="p-0089" num="0088">In the particular embodiment, the state processor <b>328</b> starts the state processing by using the last protocol recognized by the parser as an offset into a jump table (jump vector). The jump table finds the state processor instructions to use for that protocol in the state patterns and processes database <b>326</b>. Most instructions test something in the unified flow key buffer, or the flow-entry in the database of known flows <b>324</b>, if the entry exists. The state processor may have to test bits, do comparisons, add, or subtract to perform the test. For example, a common operation carried out by the state processor is searching for one or more patterns in the payload part of the UFKB.</p>
<p id="p-0090" num="0089">Thus, in <b>332</b> in the classification, the analyzer decides whether the flow is at an end state. If not at an end state, the flow-entry is updated (or created if a new flow) for this flow-entry in process <b>322</b>.</p>
<p id="p-0091" num="0090">Furthermore, if the flow is known and if in <b>332</b> it is determined that there are further states to be processed using later packets, the flow-entry is updated in process <b>322</b>.</p>
<p id="p-0092" num="0091">The flow-entry also is updated after classification finalization so that any further packets belonging to this flow will be readily identified from their signature as belonging to this fully analyzed conversational flow.</p>
<p id="p-0093" num="0092">After updating, database <b>324</b> therefore includes the set of all the conversational flows that have occurred.</p>
<p id="p-0094" num="0093">Thus, the embodiment of present invention shown in <figref idref="DRAWINGS">FIG. 3</figref> automatically maintains flow-entries, which in one aspect includes storing states. The monitor of <figref idref="DRAWINGS">FIG. 3</figref> also generates characteristic parts of packets—the signatures—that can be used to recognize flows. The flow-entries may be identified and accessed by their signatures. Once a packet is identified to be from a known flow, the state of the flow is known and this knowledge enables state transition analysis to be performed in real time for each different protocol and application. In a complex analysis, state transitions are traversed as more and more packets are examined. Future packets that are part of the same conversational flow have their state analysis continued from a previously achieved state. When enough packets related to an application of interest have been processed, a final recognition state is ultimately reached, i.e., a set of states has been traversed by state analysis to completely characterize the conversational flow. The signature for that final state enables each new incoming packet of the same conversational flow to be individually recognized in real time.</p>
<p id="p-0095" num="0094">In this manner, one of the great advantages of the present invention is realized. Once a particular set of state transitions has been traversed for the first time and ends in a final state, a short-cut recognition pattern—a signature—an be generated that will key on every new incoming packet that relates to the conversational flow. Checking a signature involves a simple operation, allowing high packet rates to be successfully monitored on the network.</p>
<p id="p-0096" num="0095">In improved embodiments, several state analyzers are run in parallel so that a large number of protocols and applications may be checked for. Every known protocol and application will have at least one unique set of state transitions, and can therefore be uniquely identified by watching such transitions.</p>
<p id="p-0097" num="0096">When each new conversational flow starts, signatures that recognize the flow are automatically generated on-the-fly, and as further packets in the conversational flow are encountered, signatures are updated and the states of the set of state transitions for any potential application are further traversed according to the state transition rules for the flow. The new states for the flow—those associated with a set of state transitions for one or more potential applications—are added to the records of previously encountered states for easy recognition and retrieval when a new packet in the flow is encountered.</p>
<p id="h-0009" num="0000">Detailed Operation</p>
<p id="p-0098" num="0097"><figref idref="DRAWINGS">FIG. 4</figref> diagrams an initialization system <b>400</b> that includes the compilation process. That is, part of the initialization generates the pattern structures and extraction operations database <b>308</b> and the state instruction database <b>328</b>. Such initialization can occur off-line or from a central location.</p>
<p id="p-0099" num="0098">The different protocols that can exist in different layers may be thought of as nodes of one or more trees of linked nodes. The packet type is the root of a tree (called level <b>0</b>). Each protocol is either a parent node or a terminal node. A parent node links a protocol to other protocols (child protocols) that can be at higher layer levels. Thus a protocol may have zero or more children. Ethernet packets, for example, have several variants, each having a basic format that remains substantially the same. An Ethernet packet (the root or level <b>0</b> node) may be an Ethertype packet—also called an Ethernet Type/Version 2 and a DIX (DIGITAL-Intel-Xerox packet)—or an IEEE 803.2 packet. Continuing with the IEEE 802.3 packet, one of the children nodes may be the IP protocol, and one of the children of the IP protocol may be the TCP protocol.</p>
<p id="p-0100" num="0099"><figref idref="DRAWINGS">FIG. 16</figref> shows the header <b>1600</b> (base level <b>1</b>) of a complete Ethernet frame (i.e., packet) of information and includes information on the destination media access control address (Dst MAC <b>1602</b>) and the source media access control address (Src MAC <b>1604</b>). Also shown in <figref idref="DRAWINGS">FIG. 16</figref> is some (but not all) of the information specified in the PDL files for extraction the signature.</p>
<p id="p-0101" num="0100"><figref idref="DRAWINGS">FIG. 17A</figref> now shows the header information for the next level (level-<b>2</b>) for an Ethertype packet <b>1700</b>. For an Ethertype packet <b>1700</b>, the relevant information from the packet that indicates the next layer level is a two-byte type field <b>1702</b> containing the child recognition pattern for the next level. The remaining information <b>1704</b> is shown hatched because it not relevant for this level. The list <b>1712</b> shows the possible children for an Ethertype packet as indicated by what child recognition pattern is found offset <b>12</b>. <figref idref="DRAWINGS">FIG. 17B</figref> shows the structure of the header of one of the possible next levels, that of the IP protocol. The possible children of the IP protocol are shown in table <b>1752</b>.</p>
<p id="p-0102" num="0101">The pattern, parse, and extraction database (pattern recognition database, or PRD) <b>308</b> generated by compilation process <b>310</b>, in one embodiment, is in the form of a three dimensional structure that provides for rapidly searching packet headers for the next protocol. <figref idref="DRAWINGS">FIG. 18A</figref> shows such a 3-D representation <b>1800</b> (which may be considered as an indexed set of 2-D representations). A compressed form of the 3-D structure is preferred.</p>
<p id="p-0103" num="0102">An alternate embodiment of the data structure used in database <b>308</b> is illustrated in <figref idref="DRAWINGS">FIG. 18B</figref>. Thus, like the 3-D structure of <figref idref="DRAWINGS">FIG. 18A</figref>, the data structure permits rapid searches to be performed by the pattern recognition process <b>304</b> by indexing locations in a memory rather than performing address link computations. In this alternate embodiment, the PRD <b>308</b> includes two parts, a single protocol table <b>1850</b> (PT) which has an entry for each protocol known for the monitor, and a series of Look Up Tables <b>1870</b> (LUT's) that are used to identify known protocols and their children. The protocol table includes the parameters needed by the pattern analysis and recognition process <b>304</b> (implemented by PRE <b>1006</b>) to evaluate the header information in the packet that is associated with that protocol, and parameters needed by extraction process <b>306</b> (implemented by slicer <b>1007</b>) to process the packet header. When there are children, the PT describes which bytes in the header to evaluate to determine the child protocol. In particular, each PT entry contains the header length, an offset to the child, a slicer command, and some flags.</p>
<p id="p-0104" num="0103">The pattern matching is carried out by finding particular “child recognition codes” in the header fields, and using these codes to index one or more of the LUT's. Each LUT entry has a node code that can have one of four values, indicating the protocol that has been recognized, a code to indicate that the protocol has been partially recognized (more LUT lookups are needed), a code to indicate that this is a terminal node, and a null node to indicate a null entry. The next LUT to lookup is also returned from a LUT lookup.</p>
<p id="p-0105" num="0104">Compilation process is described in <figref idref="DRAWINGS">FIG. 4</figref>. The source-code information in the form of protocol description files is shown as <b>402</b>. In the particular embodiment, the high level decoding descriptions includes a set of protocol description files <b>336</b>, one for each protocol, and a set of packet layer selections <b>338</b>, which describes the particular layering (sets of trees of protocols) that the monitor is to be able to handle.</p>
<p id="p-0106" num="0105">A compiler <b>403</b> compiles the descriptions. The set of packet parse-and-extract operations <b>406</b> is generated (<b>404</b>), and a set of packet state instructions and operations <b>407</b> is generated (<b>405</b>) in the form of instructions for the state processor that implements state processing process <b>328</b>. Data files for each type of application and protocol to be recognized by the analyzer are downloaded from the pattern, parse, and extraction database <b>406</b> into the memory systems of the parser and extraction engines. (See the parsing process <b>500</b> description and <figref idref="DRAWINGS">FIG. 5</figref>; the extraction process <b>600</b> description and <figref idref="DRAWINGS">FIG. 6</figref>; and the parsing subsystem hardware description and <figref idref="DRAWINGS">FIG. 10</figref>). Data files for each type of application and protocol to be recognized by the analyzer are also downloaded from the state-processor instruction database <b>407</b> into the state processor. (see the state processor <b>1108</b> description and <figref idref="DRAWINGS">FIG. 11</figref>.).</p>
<p id="p-0107" num="0106">Note that generating the packet parse and extraction operations builds and links the three dimensional structure (one embodiment) or the or all the lookup tables for the PRD.</p>
<p id="p-0108" num="0107">Because of the large number of possible protocol trees and subtrees, the compiler process <b>400</b> includes optimization that compares the trees and subtrees to see which children share common parents. When implemented in the form of the LUT's, this process can generate a single LUT from a plurality of LUT's. The optimization process further includes a compaction process that reduces the space needed to store the data of the PRD.</p>
<p id="p-0109" num="0108">As an example of compaction, consider the 3-D structure of <figref idref="DRAWINGS">FIG. 18A</figref> that can be thought of as a set of 2-D structures each representing a protocol. To enable saving space by using only one array per protocol which may have several parents, in one embodiment, the pattern analysis subprocess keeps a “current header” pointer. Each location (offset) index for each protocol 2-D array in the 3-D structure is a relative location starting with the start of header for the particular protocol. Furthermore, each of the two-dimensional arrays is sparse. The next step of the optimization, is checking all the 2-D arrays against all the other 2-D arrays to find out which ones can share memory. Many of these 2-D arrays are often sparsely populated in that they each have only a small number of valid entries. So, a process of “folding” is next used to combine two or more 2-D arrays together into one physical 2-D array without losing the identity of any of the original 2-D arrays (i.e., all the 2-D arrays continue to exist logically). Folding can occur between any 2-D arrays irrespective of their location in the tree as long as certain conditions are met. Multiple arrays may be combined into a single array as long as the individual entries do not conflict with each other. A fold number is then used to associate each element with its original array. A similar folding process is used for the set of LUTs <b>1850</b> in the alternate embodiment of <figref idref="DRAWINGS">FIG. 18B</figref>.</p>
<p id="p-0110" num="0109">In <b>410</b>, the analyzer has been initialized and is ready to perform recognition.</p>
<p id="p-0111" num="0110"><figref idref="DRAWINGS">FIG. 5</figref> shows a flowchart of how actual parser subsystem <b>301</b> functions. Starting at <b>501</b>, the packet <b>302</b> is input to the packet buffer in step <b>502</b>. Step <b>503</b> loads the next (initially the first) packet component from the packet <b>302</b>. The packet components are extracted from each packet <b>302</b> one element at a time. A check is made (<b>504</b>) to determine if the load-packet-component operation <b>503</b> succeeded, indicating that there was more in the packet to process. If not, indicating all components have been loaded, the parser subsystem <b>301</b> builds the packet signature (<b>512</b>)—the next stage (<figref idref="DRAWINGS">FIG. 6</figref>).</p>
<p id="p-0112" num="0111">If a component is successfully loaded in <b>503</b>, the node and processes are fetched (<b>505</b>) from the pattern, parse and extraction database <b>308</b> to provide a set of patterns and processes for that node to apply to the loaded packet component. The parser subsystem <b>301</b> checks (<b>506</b>) to determine if the fetch pattern node operation <b>505</b> completed successfully, indicating there was a pattern node that loaded in <b>505</b>. If not, step <b>511</b> moves to the next packet component. If yes, then the node and pattern matching process are applied in <b>507</b> to the component extracted in <b>503</b>. A pattern match obtained in <b>507</b> (as indicated by test <b>508</b>) means the parser subsystem <b>301</b> has found a node in the parsing elements; the parser subsystem <b>301</b> proceeds to step <b>509</b> to extract the elements.</p>
<p id="p-0113" num="0112">If applying the node process to the component does not produce a match (test <b>508</b>), the parser subsystem <b>301</b> moves (<b>510</b>) to the next pattern node from the pattern database <b>308</b> and to step <b>505</b> to fetch the next node and process. Thus, there is an “applying patterns” loop between <b>508</b> and <b>505</b>. Once the parser subsystem <b>301</b> completes all the patterns and has either matched or not, the parser subsystem <b>301</b> moves to the next packet component (<b>511</b>).</p>
<p id="p-0114" num="0113">Once all the packet components have been the loaded and processed from the input packet <b>302</b>, then the load packet will fail (indicated by test <b>504</b>), and the parser subsystem <b>301</b> moves to build a packet signature which is described in <figref idref="DRAWINGS">FIG. 6</figref></p>
<p id="p-0115" num="0114"><figref idref="DRAWINGS">FIG. 6</figref> is a flow chart for extracting the information from which to build the packet signature. The flow starts at <b>601</b>, which is the exit point <b>513</b> of <figref idref="DRAWINGS">FIG. 5</figref>. At this point parser subsystem <b>301</b> has a completed packet component and a pattern node available in a buffer (<b>602</b>). Step <b>603</b> loads the packet component available from the pattern analysis process of <figref idref="DRAWINGS">FIG. 5</figref>. If the load completed (test <b>604</b>), indicating that there was indeed another packet component, the parser subsystem <b>301</b> fetches in <b>605</b> the extraction and process elements received from the pattern node component in <b>602</b>. If the fetch was successful (test <b>606</b>), indicating that there are extraction elements to apply, the parser subsystem <b>301</b> in step <b>607</b> applies that extraction process to the packet component based on an extraction instruction received from that pattern node. This removes and saves an element from the packet component.</p>
<p id="p-0116" num="0115">In step <b>608</b>, the parser subsystem <b>301</b> checks if there is more to extract from this component, and if not, the parser subsystem <b>301</b> moves back to <b>603</b> to load the next packet component at hand and repeats the process. If the answer is yes, then the parser subsystem <b>301</b> moves to the next packet component ratchet. That new packet component is then loaded in step <b>603</b>. As the parser subsystem <b>301</b> moved through the loop between <b>608</b> and <b>603</b>, extra extraction processes are applied either to the same packet component if there is more to extract, or to a different packet component if there is no more to extract.</p>
<p id="p-0117" num="0116">The extraction process thus builds the signature, extracting more and more components according to the information in the patterns and extraction database <b>308</b> for the particular packet. Once loading the next packet component operation <b>603</b> fails (test <b>604</b>), all the components have been extracted. The built signature is loaded into the signature buffer (<b>610</b>) and the parser subsystem <b>301</b> proceeds to <figref idref="DRAWINGS">FIG. 7</figref> to complete the signature generation process.</p>
<p id="p-0118" num="0117">Referring now to <figref idref="DRAWINGS">FIG. 7</figref>, the process continues at <b>701</b>. The signature buffer and the pattern node elements are available (<b>702</b>). The parser subsystem <b>301</b> loads the next pattern node element. If the load was successful (test <b>704</b>) indicating there are more nodes, the parser subsystem <b>301</b> in <b>705</b> hashes the signature buffer element based on the hash elements that are found in the pattern node that is in the element database. In <b>706</b> the resulting signature and the hash are packed. In <b>707</b> the parser subsystem <b>301</b> moves on to the next packet component which is loaded in <b>703</b>.</p>
<p id="p-0119" num="0118">The <b>703</b> to <b>707</b> loop continues until there are no more patterns of elements left (test <b>704</b>). Once all the patterns of elements have been hashed, processes <b>304</b>, <b>306</b> and <b>312</b> of parser subsystem <b>301</b> are complete. Parser subsystem <b>301</b> has generated the signature used by the analyzer subsystem <b>303</b>.</p>
<p id="p-0120" num="0119">A parser record is loaded into the analyzer, in particular, into the UFKB in the form of a UFKB record which is similar to a parser record, but with one or more different fields.</p>
<p id="p-0121" num="0120"><figref idref="DRAWINGS">FIG. 8</figref> is a flow diagram describing the operation of the lookup/update engine (LUE) that implements lookup operation <b>314</b>. The process starts at <b>801</b> from <figref idref="DRAWINGS">FIG. 7</figref> with the parser record that includes a signature, the hash and at least parts of the payload. In <b>802</b> those elements are shown in the form of a UFKB-entry in the buffer. The LUE, the lookup engine <b>314</b> computes a “record bin number” from the hash for a flow-entry. A bin herein may have one or more “buckets” each containing a flow-entry. The preferred embodiment has four buckets per bin.</p>
<p id="p-0122" num="0121">Since preferred hardware embodiment includes the cache, all data accesses to records in the flowchart of <figref idref="DRAWINGS">FIG. 8</figref> are stated as being to or from the cache.</p>
<p id="p-0123" num="0122">Thus, in <b>804</b>, the system looks up the cache for a bucket from that bin using the hash. If the cache successfully returns with a bucket from the bin number, indicating there are more buckets in the bin, the lookup/update engine compares (<b>807</b>) the current signature (the UFKB-entry's signature) from that in the bucket (i.e., the flow-entry signature). If the signatures match (test <b>808</b>), that record (in the cache) is marked in step <b>810</b> as “in process” and a timestamp added. Step <b>811</b> indicates to the UFKB that the UFKB-entry in <b>802</b> has a status of “found.” The “found” indication allows the state processing <b>328</b> to begin processing this UFKB element. The preferred hardware embodiment includes one or more state processors, and these can operate in parallel with the lookup/update engine.</p>
<p id="p-0124" num="0123">In the preferred embodiment, a set of statistical operations is performed by a calculator for every packet analyzed. The statistical operations may include one or more of counting the packets associated with the flow; determining statistics related to the size of packets of the flow; compiling statistics on differences between packets in each direction, for example using timestamps; and determining statistical relationships of timestamps of packets in the same direction. The statistical measures are kept in the flow-entries. Other statistical measures also may be compiled. These statistics may be used singly or in combination by a statistical processor component to analyze many different aspects of the flow. This may include determining network usage metrics from the statistical measures, for example to ascertain the network's ability to transfer information for this application. Such analysis provides for measuring the quality of service of a conversation, measuring how well an application is performing in the network, measuring network resources consumed by an application, and so forth.</p>
<p id="p-0125" num="0124">To provide for such analyses, the lookup/update engine updates one or more counters that are part of the flow-entry (in the cache) in step <b>812</b>. The process exits at <b>813</b>. In our embodiment, the counters include the total packets of the flow, the time, and a differential time from the last timestamp to the present timestamp.</p>
<p id="p-0126" num="0125">It may be that the bucket of the bin did not lead to a signature match (test <b>808</b>). In such a case, the analyzer in <b>809</b> moves to the next bucket for this bin. Step <b>804</b> again looks up the cache for another bucket from that bin. The lookup/update engine thus continues lookup up buckets of the bin until there is either a match in <b>808</b> or operation <b>804</b> is not successful (test <b>805</b>), indicating that there are no more buckets in the bin and no match was found.</p>
<p id="p-0127" num="0126">If no match was found, the packet belongs to a new (not previously encountered) flow. In <b>806</b> the system indicates that the record in the unified flow key buffer for this packet is new, and in <b>812</b>, any statistical updating operations are performed for this packet by updating the flow-entry in the cache. The update operation exits at <b>813</b>. A flow insertion/deletion engine (FIDE) creates a new record for this flow (again via the cache).</p>
<p id="p-0128" num="0127">Thus, the update/lookup engine ends with a UFKB-entry for the packet with a “new” status or a “found” status.</p>
<p id="p-0129" num="0128">Note that the above system uses a hash to which more than one flow-entry can match. A longer hash may be used that corresponds to a single flow-entry. In such an embodiment, the flow chart of <figref idref="DRAWINGS">FIG. 8</figref> is simplified as would be clear to those in the art.</p>
<p id="h-0010" num="0000">The Hardware System</p>
<p id="p-0130" num="0129">Each of the individual hardware elements through which the data flows in the system are now described with reference to <figref idref="DRAWINGS">FIGS. 10 and 11</figref>. Note that while we are describing a particular hardware implementation of the invention embodiment of <figref idref="DRAWINGS">FIG. 3</figref>, it would be clear to one skilled in the art that the flow of <figref idref="DRAWINGS">FIG. 3</figref> may alternatively be implemented in software running on one or more general-purpose processors, or only partly implemented in hardware. An implementation of the invention that can operate in software is shown in <figref idref="DRAWINGS">FIG. 14</figref>. The hardware embodiment (<figref idref="DRAWINGS">FIGS. 10 and 11</figref>) can operate at over a million packets per second, while the software system of <figref idref="DRAWINGS">FIG. 14</figref> may be suitable for slower networks. To one skilled in the art it would be clear that more and more of the system may be implemented in software as processors become faster.</p>
<p id="p-0131" num="0130"><figref idref="DRAWINGS">FIG. 10</figref> is a description of the parsing subsystem (<b>301</b>, shown here as subsystem <b>1000</b>) as implemented in hardware. Memory <b>1001</b> is the pattern recognition database memory, in which the patterns that are going to be analyzed are stored. Memory <b>1002</b> is the extraction-operation database memory, in which the extraction instructions are stored. Both <b>1001</b> and <b>1002</b> correspond to internal data structure <b>308</b> of <figref idref="DRAWINGS">FIG. 3</figref>. Typically, the system is initialized from a microprocessor (not shown) at which time these memories are loaded through a host interface multiplexor and control register <b>1005</b> via the internal buses <b>1003</b> and <b>1004</b>. Note that the contents of <b>1001</b> and <b>1002</b> are preferably obtained by compiling process <b>310</b> of <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0132" num="0131">A packet enters the parsing system via <b>1012</b> into a parser input buffer memory <b>1008</b> using control signals <b>1021</b> and <b>1023</b>, which control an input buffer interface controller <b>1022</b>. The buffer <b>1008</b> and interface control <b>1022</b> connect to a packet acquisition device (not shown). The buffer acquisition device generates a packet start signal <b>1021</b> and the interface control <b>1022</b> generates a next packet (i.e., ready to receive data) signal <b>1023</b> to control the data flow into parser input buffer memory <b>1008</b>. Once a packet starts loading into the buffer memory <b>1008</b>, pattern recognition engine (PRE) <b>1006</b> carries out the operations on the input buffer memory described in block <b>304</b> of <figref idref="DRAWINGS">FIG. 3</figref>. That is, protocol types and associated headers for each protocol layer that exist in the packet are determined.</p>
<p id="p-0133" num="0132">The PRE searches database <b>1001</b> and the packet in buffer <b>1008</b> in order to recognize the protocols the packet contains. In one implementation, the database <b>1001</b> includes a series of linked lookup tables. Each lookup table uses eight bits of addressing. The first lookup table is always at address zero. The Pattern Recognition Engine uses a base packet offset from a control register to start the comparison. It loads this value into a current offset pointer (COP). It then reads the byte at base packet offset from the parser input buffer and uses it as an address into the first lookup table.</p>
<p id="p-0134" num="0133">Each lookup table returns a word that links to another lookup table or it returns a terminal flag. If the lookup produces a recognition event the database also returns a command for the slicer. Finally it returns the value to add to the COP.</p>
<p id="p-0135" num="0134">The PRE <b>1006</b> includes of a comparison engine. The comparison engine has a first stage that checks the protocol type field to determine if it is an 802.3 packet and the field should be treated as a length. If it is not a length, the protocol is checked in a second stage. The first stage is the only protocol level that is not programmable. The second stage has two full sixteen bit content addressable memories (CAMs) defined for future protocol additions.</p>
<p id="p-0136" num="0135">Thus, whenever the PRE recognizes a pattern, it also generates a command for the extraction engine (also called a “slicer”) <b>1007</b>. The recognized patterns and the commands are sent to the extraction engine <b>1007</b> that extracts information from the packet to build the parser record. Thus, the operations of the extraction engine are those carried out in blocks <b>306</b> and <b>312</b> of <figref idref="DRAWINGS">FIG. 3</figref>. The commands are sent from PRE <b>1006</b> to slicer <b>1007</b> in the form of extraction instruction pointers which tell the extraction engine <b>1007</b> where to a find the instructions in the extraction operations database memory (i.e., slicer instruction database) <b>1002</b>.</p>
<p id="p-0137" num="0136">Thus, when the PRE <b>1006</b> recognizes a protocol it outputs both the protocol identifier and a process code to the extractor. The protocol identifier is added to the flow signature and the process code is used to fetch the first instruction from the instruction database <b>1002</b>. Instructions include an operation code and usually source and destination offsets as well as a length. The offsets and length are in bytes. A typical operation is the MOVE instruction. This instruction tells the slicer <b>1007</b> to copy n bytes of data unmodified from the input buffer <b>1008</b> to the output buffer <b>1010</b>. The extractor contains a byte-wise barrel shifter so that the bytes moved can be packed into the flow signature. The extractor contains another instruction called HASH. This instruction tells the extractor to copy from the input buffer <b>1008</b> to the HASH generator.</p>
<p id="p-0138" num="0137">Thus these instructions are for extracting selected element(s) of the packet in the input buffer memory and transferring the data to a parser output buffer memory <b>1010</b>. Some instructions also generate a hash.</p>
<p id="p-0139" num="0138">The extraction engine <b>1007</b> and the PRE operate as a pipeline. That is, extraction engine <b>1007</b> performs extraction operations on data in input buffer <b>1008</b> already processed by PRE <b>1006</b> while more (i.e., later arriving) packet information is being simultaneously parsed by PRE <b>1006</b>. This provides high processing speed sufficient to accommodate the high arrival rate speed of packets.</p>
<p id="p-0140" num="0139">Once all the selected parts of the packet used to form the signature are extracted, the hash is loaded into parser output buffer memory <b>1010</b>. Any additional payload from the packet that is required for further analysis is also included. The parser output memory <b>1010</b> is interfaced with the analyzer subsystem by analyzer interface control <b>1011</b>. Once all the information of a packet is in the parser output buffer memory <b>1010</b>, a data ready signal <b>1025</b> is asserted by analyzer interface control. The data from the parser subsystem <b>1000</b> is moved to the analyzer subsystem via <b>1013</b> when an analyzer ready signal <b>1027</b> is asserted.</p>
<p id="p-0141" num="0140"><figref idref="DRAWINGS">FIG. 11</figref> shows the hardware components and dataflow for the analyzer subsystem that performs the functions of the analyzer subsystem <b>303</b> of <figref idref="DRAWINGS">FIG. 3</figref>. The analyzer is initialized prior to operation, and initialization includes loading the state processing information generated by the compilation process <b>310</b> into a database memory for the state processing, called state processor instruction database (SPID) memory <b>1109</b>.</p>
<p id="p-0142" num="0141">The analyzer subsystem <b>1100</b> includes a host bus interface <b>1122</b> using an analyzer host interface controller <b>1118</b>, which in turn has access to a cache system <b>1115</b>. The cache system has bi-directional access to and from the state processor of the system <b>1108</b>. State processor <b>1108</b> is responsible for initializing the state processor instruction database memory <b>1109</b> from information given over the host bus interface <b>1122</b>.</p>
<p id="p-0143" num="0142">With the SPID <b>1109</b> loaded, the analyzer subsystem <b>1100</b> receives parser records comprising packet signatures and payloads that come from the parser into the unified flow key buffer (UFKB) <b>1103</b>. UFKB is comprised of memory set up to maintain UFKB records. A UFKB record is essentially a parser record; the UFKB holds records of packets that are to be processed or that are in process. Furthermore, the UFKB provides for one or more fields to act as modifiable status flags to allow different processes to run concurrently.</p>
<p id="p-0144" num="0143">Three processing engines run concurrently and access records in the UFKB <b>1103</b>: the lookup/update engine (LUE) <b>1107</b>, the state processor (SP) <b>1108</b>, and the flow insertion and deletion engine (FIDE) <b>1110</b>. Each of these is implemented by one or more finite state machines (FSM's). There is bi-directional access between each of the finite state machines and the unified flow key buffer <b>1103</b>. The UFKB record includes a field that stores the packet sequence number, and another that is filled with state information in the form of a program counter for the state processor <b>1108</b> that implements state processing <b>328</b>. The status flags of the UFKB for any entry includes that the LUE is done and that the LUE is transferring processing of the entry to the state processor. The LUE done indicator is also used to indicate what the next entry is for the LUE. There also is provided a flag to indicate that the state processor is done with the current flow and to indicate what the next entry is for the state processor. There also is provided a flag to indicate the state processor is transferring processing of the UFKB-entry to the flow insertion and deletion engine.</p>
<p id="p-0145" num="0144">A new UFKB record is first processed by the LUE <b>1107</b>. A record that has been processed by the LUE <b>1107</b> may be processed by the state processor <b>1108</b>, and a UFKB record data may be processed by the flow insertion/deletion engine <b>1110</b> after being processed by the state processor <b>1108</b> or only by the LUE. Whether or not a particular engine has been applied to any unified flow key buffer entry is determined by status fields set by the engines upon completion. In one embodiment, a status flag in the UFKB-entry indicates whether an entry is new or found. In other embodiments, the LUE issues a flag to pass the entry to the state processor for processing, and the required operations for a new record are included in the SP instructions.</p>
<p id="p-0146" num="0145">Note that each UFKB-entry may not need to be processed by all three engines. Furthermore, some UFKB entries may need to be processed more than once by a particular engine.</p>
<p id="p-0147" num="0146">Each of these three engines also has bi-directional access to a cache subsystem <b>1115</b> that includes a caching engine. Cache <b>1115</b> is designed to have information flowing in and out of it from five different points within the system: the three engines, external memory via a unified memory controller (UMC) <b>1119</b> and a memory interface <b>1123</b>, and a microprocessor via analyzer host interface and control unit (ACIC) <b>1118</b> and host interface bus (HIB) <b>1122</b>. The analyzer microprocessor (or dedicated logic processor) can thus directly insert or modify data in the cache.</p>
<p id="p-0148" num="0147">The cache subsystem <b>1115</b> is an associative cache that includes a set of content addressable memory cells (CAMs) each including an address portion and a pointer portion pointing to the cache memory (e.g., RAM) containing the cached flow-entries. The CAMs are arranged as a stack ordered from a top CAM to a bottom CAM. The bottom CAM's pointer points to the least recently used (LRU) cache memory entry. Whenever there is a cache miss, the contents of cache memory pointed to by the bottom CAM are replaced by the flow-entry from the flow-entry database <b>324</b>. This now becomes the most recently used entry, so the contents of the bottom CAM are moved to the top CAM and all CAM contents are shifted down. Thus, the cache is an associative cache with a true LRU replacement policy.</p>
<p id="p-0149" num="0148">The LUE <b>1107</b> first processes a UFKB-entry, and basically performs the operation of blocks <b>314</b> and <b>316</b> in <figref idref="DRAWINGS">FIG. 3</figref>. A signal is provided to the LUE to indicate that a “new” UFKB-entry is available. The LUE uses the hash in the UFKB-entry to read a matching bin of up to four buckets from the cache. The cache system attempts to obtain the matching bin. If a matching bin is not in the cache, the cache <b>1115</b> makes the request to the UMC <b>1119</b> to bring in a matching bin from the external memory.</p>
<p id="p-0150" num="0149">When a flow-entry is found using the hash, the LUE <b>1107</b> looks at each bucket and compares it using the signature to the signature of the UFKB-entry until there is a match or there are no more buckets.</p>
<p id="p-0151" num="0150">If there is no match, or if the cache failed to provide a bin of flow-entries from the cache, a time stamp in set in the flow key of the UFKB record, a protocol identification and state determination is made using a table that was loaded by compilation process <b>310</b> during initialization, the status for the record is set to indicate the LUE has processed the record, and an indication is made that the UFKB-entry is ready to start state processing. The identification and state determination generates a protocol identifier which in the preferred embodiment is a “jump vector” for the state processor which is kept by the UFKB for this UFKB-entry and used by the state processor to start state processing for the particular protocol. For example, the jump vector jumps to the subroutine for processing the state.</p>
<p id="p-0152" num="0151">If there was a match, indicating that the packet of the UFKB-entry is for a previously encountered flow, then a calculator component enters one or more statistical measures stored in the flow-entry, including the timestamp. In addition, a time difference from the last stored timestamp may be stored, and a packet count may be updated. The state of the flow is obtained from the flow-entry is examined by looking at the protocol identifier stored in the flow-entry of database <b>324</b>. If that value indicates that no more classification is required, then the status for the record is set to indicate the LUE has processed the record. In the preferred embodiment, the protocol identifier is a jump vector for the state processor to a subroutine to state processing the protocol, and no more classification is indicated in the preferred embodiment by the jump vector being zero. If the protocol identifier indicates more processing, then an indication is made that the UFKB-entry is ready to start state processing and the status for the record is set to indicate the LUE has processed the record.</p>
<p id="p-0153" num="0152">The state processor <b>1108</b> processes information in the cache system according to a UFKB-entry after the LUE has completed. State processor <b>1108</b> includes a state processor program counter SPPC that generates the address in the state processor instruction database <b>1109</b> loaded by compiler process <b>310</b> during initialization. It contains an Instruction Pointer (SPIP) which generates the SPID address. The instruction pointer can be incremented or loaded from a Jump Vector Multiplexor which facilitates conditional branching. The SPIP can be loaded from one of three sources: (1) A protocol identifier from the UFKB, (2) an immediate jump vector form the currently decoded instruction, or (3) a value provided by the arithmetic logic unit (SPALU) included in the state processor.</p>
<p id="p-0154" num="0153">Thus, after a Flow Key is placed in the UFKB by the LUE with a known protocol identifier, the Program Counter is initialized with the last protocol recognized by the Parser. This first instruction is a jump to the subroutine which analyzes the protocol that was decoded.</p>
<p id="p-0155" num="0154">The State Processor ALU (SPALU) contains all the Arithmetic; Logical and String Compare functions necessary to implement the State Processor instructions. The main blocks of the SPALU are: The A and B Registers, the Instruction Decode &amp; State Machines, the String Reference Memory the Search Engine, an Output Data Register and an Output Control Register</p>
<p id="p-0156" num="0155">The Search Engine in turn contains the Target Search Register set, the Reference Search Register set, and a Compare block which compares two operands by exclusive-or-ing them together.</p>
<p id="p-0157" num="0156">Thus, after the UFKB sets the program counter, a sequence of one or more state operations are be executed in state processor <b>1108</b> to further analyze the packet that is in the flow key buffer entry for this particular packet.</p>
<p id="p-0158" num="0157"><figref idref="DRAWINGS">FIG. 13</figref> describes the operation of the state processor <b>1108</b>. The state processor is entered at <b>1301</b> with a unified flow key buffer entry to be processed. The UFKB-entry is new or corresponding to a found flow-entry. This UFKB-entry is retrieved from unified flow key buffer <b>1103</b> in <b>1301</b>. In <b>1303</b>, the protocol identifier for the UFKB-entry is used to set the state processor's instruction counter. The state processor <b>1108</b> starts the process by using the last protocol recognized by the parser subsystem <b>301</b> as an offset into a jump table. The jump table takes us to the instructions to use for that protocol. Most instructions test something in the unified flow key buffer or the flow-entry if it exists. The state processor <b>1108</b> may have to test bits, do comparisons, add or subtract to perform the test.</p>
<p id="p-0159" num="0158">The first state processor instruction is fetched in <b>1304</b> from the state processor instruction database memory <b>1109</b>. The state processor performs the one or more fetched operations (<b>1304</b>). In our implementation, each single state processor instruction is very primitive (e.g., a move, a compare, etc.), so that many such instructions need to be performed on each unified flow key buffer entry. One aspect of the state processor is its ability to search for one or more (up to four) reference strings in the payload part of the UFKB entry. This is implemented by a search engine component of the state processor responsive to special searching instructions.</p>
<p id="p-0160" num="0159">In <b>1307</b>, a check is made to determine if there are any more instructions to be performed for the packet. If yes, then in <b>1308</b> the system sets the state processor instruction pointer (SPIP) to obtain the next instruction. The SPIP may be set by an immediate jump vector in the currently decoded instruction, or by a value provided by the SPALU during processing.</p>
<p id="p-0161" num="0160">The next instruction to be performed is now fetched (<b>1304</b>) for execution. This state processing loop between <b>1304</b> and <b>1307</b> continues until there are no more instructions to be performed.</p>
<p id="p-0162" num="0161">At this stage, a check is made in <b>1309</b> if the processing on this particular packet has resulted in a final state. That is, is the analyzer is done processing not only for this particular packet, but for the whole flow to which the packet belongs, and the flow is fully determined. If indeed there are no more states to process for this flow, then in <b>1311</b> the processor finalizes the processing. Some final states may need to put a state in place that tells the system to remove a flow—for example, if a connection disappears from a lower level connection identifier. In that case, in <b>1311</b>, a flow removal state is set and saved in the flow-entry. The flow removal state may be a NOP (no-op) instruction which means there are no removal instructions.</p>
<p id="p-0163" num="0162">Once the appropriate flow removal instruction as specified for this flow (a NOP or otherwise) is set and saved, the process is exited at <b>1313</b>. The state processor <b>1108</b> can now obtain another unified flow key buffer entry to process.</p>
<p id="p-0164" num="0163">If at <b>1309</b> it is determined that processing for this flow is not completed, then in <b>1310</b> the system saves the state processor instruction pointer in the current flow-entry in the current flow-entry. That will be the next operation that will be performed the next time the LRE <b>1107</b> finds packet in the UFKB that matches this flow. The processor now exits processing this particular unified flow key buffer entry at <b>1313</b>.</p>
<p id="p-0165" num="0164">Note that state processing updates information in the unified flow key buffer <b>1103</b> and the flow-entry in the cache. Once the state processor is done, a flag is set in the UFKB for the entry that the state processor is done. Furthermore, If the flow needs to be inserted or deleted from the database of flows, control is then passed on to the flow insertion/deletion engine <b>1110</b> for that flow signature and packet entry. This is done by the state processor setting another flag in the UFKB for this UFKB-entry indicating that the state processor is passing processing of this entry to the flow insertion and deletion engine.</p>
<p id="p-0166" num="0165">The flow insertion and deletion engine <b>1110</b> is responsible for maintaining the flow-entry database. In particular, for creating new flows in the flow database, and deleting flows from the database so that they can be reused.</p>
<p id="p-0167" num="0166">The process of flow insertion is now described with the aid of <figref idref="DRAWINGS">FIG. 12</figref>. Flows are grouped into bins of buckets by the hash value. The engine processes a UFKB-entry that may be new or that the state processor otherwise has indicated needs to be created. <figref idref="DRAWINGS">FIG. 12</figref> shows the case of a new entry being created. A conversation record bin (preferably containing 4 buckets for four records) is obtained in <b>1203</b>. This is a bin that matches the hash of the UFKB, so this bin may already have been sought for the UFKB-entry by the LUE. In <b>1204</b> the FIDE <b>1110</b> requests that the record bin/bucket be maintained in the cache system <b>1115</b>. If in <b>1205</b> the cache system <b>1115</b> indicates that the bin/bucket is empty, step <b>1207</b> inserts the flow signature (with the hash) into the bucket and the bucket is marked “used” in the cache engine of cache <b>1115</b> using a timestamp that is maintained throughout the process. In <b>1209</b>, the FIDE <b>1110</b> compares the bin and bucket record flow signature to the packet to verify that all the elements are in place to complete the record. In <b>1211</b> the system marks the record bin and bucket as “in process” and as “new” in the cache system (and hence in the external memory). In <b>1212</b>, the initial statistical measures for the flow-record are set in the cache system. This in the preferred embodiment clears the set of counters used to maintain statistics, and may perform other procedures for statistical operations requires by the analyzer for the first packet seen for a particular flow.</p>
<p id="p-0168" num="0167">Back in step <b>1205</b>, if the bucket is not empty, the FIDE <b>1110</b> requests the next bucket for this particular bin in the cache system. If this succeeds, the processes of <b>1207</b>, <b>1209</b>, <b>1211</b> and <b>1212</b> are repeated for this next bucket. If at <b>1208</b>, there is no valid bucket, the unified flow key buffer entry for the packet is set as “drop,” indicating that the system cannot process the particular packet because there are no buckets left in the system. The process exits at <b>1213</b>. The FIDE <b>1110</b> indicates to the UFKB that the flow insertion and deletion operations are completed for this UFKB-entry. This also lets the UFKB provide the FIDE with the next UFKB record.</p>
<p id="p-0169" num="0168">Once a set of operations is performed on a unified flow key buffer entry by all of the engines required to access and manage a particular packet and its flow signature, the unified flow key buffer entry is marked as “completed.” That element will then be used by the parser interface for the next packet and flow signature coming in from the parsing and extracting system.</p>
<p id="p-0170" num="0169">All flow-entries are maintained in the external memory and some are maintained in the cache <b>1115</b>. The cache system <b>1115</b> is intelligent enough to access the flow database and to understand the data structures that exists on the other side of memory interface <b>1123</b>. The lookup/update engine <b>1107</b> is able to request that the cache system pull a particular flow or “buckets” of flows from the unified memory controller <b>1119</b> into the cache system for further processing. The state processor <b>1108</b> can operate on information found in the cache system once it is looked up by means of the lookup/update engine request, and the flow insertion/deletion engine <b>1110</b> can create new entries in the cache system if required based on information in the unified flow key buffer <b>1103</b>. The cache retrieves information as required from the memory through the memory interface <b>1123</b> and the unified memory controller <b>1119</b>, and updates information as required in the memory through the memory controller <b>1119</b>.</p>
<p id="p-0171" num="0170">There are several interfaces to components of the system external to the module of <figref idref="DRAWINGS">FIG. 11</figref> for the particular hardware implementation. These include host bus interface <b>1122</b>, which is designed as a generic interface that can operate with any kind of external processing system such as a microprocessor or a multiplexor (MUX) system. Consequently, one can connect the overall traffic classification system of <figref idref="DRAWINGS">FIGS. 11 and 12</figref> into some other processing system to manage the classification system and to extract data gathered by the system.</p>
<p id="p-0172" num="0171">The memory interface <b>1123</b> is designed to interface to any of a variety of memory systems that one may want to use to store the flow-entries. One can use different types of memory systems like regular dynamic random access memory (DRAM), synchronous DRAM, synchronous graphic memory (SGRAM), static random access memory (SRAM), and so forth.</p>
<p id="p-0173" num="0172"><figref idref="DRAWINGS">FIG. 10</figref> also includes some “generic” interfaces. There is a packet input interface <b>1012</b>—a general interface that works in tandem with the signals of the input buffer interface control <b>1022</b>. These are designed so that they can be used with any kind of generic systems that can then feed packet information into the parser. Another generic interface is the interface of pipes <b>1031</b> and <b>1033</b> respectively out of and into host interface multiplexor and control registers <b>1005</b>. This enables the parsing system to be managed by an external system, for example a microprocessor or another kind of external logic, and enables the external system to program and otherwise control the parser.</p>
<p id="p-0174" num="0173">The preferred embodiment of this aspect of the invention is described in a hardware description language (HDL) such as VHDL or Verilog. It is designed and created in an HDL so that it may be used as a single chip system or, for instance, integrated into another general-purpose system that is being designed for purposes related to creating and analyzing traffic within a network. Verilog or other HDL implementation is only one method of describing the hardware.</p>
<p id="p-0175" num="0174">In accordance with one hardware implementation, the elements shown in <figref idref="DRAWINGS">FIGS. 10 and 11</figref> are implemented in a set of six field programmable logic arrays (FPGA's). The boundaries of these FPGA's are as follows. The parsing subsystem of <figref idref="DRAWINGS">FIG. 10</figref> is implemented as two FPGAS; one FPGA, and includes blocks <b>1006</b>, <b>1008</b> and <b>1012</b>, parts of <b>1005</b>, and memory <b>1001</b>. The second FPGA includes <b>1002</b>, <b>1007</b>, <b>1013</b>, <b>1011</b> parts of <b>1005</b>. Referring to <figref idref="DRAWINGS">FIG. 11</figref>, the unified look-up buffer <b>1103</b> is implemented as a single FPGA. State processor <b>1108</b> and part of state processor instruction database memory <b>1109</b> is another FPGA. Portions of the state processor instruction database memory <b>1109</b> are maintained in external SRAM's. The lookup/update engine <b>1107</b> and the flow insertion/deletion engine <b>1110</b> are in another FPGA. The sixth FPGA includes the cache system <b>1115</b>, the unified memory control <b>1119</b>, and the analyzer host interface and control <b>1118</b>.</p>
<p id="p-0176" num="0175">Note that one can implement the system as one or more VSLI devices, rather than as a set of application specific integrated circuits (ASIC's) such as FPGA's. It is anticipated that in the future device densities will continue to increase, so that the complete system may eventually form a sub-unit (a “core”) of a larger single chip unit.</p>
<p id="h-0011" num="0000">Operation of the Invention</p>
<p id="p-0177" num="0176"><figref idref="DRAWINGS">FIG. 15</figref> shows how an embodiment of the network monitor <b>300</b> might be used to analyze traffic in a network <b>102</b>. Packet acquisition device <b>1502</b> acquires all the packets from a connection point <b>121</b> on network <b>102</b> so that all packets passing point <b>121</b> in either direction are supplied to monitor <b>300</b>. Monitor <b>300</b> comprises the parser sub-system <b>301</b>, which determines flow signatures, and analyzer sub-system <b>303</b> that analyzes the flow signature of each packet. A memory <b>324</b> is used to store the database of flows that are determined and updated by monitor <b>300</b>. A host computer <b>1504</b>, which might be any processor, for example, a general-purpose computer, is used to analyze the flows in memory <b>324</b>. As is conventional, host computer <b>1504</b> includes a memory, say RAM, shown as host memory <b>1506</b>. In addition, the host might contain a disk. In one application, the system can operate as an RMON probe, in which case the host computer is coupled to a network interface card <b>1510</b> that is connected to the network <b>102</b>.</p>
<p id="p-0178" num="0177">The preferred embodiment of the invention is supported by an optional Simple Network Management Protocol (SNMP) implementation. <figref idref="DRAWINGS">FIG. 15</figref> describes how one would, for example, implement an RMON probe, where a network interface card is used to send RMON information to the network. Commercial SNMP implementations also are available, and using such an implementation can simplify the process of porting the preferred embodiment of the invention to any platform.</p>
<p id="p-0179" num="0178">In addition, MIB Compilers are available. An MIB Compiler is a tool that greatly simplifies the creation and maintenance of proprietary MIB extensions.</p>
<heading id="h-0012" level="1">EXAMPLES OF PACKET ELUCIDATION</heading>
<p id="p-0180" num="0179">Monitor <b>300</b>, and in particular, analyzer <b>303</b> is capable of carrying out state analysis for packet exchanges that are commonly referred to as “server announcement” type exchanges. Server announcement is,a process used to ease communications between a server with multiple applications that can all be simultaneously accessed from multiple clients. Many applications use a server announcement process as a means of multiplexing a single port or socket into many applications and services. With this type of exchange, messages are sent on the network, in either a broadcast or multicast approach, to announce a server and application, and all stations in the network may receive and decode these messages. The messages enable the stations to derive the appropriate connection point for communicating that particular application with the particular server. Using the server announcement method, a particular application communicates using a service channel, in the form of a TCP or UDP socket or port as in the IP protocol suite, or using a SAP as in the Novell IPX protocol suite.</p>
<p id="p-0181" num="0180">The analyzer <b>303</b> is also capable of carrying out “in-stream analysis” of packet exchanges. The “in-stream analysis” method is used either as a primary or secondary recognition process. As a primary process, in-stream analysis assists in extracting detailed information which will be used to further recognize both the specific application and application component. A good example of in-stream analysis is any Web-based application. For example, the commonly used PointCast Web information application can be recognized using this process; during the initial connection between a PointCast server and client, specific key tokens exist in the data exchange that will result in a signature being generated to recognize PointCast.</p>
<p id="p-0182" num="0181">The in-stream analysis process may also be combined with the server announcement process. In many cases in-stream analysis will augment other recognition processes. An example of combining in-stream analysis with server announcement can be found in business applications such as SAP and BAAN.</p>
<p id="p-0183" num="0182">“Session tracking” also is known as one of the primary processes for tracking applications in client/server packet exchanges. The process of tracking sessions requires an initial connection to a predefined socket or port number. This method of communication is used in a variety of transport layer protocols. It is most commonly seen in the TCP and UDP transport protocols of the IP protocol.</p>
<p id="p-0184" num="0183">During the session tracking, a client makes a request to a server using a specific port or socket number. This initial request will cause the server to create a TCP or UDP port to exchange the remainder of the data between the client and the server. The server then replies to the request of the client using this newly created port. The original port used by the client to connect to the server will never be used again during this data exchange.</p>
<p id="p-0185" num="0184">One example of session tracking is TFTP (Trivial File Transfer-Protocol), a version of the TCP/IP FTP protocol that has no directory or password capability. During the client/server exchange process of TFTP, a specific port (port number <b>69</b>) is always used to initiate the packet exchange. Thus, when the client begins the process of communicating, a request is made to UDP port <b>69</b>. Once the server receives this request, a new port number is created on the server. The server then replies to the client using the new port. In this example, it is clear that in order to recognize TFTP; network monitor <b>300</b> analyzes the initial request from the client and generates a signature for it. Monitor <b>300</b> uses that signature to recognize the reply. Monitor <b>300</b> also analyzes the reply from the server with the key port information, and uses this to create a signature for monitoring the remaining packets of this data exchange.</p>
<p id="p-0186" num="0185">Network monitor <b>300</b> can also understand the current state of particular connections in the network. Connection-oriented exchanges often benefit from state tracking to correctly identify the application. An example is the common TCP transport protocol that provides a reliable means of sending information between a client and a server. When a data exchange is initiated, a TCP request for synchronization message is sent. This message contains a specific sequence number that is used to track an acknowledgement from the server. Once the server has acknowledged the synchronization request, data may be exchanged between the client and the server. When communication is no longer required, the client sends a finish or complete message to the server, and the server acknowledges this finish request with a reply containing the sequence numbers from the request. The states of such a connection-oriented exchange relate to the various types of connection and maintenance messages.</p>
<heading id="h-0013" level="1">Server Announcement Example</heading>
<p id="p-0187" num="0186">The individual methods of server announcement protocols vary. However, the basic underlying process remains similar. A typical server announcement message is sent to one or more clients in a network. This type of announcement message has specific content, which, in another aspect of the invention, is salvaged and maintained in the database of flow-entries in the system. Because the announcement is sent to one or more stations, the client involved in a future packet exchange with the server will make an assumption that the information announced is known, and an aspect of the inventive monitor is that it too can make the same assumption.</p>
<p id="p-0188" num="0187">Sun-RPC is the implementation by Sun Microsystems, Inc. (Palo Alto, Calif.) of the Remote Procedure Call (RPC), a programming interface that allows one program to use the services of another on a remote machine. A Sun-RPC example is now used to explain how monitor <b>300</b> can capture server announcements.</p>
<p id="p-0189" num="0188">A remote program or client that wishes to use a server or procedure must establish a connection, for which the RPC protocol can be used.</p>
<p id="p-0190" num="0189">Each server running the Sun-RPC protocol must maintain a process and database called the port Mapper. The port Mapper creates a direct association between a Sun-RPC program or application and a TCP or UDP socket or port (for TCP or UDP implementations). An application or program number is a 32-bit unique identifier assigned by ICANN (the Internet Corporation for Assigned Names and Numbers, www.icann.org), which manages the huge number of parameters associated with Internet protocols (port numbers, router protocols, multicast addresses, etc.) Each port Mapper on a Sun-RPC server can present the mappings between a unique program number and a specific transport socket through the use of specific request or a directed announcement. According to ICANN, port number <b>111</b> is associated with Sun RPC.</p>
<p id="p-0191" num="0190">As an example, consider a client (e.g., CLIENT <b>3</b> shown as <b>106</b> in <figref idref="DRAWINGS">FIG. 1</figref>) making a specific request to the server (e.g., SERVER <b>2</b> of <figref idref="DRAWINGS">FIG. 1</figref>, shown as <b>110</b>) on a predefined UDP or TCP socket. Once the port Mapper process on the sun RPC server receives the request, the specific mapping is returned in a directed reply to the client.
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0191">1. A client (CLIENT <b>3</b>, <b>106</b> in <figref idref="DRAWINGS">FIG. 1</figref>) sends a TCP packet to SERVER <b>2</b> (<b>110</b> in <figref idref="DRAWINGS">FIG. 1</figref>) on port <b>111</b>, with an RPC Bind Lookup Request (rpcBindLookup). TCP or UDP port <b>111</b> is always associated Sun RPC. This request specifies the program (as a program identifier), version, and might specify the protocol (UDP or TCP).</li>
        <li id="ul0002-0002" num="0192">2. The server SERVER <b>2</b> (<b>110</b> in <figref idref="DRAWINGS">FIG. 1</figref>) extracts the program identifier and version identifier from the request. The server also uses the fact that this packet came in using the TCP transport and that no protocol was specified, and thus will use the TCP protocol for its reply.</li>
        <li id="ul0002-0003" num="0193">3. The server <b>110</b> sends a TCP packet to port number <b>111</b>, with an RPC Bind Lookup Reply. The reply contains the specific port number (e.g., port number ‘port’) on which future transactions will be accepted for the specific RPC program identifier (e.g., Program ‘program’) and the protocol (UDP or TCP) for use.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0192" num="0194">It is desired that from now on every time that port number ‘port’ is used, the packet is associated with the application program ‘program’ until the number ‘port’ no longer is to be associated with the program ‘program’. Network monitor <b>300</b> by creating a flow-entry and a signature includes a mechanism for remembering the exchange so that future packets that use the port number ‘port’ will be associated by the network monitor with the application program ‘program’.</p>
<p id="p-0193" num="0195">In addition to the Sun RPC Bind Lookup request and reply, there are other ways that a particular program—say ‘program’—might be associated with a particular port number, for example number ‘port’. One is by a broadcast announcement of a particular association between an application service and a port number, called a Sun RPC portMapper Announcement. Another, is when some server—say the same SERVER <b>2</b>—replies to some client—say CLIENT <b>1</b>—requesting some portMapper assignment with a RPC portMapper Reply. Some other client—say CLIENT <b>2</b>—might inadvertently see this request, and thus know that for this particular server, SERVER <b>2</b>, port number ‘port’ is associated with the application service ‘program’. It is desirable for the network monitor <b>300</b> to be able to associate any packets to SERVER <b>2</b> using port number ‘port’ with the application program ‘program’.</p>
<p id="p-0194" num="0196"><figref idref="DRAWINGS">FIG. 9</figref> represents a dataflow <b>900</b> of some operations in the monitor <b>300</b> of <figref idref="DRAWINGS">FIG. 3</figref> for Sun Remote Procedure Call. Suppose a client <b>106</b> (e.g., CLIENT <b>3</b> in <figref idref="DRAWINGS">FIG. 1</figref>) is communicating via its interface to the network <b>118</b> to a server <b>110</b> (e.g., SERVER <b>2</b> in <figref idref="DRAWINGS">FIG. 1</figref>) via the server's interface to the network <b>116</b>. Further assume that Remote Procedure Call is used to communicate with the server <b>110</b>. One path in the data flow <b>900</b> starts with a step <b>910</b> that a Remote Procedure Call bind lookup request is issued by client <b>106</b> and ends with the server state creation step <b>904</b>. Such RPC bind lookup request includes values for the ‘program,’ ‘version,’ and ‘protocol’ to use, e.g., TCP or UDP. The process for Sun RPC analysis in the network monitor <b>300</b> includes the following aspects.:
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0197">Process <b>909</b>: Extranct the ‘program,’ ‘version,’ and ‘protocol’ (UDP or TCP). Extract the TCP or UDP port (process <b>909</b>) which is <b>111</b> indicating Sun RPC.</li>
    <li id="ul0003-0002" num="0198">Process <b>908</b>: Decode the Sun RPC packet. Check RPC type field for ID. If value is portMapper, save paired socket (i.e., dest for destination address, src for source address). Decode ports and mapping, save ports with socket/addr key. There may be more than one pairing per mapper packet. Form a signature (e.g., a key). A flow-entry is created in database <b>324</b>. The saving of the request is now complete.</li>
</ul>
</p>
<p id="p-0195" num="0199">At some later time, the server (process <b>907</b>) issues a RPC bind lookup reply. The packet monitor <b>300</b> will extract a signature from the packet and recognize it from the previously stored flow. The monitor will get the protocol port number (<b>906</b>) and lookup the request (<b>905</b>). A new signature (i.e., a key) will be created and the creation of the server state (<b>904</b>) will be stored as an entry identified by the new signature in the flow-entry database. That signature now may be used to identify packets associated with the server.</p>
<p id="p-0196" num="0200">The server state creation step <b>904</b> can be reached not only from a Bind Lookup Request/Reply pair, but also from a RPC Reply portMapper packet shown as <b>901</b> or an RPC Announcement portMapper shown as <b>902</b>. The Remote Procedure Call protocol can announce that it is able to provide a particular application service. Embodiments of the present invention preferably can analyze when an exchange occurs between a client and a server, and also can track those stations that have received the announcement of a service in the network.</p>
<p id="p-0197" num="0201">The RPC Announcement portMapper announcement <b>902</b> is a broadcast. Such causes various clients to execute a similar set of operations, for example, saving the information obtained from the announcement. The RPC Reply portMapper step <b>901</b> could be in reply to a portMapper request, and is also broadcast. It includes all the service parameters.</p>
<p id="p-0198" num="0202">Thus monitor <b>300</b> creates and saves all such states for later classification of flows that relate to the particular service ‘program’.</p>
<p id="p-0199" num="0203"><figref idref="DRAWINGS">FIG. 2</figref> shows how the monitor <b>300</b> in the example of Sun RPC builds a signature and flow states. A plurality of packets <b>206</b>-<b>209</b> are exchanged, e.g., in an exemplary Sun Microsystems Remote Procedure Call protocol. A method embodiment of the present invention might generate a pair of flow signatures, “signature-1” <b>210</b> and “signature-2” <b>212</b>, from information found in the packets <b>206</b> and <b>207</b> which, in the example, correspond to a Sun RPC Bind Lookup request and reply, respectively.</p>
<p id="p-0200" num="0204">Consider first the Sun RPC Bind Lookup request. Suppose packet <b>206</b> corresponds to such a request sent from CLIENT <b>3</b> to SERVER <b>2</b>. This packet contains important information that is used in building a signature according to an aspect of the invention. A source and destination network address occupy the first two fields of each packet, and according to the patterns in pattern database <b>308</b>, the flow signature (shown as KEY<b>1</b> <b>230</b> in <figref idref="DRAWINGS">FIG. 2</figref>) will also contain these two fields, so the parser subsystem <b>301</b> will include these two fields in signature KEY <b>1</b> (<b>230</b>). Note that in <figref idref="DRAWINGS">FIG. 2</figref>, if an address identifies the client <b>106</b> (shown also as <b>202</b>), the label used in the drawing is “C<sub>1</sub>”. If such address identifies the server <b>110</b> (shown also as server <b>204</b>), the label used in the drawing is “S<sub>1</sub>”. The first two fields <b>214</b> and <b>215</b> in packet <b>206</b> are “S<sub>1</sub>” and C<sub>1</sub>” because packet <b>206</b> is provided from the server <b>110</b> and is destined for the client <b>106</b>. Suppose for this example, “S<sub>1</sub>” is an address numerically less than address “C<sub>1</sub>”. A third field “p<sup>1</sup>” <b>216</b> identifies the particular protocol being used, e.g., TCP, UDP, etc.</p>
<p id="p-0201" num="0205">In packet <b>206</b>, a fourth field <b>217</b> and a fifth field <b>218</b> are used to communicate port numbers that are used. The conversation direction determines where the port number field is. The diagonal pattern in field <b>217</b> is used to identify a source-port pattern, and the hash pattern in field <b>218</b> is used to identify the destination-port pattern. The order indicates the client-server message direction. A sixth field denoted “i<sup>1</sup>” <b>219</b> is an element that is being requested by the client from the server. A seventh field denoted “s<sub>1</sub>a” <b>220</b> is the service requested by the client from server <b>110</b>. The following eighth field “QA” <b>221</b> (for question mark) indicates that the client <b>106</b> wants to know what to use to access application “s<sub>1</sub>a”. A tenth field “QP” <b>223</b> is used to indicate that the client wants the server to indicate what protocol to use for the particular application.</p>
<p id="p-0202" num="0206">Packet <b>206</b> initiates the sequence of packet exchanges, e.g., a RPC Bind Lookup Request to SERVER <b>2</b>. It follows a well-defined format, as do all the packets, and is transmitted to the server <b>110</b> on a well-known service connection identifier (port <b>111</b> indicating Sun RPC).</p>
<p id="p-0203" num="0207">Packet <b>207</b> is the first sent in reply to the client <b>106</b> from the server. It is the RPC Bind Lookup Reply as a result of the request packet <b>206</b>.</p>
<p id="p-0204" num="0208">Packet <b>207</b> includes ten fields <b>224</b>-<b>233</b>. The destination and source addresses are carried in fields <b>224</b> and <b>225</b>, e.g., indicated “C<sub>1</sub>” and “S<sub>1</sub>”, respectively. Notice the order is now reversed, since the client-server message direction is from the server <b>110</b> to the client <b>106</b>. The protocol “p<sup>1</sup>” is used as indicated in field <b>226</b>. The request “i<sup>1</sup>” is in field <b>229</b>. Values have been filled in for the application port number, e.g., in field <b>233</b> and protocol ““p<sup>2</sup>”” in field <b>233</b>.</p>
<p id="p-0205" num="0209">The flow signature and flow states built up as a result of this exchange are now described. When the packet monitor <b>300</b> sees the request packet <b>206</b> from the client, a first flow signature <b>210</b> is built in the parser subsystem <b>301</b> according to the pattern and extraction operations database <b>308</b>. This signature <b>210</b> includes a destination and a source address <b>240</b> and <b>241</b>. One aspect of the invention is that the flow keys are built consistently in a particular order no matter what the direction of conversation. Several mechanisms may be used to achieve this. In the particular embodiment, the numerically lower address is always placed before the numerically higher address. Such least to highest order is used to get the best spread of signatures and hashes for the lookup operations. In this case, therefore, since we assume “S<sub>1</sub>”&lt;“C<sub>1</sub>”, the order is address “S<sub>1</sub>” followed by client address “C<sub>1</sub>”. The next field used to build the signature is a protocol field <b>242</b> extracted from packet <b>206</b>'s field <b>216</b>, and thus is the protocol “p<sup>1</sup>”. The next field used for the signature is field <b>243</b>, which contains the destination source port number shown as a crosshatched pattern from the field <b>218</b> of the packet <b>206</b>. This pattern will be recognized in the payload of packets to derive how this packet or sequence of packets exists as a flow. In practice, these may be TCP port numbers, or a combination of TCP port numbers. In the case of the Sun RPC example, the crosshatch represents a set of port numbers of UDS for p<sup>1 </sup>that will be used to recognize this flow (e.g., port <b>111</b>). Port <b>111</b> indicates this is Sun RPC. Some applications, such as the Sun RPC Bind Lookups, are directly determinable (“known”) at the parser level. So in this case, the signature KEY-<b>1</b> points to a known application denoted “a<sup>1</sup>” (Sun RPC Bind Lookup), and a next-state that the state processor should proceed to for more complex recognition jobs, denoted as state “st<sub>D</sub>” is placed in the field <b>245</b> of the flow-entry.</p>
<p id="p-0206" num="0210">When the Sun RPC Bind Lookup reply is acquired, a flow signature is again built by the parser. This flow signature is identical to KEY-<b>1</b>. Hence, when the signature enters the analyzer subsystem <b>303</b> from the parser subsystem <b>301</b>, the complete flow-entry is obtained, and in this flow-entry indicates state “st<sub>D</sub>”. The operations for state “st<sub>D</sub>” in the state processor instruction database <b>326</b> instructs the state processor to build and store a new flow signature, shown as KEY-<b>2</b> (<b>212</b>) in <figref idref="DRAWINGS">FIG. 2</figref>. This flow signature built by the state processor also includes the destination and a source addresses <b>250</b> and <b>251</b>, respectively, for server “S<sub>1</sub>” followed by (the numerically higher address) client “C<sub>1</sub>”. A protocol field <b>252</b> defines the protocol to be used, e.g., “p<sup>2</sup>” which is obtained from the reply packet. A field <b>253</b> contains a recognition pattern also obtained from the reply packet. In this case, the application is Sun RPC, and field <b>254</b> indicates this application “a<sup>2</sup>”. A next-state field <b>255</b> defines the next state that the state processor should proceed to for more complex recognition jobs, e.g., a state “st<sup>1</sup>”. In this particular example, this is a final state. Thus, KEY-<b>2</b> may now be used to recognize packets that are in any way associated with the application “a<sup>2</sup>”. Two such packets <b>208</b> and <b>209</b> are shown, one in each direction. They use the particular application service requested in the original Bind Lookup Request, and each will be recognized because the signature KEY-<b>2</b> will be built in each case.</p>
<p id="p-0207" num="0211">The two flow signatures <b>210</b> and <b>212</b> always order the destination and source address fields with server “S<sub>1</sub>” followed by client “C<sub>1</sub>”. Such values are automatically filled in when the addresses are first created in a particular flow signature. Preferably, large collections of flow signatures are kept in a lookup table in a least-to-highest order for the best spread of flow signatures and hashes.</p>
<p id="p-0208" num="0212">Thereafter, the client and server exchange a number of packets, e.g., represented by request packet <b>208</b> and response packet <b>209</b>. The client <b>106</b> sends packets <b>208</b> that have a destination and source address S<sub>1 </sub>and C<sub>1</sub>, in a pair of fields <b>260</b> and <b>261</b>. A field <b>262</b> defines the protocol as “p<sup>2</sup>”, and a field <b>263</b> defines the destination port number.</p>
<p id="p-0209" num="0213">Some network-server application recognition jobs are so simple that only a single state transition has to occur to be able to pinpoint the application that produced the packet. Others require a sequence of state transitions to occur in order to match a known and predefined climb from state-to-state.</p>
<p id="p-0210" num="0214">Thus the flow signature for the recognition of application “a<sup>2</sup>” is automatically set up by predefining what packet-exchange sequences occur for this example when a relatively simple Sun Microsystems Remote Procedure Call bind lookup request instruction executes. More complicated exchanges than this may generate more than two flow signatures and their corresponding states. Each recognition may involve setting up a complex state transition diagram to be traversed before a “final” resting state such as “st<sub>1</sub>” in field <b>255</b> is reached. All these are used to build the final set of flow signatures for recognizing a particular application in the future.</p>
<p id="h-0014" num="0000">The State Processor in Detail</p>
<p id="p-0211" num="0215">The state processor <b>1108</b> analyzes both new and existing flows in order to classify them by application. It does this by proceeding from state to state based on rules defined by the engineer. A rule is a test followed by the next state to proceed to if the test is true. The state processor <b>1108</b> goes through each rule until the test is true or there are no more tests to perform. The state processor <b>1108</b> starts the process by using the last protocol recognized by parser subsystem <b>1000</b> as an offset into a jump table (the jump vector). The jump table takes us to the instructions to use for that protocol. Most instructions test something in the unified flow key buffer <b>1103</b> or the flow-entry if it exists. The state processor <b>1108</b> may have to test bits, do comparisons, add or subtract to perform the test.</p>
<p id="p-0212" num="0216">In most common processing systems, the set of instructions implemented are general purpose in nature. All processing systems have a typical set of instructions related to the analysis and manipulation of the Instruction and program counters. These instructions include Jump, Call and Return. In addition, these same processing systems contain the appropriate instructions to analyze and manipulate registers and memory locations. These instructions include Increment, Decrement and Move; Compare and Logical manipulation.</p>
<p id="p-0213" num="0217">The state processor <b>1108</b> of the preferred embodiment also includes such a basic set of standard instructions. However, the preferred embodiment state processor <b>1108</b> has some very specific functions that are required in order to evaluate the content of and data within packets on networks. There are four specific functions performed by the preferred embodiment state processor to meet these objectives. Two of these are specialized conversion instructions designed to interpret and transpose text elements in a specific for into a mathematical and numerical format. These instructions are AH2B (ASCII Hexadecimal to Binary) and AD2D (ASCII Decimal to Binary). These instructions are single cycle in nature. These instructions are novel and included to provide for the time sensitive nature of the functions performed by the preferred embodiment state processor.</p>
<p id="p-0214" num="0218">In order to have the system make speed and meet the objective for classification, there are several other special functions provided in the State Processor. These functions primarily deal with seeking, locating, analyzing and evaluating sequences of strings. These strings can be either formatted or unformatted.</p>
<p id="p-0215" num="0219">The primary high level instructions are the In_Find and In_Find_CONTINUE instructions, and are implemented by a searching apparatus (search engine) that is part of the state processor. These functions and the searching apparatus have been designed to make the state processor <b>1108</b> capable of simultaneous searching payload content from a packet sent into the monitor <b>300</b>. This enables the monitor to scale and meet any network speed requirements.</p>
<p id="p-0216" num="0220">The state processor is shown in <figref idref="DRAWINGS">FIG. 19</figref> as processor <b>1108</b>. It executes its instructions from the state processor instruction database (SPID) <b>1109</b> which if filled by the host CPU as part of the compilation process <b>310</b>. The SP <b>1108</b> contains several sub blocks including a program counter <b>1903</b> (SPPC) a control block <b>1905</b> (SPCB), an arithmetic logic unit <b>1907</b> (SPALU), address generators and data bus multiplexors (Muxes) to enable the movement of data from various sources to various destinations. The two address generators are a SP flow key address generator <b>1911</b> (SPFKAG) that points to the UFKB and a SP flow-entry address generator <b>1913</b> (SPFEAG) that points to the cache subsystem <b>1115</b>. The SP <b>1108</b> also includes four data Muxes: SP ALU Data Mux A <b>1919</b>, SP ALU Data Mux B <b>1921</b>, SP UFKB Data Mux <b>1915</b>, and SP Cache Data Mux <b>1917</b>. These Muxes facilitate the movement of data within the various blocks of the state processor <b>1108</b> and to/from the UFKB <b>1103</b> and the cache subsystem <b>1115</b>.</p>
<p id="p-0217" num="0221">The SP control block <b>1905</b> decodes instructions coming out of the SPID <b>1109</b> and separates them into various fields to control the state processor <b>1108</b>. The main function of the SPCB <b>1905</b> is instruction decoding and control signal generation. There are two classes of instructions. One that are executed completely by the SPCB and one that are passed along to the SPALU <b>1907</b> for partial or complete execution. Some of the SP instructions are described herein below.</p>
<p id="p-0218" num="0222">When an instruction needs to be passed to the SPALU <b>1907</b>, the SPCB <b>1905</b> decodes the instruction and supplies the SPALU <b>1907</b> instruction code on a bus and asserts a “Go” signal.</p>
<p id="p-0219" num="0223">When an instruction, e.g., a move or jump instruction, can be completely executed by the SPCB <b>1905</b>, the SPCB generates the appropriate control signals to the SP program counter <b>1903</b>, SP Address Generators <b>1911</b> and/or <b>1913</b>, and the SP Muxes in order to implement the specific move or jump instruction.</p>
<p id="p-0220" num="0224">Words in the SPID <b>1109</b> are <b>40</b> bits long and partitioned into various fields by the SPCB <b>1905</b> depending on the instruction code. One field is the instruction code. The remaining bits in the SPID word is partitioned into various fields depending on the accompanying instruction. For example, the SP <b>1108</b> can implement Jump, Call, Wait, and WaitRJ instructions that are followed by a condition code and a jump address. The SP <b>1108</b> also can execute a Move Immediate instruction that is followed by the constant value. Furthermore, SP <b>1008</b> can execute Load Address Generator instructions that are followed by the address to be loaded. Upon decoding the instruction field, the SPCB generates a combination of control signals from an included decode PAL. These control signals select the various Muxes that facilitate data movement and generate strobe signals that load values in various registers.</p>
<p id="p-0221" num="0225">The program counter SPPC <b>1903</b> generates the address to the state processor instruction database. It contained an instruction pointer that generates the SPID <b>1109</b> address. The instruction pointer can be incremented or loaded from a jump vector multiplexor that facilitates conditional branching. The instruction pointer can be loaded from one of three sources: (1) a protocol identifier from the UFKB, (2) an immediate jump vector form the currently decoded instruction or (3) a value provided by the SPALU <b>1907</b>.</p>
<p id="p-0222" num="0226">After a flow signature is placed in the UFKB by the LUE with a known protocol identifier, the program counter <b>1903</b> is initialized with the last protocol recognized by the parser subsystem. This first instruction is a jump to the subroutine that analyzes the protocol that was decoded.</p>
<p id="p-0223" num="0227">In order to facilitate JUMP immediate instructions, the program counter takes an input field from the SPCB <b>1905</b> with the jump vector and loads the instruction pointer with the jump vector.</p>
<p id="p-0224" num="0228">The state processor ALU <b>1907</b> contains all the arithmetic, logical and string compare functions necessary to implement the state processor instructions. The main blocks of the SP ALU <b>1907</b> are: an A register and a B register, instruction decode &amp; state machines, a reference string memory, a search engine <b>1930</b>, an output data register and an output control register.</p>
<p id="p-0225" num="0229">The state processor ALU search engine <b>1930</b> (SPALU_SE) in turn contains a target search register set, a reference search register set, and a compare block. The search engine <b>1930</b> is able to search for up to several (four in our embodiment) reference strings anywhere in a target, and, if one of the reference strings is found, returns which reference string and the position in the target of the reference string.</p>
<p id="p-0226" num="0230">The flow key address generator <b>1911</b> generates the address to where the state processor <b>1108</b> is accessing in the unified flow key buffer. The main blocks of the SPFKAG are a flow key address pointer register, and a ROM decode that generates addresses.</p>
<p id="p-0227" num="0231">The flow-entry address generator <b>1913</b> provides. the address where the state processor <b>1108</b> is accessing the flow-entry in the cache subsystem <b>1115</b>. If a flow-entry exists, the upper address bits come from the hash is used to lookup the bucket in the flow database <b>324</b>. The middle bits come from the bucket entry found. The lower bits come from the offset the state processor <b>1108</b> is using.</p>
<p id="p-0228" num="0232">The main blocks of the SPFKAG are a flow key pointer register, and a ROM decode that generates addresses.</p>
<p id="p-0229" num="0233">The state processor UFKB Data Mux <b>1915</b> selects the data source destined to the UFKB. It multiplexes one of three sources of data into the UFKB. The three sources are an ALU output data bus, the cache output data bus and the SPCB data. The select signal is a 2-bit signal.</p>
<p id="p-0230" num="0234">The state processor Cache Data Mux <b>1917</b> selects the data source destined to the cache subsystem out of four sources of data into the cache subsystem. -The four sources are: the ALU output data bus, the lower bits of the UFKB data bus, the upper bits of the UFKB data bus and the SPCB Data. The select signal is a 2-bit signal. In order to allow for 16 bit moves, the SPMUXCA incorporates two 16 bit Muxes that supply information to the lower and upper 16 bits of the cache subsystem.</p>
<p id="p-0231" num="0235">The State Processor ALU Data Mux A <b>1919</b> selects the data source destined to the UFKB and multiplexes one of three sources of 32 bit data into the A side of the ALU. The three sources are the cache subsystem data bus, the lower 32 bits of the UFKB data bus and the upper 32 bits of the UFKB data bus. The select signal is a 2-bit signal.</p>
<p id="p-0232" num="0236">The state processor ALU Data Mux B <b>1919</b> selects the data source destined to the B side of the SP ALU and multiplexes one of two sources of 32 bit data into the B side of the ALU. The two sources are the cache subsystem data bus, an the SPCB data word. The select signal is a 1-bit signal.</p>
<p id="h-0015" num="0000">State Processor Instruction Definitions</p>
<p id="p-0233" num="0237">The following sections describe some of the instructions available in the state processor <b>1108</b>. It should be noted that typically, no assembler is provided for the state processor <b>1108</b>. This is because the engineer typically need not write code for this processor. The Compiler writes the code and loads it into the state processor instruction database from the protocols defined in the Protocol List (PDL files).</p>
<p id="p-0234" num="0238">The table is divided into two embodiments, embodiment 1, and embodiment 2 which is a more complex embodiment that includes more complex versions of embodiment 1 instructions and additional instructions.</p>
<p id="p-0235" num="0239">
<tables id="TABLE-US-00002" num="00002">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="center"/>
<tbody valign="top">
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry>State Processor Instruction Definition</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="77pt" align="left"/>
<colspec colname="2" colwidth="140pt" align="left"/>
<tbody valign="top">
<row>
<entry>Instruction</entry>
<entry>Description</entry>
</row>
<row>
<entry namest="1" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="center"/>
<tbody valign="top">
<row>
<entry>EMBODIMENT 1 Instructions (a simpler embodiment)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="77pt" align="left"/>
<colspec colname="2" colwidth="140pt" align="left"/>
<tbody valign="top">
<row>
<entry>In_Noop</entry>
<entry>No Operation</entry>
</row>
<row>
<entry>In_Wait</entry>
<entry>Wait for a condition to occur,</entry>
</row>
<row>
<entry/>
<entry>jump absolute based on the</entry>
</row>
<row>
<entry/>
<entry>condition</entry>
</row>
<row>
<entry>In_Call</entry>
<entry>Call a subroutine</entry>
</row>
<row>
<entry>In_Return</entry>
<entry>Return from a subroutine</entry>
</row>
<row>
<entry>In_WaitJR</entry>
<entry>Wait for a condition to occur,</entry>
</row>
<row>
<entry/>
<entry>jump relative based on the</entry>
</row>
<row>
<entry/>
<entry>condition</entry>
</row>
<row>
<entry>ln_Jump</entry>
<entry>Jump to an immediate jump vector</entry>
</row>
<row>
<entry/>
<entry>based on a condition</entry>
</row>
<row>
<entry>In_Move</entry>
<entry>Move Data from Location X, to Location Y</entry>
</row>
<row>
<entry>In_Load_FKAG</entry>
<entry>Load the FK Address Generator 1911</entry>
</row>
<row>
<entry>In_Inc_FKAG</entry>
<entry>Increment the FK Address Generator 1911</entry>
</row>
<row>
<entry>In_Dec_FKAG</entry>
<entry>Decrement the FK Address Generator 1911</entry>
</row>
<row>
<entry>In_Load_FEAG</entry>
<entry>Load the FE Address Generator 1913</entry>
</row>
<row>
<entry>In_Inc_FEAG</entry>
<entry>Increment the FE Address Generator 1913</entry>
</row>
<row>
<entry>In_Dec_FEAG</entry>
<entry>Decrement the FE Address Generator 1913</entry>
</row>
<row>
<entry>In_Set_SPDone</entry>
<entry>Set the SP Done Bit, a bot to indicate</entry>
</row>
<row>
<entry/>
<entry>SP1108 done</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="center"/>
<tbody valign="top">
<row>
<entry>EMBODIMENT 1 ALU Instructions</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="77pt" align="left"/>
<colspec colname="2" colwidth="140pt" align="left"/>
<tbody valign="top">
<row>
<entry>In_INC</entry>
<entry>Increment the value in the A Register</entry>
</row>
<row>
<entry>In_DEC</entry>
<entry>Decrement the value in the A Register</entry>
</row>
<row>
<entry>In_ADD</entry>
<entry>ADD Register A + Register B</entry>
</row>
<row>
<entry>In_SUB</entry>
<entry>Subtract Register A − Register B</entry>
</row>
<row>
<entry>In_AND</entry>
<entry>Bitwise OR Register A, Register B</entry>
</row>
<row>
<entry>In_OR</entry>
<entry>Bitwise OR Register A, Register B</entry>
</row>
<row>
<entry>In_XOR</entry>
<entry>Bitwise XOR Register A, Register B</entry>
</row>
<row>
<entry>In_COM</entry>
<entry>Bitwise Complement Register A</entry>
</row>
<row>
<entry>In_Simple_Compare</entry>
<entry>Compare Reg A, with Reg B. Returns a</entry>
</row>
<row>
<entry/>
<entry>SPALU_MATCH if equal</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="center"/>
<tbody valign="top">
<row>
<entry>EMBODIMENT 2 ALU Instructions (more complex implementation)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="77pt" align="left"/>
<colspec colname="2" colwidth="140pt" align="left"/>
<tbody valign="top">
<row>
<entry>In_Compare</entry>
<entry>See if the string at a fixed location</entry>
</row>
<row>
<entry/>
<entry>matches one in a reference</entry>
</row>
<row>
<entry/>
<entry>string array of reference strings</entry>
</row>
<row>
<entry>In_Find</entry>
<entry>Find a string (or a set of strings) in a range,</entry>
</row>
<row>
<entry/>
<entry>with the starting position unknown</entry>
</row>
<row>
<entry>In_FindContinue</entry>
<entry>Perform a Find operation starting</entry>
</row>
<row>
<entry/>
<entry>from the location where the</entry>
</row>
<row>
<entry/>
<entry>last string was found.</entry>
</row>
<row>
<entry>In_AD2B</entry>
<entry>Convert an ASCII Decimal character</entry>
</row>
<row>
<entry/>
<entry>to Binary</entry>
</row>
<row>
<entry>In_AD2BContinue</entry>
<entry>Convert an ASCII Decimal character</entry>
</row>
<row>
<entry/>
<entry>to Binary</entry>
</row>
<row>
<entry>In_AH2B</entry>
<entry>Convert an ASCII Hex character</entry>
</row>
<row>
<entry/>
<entry>to Binary</entry>
</row>
<row>
<entry>In_AH2BContinue</entry>
<entry>Convert an ASCII Hex character</entry>
</row>
<row>
<entry/>
<entry>to Binary</entry>
</row>
<row>
<entry namest="1" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
<br/>
Some of these instructions are now described in more detail.
<br/>
Move
</p>
<p id="p-0236" num="0240">The move instruction set includes specific move instructions that deal with moving different size words from a source to a destination. The set of Move instructions has been developed to ensure the word sizes always match, and includes 32 bit and 16 bit Move instructions</p>
<p id="p-0237" num="0241">The Move instruction moves data from: immediate data to the SP ALU B register, immediate data to the cache subsystem, immediate data to the UFKB, the SP ALU Output to the UFKB, the SP ALU Output to the cache subsystem, the cache to the UFKB, the cache to the SP ALU A register, the cache to the SP ALU B register, UFKB to the cache subsystem, and the UFKB to the SP ALU A register.</p>
<p id="h-0016" num="0000">In_Compare</p>
<p id="p-0238" num="0242">The In_Compare instruction instructs the ALU <b>1907</b> to perform a compare operation and return a MATCH signal along with the matched string information. A compare operation compares a target data whose first character is located at a known location in the UFKB, and a known reference string in the reference string memory. Prior to executing this instruction, the SP UFKB address generator <b>1911</b> is loaded with the address pointing to the target character. A location in the ALU reference memory holds a list of reference characters to compare.</p>
<p id="h-0017" num="0000">ASCII Decimal to Binary</p>
<p id="p-0239" num="0243">This instruction passes the location of an ASCII code string representing a decimal value. The result is the binary equivalent value. This is carried out in one cycle.</p>
<p id="h-0018" num="0000">ASCII Hex to Binary</p>
<p id="p-0240" num="0244">This instruction passes the location of an ASCII code string representing a hex value. The result is the binary equivalent value. This is carried out in one cycle.</p>
<p id="h-0019" num="0000">In_Find</p>
<p id="h-0020" num="0000">In_Find_Continue</p>
<p id="p-0241" num="0245">These instructions are described in more detail in the following section describing the search engine <b>1930</b>.</p>
<p id="h-0021" num="0000">The Search Engine and SP Instructions Invoking the Search Engine</p>
<p id="p-0242" num="0246">One aspect of the monitor <b>300</b> is its ability to analyze each and every packet in real time. Network traffic may move at a very fast rate. One of the tasks of the state processor <b>1107</b> is to search for one or more known strings of data. Such searches are carried out on the UFKB records, for example, in the payload section of the record. The searches may be in known parts of the record, or may be in unknown parts of the record, for example, anywhere in the payload part of a UFKB record. Furthermore, the searches may need to be carried out at extremely high rates.</p>
<p id="p-0243" num="0247">The state processor ALU includes a search engine SPALU_SE <b>1930</b> for carrying out such searches. The search engine <b>1930</b> is capable of searching up to four reference strings in a target area in the UFKB, and in parallel indicates (1) if any of the four strings are found anywhere in the target, (2) which string was found, and (3) where in the target the string was found.</p>
<p id="p-0244" num="0248">The search engine provides for carrying out the following state processor instructions.</p>
<p id="h-0022" num="0000">In_Find</p>
<p id="p-0245" num="0249">The In_Find instruction provides information to the ALU-Search Engine to perform a Find operation and return a match signal along with the matched string information and the location at which the string was found in the target.</p>
<p id="p-0246" num="0250">The instruction format is as follows:</p>
<p id="p-0247" num="0251">In_Find [Reference String Array Address], [UFKB Byte Offset], [Range]</p>
<p id="p-0248" num="0252">
<tables id="TABLE-US-00003" num="00003">
<table frame="none" colsep="0" rowsep="0" pgwide="1">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="259pt" align="center"/>
<thead>
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry>Instruction Word Definition</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="42pt" align="left"/>
<colspec colname="2" colwidth="217pt" align="left"/>
<tbody valign="top">
<row>
<entry>Bit</entry>
<entry>Description</entry>
</row>
<row>
<entry namest="1" nameend="2" align="center" rowsep="1"/>
</row>
<row>
<entry>In_Find</entry>
<entry>OpCode</entry>
</row>
<row>
<entry>N (size of</entry>
<entry>Reference String Array Address in the ALU Reference Memory.</entry>
</row>
<row>
<entry>Abus)</entry>
<entry>the ALU Reference Memory can store an array of one to four</entry>
</row>
<row>
<entry/>
<entry>reference strings to be found. Each reference string is N<sub>R </sub>units long, in our</entry>
</row>
<row>
<entry/>
<entry>implementation, a unit is a byte, and N<sub>R </sub>is 16.</entry>
</row>
<row>
<entry>Offset (2:0)</entry>
<entry>UFKB Byte Offset</entry>
</row>
<row>
<entry/>
<entry>This is the offset address pointing to a byte in the selected UFKB</entry>
</row>
<row>
<entry/>
<entry>entry.</entry>
</row>
<row>
<entry/>
<entry>The offset is used to determine which byte within the selected</entry>
</row>
<row>
<entry/>
<entry>UFKB entry is the first byte location to start the find operation. If the</entry>
</row>
<row>
<entry/>
<entry>UFKB is 64 bits (8 bytes) this field would be 3 bits wide and</entry>
</row>
<row>
<entry/>
<entry>point to the first target byte to start the find operation.</entry>
</row>
<row>
<entry>Range (7:0)</entry>
<entry>The Range, in number of bytes, in the UFKB area to be searched.</entry>
</row>
<row>
<entry/>
<entry>This means the number of bytes to search. It typically specifies how</entry>
</row>
<row>
<entry/>
<entry>many bytes of a particular field in the particular UFKB record to</entry>
</row>
<row>
<entry/>
<entry>search.</entry>
</row>
<row>
<entry/>
<entry>If a full MATCH does not result after comparing this range, the find</entry>
</row>
<row>
<entry/>
<entry>operation is concluded.</entry>
</row>
<row>
<entry namest="1" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="259pt" align="center"/>
<tbody valign="top">
<row>
<entry>Reference String Memory Data Structure for In_Find Operations</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="42pt" align="left"/>
<colspec colname="2" colwidth="217pt" align="left"/>
<tbody valign="top">
<row>
<entry>Bit Field</entry>
<entry>Description</entry>
</row>
<row>
<entry namest="1" nameend="2" align="center" rowsep="1"/>
</row>
<row>
<entry># of Strings</entry>
<entry># of Strings in Array indicates the total number of strings in this array.</entry>
</row>
<row>
<entry>(8 bits)</entry>
<entry>Valid numbers are 0,1,2,3 for 1,2,3 or 4 strings.</entry>
</row>
<row>
<entry/>
<entry>8 bits are allocated for future expansion and to simplify the</entry>
</row>
<row>
<entry/>
<entry>implementation.</entry>
</row>
<row>
<entry>Size of 1<sup>st</sup></entry>
<entry>This parameter indicates the size of the 1<sup>st </sup>string in bytes. The value</entry>
</row>
<row>
<entry>String</entry>
<entry>placed here is N<sub>R1 </sub>−1. Valid numbers are 0-F for a string as small as</entry>
</row>
<row>
<entry>(4 bits)</entry>
<entry>1 character and as large as 0xF characters.</entry>
</row>
<row>
<entry>Size of 2<sup>nd</sup></entry>
<entry>This parameter indicates the size of the 2<sup>nd </sup>string in bytes. The value</entry>
</row>
<row>
<entry>String</entry>
<entry>placed here is N<sub>R2 </sub>−1. Valid numbers are 0-F for a string as small as</entry>
</row>
<row>
<entry>(4 bits)</entry>
<entry>1 character and as large as 0xF characters.</entry>
</row>
<row>
<entry>Size of 3<sup>rd</sup></entry>
<entry>This parameter indicates the size of the 3<sup>rd </sup>string in bytes. The value</entry>
</row>
<row>
<entry>String</entry>
<entry>placed here in N<sub>R3 </sub>−1. Valid numbers are 0-F for a string as small as</entry>
</row>
<row>
<entry>(4 bits)</entry>
<entry>1 character and as large as 0xF characters.</entry>
</row>
<row>
<entry>Size of 4<sup>th</sup></entry>
<entry>This parameter indicates the size of the 4<sup>th </sup>string in bytes. The value</entry>
</row>
<row>
<entry>String</entry>
<entry>placed here in N<sub>R4 </sub>−1. Valid numbers are 0-F for a string as small as</entry>
</row>
<row>
<entry>(4 bits)</entry>
<entry>1 character and as large as 0xF characters.</entry>
</row>
<row>
<entry>String1</entry>
<entry>1 to 16 (=N<sub>R</sub>) characters of string1.</entry>
</row>
<row>
<entry>String2</entry>
<entry>1 to 16 (=N<sub>R</sub>) characters of string2.</entry>
</row>
<row>
<entry>String3</entry>
<entry>1 to 16 (=N<sub>R</sub>) characters of string3.</entry>
</row>
<row>
<entry>String4</entry>
<entry>1 to 16 (=N<sub>R</sub>) characters of string4.</entry>
</row>
<row>
<entry>Vector</entry>
<entry>This is a 16 bit (i.e., N<sub>R</sub>-bit) vector returned to the program counter</entry>
</row>
<row>
<entry>(16 bits)</entry>
<entry>to point to an area in the SPID that processes the result of the</entry>
</row>
<row>
<entry/>
<entry>In_Find.</entry>
</row>
<row>
<entry namest="1" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0249" num="0253">When the search is complete, a Search Done bit is asserted. A MATCH bit is asserted or reset based on the result of the search. A bus in the ALU, called the ALU_DATA bus, will hold the following information:
<ul id="ul0004" list-style="none">
    <li id="ul0004-0001" num="0000">
    <ul id="ul0005" list-style="none">
        <li id="ul0005-0001" num="0254">Jump_Vector[<b>15</b>:<b>0</b>]—this is a vector stored in the Reference String Array and indicates what instructions (e.g., subroutine) the state processor jumps to when a reference string is found.</li>
        <li id="ul0005-0002" num="0255">String Code[<b>1</b>:<b>0</b>]—this is the string code indicating which of the reference strings was found, i.e., 0, 1, 2, or 3 for the four reference string implementation.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0250" num="0256">The location at which the string was found in the Flow Key Buffer is maintained. This is a combination of the UFKB word address and the byte location of the first character of the target found string.</p>
<p id="p-0251" num="0257">The search is done if the first occurrence of any of the reference strings is found, or if there is no MATCH in the entire search range.</p>
<p id="p-0252" num="0258">Consider the following example. Assume we wish to search for a reference string in the payload area of the UFKB and search starting at byte location 5 of the payload and stop searching at byte location 100. Assume the reference string is located at location 0050h. The instruction format for this example would be as follows:</p>
<p id="p-0253" num="0259">In_Load_FKAG, payload address</p>
<p id="p-0254" num="0260">In_Find, 0050<sub>16</sub>, 5, 60<sub>16 </sub></p>
<p id="p-0255" num="0261">The range would be 100−5+1=96=60<sub>16 </sub></p>
<p id="p-0256" num="0262">Consider as a second example, searching locations 12<sub>16 </sub>to location 2A<sub>16 </sub>in the UFKB.</p>
<p id="h-0023" num="0000">The following state processor instructions will achieve this.</p>
<p id="p-0257" num="0263">In_Load_FKAG 02<sub>16 </sub></p>
<p id="p-0258" num="0264">in_Find [Reference String Address], 2,19<sub>16 </sub></p>
<p id="p-0259" num="0265">Note that 2A<sub>16</sub>−12<sub>16</sub>+1=19<sub>16</sub>.</p>
<p id="h-0024" num="0000">In_Find_Continue</p>
<p id="p-0260" num="0266">This instruction follows an In_Find instruction and tells the ALU-Search Engine <b>1930</b> to perform a Find operation starting from the location where the last string was found and return a MATCH along with the matched string information and the location at which the target string was found. The purpose for this instruction is to facilitate searching for a new reference string starting from the location where a previous search ended. Therefore, an offset is not provided since the Search Engine will remember the location where it finished its previous search.</p>
<p id="p-0261" num="0267">The instruction format is as follows:</p>
<p id="p-0262" num="0268">In_Find_Continue [Reference String Array Address], [<b>0</b>], [Range]</p>
<p id="p-0263" num="0269">
<tables id="TABLE-US-00004" num="00004">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="center"/>
<tbody valign="top">
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry>Instruction Word Definition</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="offset" colwidth="14pt" align="left"/>
<colspec colname="1" colwidth="49pt" align="left"/>
<colspec colname="2" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>Bit</entry>
<entry>Description</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
<row>
<entry/>
<entry>In_Find</entry>
<entry>Opcode</entry>
</row>
<row>
<entry/>
<entry>N (size of</entry>
<entry>Reference String Array Address in the ALU</entry>
</row>
<row>
<entry/>
<entry>Abus)</entry>
<entry>Reference Memory. At this location, there is an</entry>
</row>
<row>
<entry/>
<entry/>
<entry>array of one to four reference strings to</entry>
</row>
<row>
<entry/>
<entry/>
<entry>be found. A Reference String Data Structure</entry>
</row>
<row>
<entry/>
<entry/>
<entry>of the array is defined in the Reference Memory</entry>
</row>
<row>
<entry/>
<entry/>
<entry>Data Structure section below.</entry>
</row>
<row>
<entry/>
<entry/>
<entry>(Default N = 16)</entry>
</row>
<row>
<entry/>
<entry>Offset (2:0)</entry>
<entry>UFKB Byte Offset</entry>
</row>
<row>
<entry/>
<entry/>
<entry>Always Zero.</entry>
</row>
<row>
<entry/>
<entry>Range (7:0)</entry>
<entry>The Range, in number of byte, in the UFKB</entry>
</row>
<row>
<entry/>
<entry/>
<entry>area to be searched.</entry>
</row>
<row>
<entry/>
<entry/>
<entry>This means the number of bytes to search.</entry>
</row>
<row>
<entry/>
<entry/>
<entry>If a full MATCH does not result after</entry>
</row>
<row>
<entry/>
<entry/>
<entry>comparing this range, the find</entry>
</row>
<row>
<entry/>
<entry/>
<entry>operation is concluded.</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0264" num="0270">As an example, assume we wish to In_Find a string (String A) in the payload area of the UFKB and search starting at byte location 5 of the payload and stop searching at byte location 100. Assume the reference string (String A) is located at location 0050<sub>16</sub>. After finding the first reference string, assume we wish to continue searching for a new string (String B) in the following 30<sub>16 </sub>bytes. Assume String B is located at location 0080h.</p>
<p id="p-0265" num="0271">The instruction format for this example would be as follows:
<ul id="ul0006" list-style="none">
    <li id="ul0006-0001" num="0000">
    <ul id="ul0007" list-style="none">
        <li id="ul0007-0001" num="0272">In_Load_FKAG, payload address</li>
        <li id="ul0007-0002" num="0273">In_Find, 005016, 5, 6016</li>
        <li id="ul0007-0003" num="0274">. . .</li>
        <li id="ul0007-0004" num="0275">In_Find_Continue, 0080<sub>16</sub>, 5, 30<sub>16 </sub></li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0266" num="0276">The range would be 100−5+1=96=60<sub>16 </sub></p>
<p id="p-0267" num="0277"><figref idref="DRAWINGS">FIG. 20</figref> is an overall block diagram of the search engine (SPALU_SE) <b>1930</b> that is part of the ALU <b>1907</b> and that executes the In_Find and In_Find_Continue instructions issued to the ALU <b>1907</b>. The In_Find Instructions searches an area of the UFKB and looks for up to four possible reference strings in the target (UFKB) area. The reference strings are stored in the ALU Reference String Memory.</p>
<p id="p-0268" num="0278">As shown in <figref idref="DRAWINGS">FIG. 20</figref>, the Search Engine is coupled with the following components:</p>
<p id="p-0269" num="0279">(a) ALU String Reference Memory <b>2003</b> where the reference strings are stored.</p>
<p id="p-0270" num="0280">(b) SPALU Data Mux A <b>1919</b> through which the target data <b>2011</b> for matching with the reference string is supplied. This is coupled to the UFKB during operation of the In_Find instruction using SP_UFKB Data Mux <b>1915</b>.</p>
<p id="p-0271" num="0281">(c) SPALU Data Mux B <b>1921</b> through which the instruction code is supplied, including the “Go” signal SPALUGO <b>2005</b> to start the search.</p>
<p id="p-0272" num="0282">(d) The state processor flow key address generator <b>1911</b> used to increment and decrement the UFKB address.</p>
<p id="p-0273" num="0283">(e) The state processor program counter <b>1903</b> where the results of the search are reported.</p>
<p id="p-0274" num="0284">The system is run by a clock signal CLK <b>2001</b> and may be reset by a RESET signal. An instruction decode block SE_INST <b>2009</b> decodes the instruction code for In_Find and In_Find_Continue and starts the Search Engine upon the activation of the SPALUGO signal <b>2005</b>. The Search Engine continuously monitors the SPMuxB <b>1921</b> output bus <b>2007</b> and SPALUGO signal <b>2005</b> to detect the In_Find and In_Find_Continue instructions. During operation of the search engine <b>1930</b> the engine receives the target data <b>2011</b>, in word size, from the UFKB <b>1103</b> through SPMUXA <b>1919</b>. Similarly, the reference string(s) from the appropriate address of a reference string memory <b>2003</b> arrives as data SP_Data_RMB <b>2013</b>.</p>
<p id="p-0275" num="0285">A Search Engine Reference Load (SE_LOAD) module <b>2015</b> is responsible for “priming” reference string registers once an In_Find or In_Find_Continue instruction is issued. It takes a reference string array from the reference string memory <b>2003</b> and interprets it and loads the reference string registers with the information.</p>
<p id="p-0276" num="0286">In the processing state, the SE-LOAD module <b>2015</b> first loads the first word from the starting location of the reference memory <b>2003</b>. The starting location is assumed to be set up at the proper location prior to issuing of the instruction. Once the number of strings and the size of the strings are loaded, the loading process continues loading all of the reference strings. An increment reference signal <b>2025</b> increments the reference memory from where the reference string is being loaded. During the loading of the strings, a LOAD_KEY_DONE signal <b>2017</b> is unasserted. A LOAD_KEY signal <b>2019</b> is pulsed when the last word of the last reference string is being loaded indicating to the search_engine_module <b>2030</b> to start searching from the next clock cycle. The LOAD_KEY_DONE signal <b>2017</b> is asserted during the next clock cycle and the jump vector <b>2021</b> is loaded at the same time from the Reference Memory <b>2003</b>.</p>
<p id="p-0277" num="0287">The Search Engine Increment/Control module (SE_INC) <b>2023</b> is responsible for incrementing the flow key address generator <b>1911</b> in order to supply new words from the UFKB to the Search Engine. It monitors the found signals out of the Search Engine modules and reports results. SE_INC <b>2023</b> is also responsible for calculating true ending address and determines the last byte to be checked in the last word based on the Range provided in the In_Find instruction.</p>
<p id="p-0278" num="0288">The SE-4SEARCH <b>2030</b> module includes four search engines to search for four strings simultaneously. The engine outputs a found signal <b>2031</b> and a position signal <b>2033</b> for each of the four reference strings to indicate if and where the string was found.</p>
<p id="p-0279" num="0289">The assertion of SPALU_Done signal <b>2035</b> by SE-INC <b>2023</b> indicates the search is completed. If the SPALU_Match signal <b>2037</b> is asserted at the same time then it is a successful search. The successful search also results in the SPALU_Data bus <b>2039</b> carrying the jump vector along with the search engine number that found the reference string.</p>
<p id="p-0280" num="0290">One aspect of the invention is the speediness of searching. The longest time for the SPALU_Done <b>2035</b> to be asserted from the time the instruction is issued for searching anywhere in a number N of words in the UFKB is N clock cycles plus an additional number of clock cycles for pre-loading and pointer adjustment in case of successful search. In our embodiment, this additional overhead is 11 clock cycles. Therefore, each extra word takes only one clock cycle.</p>
<p id="p-0281" num="0291"><figref idref="DRAWINGS">FIG. 21</figref> shows the SE<sub>—</sub>4SEARCH module <b>2030</b> that includes four single search modules. Alternate embodiments may include more single search modules to enable searching for more than four reference strings simultaneously. Each of the four search engine modules is identical, so only one such module <b>2103</b> will be described.</p>
<p id="p-0282" num="0292">Each of the single search modules <b>2103</b> performs a single reference string search. Using multiple copies of this module multiple distinct reference strings can be searched in a common source buffer (the UFKB). The module includes a core comparator matrix block <b>2105</b> (the search engine core) and a state machine SE_SM <b>2107</b>. The search engine core <b>2105</b> is capable of comparing a reference string up to N<sub>R </sub>units (16 bytes in our embodiment) with a target string of three eight-byte words (loaded in three successive cycles, one word at a time). During each clock cycle, the single search modules <b>2103</b> searches for the reference string anywhere in the target starting from any of the eight bytes of the first word. Each of the reference string bytes is appended with a check bit, which indicates whether to check this byte, or not. If the check bit is asserted, then the corresponding byte checking is disabled. As 64-bit words (8 bytes) are loaded into three registers in a pipelined fashion, the comparison takes place two clock cycles after they are fetched.</p>
<p id="p-0283" num="0293">The source (UFKB) address pointer needs to be adjusted if the search is successful. If the search is successful, a match signal <b>2111</b> becomes active and the position of the first byte of the reference string is placed out on a position bus <b>2113</b>. The SE_SM state machine <b>2107</b> performs several tasks every clock cycle. It has three states: reset, idle, and process. While in the idle state, the state machine <b>2107</b> waits for a signal from the SE_LOAD module <b>2015</b> to switch to the Process State. During the first clock cycle in the Process State, if a match occurs then the position is checked against the byte offset <b>2115</b>. If the byte offset is greater then the position, then it is ignored, i.e. found is not asserted. Similarly, if it is the last word to be checked, then the end offset byte is checked with the position and the found is ignored if the position is greater then last byte to be checked in the range <b>2117</b>. Otherwise, the found signal is asserted when the match is found by the search engine core <b>2105</b> and the position is latched and forwarded to the SE_INC module <b>2023</b>.</p>
<p id="p-0284" num="0294">Referring now to <figref idref="DRAWINGS">FIG. 22A</figref>, the search engine core <b>2105</b> is the core comparator matrix of the search engine module. It searches for an N<sub>R</sub>-unit reference string in a target string. It includes a reference axis and a target axis. The reference axis includes a register that holds the reference string, in general a string of N<sub>R </sub>units. The unit is a byte and N<sub>R </sub>is 16 in the preferred embodiment, and other units and the matrix may easily be modified to search for other reference string sizes. The target data is organized as words. The target axis is arranged as a series of one word registers each holding a word of target data. A word is clocked into the register in one clock cycle. Thus, the first word of the target data is clocked into the target axis in three cycles.</p>
<p id="p-0285" num="0295">The search engine core <b>2105</b> includes at least one N<sub>R</sub>-unit comparator each having N<sub>R </sub>pairs of inputs and an output indicating a match of each pair of the N<sub>R</sub>-pairs of inputs. One such comparator <b>2203</b> is shown in <figref idref="DRAWINGS">FIG. 22B</figref>. The pairs of inputs are shown as (<b>2207</b>-<b>1</b>, <b>2209</b>-<b>1</b>), (<b>2207</b>-<b>2</b>, <b>2202</b>-<b>2</b>), . . . , (<b>2207</b>-N<sub>R</sub>, <b>2207</b>-N<sub>R</sub>). The output is <b>2211</b>. <figref idref="DRAWINGS">FIG. 22A</figref> shown a number (say N<sub>start</sub>) comparators labeled <b>2203</b>-<b>1</b>, <b>2203</b>-<b>2</b>, . . . , <b>2203</b>-N<sub>start</sub>. Considering any one of the comparators, the search engine core also includes a matrix of connections including N<sub>R </sub>connections indicating values of the reference string along the reference axis, and N<sub>R </sub>connections indicating values of the target data along the target axis, the target data connections starting from a first starting location of the target data and ending at an ending location. The comparators are connected such that when the reference and target axes are oriented perpendicular to each other, any comparator is oriented along the diagonal of the matrix such that N<sub>R </sub>connections of the target data are compared to the reference string. Each comparator starts at a different location in the target axis. In our implementation, each word is 8 bytes long, the number of comparators N<sub>start </sub>is the same as the word size, and the comparators start at contiguous locations on the target axis. Thus, in one clock cycle the search engine core <b>2105</b> can find the reference string starting from any location in the first word. Notice that if a target string happens to cross a word boundary, the search engine core will still automatically find the word.</p>
<p id="p-0286" num="0296">The outputs of the comparators are input into an N<sub>start </sub>input priority encoder that indicates if a string is found which of the N<sub>start </sub>comparators found the string. This provides for the location.</p>
<p id="p-0287" num="0297">During operation after the data is loaded, in the first clock cycle, the state machine <b>2107</b> will ignore any strings that might be found in the first few comparators, that number of comparators indicated by the offset. During each subsequent clock cycle, the search engine core <b>2105</b> will find the reference string if it starts anywhere in the first N<sub>start </sub>positions. Thus, in a number of clock cycles, the search engine core <b>2105</b> will find the reference string anywhere in the target data.</p>
<p id="p-0288" num="0298"><figref idref="DRAWINGS">FIG. 23A</figref> shows an implementation of the input core in more detail. This implementation is for finding the reference string in any of a set of starting positions. The implementation includes a reference register <b>2203</b> for receiving the N<sub>R </sub>units of one of the reference strings, a set of target data registers <b>2205</b> coupled in series to receive the target data, a plurality of comparator sets, one comparator set corresponding to each of the starting positions, the comparator set of a particular starting position coupled to each unit—each byte in this implementation—of the reference register and to N<sub>R </sub>units—bytes in this case—of the target data registers starting from the particular starting position and comparing the first reference register contents to N<sub>R </sub>units of the target data registers starting from the particular staring position. Each comparator set indicates if there is a match of first reference string in the target data starting from its corresponding different starting position. The set of possible starting positions might include N<sub>start </sub>different positions. These positions may or may not be contiguous, and if contiguous, the one or more target data registers are coupled in series to receive at least N<sub>R</sub>+N<sub>start</sub>−1 units of the target data. Thus there are N<sub>start </sub>comparator sets, one comparator set for each of the N<sub>start </sub>starting positions.</p>
<p id="p-0289" num="0299">Each comparator set includes N<sub>R </sub>consecutive comparators. One such comparator <b>2313</b> is shown in <figref idref="DRAWINGS">FIG. 23B</figref>, and includes a reference input, a target input, an enable input, and an output indicating a match, such that the output of a comparator <b>2313</b> is asserted when the reference and target inputs match and the enable input is asserted. For a particular set of comparators for a particular starting position, the reference inputs of consecutive comparators are coupled to consecutive units of the reference register, the target data inputs of consecutive comparators are coupled to consecutive units of the target data registers starting at the particular starting location, the first comparator of the set is enabled, and the enable input of each comparator is coupled to the output of the previous comparator, such that the output of the final comparator is asserted when the N<sub>R </sub>units of the reference string and the N<sub>R </sub>units of the target data agree.</p>
<p id="p-0290" num="0300">In this way, the state processor is able to locate strings at unknown locations in areas of the packets (stored in the UFKB) at an extremely high rate.</p>
<p id="p-0291" num="0301">Although the present invention has been described in terms of the presently preferred embodiments, it is to be understood that the disclosure is not to be interpreted as limiting. Various alterations and modifications will no doubt become apparent to those or ordinary skill in the art after having read the above disclosure. Accordingly, it is intended that the claims be interpreted as covering all alterations and modifications as fall within the true spirit and scope of the present invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A processor configured to process contents of packets passing through a connection point on a computer network, the processor comprising:
<claim-text>(a) a buffer for receiving at least some of the contents of each packet passing through the connection point;</claim-text>
<claim-text>(b) a memory containing one or more instructions of an instruction set for the state processor;</claim-text>
<claim-text>(c) an arithmetic logic unit (ALU) coupled to the buffer;</claim-text>
<claim-text>(d) a control block coupled to the ALU and to the instruction memory for decoding instructions; and</claim-text>
<claim-text>(e) a program counter coupled to the instruction memory and to the ALU for indicating the next state processor instruction in the memory to process,</claim-text>
</claim-text>
<claim-text>wherein the ALU includes a searching apparatus comprising one or more comparators for searching for a reference string in the contents of a packet.</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. A processor according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the state processor processes contents of all packets passing through the connection point in real time.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. A processor according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instruction set includes an instruction for invoking the searching apparatus of the ALU to search for a specified reference string in the packet starting at an unknown location within a range of the packet.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A processor according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the searching apparatus searches for any of a set of reference strings in the contents of a packet, and wherein the instruction set includes an instruction for invoking the searching apparatus to search for any of a set of specified reference strings in the packet starting at an unknown location within a range of the packet.</claim-text>
</claim>
</claims>
</us-patent-grant>
