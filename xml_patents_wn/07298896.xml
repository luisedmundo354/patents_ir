<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298896-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298896</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>09796743</doc-number>
<date>20010302</date>
</document-id>
</application-reference>
<us-application-series-code>09</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2000-059341</doc-number>
<date>20000303</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>203</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>38</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382172</main-classification>
<further-classification>382273</further-classification>
</classification-national>
<invention-title id="d0e71">Image processing device for optically decoding an image recorded on a medium for digital transmission of the image information</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5179599</doc-number>
<kind>A</kind>
<name>Formanek</name>
<date>19930100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382172</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5280367</doc-number>
<kind>A</kind>
<name>Zuniga</name>
<date>19940100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358462</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5617484</doc-number>
<kind>A</kind>
<name>Wada et al.</name>
<date>19970400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382172</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5751848</doc-number>
<kind>A</kind>
<name>Farrell</name>
<date>19980500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382172</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5784500</doc-number>
<kind>A</kind>
<name>Homma et al.</name>
<date>19980700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382270</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5848182</doc-number>
<kind>A</kind>
<name>Kanamori</name>
<date>19981200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382171</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>5889885</doc-number>
<kind>A</kind>
<name>Moed et al.</name>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382172</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6028958</doc-number>
<kind>A</kind>
<name>Kanamori</name>
<date>20000200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382171</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6363381</doc-number>
<kind>B1</kind>
<name>Lee et al.</name>
<date>20020300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  6</main-classification></classification-national>
</citation>
</references-cited>
<number-of-claims>2</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382168</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382170</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382172</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382270</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382271</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382273</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358465</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>15</number-of-drawing-sheets>
<number-of-figures>18</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20010036314</doc-number>
<kind>A1</kind>
<date>20011101</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Yamaguchi</last-name>
<first-name>Nobuyasu</first-name>
<address>
<city>Machida</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Chiba</last-name>
<first-name>Hirotaka</first-name>
<address>
<city>Atsugi</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Noda</last-name>
<first-name>Tsugio</first-name>
<address>
<city>Hadano</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Kratz, Quintos &amp; Hanson, LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Fujitsu Limited</orgname>
<role>03</role>
<address>
<city>Kawasaki</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>LaRose</last-name>
<first-name>Colin</first-name>
<department>2624</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An image processing device such as an image scanner, etc., and its objective is to actualize a proper binarizing routine specific to the types of images. A histogram of density values is drawn based on decoded data, and after the respective levels and frequencies of the white and black peak values have been calculated, the types of decoded images are classified based on their relationships. After the original type has been thus determined, a binarization threshold value calculation method optimally suited for said type is selected, and after the threshold value has been thereby calculated, an image binarizing routine is executed.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="157.90mm" wi="165.10mm" file="US07298896-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="189.65mm" wi="182.03mm" file="US07298896-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="201.68mm" wi="156.72mm" file="US07298896-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="214.29mm" wi="186.18mm" file="US07298896-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="248.92mm" wi="189.06mm" file="US07298896-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="238.17mm" wi="181.10mm" file="US07298896-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="247.90mm" wi="183.56mm" file="US07298896-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="190.33mm" wi="164.51mm" file="US07298896-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="192.79mm" wi="175.01mm" file="US07298896-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="222.67mm" wi="173.82mm" file="US07298896-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="194.73mm" wi="176.95mm" file="US07298896-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="188.47mm" wi="160.78mm" file="US07298896-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="261.79mm" wi="171.03mm" file="US07298896-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="209.47mm" wi="185.34mm" file="US07298896-20071120-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="224.11mm" wi="180.85mm" file="US07298896-20071120-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="214.21mm" wi="169.67mm" file="US07298896-20071120-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">1. Field of the Invention</p>
<p id="p-0003" num="0002">The present invention relates to an image processing device such as an image scanner, facsimile, etc. More specifically, it relates to an image processing device that optically decodes an image which has been recorded on a medium and then converts it into an electrical signal to enable the display and transmission of digitalized information.</p>
<p id="p-0004" num="0003">2. Description of the Related Art</p>
<p id="p-0005" num="0004">As far as image processing devices of the prior art are concerned, routines for binarizing recorded multivalent image data by comparing it with threshold levels is being widely practiced, and various techniques are known for executing such binarizing routines.</p>
<p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. 13</figref> is a diagram which shows the constitution of an image processing device <b>5</b> of the prior art. The image decoding unit <b>14</b> includes a sensor unit <b>10</b>. An analog signal <b>12</b> produced by said sensor unit <b>10</b> in accordance with the original decoding action of the image decoding unit <b>14</b> is converted into a digital signal <b>16</b> in an analog-digital conversion unit (A/D conversion unit) <b>18</b>. The digital signal <b>16</b> which has been outputted by said A/D conversion unit <b>18</b> (one decoded line equivalent) is temporarily retained in a line data retention unit <b>20</b>.</p>
<p id="p-0007" num="0006">The digital signal <b>16</b> which has been produced by the A/D conversion unit <b>18</b> is further transferred to a density histogram generation unit <b>22</b> in the image processing unit <b>28</b>. The density histogram generation unit <b>22</b> generates a histogram of the densities of the respective image pixels decoded.</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIGS. 14(</figref><i>a</i>) and <b>14</b>(<i>b</i>) are diagrams explaining the action of the density histogram generation unit <b>22</b>. Raw image data which have been decoded by the sensor unit <b>10</b> are shown in <figref idref="DRAWINGS">FIG. 14(</figref><i>a</i>). The image data shown in <figref idref="DRAWINGS">FIG. 14(</figref><i>b</i>), which have been decoded, are transferred to the density histogram generation unit <b>22</b>, from which a density histogram characterized by the distribution shown in <figref idref="DRAWINGS">FIG. 14(</figref><i>b</i>) is generated.</p>
<p id="p-0009" num="0008">As far as the device of the prior art is concerned, a threshold level for binarizing an image is generated by using this density histogram. The density histogram information is transferred to a threshold value generation unit <b>24</b>, from which a threshold value <b>26</b> is generated, as shown in <figref idref="DRAWINGS">FIG. 13</figref>. The following calculation is involved in one example: Threshold value=0.5×(white peak value−black peak value)+black peak value. It may be assumed that “black peak value” signifies the peak density value of character segments, whereas the “white peak density” signifies the peak density value of the white background of the original. As far as the aforementioned example of the prior art is concerned, an intermediate level of the high-density peak level and the low-density peak level (i.e., ½) is designated as a “standard binarization” threshold value <b>26</b>. This binarization threshold value <b>26</b> is input to a binarization unit <b>27</b> to produce binarized image data <b>29</b>.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 15</figref> is a diagram that shows another prior art example of an image processing device <b>5</b> for generating a threshold value <b>26</b>. A digital signal <b>16</b>, which has been outputted from an A/D conversion unit <b>18</b>, is inputted into a shading calibration unit <b>30</b>. Subsequently, a threshold level is generated according to procedures similar to those for the device of <figref idref="DRAWINGS">FIG. 13</figref>.</p>
<p id="p-0011" num="0010">In the example of <figref idref="DRAWINGS">FIG. 15</figref>, however, the binarization threshold value <b>26</b> is designated while the low-density/high-density peak frequency is being taken into account. <figref idref="DRAWINGS">FIGS. 16(</figref><i>a</i>) and <b>16</b>(<i>b</i>) are diagrams explaining the action of the density histogram generation unit <b>22</b> of <figref idref="DRAWINGS">FIG. 15</figref>. the following values are specifically calculated: Minimal-to-maximal density ratio=maximal density peak frequency/(maximal density peak frequency+minimal density peak frequency); threshold value=minimal-to-maximal density ratio×(maximal density peak value−minimal density peak value)+minimal density peak value.</p>
<p id="p-0012" num="0011">The example shown in <figref idref="DRAWINGS">FIGS. 13</figref>, <b>14</b>(<i>a</i>) and <b>14</b>(<i>b</i>) suffers from a disadvantage in that when the frequency rations of black and white segments radically differ (e.g., two-dimensional code), the two-dimensional code information may become excessively dense or thin even if the threshold value <b>26</b> is designated at the ½ level of the respective peak values, as a result of which it becomes impossible to binarize and reproduce the white and black dimensions of the original in high fidelity.</p>
<p id="p-0013" num="0012">The example shown in <figref idref="DRAWINGS">FIGS. 15</figref>, <b>16</b>(<i>a</i>) and <b>16</b>(<i>b</i>), on the other hand, is capable of alleviating the problem of the example shown in <figref idref="DRAWINGS">FIGS. 13</figref>, <b>14</b>(<i>a</i>) and <b>14</b>(<i>b</i>) to some extent, but depending on the types of originals, it may become impossible to reproduce and express the frequency ratios of the black and white segments of the original in high fidelity, as a result of which it becomes impossible to execute a binarizing routine whereby the information specific to the original is reproduced in high fidelity.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0014" num="0013">The objective of the present invention, which has been conceived in response to the aforementioned problems, is to provide an image processing device which enables a stable original binarizing routine.</p>
<p id="p-0015" num="0014">The present invention concerns an image processing device that possesses a histogram generation mechanism which generates a density histogram that shows a density value distribution based on image data obtained from an image decoding unit which serves a function of decoding images recorded on a medium, a mechanism which calculates not only low-density-side peak levels and high-density-side peak levels but also the low-density peak frequency and the high-density peak frequency based on the density histogram generated above, an image type classification mechanism which determines the type of the decoded image based on the comparison results on the low-density peak frequency and the high-density peak frequency calculated above, and a threshold level generation mechanism which generates a threshold level for quantizing said image data based on said density histogram by means of a method specific to the type of the image determined above.</p>
<p id="p-0016" num="0015">A threshold level specific to an image to be decoded can be designated by using such an image processing device, based on which a more accurate binarizing routine can be executed.</p>
<p id="p-0017" num="0016">In particular, peak levels and peak frequencies which have been obtained during previous image decoding operations are stored, and a threshold level is generated by using the stored sets of information on low-density and high-density peaks.</p>
<p id="p-0018" num="0017">Peak levels and peak frequencies obtained in previous image decoding operations are stored, and after the original type has been determined by comparing the current peak information with the stored peak information, a threshold level is generated based on the stored sets of information on the low-density peak or high-density peak.</p>
<p id="p-0019" num="0018">The present invention also provides an image processing device which divides the binarized data obtained as a result of binarization into multiple regions, calculates the ratio between the number of high-density pixels and the number of low-density pixels with regard to each of the divided regions, and determines the type of the binarized image data within each region based on the high-density/low-density pixel number ratio.</p>
<p id="p-0020" num="0019">In particular, such divided regions are obtained based on the pixel density distribution along the row direction which has been obtained from one-line-equivalent image data and the low-density/high-density pixel number ratio of each row, based on which the types of the respective divided regions are classified.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram which shows the image processing device of the first embodiment of the present invention.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart which shows the binarized threshold value calculation procedures in the first embodiment.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram which shows a density histogram and threshold value determination procedures.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram which shows another density histogram and threshold value determination procedures.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram provided for explaining a method for estimating the threshold value based on actual measurement data.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 6</figref> is a block diagram which shows the image processing device of another embodiment of the present invention.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 7</figref> is a diagram provided for explaining the procedures for determining the optimal threshold value based on stored measurement data.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 8</figref> is a block diagram which an image processing device of still another embodiment of the present invention.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 9</figref> is a diagram provided for explaining the procedures for decoding an original which can be divided into image data regions and text regions.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 10</figref> is a diagram which shows the line-specific black pixel ratios of the image data obtained as a result of the decoding procedures shown in <figref idref="DRAWINGS">FIG. 9</figref>.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 11</figref> is a diagram provided for explaining another example for decoding an original which can be divided into image data regions and text regions.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 12</figref> is a graph which shows the line-specific black pixel ratio distribution among the respective divided regions.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 13</figref> is a diagram provided for explaining an image processing device of the prior art.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIGS. 14(</figref><i>a</i>) and <b>14</b>(<i>b</i>) are diagrams provided for explaining threshold value determination and binarization routines of the image processing device of the prior art shown in <figref idref="DRAWINGS">FIG. 13</figref>.</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 15</figref> is a diagram provided for explaining another image processing device of the prior art.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIGS. 16(</figref><i>a</i>) and <b>16</b>(<i>b</i>) are diagrams provided for explaining threshold value determination and binarization routines in the image processing device of the prior art shown in <figref idref="DRAWINGS">FIG. 15</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram explaining of the image processing device <b>5</b> of one embodiment of the present invention. The image processing device <b>5</b> of this embodiment adds an image type classification unit <b>32</b> to the image processing device of the prior art shown in <figref idref="DRAWINGS">FIG. 13</figref>. All other elements in <figref idref="DRAWINGS">FIG. 1</figref> are the same as in <figref idref="DRAWINGS">FIG. 13</figref>.</p>
<p id="p-0038" num="0037">The densities of inputted image data in this embodiment are distributed not only in the vicinity of the background density of a paper (maximal density) and the density of a character segment (minimal density) but also within an intermediate zone. Generally speaking, when a bichrome-printed text original is decoded, character segments exist at a certain ratio in relation to their background, and when its density distribution histogram is analyzed, two peaks can be ascertained to exist in the vicinity of the background density and in the vicinity of the character density. In the case of a text original, the area ratio of the characters (ink) with respect to their background is low, and therefore, the peak density of the background becomes greater than the character peak density. The density distribution is further moderated in the border between the character and background due to the effects of the optical properties of the decoding device and the background density. For this reason, a certain specifiable distribution is observed between the respective peak density levels of the density histogram distribution.</p>
<p id="p-0039" num="0038">This attribute differs peculiarly depending on the types of originals, namely on the area ratio between background and character segments, character line thickness, etc. For this reason, it is necessary to determine the optimal threshold level while the specific characteristics of the density histogram distribution are taken into account for the purpose of reproducing original character thicknesses in high fidelity during a binarizing routine. The magnitude of the density peak corresponds fundamentally to the area ratio between the background and character segments of the original, but it is also affected greatly by the character line thickness, certain non-character designs or data formats (e.g., various codes, etc.). The peak density level itself, furthermore, may deviate from the default ink density depending on these characteristics of the original, and therefore, it is necessary to establish a threshold level determination method that optimally suits these density distribution attributes which reflect the characteristics of the original.</p>
<p id="p-0040" num="0039">Put another way, it is also possible to classify the characteristics of an original, namely the types of text and data formats printed on the original, from such density histogram characteristics as the density peak magnitude and density level differential.</p>
<p id="p-0041" num="0040">An optimal binarization threshold value determination method furthermore differs depending on the density distribution characteristics of character edge segments. For this reason, an optimal binarization threshold value specific to the original type classified depending on the ratio between the minimal density and maximal density histogram distribution may be preliminarily selected in preparation for a binarizing routine. In such a case, an accurate binarization which reflects the character thickness specific to the original characteristic in high fidelity can be executed.</p>
<p id="p-0042" num="0041">The aforementioned image type classification unit <b>32</b> determines the type of an inputted image based on the density histogram thus inputted. The information on the specific type of the inputted image thereby determined is transferred to a threshold value generation unit <b>24</b>. The threshold value generation unit <b>24</b> selects the threshold value determination method most suited for the image type based on the information obtained from the image type classification unit <b>32</b>, which reveals the image types.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart for explaining the binarization threshold value calculation procedures by using the image processing device shown in <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0044" num="0043">Once the input image has been initialized, one-line-equivalent line data are first decoded at step S<b>1</b>. The one-line-equivalent line data thus inputted are temporarily stored in the line data retention unit <b>20</b> at step S<b>2</b>. A density histogram corresponding to the line is subsequently generated by the density histogram unit <b>22</b> based on the pixel-specific density values of the inputted line data at step S<b>3</b>.</p>
<p id="p-0045" num="0044">Next, the density histogram generation unit <b>22</b> calculates not only the white and black peak levels within the line data but also the respective frequencies of the white and black peaks at step S<b>4</b>.</p>
<p id="p-0046" num="0045">The image type classification unit <b>32</b> subsequently determines the type of the decoding object original based on the white and black peak levels and white and black peak frequencies which have been calculated by the density histogram generation unit at steps S<b>5</b> and S<b>6</b>. After the original classification results have subsequently been transferred to the threshold value generation unit <b>24</b>, the threshold value calculation method optimal for the image is determined at step S<b>7</b>, followed by the calculation of the threshold value at step S<b>8</b>.</p>
<p id="p-0047" num="0046">Incidentally, when the line data re entirely black or entirely white, it becomes impossible to calculate either the white peak value or the black peak value. In such a case, the peak value on the incalculable side is assumed to correspond to a preliminarily prepared maximal density value (255) or minimal density value (0) without classifying the original type in subsequent processing steps.</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram provided for explaining one method for determining the original type and for determining the optimal threshold value.</p>
<p id="p-0049" num="0048">Two types of originals to be decoded, namely an ordinary text original and an original, the black-to-white density ratio of which is approximately 50:50, are hereby assumed. Incidentally, the background color and ink color are identical for the two types of originals.</p>
<p id="p-0050" num="0049">When the ordinary text is decoded, the ration of the character black region with respect to the background white region is low, and therefore, when the white and black peak frequencies are compared, a relationship of “white-peak frequency&gt;black peak frequency” can be ascertained. Due to the effects of the black region and the optical properties of the decoding device, furthermore, a relationship of “white peak frequency&lt;black peak frequency” can be ascertained with regard to the image data decoded from the original with a black-to-white density ratio of approximately 50:50.</p>
<p id="p-0051" num="0050">In the case of the original on which image data with a black-to-white density ratio of 50:50 have been recorded, the white peak level tends to deviate or shift toward the black density side form the otherwise expected white density (background color of the original). As a result, a relationship of “text white peak level&gt;image white peak level” can be ascertained with regard to the density histogram distribution.</p>
<p id="p-0052" num="0051">It can be determined based on the hierarchical relationship between the white and black peak frequencies whether the region in which the input data are measured corresponds to a text region or image region by virtue of these characteristics.</p>
<p id="p-0053" num="0052">As <figref idref="DRAWINGS">FIG. 3</figref> graphically illustrates, the black peak levels of the cases of the text and image data should be virtually identical if an identical ink is being used. The black peak value frequency, however, differs depending on the types of originals on which it is recorded, and accordingly, the black peak value frequency of the image data is higher than the black peak value frequency of the text original. When the respective white level peaks of the text and image data are compared, the white peak value of the image data is shifted toward the black side in comparison with the white peak value of the text. An example of a case where the background of the paper alone has been decoded is also shown in <figref idref="DRAWINGS">FIG. 3</figref> for comparative purposes. Thus, when the background of the paper alone is decoded, the white peak value further shifts toward the right side of the figure in comparison with a case where a text is decoded.</p>
<p id="p-0054" num="0053">When an image to be decoded is a text, the intermediate value of detected black and white peak values, namely a value that yields a 50:50 ratio, is designated as the optimal binarization threshold level, for it has been known that a level that splits the spectrum between the white and black levels at a ratio of 50:50 serves as the optimal threshold level in relation to ordinary texts. When an image to be decoded pertains to non-character image data, on the other hand, a level that splits the spectrum between the black-and white peak values at a ratio of 35:65 is designated as the optimal threshold level with regard to the example of <figref idref="DRAWINGS">FIG. 3</figref>. The ratios for determining the image data threshold values have been determined experimentally, and the ratios may differ from the aforementioned ones depending on the types of images or conditions.</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram provided for explaining another method for determining the threshold value, and a threshold value determination method on image data which yields a white-to-black ratio of 50:50 is hereby explained, as in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0056" num="0055">As has been mentioned above, when an original whose white-to-black ratio has preliminarily been known to be 50:50 is decoded, a binarization result, which more accurately reflects the characteristics of the original, can be expected by designating the threshold value at a level which yields a binarized image with a white-to-black pixel ratio of 50:50. In the example of <figref idref="DRAWINGS">FIG. 4</figref>, therefore, the number of pixels (=frequency) at the respective densities of the density histogram are calculated, and a level which yields a constant ratio between the number of pixels on the black side and the number of pixels on the white side (identical numbers of pixels in accordance with the characteristics of the original in <figref idref="DRAWINGS">FIG. 4</figref>) is designated as the threshold level. In such a case, binarization results which accurately reflect the characteristics of the original can be obtained by designating the ratio between the number of pixels which become black after binarization and the number of pixels which likewise become white at 50:50 or its vicinity.</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram provided for explaining a method for determining optimal threshold levels with regard to other assessable types of originals apart from the optimal threshold levels specific to the types of originals as they are calculated from the density histogram distribution.</p>
<p id="p-0058" num="0057">It is not uncommon for a single page of an original to be decoded to be characterized by the coexistence of an ordinary text which has been printed by using an identical ink and image data characterized by a white-to-black pixel ratio of 50:50, as in the aforementioned case. When an attempt is made to decode such an original for the purpose of effectively utilizing the image data segment, however, it becomes necessary to designate a threshold level specific to the image data. When density histogram data are obtained in a region of said original in which an ordinary text has been printed, however, the image input device determines that the decoded image is constituted by an ordinary text in that the relationship of “white peak frequency&gt;black peak frequency” holds with regard to the density histogram, and accordingly, the level that splits the spectrum between the white and black peak levels at a 50:50 ratio is finalized as the optimal threshold level. When a decoding action is directly invoked in such a state, it becomes impossible to perform a binarization routine optimally suited for the recorded original within the image data region, which has been initially targeted for effective utilization.</p>
<p id="p-0059" num="0058">It is hereby assumed to be preliminarily known that ordinary text and image data are characterized by the density histogram distribution shown in <figref idref="DRAWINGS">FIG. 3</figref>. In other words, when it is known that the white peak level of the image data is consistently lower than the white peak level of the ordinary text by a specifiable margin and where their respective black levels are comparable, the image white peak level comes to be estimated from the white peak level of the text, and a level which splits the spectrum between this estimated white peak level and the actually measured black peak level at a ratio of 35:65 may, for example, come to be ascertained as the optimal threshold level for the image data.</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram which shows the image processing unit <b>28</b> of an image processing device <b>5</b> of another embodiment of the present invention. Its image decoding unit, however, is identical to that shown in <figref idref="DRAWINGS">FIG. 1</figref> and is not reproduced in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0061" num="0060">A digital image signal <b>16</b> which has been inputted from the A/D conversion unit <b>18</b> is temporarily retained in a line data retention unit <b>20</b>. After the line data have been transferred to the density histogram generation unit <b>22</b>, a density histogram is generated and then transferred to the threshold generation unit <b>24</b> and the image type classification unit <b>32</b>.</p>
<p id="p-0062" num="0061">The image type classification unit <b>32</b> determines the type of the inputted image based on the density histogram distribution and then transfers the obtained results to the threshold generation unit <b>24</b>. The threshold generation unit <b>24</b> determines the threshold level based on the density histogram distribution and on the image type determined above, whereas the binarization unit <b>27</b> binarizes the image data retained in the line data retention unit <b>20</b> in pixel-specific fashion based on the threshold value <b>26</b> generated by the threshold generation unit <b>24</b>.</p>
<p id="p-0063" num="0062">A measurement data storage unit <b>34</b> is configured in the image processing device <b>5</b> shown in <figref idref="DRAWINGS">FIG. 6</figref>. Measurement data obtained during previous decoding operations are stored in the measurement data storage unit <b>34</b>. More specifically, the measurement data, peak levels or peak frequencies calculated from the density histogram distribution, image types, threshold levels, etc. are stored. Functions of classifying image types or of generating threshold values are served with reference to the various sets of information stored in said measurement data storage unit <b>34</b> at a step where the image type is determined by the image type classification unit <b>32</b> or where the threshold value <b>26</b> is determined by the threshold value generation unit <b>24</b> during an image decoding operation.</p>
<p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. 7</figref> is a diagram provided for explaining a routine performed by using the apparatus shown in <figref idref="DRAWINGS">FIG. 6</figref>. In the figure, the solid line pertains to actual measurement data, whereas the dotted line pertains to storage data which are being stored in the measurement data storage unit.</p>
<p id="p-0065" num="0064">The solid line in <figref idref="DRAWINGS">FIG. 7</figref> shows the density histogram obtained based on the measurement results within the background region of the ordinary text original alone. In this case, a white peak which corresponds to the background exists in the measurement data, but no black peak level which corresponds to the ordinary text ink density exists. For this reason, necessary data for determining the threshold value have not been obtained. In such a case, it is also possible to determine the threshold level by assuming the black peak level to be “0” as an alternative to an undetectable black peak level.</p>
<p id="p-0066" num="0065">As <figref idref="DRAWINGS">FIG. 3</figref> graphically illustrates, however, the actually obtained black peak value is not “0”, and therefore, a threshold level ascertained by assuming a black peak level of “0” is not a threshold level which is specific to the actual original state. Even when an attempt is made to beinarize the original by using this threshold value, therefore, it is possible for an immense disparity to be incurred between the actual original and the binarized original. Since only one peak is obtained, furthermore, it is impossible to classify the original type. Nor is it possible to select a method for determining a threshold level optimally suited for the original to be decoded.</p>
<p id="p-0067" num="0066">As far as this embodiment is concerned, an attempt is made to refer to the white and black peak level information and original type information which have been obtained from the density histogram distributions of previous decoding operations and which are being stored in the measurement data storage unit <b>34</b>. In <figref idref="DRAWINGS">FIG. 7</figref>, the dotted line pertains to the storage data which have been decoded from the measurement data storage unit <b>34</b>. As the figure graphically illustrates, black peak values exist in the storage data which are being stored in the measurement data storage unit The black peak values within the decoded storage data can therefore be used n the context of determining the threshold level.</p>
<p id="p-0068" num="0067">When the actually-measured white peak and the white peak of the storage data are compared, on the other hand, the respective peak values may not be very different. Furthermore, characters are included in the previously decoded data, whereas no characters are included int eh currently decoded data, and if these factors are taken into consideration, the peak level difference observed in <figref idref="DRAWINGS">FIG. 7</figref> may be attributed to the effect of the black density region, as in the case of <figref idref="DRAWINGS">FIG. 3</figref>. It may be estimated, therefore, that the backgrounds of the currently decoded original and of the previously decoded original are identical.</p>
<p id="p-0069" num="0068">As far as the example shown in <figref idref="DRAWINGS">FIG. 7</figref> is concerned, therefore, the optimal threshold value is determined by using the currently measured white peak level and the black peak level of the storage data. Even when either peak cannot be found in the measurement data, therefore, the threshold level can be determined by assuming the black peak level to be “0”, based on which the error potentials of the threshold level determination and binarizing routines can be alleviated.</p>
<p id="p-0070" num="0069">The white peak level of the storage data on the previous operation and the white peak level of the current measurement data are specifically compared in the first place. When the level differential between the two is confined to a certain range, it is highly likely that the background colors of the currently and previously decoded originals will be the same. After it has ben assumed that the types of the currently and previously decoded originals are the same, the threshold level is determined based on an optimal threshold level calculation method specific to the original type classification results on the previous storage data by using the black peak level of the storage data and the white peak level of the measurement data. A level that splits the spectrum between the currently obtained white peak level and the previously obtained black peak level at 50:50 is ascertained as the threshold level in the example shown in <figref idref="DRAWINGS">FIG. 7</figref>.</p>
<p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. 8</figref> is a diagram which shows another embodiment of the image processing device <b>5</b> including a threshold value alteration unit <b>50</b>.</p>
<p id="p-0072" num="0071">The threshold value alteration unit <b>50</b> shown in <figref idref="DRAWINGS">FIG. 8</figref> includes a divided region extraction unit <b>36</b> which divides received binarized image data <b>29</b> and extracts minor region units which are to become processing units in subsequent operations. The divided region extraction unit <b>36</b> is connected to the white and black pixel ration calculation unit <b>38</b>. The white and black pixel ration calculation unit <b>38</b> calculates the white-to-black pixel ratio of each row of the decoded original. The divided region extraction unit <b>36</b> divides the original into the respective minor region units based on the calculated row-specific white-to-black pixel ratio.</p>
<p id="p-0073" num="0072">The white and black pixel ratio data of temporally posterior and anterior regions during the decoding routine are stored in the white and black pixel ratio data storage unit <b>40</b>. The binary image type classification unit <b>42</b>, furthermore, classifies the image type of an isolated minor region of the original. The classification results obtained from the binary image type classification unit, furthermore, are stored in the classification result storage unit <b>44</b>. The binary image type classification unit outputs a threshold value alteration <b>46</b> to the binarization unit <b>27</b>.</p>
<p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. 9</figref> is a diagram explaining an example in which the image type is classified from the binarized image data <b>29</b>. A hand scanner <b>48</b> which is manually operated is hereby used as the image decoding unit <b>14</b> shown in <figref idref="DRAWINGS">FIG. 1</figref>. The decoded original, furthermore, is divided into three regions, namely, the image data region <b>1</b>, text region, and the image data region <b>2</b>.</p>
<p id="p-0075" num="0074">The minor regions are hereby divided and extracted by using one-line-equivalent data which are inputted over time in accordance with the scanning action of the hand scanner <b>48</b> in the direction of the arrow. <figref idref="DRAWINGS">FIG. 10</figref> shows the line-specific black pixel ratio of a case where this original is binarized by using a threshold level suitable for an ordinary text.</p>
<p id="p-0076" num="0075">As <figref idref="DRAWINGS">FIG. 10</figref> indicates, the black pixel ratio per line is 40% or below within the ordinary text region, and the black pixel ratio varies drastically depending on the row alignment of the text. The black pixel ratio, on the other hand, is greater than 50% in each of the image data regions <b>1</b> and <b>2</b>, and there are no significant black pixel ratio discrepancies among the respective lines.</p>
<p id="p-0077" num="0076">It can thus be determined whether a given region above the original is a text region or an image data region based on the black pixel ratio and its variation pattern by conversely utilizing these characteristics of the black pixel ratio. A binarizing routine is further executed by generating a threshold level corresponding to a determined original type with regard to each region.</p>
<p id="p-0078" num="0077">When binarization is carried out by using the threshold level suitable for image data, the black pixel ratios of the image data region <b>1</b> and image data region <b>2</b> become approximately 50%. The black pixel ratio, however, is greater than 50% in the example shown in <figref idref="DRAWINGS">FIG. 10</figref> in that a threshold level suitable for the ordinary text has been selected. Conversely, a more accurate binarized image can be obtained by selecting a correspondingly appropriate threshold level when the image decoding unit <b>14</b> is located in the image data region and by selecting a threshold level appropriate for ordinary texts when the same is located in the text region based on the classification results shown in <figref idref="DRAWINGS">FIG. 10</figref>.</p>
<p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. 11</figref> is a diagram provided for explaining another method for classifying the image type from binarized image data <b>29</b>, and two-dimensional configurations of minor regions can be hereby determined. In <figref idref="DRAWINGS">FIG. 11</figref>, divided regions are plotted not only along the auxiliary scanning direction but also along the main scanning direction (direction along the extension of the image decoding unit <b>14</b> shown in the figure), and the original type is classified by determining the black pixel ratios within the respective regions.</p>
<p id="p-0080" num="0079">As has been mentioned above, the black pixel ratio of an ordinary text region is equal to less than 40%, and it varies considerably depending on the allocation of the text lines. The black pixel ratios of the image data region <b>1</b> and image data region <b>2</b>, on the other hand, are consistently equal to greater than 50%, and no significant disparities are observed among the respective lines.</p>
<p id="p-0081" num="0080">A text region and an image region, however, coexist on the original shown in <figref idref="DRAWINGS">FIG. 11</figref>, and when such an original is subjected to the routine explained above with reference to <figref idref="DRAWINGS">FIGS. 9 and 10</figref>, it may become impossible to execute an accurate binarizing routine.</p>
<p id="p-0082" num="0081">In the embodiment of <figref idref="DRAWINGS">FIG. 11</figref>, therefore, a single line is divided into multiple regions, and line-specific black pixel ratios of the respective divided regions are classified, based on which two-dimensional image/text configurations can be determined. Two-dimensional image data configurations on the original, furthermore, are classified based on the classification results on the respective divided regions.</p>
<p id="p-0083" num="0082">The action of the device of <figref idref="DRAWINGS">FIG. 8</figref> is invoked in such a way that the white and black pixel ratio calculation unit <b>38</b> will compute the individual white and black pixel ratios of the respective divided regions mentioned above (divided regions <b>1</b> through <b>3</b> in <figref idref="DRAWINGS">FIG. 11</figref>).</p>
<p id="p-0084" num="0083">Incidentally, the original is divided into three longitudinally in the example of <figref idref="DRAWINGS">FIG. 11</figref>. Exact division specifications may be adventitiously determined, and the number of divided regions may be enlarged for enabling a more accurate classification of an image/text configurational state. If the number of divided regions is excessively enlarged, however, cumbersome region-specific image type classification routines become required, and an extremely long processing time is incurred by a low-capacity device. An appropriate value should therefore be selected within a reasonable spectrum of region division numbers.</p>
<p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. 12</figref> is a diagram which shows the line-specific black pixel ratio distribution among the respective three divided regions of the original shown in <figref idref="DRAWINGS">FIG. 11</figref>,</p>
<p id="p-0086" num="0085">As <figref idref="DRAWINGS">FIG. 12</figref> graphically illustrates, black pixel ratios of greater than 50% are achieved in the respective regions between lines L<b>0</b> and L<b>1</b> of divided regions <b>1</b> and <b>2</b> as well as in the respective regions between lines L<b>1</b> and L<b>2</b> of divided regions <b>2</b> and <b>3</b>, and since the value variation spectrum is minimal, these regions can be classified to be image data regions.</p>
<p id="p-0087" num="0086">In the other regions, furthermore, the black pixel ratios were approximately 40% or below, and the line-by-line value variation spectrum was extremely broad. These regions can therefore be classified to be text regions.</p>
<p id="p-0088" num="0087">As has been mentioned above, two-dimensional configurations of the respective image data on originals can be determined in the present application embodiment, and threshold value determination and binarization routines which reflect the types of originals more accurately can be executed.</p>
<p id="p-0089" num="0088">As the foregoing explanations have demonstrated, in the present invention, the maximal density which corresponds to a background and the minimal density which corresponds to character/ink segments as well as their frequencies are calculated, and the type of an original which is being decoded can be classified based on such data. Since a threshold level corresponding specifically to the type of the original thus determined is generated, furthermore, binarization can be carried out by using the threshold value optimally suited for the original which is being decoded can be carried out, and accordingly, the binarizing accuracy can be upgraded.</p>
<p id="p-0090" num="0089">The present invention, furthermore, enables the classification of the type of an original based on the white and black pixel ratios of a binarized image.</p>
<p id="p-0091" num="0090">The type of an original which is being decoded, furthermore, can be determined in the midst of a binarizing routine even when multiple different types of image data exist on a singular original, and since optimal threshold levels can accordingly be designated adventitiously, accurate binarization is enabled.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention of claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image processing device comprising:
<claim-text>an image decoding means for decoding images recorded on a medium;</claim-text>
<claim-text>a dividing image means for dividing said decoded image into multiple regions;</claim-text>
<claim-text>a histogram generating means for generating a density histogram for each of said multiple regions that shows a density value distribution based on image data obtained from said image decoding means;</claim-text>
<claim-text>a means for calculating for each of said multiple regions low-density-side and high-density-side peak levels and the low-density side and high-density side peak frequencies based on the generated density histogram;</claim-text>
<claim-text>an image type classification means for determining the type of text and data formats printed on the original decoded image based on a magnitude relation between the low-density peak frequency and the high-density peak frequency;</claim-text>
<claim-text>a threshold level generating means for generating for each of said multiple regions a threshold level based on the determined type of image; and</claim-text>
<claim-text>a binarizing unit binarizing said image data based on the generated threshold level.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The image processing device recited in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said image processing device further comprises:
<claim-text>a storage means for storing at least one selected from among the high density side peak level, high-density side peak frequency, low-density side peak level and low-density side peak frequency which have been obtained as a result of previously generated density histograms,</claim-text>
<claim-text>wherein, whenever there is either the absence of a low-density side peak level or high-density side peak level within the currently decoded image, the information on the low-density peaks or high-density peaks which is being stored in said storage means is decoded from the storage means wherein a threshold level is generated by using the decoded information.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
