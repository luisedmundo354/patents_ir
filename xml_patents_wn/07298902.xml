<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298902-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298902</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10760850</doc-number>
<date>20040120</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>548</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>18</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382184</main-classification>
<further-classification>382165</further-classification>
<further-classification>382175</further-classification>
<further-classification>382318</further-classification>
<further-classification>434354</further-classification>
<further-classification>434359</further-classification>
</classification-national>
<invention-title id="d0e53">Method and system for performing image mark recognition</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>3601906</doc-number>
<kind>A</kind>
<name>Roche</name>
<date>19710800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>3870865</doc-number>
<kind>A</kind>
<name>Schneiderhan et al.</name>
<date>19750300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>4153895</doc-number>
<kind>A</kind>
<name>Weisbrod et al.</name>
<date>19790500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>4217487</doc-number>
<kind>A</kind>
<name>Kjeer</name>
<date>19800800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>4300123</doc-number>
<kind>A</kind>
<name>McMillin et al.</name>
<date>19811100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>4817179</doc-number>
<kind>A</kind>
<name>Buck</name>
<date>19890300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>4979136</doc-number>
<kind>A</kind>
<name>Weiman et al.</name>
<date>19901200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5038393</doc-number>
<kind>A</kind>
<name>Nanba</name>
<date>19910800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5101448</doc-number>
<kind>A</kind>
<name>Kawachiya et al.</name>
<date>19920300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>5102341</doc-number>
<kind>A</kind>
<name>Koslin</name>
<date>19920400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>434353</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>5103490</doc-number>
<kind>A</kind>
<name>McMillin</name>
<date>19920400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382284</main-classification></classification-national>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>5129014</doc-number>
<kind>A</kind>
<name>Bloomberg</name>
<date>19920700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>5134669</doc-number>
<kind>A</kind>
<name>Keogh et al.</name>
<date>19920700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382318</main-classification></classification-national>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>5253304</doc-number>
<kind>A</kind>
<name>LeCun et al.</name>
<date>19931000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>5452379</doc-number>
<kind>A</kind>
<name>Poor</name>
<date>19950900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>5568571</doc-number>
<kind>A</kind>
<name>Willis et al.</name>
<date>19961000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>5572601</doc-number>
<kind>A</kind>
<name>Bloomberg</name>
<date>19961100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382175</main-classification></classification-national>
</citation>
<citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>5600732</doc-number>
<kind>A</kind>
<name>Ott et al.</name>
<date>19970200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>5625770</doc-number>
<kind>A</kind>
<name>Nomura</name>
<date>19970400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>5649026</doc-number>
<kind>A</kind>
<name>Heins</name>
<date>19970700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>5672060</doc-number>
<kind>A</kind>
<name>Poor</name>
<date>19970900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>434322</main-classification></classification-national>
</citation>
<citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>5675671</doc-number>
<kind>A</kind>
<name>Hayduchok et al.</name>
<date>19971000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>5754674</doc-number>
<kind>A</kind>
<name>Ott et al.</name>
<date>19980500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>5818976</doc-number>
<kind>A</kind>
<name>Pasco et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>5825947</doc-number>
<kind>A</kind>
<name>Sasaki et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>5870488</doc-number>
<kind>A</kind>
<name>Rush et al.</name>
<date>19990200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>5956422</doc-number>
<kind>A</kind>
<name>Alam</name>
<date>19990900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>6079624</doc-number>
<kind>A</kind>
<name>Apperson et al.</name>
<date>20000600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>235494</main-classification></classification-national>
</citation>
<citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>6129278</doc-number>
<kind>A</kind>
<name>Wang et al.</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>6173154</doc-number>
<kind>B1</kind>
<name>Kucinski et al.</name>
<date>20010100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>434359</main-classification></classification-national>
</citation>
<citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>6188787</doc-number>
<kind>B1</kind>
<name>Ohmae et al.</name>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382165</main-classification></classification-national>
</citation>
<citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>6213664</doc-number>
<kind>B1</kind>
<name>Kondo</name>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>401205</main-classification></classification-national>
</citation>
<citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>6259814</doc-number>
<kind>B1</kind>
<name>Krtolica et al.</name>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>6299066</doc-number>
<kind>B1</kind>
<name>Howland et al.</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>6311040</doc-number>
<kind>B1</kind>
<name>Kucinski et al.</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>434350</main-classification></classification-national>
</citation>
<citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>6325286</doc-number>
<kind>B1</kind>
<name>Howland et al.</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00037">
<document-id>
<country>US</country>
<doc-number>6408106</doc-number>
<kind>B1</kind>
<name>Tatsuta et al.</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00038">
<document-id>
<country>US</country>
<doc-number>6542629</doc-number>
<kind>B1</kind>
<name>Wu et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382135</main-classification></classification-national>
</citation>
<citation>
<patcit num="00039">
<document-id>
<country>US</country>
<doc-number>6575367</doc-number>
<kind>B1</kind>
<name>Longacre</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00040">
<document-id>
<country>US</country>
<doc-number>6580820</doc-number>
<kind>B1</kind>
<name>Fan</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382135</main-classification></classification-national>
</citation>
<citation>
<patcit num="00041">
<document-id>
<country>US</country>
<doc-number>6684052</doc-number>
<kind>B2</kind>
<name>Kucinski et al.</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>434359</main-classification></classification-national>
</citation>
<citation>
<patcit num="00042">
<document-id>
<country>US</country>
<doc-number>6741738</doc-number>
<kind>B2</kind>
<name>Taylor</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382187</main-classification></classification-national>
</citation>
<citation>
<patcit num="00043">
<document-id>
<country>US</country>
<doc-number>6927872</doc-number>
<kind>B2</kind>
<name>Currans</name>
<date>20050800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358  115</main-classification></classification-national>
</citation>
<citation>
<patcit num="00044">
<document-id>
<country>US</country>
<doc-number>6970267</doc-number>
<kind>B1</kind>
<name>Scanlon</name>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358  14</main-classification></classification-national>
</citation>
<citation>
<patcit num="00045">
<document-id>
<country>US</country>
<doc-number>7004393</doc-number>
<kind>B2</kind>
<name>Schum et al.</name>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>23546208</main-classification></classification-national>
</citation>
<citation>
<patcit num="00046">
<document-id>
<country>US</country>
<doc-number>2001/0033688</doc-number>
<kind>A1</kind>
<name>Taylor</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382181</main-classification></classification-national>
</citation>
<citation>
<patcit num="00047">
<document-id>
<country>US</country>
<doc-number>2002/0168090</doc-number>
<kind>A1</kind>
<name>Bruce et al.</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382101</main-classification></classification-national>
</citation>
<citation>
<patcit num="00048">
<document-id>
<country>US</country>
<doc-number>2002/0181805</doc-number>
<kind>A1</kind>
<name>Loeb et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00049">
<document-id>
<country>US</country>
<doc-number>2003/0072019</doc-number>
<kind>A1</kind>
<name>Haines et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00050">
<document-id>
<country>US</country>
<doc-number>2003/0173404</doc-number>
<kind>A1</kind>
<name>Chung et al.</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>235386</main-classification></classification-national>
</citation>
<citation>
<patcit num="00051">
<document-id>
<country>US</country>
<doc-number>2004/0185424</doc-number>
<kind>A1</kind>
<name>Kucinski et al.</name>
<date>20040900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>434359</main-classification></classification-national>
</citation>
<citation>
<patcit num="00052">
<document-id>
<country>US</country>
<doc-number>2004/0202992</doc-number>
<kind>A1</kind>
<name>Moulthrop et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>434353</main-classification></classification-national>
</citation>
<citation>
<patcit num="00053">
<document-id>
<country>US</country>
<doc-number>2005/0157930</doc-number>
<kind>A1</kind>
<name>Cichielo et al.</name>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382184</main-classification></classification-national>
</citation>
<citation>
<patcit num="00054">
<document-id>
<country>US</country>
<doc-number>2005/0201639</doc-number>
<kind>A1</kind>
<name>Wu</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382294</main-classification></classification-national>
</citation>
<citation>
<patcit num="00055">
<document-id>
<country>US</country>
<doc-number>2006/0062453</doc-number>
<kind>A1</kind>
<name>Schacht</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382164</main-classification></classification-national>
</citation>
<citation>
<patcit num="00056">
<document-id>
<country>US</country>
<doc-number>2006/0250660</doc-number>
<kind>A1</kind>
<name>Cui</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358448</main-classification></classification-national>
</citation>
<citation>
<patcit num="00057">
<document-id>
<country>US</country>
<doc-number>2006/0252023</doc-number>
<kind>A1</kind>
<name>Cui</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>434353</main-classification></classification-national>
</citation>
<citation>
<patcit num="00058">
<document-id>
<country>JP</country>
<doc-number>62263584</doc-number>
<kind>A</kind>
<date>19871100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00059">
<document-id>
<country>JP</country>
<doc-number>6176192</doc-number>
<kind>A</kind>
<date>19940600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>13</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382164</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382165</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382184</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382175</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382318</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>235494</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>434354</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>434359</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>434322</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>434353</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>4</number-of-drawing-sheets>
<number-of-figures>5</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20050157930</doc-number>
<kind>A1</kind>
<date>20050721</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Cichielo</last-name>
<first-name>Robert</first-name>
<address>
<city>Asbury</city>
<state>NJ</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Hoffman</last-name>
<first-name>Jeffrey</first-name>
<address>
<city>Lebanon</city>
<state>NJ</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Mayer Brown LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Educational Testing Service</orgname>
<role>02</role>
<address>
<city>Princeton</city>
<state>NJ</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Desire</last-name>
<first-name>Gregory M</first-name>
<department>2624</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method and system for performing image mark recognition for a document is disclosed. A document is scanned into a digital image. Reference image marks are sensed from the digital image. The reference image marks may include trigger row marks and/or corner/crop marks. Coordinates denoting the location of cells within the digital image are determined based on the locations of the reference image marks. Response marks are evaluated for darkness, opacity, and/or grayness on a pixel-by-pixel basis. The response marks are each assigned a percentage value based on the ratio between a total color value for a cell and a maximum color value for a cell.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="165.10mm" wi="57.32mm" file="US07298902-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="188.64mm" wi="61.21mm" file="US07298902-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="166.37mm" wi="139.02mm" file="US07298902-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="137.50mm" wi="149.10mm" file="US07298902-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="164.25mm" wi="158.92mm" file="US07298902-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">The present invention generally relates to the field of mark recognition. The present invention particularly relates to scanning an image of a document and performing mark recognition on the scanned image. In an embodiment, a response mark may be indicative of an intended response to a question and/or may be representative of coded information. In a preferred embodiment, the present invention provides a hardware independent methodology for evaluating the presence or absence of one or more marks on a document, which may be configured to higher or lower resolutions as needed.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">Conventional mark reading systems have been employed to extract information, such as pencil marks, from a document. These systems typically include a scanner configured to read marks from the document. The scanner creates a digitized representation of the document. The digitized document is then processed by a separate application to evaluate the document. In an assessment environment, this system can be used to score examination responses. For example, many students and other examinees are familiar with the typical response format for answering multiple choice questions which requires the student to fill-in a space (e.g. a circle, square, etc.) associated with the question. Mark reading systems can grade such answer sheets significantly faster and more accurately than a human grader. However, conventional mark reading systems are limited by the accuracy with which the document is digitized. Increased accuracy is available with more sophisticated and more expensive systems. When a high degree of accuracy is required, expensive scanning equipment can be purchased which will provide a digitized representation of the document within most accepted error rates. However, in addition to the expense associated with such systems, they may not be easily configured to alternate environments where differing accuracy levels are required. When accuracy in the digitizing process is sacrificed, such systems often improperly grade test answers. For example, the systems may not recognize properly marked target areas that are incompletely filled or in which the pencil marking is lighter than a threshold value. Moreover, the systems may recognize stray marks and erasures as incorrect answers when a test taker did not intend such an answer.</p>
<p id="p-0004" num="0003">A particularly egregious error may result when a test taker properly marks a correct answer for a question, but a mark reading system recognizes a stray mark or erasure as an incorrect answer for the same question. In this case, although the test taker correctly answered the question, the test taker would not receive credit because the system would report that the test taker provided two answers. As such, the test taker may be penalized because of the medium in which the test is presented rather than the substantive material on which the test is based.</p>
<p id="p-0005" num="0004">What is needed is an improved image mark recognition system that can accurately evaluate the marks on a document to be digitized which is both cost effective and independent of the hardware being used to scan the document.</p>
<heading id="h-0003" level="1">SUMMARY OF PREFERRED EMBODIMENTS</heading>
<p id="p-0006" num="0005">Before the present methods, systems, and materials are described, it is to be understood that this invention is not limited to the particular methodologies, systems and materials described, as these may vary. It is also to be understood that the terminology used in the description is for the purpose of describing the particular versions or embodiments only, and is not intended to limit the scope of the present invention which will be limited only by the appended claims.</p>
<p id="p-0007" num="0006">It must also be noted that as used herein and in the appended claims, the singular forms “a,” “an,” and “the” include plural references unless the context clearly dictates otherwise. Thus, for example, reference to a “mark” is a reference to one or more marks and equivalents thereof known to those skilled in the art, and so forth. Unless defined otherwise, all technical and scientific terms used herein have the same meanings as commonly understood by one of ordinary skill in the art. Although any methods, materials, and devices similar or equivalent to those described herein can be used in the practice or testing of embodiments of the present invention, the preferred methods, materials, and devices are now described. All publications mentioned herein are incorporated by reference. Nothing herein is to be construed as an admission that the invention is not entitled to antedate such disclosure by virtue of prior invention.</p>
<p id="p-0008" num="0007">The present invention relates to enhancing a scanned image of a document or more accurately performing mark recognition of the scanned image to determine the presence or absence of a mark. The methodology of the present invention begins after a document has been digitized. The digitized image is then mapped to a coordinate system. The mapping is performed on the digitized image by using trigger rows, which are determined using existing marks on one margin of the document. The trigger rows are then logically extended across the document. Next, the present invention completes the mapping process by logically creating columns orthogonal to the extended trigger rows. The number of columns created can vary and may be configured to the degree of accuracy required. Alternately, the mapping process may be performed by using corner marks (also known as anchor marks or crop marks), which are marks printed at each corner of the document. A coordinate system is then created by determining the number of rows desired, which may vary, and equally dividing the space into horizontal rows, and by determining the number of columns desired, which may vary, and equally dividing the space into vertical columns. Document deskew may also be performed. Those skilled in the art will understand that other methods for mapping the digitized image to a coordinate system may also be used.</p>
<p id="p-0009" num="0008">Next, a resolver engine evaluates each cell on a pixel-by-pixel basis. The pixel-by-pixel analysis results in a value for each cell. The value may represent the opacity of a response mark present in the cell. The result is that the digitized image has been converted into a series of numeric values each representing a potential response mark on the original document.</p>
<p id="p-0010" num="0009">In a preferred embodiment, a method of performing image mark recognition includes accessing a scanned image of a document containing a plurality of image marks, performing reference image mark recognition on the scanned image, performing coordinate mapping on the scanned image to determine coordinates for a plurality of cells within the scanned image, analyzing one or more pixels in each cell, and determining a cell color value for each cell based on values assigned to the one or more pixels. In an embodiment, performing reference image mark recognition includes determining a location for each of one or more alignment marks and may further include verifying image mark alignment and spacing based on a resolution of the scanned image and the locations of the one or more alignment marks. In an embodiment, determining the location of one or more alignment marks includes examining each corner of the scanned image. In an embodiment, determining the location of one or more alignment marks includes searching for trigger rows on at least one margin of the scanned image.</p>
<p id="p-0011" num="0010">In an embodiment, performing coordinate mapping includes computing logical row coordinates for a number of rows in the scanned image, computing logical column coordinates for a number of columns in the scanned image, creating a mapping within the scanned image, and resolving the mapping into coordinate values for each of a plurality of cells. In an embodiment, computing logical row coordinates and logical column coordinates includes using one or more trigger marks as reference points. In an embodiment, computing logical row coordinates and logical column coordinates includes using one or more corner marks as reference points. The number of rows and the number of columns may be automatically determined based on the step of performing reference image mark recognition. Alternately, the number of rows and the number of columns may be predetermined. In an embodiment, creating a mapping includes determining absolute pixel positions for each cell within the scanned document as defined by an intersection of a row and a column.</p>
<p id="p-0012" num="0011">In an embodiment, analyzing one or more pixels includes incrementing a total color value by a color value for each pixel in a cell. Determining a cell color value may include setting the cell color value to the ratio of the total color value to a maximum color value.</p>
<p id="p-0013" num="0012">In a preferred embodiment, a system for performing image mark recognition includes a processor and one or more computer readable mediums operatively coupled to the processor. At least one of the one or more computer readable mediums contains a scanned image of a document. At least one of the one or more computer readable mediums contains computer program instructions for performing a method of performing image mark recognition.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0014" num="0013">The accompanying drawings, which are incorporated in and form a part of the specification, illustrate preferred embodiments of the present invention and, together with the description serve to explain the principles of the invention. The embodiments illustrated in the drawings should not be read to constitute limiting requirements, but instead are intended to assist the reader in understanding the invention.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 1</figref> depicts an exemplary process flow for the image mark recognition process according to an embodiment of the present invention.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 2</figref> depicts an exemplary cell evaluation ordering according to an embodiment of the present invention.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIGS. 3A and 3B</figref> depict exemplary computations of cell color values according to an embodiment of the present invention.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram of exemplary internal hardware that may be used to contain or implement the program instructions of a system embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS</heading>
<p id="p-0019" num="0018">The present invention relates to resolving a scanner image of a document to perform mark recognition on the scanned image. The present invention provides a system and method for resolving a digitized image of a document, independent of the hardware used to create the digitized image. The digitized image is enlisted by the present invention and a sequence of values representing the presence or absence of response marks on the document is created. This sequence of values is then available for use by any application which may be created to enhance the document, such as a scoring application which may be used to return a score for an examination.</p>
<p id="p-0020" num="0019">An aspect of the present invention involves mapping the digitized image of a document to a coordinate system. This coordinate mapping may be performed by detecting trigger row marks and/or corner/crop marks to create a logical document mapping. A trigger row mark is a mark on an edge of a document that denotes boundaries of a row logically extending across the document. In an assessment environment, responses may be entered within the logical rows. Each row for which a test taker can potentially enter one or more responses may have a separate trigger row mark. Alternatively, a trigger row mark may be used to denote every second row, third row, or any other pattern that may be used to logically subdivide a document. An alternate method of coordinate mapping includes use of corner/crop marks placed in each corner of the document. The crop marks are located and used to define the coordinate system by subdividing the space between the crop marks into a logical coordinate system. For example, adjacent crop marks along the vertical margin of the document may be subdivided into a predetermined number of equally sized rows. Similarly, adjacent crop marks along the horizontal margin of the document may be subdivided into a predetermined number of equally sized columns intersecting with the rows. The pre-determined number of rows and columns may be verified by analyzing the location of the response marks. Alternatively, a user may enter information regarding the document, such as a document number, from which the row and column placement is determined.</p>
<p id="p-0021" num="0020">As shown in <figref idref="DRAWINGS">FIG. 1</figref>, the process begins by accessing the digital image of a previously scanned document <b>105</b>. The digital image may have been created by any means available and is not dependent on any particular hardware, format or resolution. A logical coordinate system is then mapped over the digital image <b>110</b> using the trigger row technique, the corner/crop mark techniques, or any other technique. The result of the coordinate mapping process <b>110</b> is that the digital image of the document has been logically subdivided into a plurality of cells that, in combination, comprise the entire digital image. The number of cells is configurable during the mapping process, and more or fewer cells may preferably be generated depending on the type of document being scanned and the processing required. The process then begins to iteratively analyze the image on a cell-by-cell basis to generate machine-readable data representative of the response marks on the document. This iterative process begins by obtaining the image <b>115</b> in the first cell. For example, as shown in <figref idref="DRAWINGS">FIG. 2</figref>, the mapping process may create an (N×M) coordinate system requiring evaluation of N*M cells. This process may, for example, begin by evaluating cell (<b>1</b>,<b>1</b>) <b>205</b>, proceed to cell (<b>1</b>,<b>2</b>) <b>210</b> and continue in the same manner to cell (<b>1</b>,M) <b>215</b>. Next, cell (<b>2</b>,<b>1</b>) <b>220</b> through (<b>2</b>,M) <b>225</b> and so on to cell (N,M) <b>230</b> may be evaluated. Alternate cell evaluation orderings and numberings are considered to be within the scope of this invention.</p>
<p id="p-0022" num="0021">Returning to <figref idref="DRAWINGS">FIG. 1</figref>, the process may resolve the response marks in each cell into computer readable values. For each cell, a cell color value from, for example, 0 to 100, inclusive, representing the amount of darkness/lightness of a cell's coloration may be assigned <b>120</b>. The cell color value may be assigned <b>120</b> based on a ratio of the sum of color values for each pixel in a cell having a non-white color (collectively, a total color value) to a maximum color value for the cell. The maximum color value may be equal to the number of pixels in a cell multiplied by a maximum pixel color value.</p>
<p id="p-0023" num="0022">Two exemplary computations of a cell color value are shown in <figref idref="DRAWINGS">FIGS. 3A and 3B</figref>. In the exemplary computations, each pixel within a cell may be assigned a pixel color value ranging from 0 to 15, inclusive. In <figref idref="DRAWINGS">FIG. 3A</figref>, the cell has 4 pixels having a pixel color value equal to 0, 8 pixels having a pixel color value equal to 4, 12 pixels having a pixel color value equal to 9, and 12 pixels having a pixel color value equal to 15. The total color value for the cell in <figref idref="DRAWINGS">FIG. 3A</figref> is tc=(4*0)+(8*4)+(12*9)+(12*15)=32+108+180=320. The maximum color value for the cell in <figref idref="DRAWINGS">FIG. 3A</figref> is pc=(6 rows*6 columns*15)=540. The cell color value for the cell in <figref idref="DRAWINGS">FIG. 3A</figref> is v=tc/pc≈59%. Thus, the cell color value for the cell in <figref idref="DRAWINGS">FIG. 3A</figref> is 59.</p>
<p id="p-0024" num="0023">Similar computations are used to compute the total color value, maximum color value and cell color value in <figref idref="DRAWINGS">FIG. 3B</figref>. Here, tc=172, pc=540, and v≈32%. Hence, the cell color value for the cell in <figref idref="DRAWINGS">FIG. 3B</figref> is 32.</p>
<p id="p-0025" num="0024">Preferably, a value of 0 may represent the lightest possible mark (e.g., white), and a value of 100 may represent the darkest possible mark (e.g., black). The machine-readable data values for each cell may optionally be stored <b>125</b> to an output file.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram of exemplary internal hardware that may be used to contain or implement the program instructions of a system embodiment of the present invention. Referring to <figref idref="DRAWINGS">FIG. 4</figref>, a bus <b>428</b> serves as the main information highway interconnecting the other illustrated components of the hardware. CPU <b>402</b> is the central processing unit of the system, performing calculations and logic operations required to execute a program. Read only memory (ROM) <b>418</b> and random access memory (RAM) <b>420</b> constitute exemplary memory devices.</p>
<p id="p-0027" num="0026">A disk controller <b>404</b> interfaces with one or more optional disk drives to the system bus <b>428</b>. These disk drives may be external or internal floppy disk drives such as <b>410</b>, CD ROM drives <b>406</b>, or external or internal hard drives <b>408</b>. As indicated previously, these various disk drives and disk controllers are optional devices.</p>
<p id="p-0028" num="0027">Program instructions may be stored in the ROM <b>418</b> and/or the RAM <b>420</b>. Optionally, program instructions may be stored on a computer readable medium such as a floppy disk or a digital disk or other recording medium, a communications signal or a carrier wave.</p>
<p id="p-0029" num="0028">An optional display interface <b>422</b> may permit information from the bus <b>428</b> to be displayed on the display <b>424</b> in audio, graphic or alphanumeric format. Communication with external devices may optionally occur using various communication ports <b>426</b>. An exemplary communication port <b>426</b> may be attached to a scanner <b>430</b> used to scan an image of a document into one or more of the memory devices or disk drives.</p>
<p id="p-0030" num="0029">In addition to the standard computer-type components, the hardware may also include an interface <b>412</b> which allows for receipt of data from input devices such as a keyboard <b>414</b> or other input device <b>416</b> such as a remote control, pointer and/or joystick.</p>
<p id="p-0031" num="0030">An embedded system may optionally be used to perform one, some or all of the operations of the present invention. Likewise, a multiprocessor system may optionally be used to perform one, some or all of the operations of the present invention.</p>
<p id="p-0032" num="0031">Although the invention has been described with reference to the preferred embodiments, it will be apparent to one skilled in the art that variations and modifications are contemplated within the spirit and scope of the invention. The drawings and description of the preferred embodiments are made by way of example rather than to limit the scope of the invention, and it is intended to cover within the spirit and scope of the invention all such changes and modifications.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of performing image mark recognition, comprising:
<claim-text>(a) accessing a scanned image of a document containing a plurality of image marks;</claim-text>
<claim-text>(b) performing reference image mark recognition on the scanned image;</claim-text>
<claim-text>(c) performing coordinate mapping on the scanned image to determine coordinates for a plurality of cells within the scanned image, wherein performing coordinate mapping comprises:
<claim-text>(i) computing logical row coordinates for a number of rows in the scanned image,</claim-text>
<claim-text>(ii) computing logical coordinates for a number of columns in the scanned image,</claim-text>
<claim-text>(iii) creating a mapping within the scanned image,</claim-text>
<claim-text>(iv) resolving the mapping into coordinate values for each of a plurality of cells;</claim-text>
</claim-text>
<claim-text>(d) analyzing one or more pixels in each cell; and</claim-text>
<claim-text>(e) determining a cell color value for each cell based on values assigned to the one or more pixels.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein computing logical row coordinates and logical column coordinates comprises using one or more trigger marks as reference points.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein computing logical row coordinates and logical column coordinates comprises using one or more corner marks as reference points.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the number of rows and the number of columns are automatically determined based on the step of performing reference image mark recognition.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the number of rows and the number of columns are pre-determined.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein creating a mapping comprises determining absolute pixel positions for each cell within the scanned document as defined by an intersection of a row and a column.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A system for performing image mark recognition, comprising:
<claim-text>(a) a processor; and</claim-text>
<claim-text>(b) one or more computer readable mediums operatively coupled to the processor, wherein at least one of the one or more computer readable mediums contains a scanned image of a document, wherein at least one of the one or more of the computer readable mediums contains computer program instructions for performing a method of performing image mark recognition, the method comprising:
<claim-text>(i) accessing a scanned image of a document containing a plurality of image marks,</claim-text>
<claim-text>(ii) performing reference image mark recognition on the scanned image,</claim-text>
<claim-text>(iii) performing coordinate mapping on the scanned image to determine coordinates for a plurality of cells within the scanned image, wherein the computer instructions for the step of performing coordinate mapping comprise;
<claim-text>(1) computing logical row coordinates for a number of rows in the scanned image,</claim-text>
<claim-text>(2) computing logical column coordinates for a number of columns in the scanned image,</claim-text>
<claim-text>(3) creating a mapping within the scanned image,</claim-text>
<claim-text>(4) resolving the mapping into coordinate values for each of a plurality of cells,</claim-text>
</claim-text>
<claim-text>(iv) analyzing one or more pixels in each cell, and</claim-text>
<claim-text>(v) determining a cell color value for each cell based on values assigned to the one or more pixels.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein computing logical row coordinates and logical column coordinates comprises using one or more trigger marks as reference points.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein computing logical row coordinates and logical column coordinates comprises using one or more corner marks as reference points.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein the number of rows and the number of columns are automatically determined based on the step of performing reference image mark recognition.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein the number of rows and the number of columns are pre-determined.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref> wherein the pre-determined number of rows and the pre-determined number of columns are verified.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein the computer program instructions for the step of creating a mapping comprise determining absolute pixel positions for each cell within the scanned document as defined by an intersection of a row and a column.</claim-text>
</claim>
</claims>
</us-patent-grant>
