<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298760-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298760</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11510952</doc-number>
<date>20060828</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<us-term-of-grant>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>J</subclass>
<main-group>15</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>370464</main-classification>
<further-classification>370431</further-classification>
<further-classification>370437</further-classification>
</classification-national>
<invention-title id="d0e51">System and method for processing audio and video data in a wireless handset</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5561466</doc-number>
<kind>A</kind>
<name>Kiriyama</name>
<date>19961000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>37524025</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5608651</doc-number>
<kind>A</kind>
<name>Leavy et al.</name>
<date>19970300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348 1412</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5784572</doc-number>
<kind>A</kind>
<name>Rostoker et al.</name>
<date>19980700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5982360</doc-number>
<kind>A</kind>
<name>Wu et al.</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5991313</doc-number>
<kind>A</kind>
<name>Tanaka et al.</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6016166</doc-number>
<kind>A</kind>
<name>Huang et al.</name>
<date>20000100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348515</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6111863</doc-number>
<kind>A</kind>
<name>Rostoker et al.</name>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370329</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6396816</doc-number>
<kind>B1</kind>
<name>Astle et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6445686</doc-number>
<kind>B1</kind>
<name>Hoffbeck et al.</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6477185</doc-number>
<kind>B1</kind>
<name>Komi et al.</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370536</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6484285</doc-number>
<kind>B1</kind>
<name>Dent</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>6510325</doc-number>
<kind>B1</kind>
<name>Mack et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>6516005</doc-number>
<kind>B1</kind>
<name>Murayama et al.</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>6522672</doc-number>
<kind>B1</kind>
<name>Matsuzaki et al.</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>6563513</doc-number>
<kind>B1</kind>
<name>Yu et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>6567475</doc-number>
<kind>B1</kind>
<name>Dent et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>6570080</doc-number>
<kind>B1</kind>
<name>Hasegawa et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>6584509</doc-number>
<kind>B2</kind>
<name>Putzolu</name>
<date>20030600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709240</main-classification></classification-national>
</citation>
<citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>6611674</doc-number>
<kind>B1</kind>
<name>Jokimies et al.</name>
<date>20030800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>6681120</doc-number>
<kind>B1</kind>
<name>Kim</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>6728795</doc-number>
<kind>B1</kind>
<name>Farazmandnia et al.</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>6738357</doc-number>
<kind>B1</kind>
<name>Richter et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370263</main-classification></classification-national>
</citation>
<citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2001/0031043</doc-number>
<kind>A1</kind>
<name>Kim</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2002/0065076</doc-number>
<kind>A1</kind>
<name>Monroe</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2002/0127969</doc-number>
<kind>A1</kind>
<name>Meade</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00026">
<othercit>“Annex B: Muliplexing protocol for low bit rate multimedia mobile communication over moderate error-prone channels,” ITU-T Telecommunications Standardization Section of ITU, H.223 Annex B, International Telecommunication Unit, Series H: Audiovisual and Multimedia Systems, Infrastructure of Audiovisual Services—Transmission Multiplexing and Synchronization, Feb. 1998.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00027">
<othercit>“Draft ITU-T Recommendation H.324,” Rapporteur for Q2/15 (Richard Schaphorst), International Telecommunication Union, Standardization Sector. Study Period 1993-1996, COM 15, Nov. 1995.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>709102</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370464</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370437</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370431</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>7</number-of-drawing-sheets>
<number-of-figures>10</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>09631511</doc-number>
<kind>00</kind>
<date>20000803</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7120162</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>11510952</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20060285530</doc-number>
<kind>A1</kind>
<date>20061221</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Katibian</last-name>
<first-name>Behnam</first-name>
<address>
<city>Irvine</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Hsueh</last-name>
<first-name>Albert</first-name>
<address>
<city>Laguna Niguel</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Skyworks Solutions, Inc.</orgname>
<role>02</role>
<address>
<city>Newport Beach</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Lee</last-name>
<first-name>Thomas</first-name>
<department>2115</department>
</primary-examiner>
<assistant-examiner>
<last-name>Cribbs</last-name>
<first-name>Malcolm D</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A system for processing audio and video data for a wireless handset is provided. The system includes an audio sampler receiving audio data and converting the audio data into digitally encoded audio data. The system also includes a digital imager receiving image data and converting the image data to digitally encoded image data. A processor coupled to the audio sampler and the digital imager and receives the digitally encoded audio data and the digitally encoded image data and gives processing priority to one of the digitally encoded audio data and the digitally encoded image data.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="204.22mm" wi="133.01mm" file="US07298760-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="207.35mm" wi="136.06mm" file="US07298760-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="226.82mm" wi="166.20mm" file="US07298760-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="233.34mm" wi="156.72mm" file="US07298760-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="229.95mm" wi="172.38mm" file="US07298760-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="212.77mm" wi="175.51mm" file="US07298760-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="236.39mm" wi="177.21mm" file="US07298760-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="226.99mm" wi="178.05mm" file="US07298760-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">RELATED APPLICATION</heading>
<p id="p-0002" num="0001">This application is related to U.S. patent application Ser. No. 09/631,511, filed August 3, 2000, and U.S. patent application Ser. No. 09/631,508, filed Aug. 3, 2000, which is abandoned.</p>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention pertains to the field of wireless telecommunications handsets. More specifically, the invention relates to a system and method for processing audio and video data in a wireless handset that allows processing priority to be given to either the audio or the video data.</p>
<heading id="h-0003" level="1">BACKGROUND</heading>
<p id="p-0004" num="0003">The transmission of low bit rate multimedia data is known in the art. For example, the International Telecommunications Union standard H.223 “Series H: Transmission of Non-Telephone Signals—Multiplexing Protocol for Low Bit Rate Multimedia Communications,” including annexes A through D, addresses combination of audio, video, and data in a single low bit rate data stream. Nevertheless, although implementation of such combinations of audio and video data for desktop video telephone sets and other stationary applications are known, the implementation of audio and video data in a wireless device is not completely addressed by any of the prior art.</p>
<p id="p-0005" num="0004">One reason why the combination of audio and video data in a wireless device has not been addressed may be because wireless handsets have significant power and processor capability constraints that limit the ability of the wireless handset to handle audio and video data. The ways in which audio and video data are processed for transmission in a stationary device, where size and power requirements are not limited, are not directly applicable to a wireless handset, where the reduced processor power and transmission power, the requirement for interaction with wireless transmission protocols, and other requirements and limitations of wireless handsets prevent direct application of stationary device design to the wireless handset.</p>
<p id="p-0006" num="0005">Thus, while standards for the combination of audio and video data for stationary devices have been developed, these standards do not address the unique requirements of wireless devices, which are generally perceived as being unable to transmit, receive, and process audio and video data.</p>
<heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0007" num="0006">In accordance with the present invention, a system and method for processing audio and video data in a wireless handset are provided that overcome known problems with processing audio and video data in wireless handsets.</p>
<p id="p-0008" num="0007">In particular, a system and method for processing audio and video data in a wireless handset are provided that processor resources to allocated to the preferred communications data type, thus ensuring that the level of service desired by the user is provided.</p>
<p id="p-0009" num="0008">In accordance with an exemplary embodiment of the present invention, a system for processing audio and video data for a wireless handset is provided. The system includes an audio sampler receiving audio data and converting the audio data into digitally encoded audio data. The system also includes a digital imager receiving image data and converting the image data to digitally encoded image data. A processor coupled to the audio sampler and the digital imager and receives the digitally encoded audio data and the digitally encoded image data and gives processing priority to one of the digitally encoded audio data and the digitally encoded image data.</p>
<p id="p-0010" num="0009">The present invention provides many important technical advantages. One important technical advantage of the present invention is a system and method for processing audio and video data in a wireless handset that allows priority levels to be assigned to the processing of the video and audio data, such that processor resources, which are typically limited, can be applied to the type of data that is of primary importance before data that has a secondary importance is processed.</p>
<p id="p-0011" num="0010">Those skilled in the art will further appreciate the advantages and superior features of the invention together with other important aspects thereof on reading the detailed description that follows in conjunction with the drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram of a system for transmitting and processing audio and video data from a wireless handset in accordance with an exemplary embodiment of the present invention;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram of a system for controlling the processing and transmission of audio and video data from wireless handsets in accordance with an exemplary embodiment of the present invention;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram of a system for storing data in accordance with an exemplary embodiment of the present invention;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram of a system for controlling transmission protocol in accordance with an exemplary embodiment of the present invention;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram of a system for controlling the multiplexing of audio, video, and control data in a wireless handset in accordance with an exemplary embodiment of the present invention;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram of a system for providing framing in accordance with an exemplary embodiment of the present invention;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart of a method for setting priority in a wireless handset for processing of audio and video data in accordance with an exemplary embodiment of the present invention;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 8</figref> is a diagram of a flowchart of a method for assembling transmission data packets in accordance with an exemplary embodiment of the present invention;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart of a method for transmitting audio and video data in accordance with an exemplary embodiment of the present invention; and</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 10</figref> is a flowchart of a method for processing audio and video data in accordance with an exemplary embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS</heading>
<p id="p-0022" num="0021">In the description that follows, like parts are marked throughout the specification and drawings with the same reference numerals, respectively. The drawing figures might not be to scale, and certain components can be shown in generalized or schematic form and identified by commercial designations in the interest of clarity and conciseness.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 1</figref> is a diagram of a system <b>100</b> for transmitting and processing audio and video data from a wireless handset in accordance with an exemplary embodiment of the present invention. System <b>100</b> allows audio data and video data to be processed and transmitted from a wireless handset and is compatible with the processing and power limitations of wireless handsets.</p>
<p id="p-0024" num="0023">System <b>100</b> includes baseband processor <b>102</b>, audio sampler <b>104</b>, and digital imager <b>106</b>, which can be contained within a wireless handset housing. Baseband processor <b>102</b> and audio sampler <b>104</b> can be implemented as suitable existing wireless handset baseband processors and audio samplers. Digital imager <b>106</b> can be a digital imager, model number CX20450, provided by Conexant Systems, Inc. of Newport Beach, Calif., or other suitable imagers with different numbers of picture elements (“pixels”) and array structures.</p>
<p id="p-0025" num="0024">Baseband processor <b>102</b> includes controller <b>108</b>, audio data processor <b>110</b>, video data processor <b>112</b>, and data buffer system <b>114</b>, each of which can be implemented in hardware, software, or a suitable combination of hardware and software, and which can be one or more software systems operating on a digital signal processing device of baseband processor <b>102</b>. As used herein, a software system can be implemented as one or more objects, agents, lines of code, subroutines, separate software applications, two or more lines of code operating two or more software applications, or other suitable software architectures. In one exemplary embodiment, a software system can be a first line of code in a general purpose baseband operating system, and a second line of code in a specific purpose software module operating on the baseband processor.</p>
<p id="p-0026" num="0025">Controller <b>108</b> is coupled to audio data processor <b>110</b>, video data processor <b>112</b>, and data buffer system <b>114</b>. As used herein, the term “couple” and its cognate terms such as “couples” and “coupled” can refer to a physical connection (such as copper conductor), a virtual connection (such as randomly-assigned memory locations of a data memory device), a logical connection (such as through logical devices of a semiconducting circuit), other suitable connections, or a suitable combination of such connections. In one exemplary embodiment, systems and components can be coupled to other systems and components through intervening systems and components, such as through an operating system of a digital signal processor.</p>
<p id="p-0027" num="0026">Controller <b>108</b> is coupled to audio sampler <b>104</b> and digital imager <b>106</b> by connection <b>116</b>, which can be a data bus, or one or more physical connections through a circuit board, or other suitable connections. Controller <b>108</b> can provide control data to audio sampler <b>104</b> and digital imager <b>106</b> so as to cause the audio sample rate or the digital image generation rate, respectively, to be varied to match process requirements of baseband processor <b>102</b>.</p>
<p id="p-0028" num="0027">Controller <b>108</b> also provides control data to audio data processor <b>110</b> and video data processor <b>112</b> to control the rate of data processing. In one exemplary embodiment, predetermined data can be entered by a user to control the priority of audio or video data processing, such as when a user wishes to transmit higher quality audio data or video data. In a wireless handset, power and processor limitations typically prevent both audio data and video data from being transmitted at desirable quality levels. Thus, controller <b>108</b> can allow a user to select different operating modes in accordance with user's needs, so as to allow the user to receive a preferred data type at a higher quality than the secondary data type.</p>
<p id="p-0029" num="0028">In one exemplary embodiment, a user can engage in a conversation, such that audio-only mode is selected. The user may then send a single picture of high image resolution quality. In this exemplary embodiment, the user can select to change from the audio-only data mode to a video-only data mode, such that only. video data is transmitted at a predetermined image quality, such as a 640×480 pixel image. In this exemplary embodiment, controller <b>108</b> can receive suitable data commands from the user, such as through keypad entries or verbal commands, and can cause audio sampler <b>104</b> and audio data processor <b>110</b> to cease operations and can likewise cause digital imager <b>106</b> and video data processor <b>112</b> to generate a high quality video image data for transmission. Likewise, when the user has completed transmission of the image data, the user may enter suitable commands to cause controller <b>108</b> to return to an audio-only mode, such as where digital imager <b>106</b> and video data processor <b>112</b> are disabled and audio sampler <b>104</b> and audio data processor <b>110</b> are allowed to perform at peak capacity.</p>
<p id="p-0030" num="0029">In another exemplary embodiment, the wireless handset can be used to transmit audio data and video data simultaneously, where the video data can be given a secondary priority to the audio data. In this manner, video data processor <b>112</b> can use suitable video data processing techniques to transmit image quality in accordance with available video data processing power. Thus, when baseband processor <b>102</b> processing capability is being used to process audio data, the video data will be decreased in quality, but during pauses in conversation where audio data processing is not being performed, video data processing can be performed thus improving the quality of the video data. In this manner, baseband processor <b>102</b> can be advantageously used in a peak processing mode, as opposed to existing wireless handset applications where the baseband processor must be sized for the instantaneous peak, but may be dormant or used to less than maximum capacity over time.</p>
<p id="p-0031" num="0030">Audio data processor <b>110</b> and video data processor <b>112</b> can be implemented in hardware, software, or a suitable combination of hardware and software, and can be one or more software systems operating on a digital signal processor of a baseband processor <b>102</b>. Audio data processor <b>110</b> and video data processor <b>112</b> receive audio and video data, respectively, and process the data to reduce the volume of data that is required to transmit the data. In one exemplary embodiment, audio data processor <b>110</b> performs audio data compression in accordance with ITU-T audio compression standard G.723 and video data processor <b>112</b> performs video data compression in accordance with the MPEG 4 or H263 video compression standards.</p>
<p id="p-0032" num="0031">Data buffer system <b>114</b> can be implemented in hardware, software, or a suitable combination of hardware and software, and can be one or more digital data memory devices of a digital signal processor or of baseband processor <b>102</b>. In one exemplary embodiment, data buffer system <b>114</b> is one or more random access memory devices that have been partitioned into predetermined data buffer areas.</p>
<p id="p-0033" num="0032">In operation, system <b>100</b> allows a user to receive and transmit audio and video data from a wireless handset. System <b>100</b> further allows the user to select priority modes for the audio and video data, such that the user can select for the audio data processing and transmission to be given priority over video data, for video data processing and transmission to be given priority over audio data, or for intermediate values of audio and video data priority to be assigned to meet the user's particular needs and requirements. Likewise, system <b>100</b> can receive audio and video data according to predetermined encoding priorities from the sender. A user can also elect to receive video data and transmit and receive audio data, to receive audio data and transmit and receive video data, to receive only video data or transmit only video data, to receive video data when transmitting audio data and to transmit audio data when receiving video data, to receive audio and video data simultaneously and then transmit audio and video data simultaneously, or other suitable combinations may be processed by the system of system <b>100</b>.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram of a system <b>200</b> from controlling the processing and transmission of audio and video data from wireless handsets in accordance with an exemplary embodiment of the present invention. System <b>200</b> includes controller <b>108</b>, logical channel controller <b>202</b>, multiplex system <b>204</b>, digital image rate controller <b>206</b>, audio sample rate controller <b>208</b>, framing system <b>210</b>, and transmission protocol system <b>212</b>, each of which can be implemented in hardware, software, or a suitable combination of hardware and software, and which can be one or more software systems operating on a baseband processor of a wireless handset.</p>
<p id="p-0035" num="0034">Logical channel controller <b>202</b> controls the assignment of logical channels to audio, video, and control data. In one exemplary embodiment, audio data can be assigned to a first logical channel, video data can be assigned to a second logical channel, and control data can be assigned to a third logical channel, such that predetermined relationships between the channels can be used to separate the audio, video, and control data. Logical channel controller <b>202</b> can further control the placement of logical channels within a transmission data frame. For example, a transmission data frame can include a predetermined number of slots of data, where each slot can include a predetermined number of bits. In the following exemplary embodiment, the transmission data frame includes a flag slot that includes predetermined data sequence, such as “01111110.” The flag slot is followed by a header slot that includes suitable data, such as a packet marker data field, a multiplex code data field, and a header error control data field. The header slot can be used to identify the protocol and format of the remaining slots in the transmission data packet.</p>
<p id="p-0036" num="0035">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="1" colwidth="70pt" align="center"/>
<colspec colname="2" colwidth="35pt" align="center"/>
<colspec colname="3" colwidth="112pt" align="center"/>
<thead>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
<row>
<entry>LCN1</entry>
<entry>LCN2</entry>
<entry>Transmission Data Packet</entry>
</row>
<row>
<entry namest="1" nameend="3" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry>[3 Slots]</entry>
<entry>[5 Slots]</entry>
<entry>[8 Slots]</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="left"/>
<tbody valign="top">
<row>
<entry>[FLAG] [HEADER] [LCN-1] [LCN1-2] [LCN1-3] [LCN2-1] [LCN2-2]</entry>
</row>
<row>
<entry>[FLAG]</entry>
</row>
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0037" num="0036">In this exemplary embodiment, two logical channels are used as payload data in the Transmission Data Packet, which has a total of 8 slots available for transmission. The payload is included after the flag data and the header data slots, and a final flag data slot is used to delimit the Transmission Data Packet. The first logical channel, LCN<b>1</b>, is an audio channel. This audio channel includes three slots of non-segmentable data that make up an audio data packet. The remaining slots in the transmission data packet comprise a portion of a segmentable video data packet, LCN<b>2</b>. The video service data packet includes 5 slots of data. As the Transmission Data Packet in this exemplary embodiment only has eight total slots, only the first two video data slots can be transmitted in the data transmission data packet shown. Data is then included with the header data packet to indicate that an incomplete LCN<b>2</b> data packet was transmitted with the Transmission Data Packet, so as to indicate that the remainder of LCN<b>2</b> is being transmitted in one or more subsequent Transmission Data Packets. Thus, logical channel controller <b>202</b> receives data from various logical channels such as audio data, video data, and control data, and assembles the logical channels into Transmission Data Packets in accordance with predetermined slot sequences</p>
<p id="p-0038" num="0037">Multiplex system <b>204</b> is coupled to logical channel controller <b>202</b> and controls the slot sequences used to combine data into a Transmission Data Packet. In the exemplary embodiment shown in Table 1, the logical channel <b>1</b> audio data and logical channel <b>2</b> video data are assembled by multiplex system <b>204</b>. Multiplex system <b>204</b> interfaces with the adaptation layer of the wireless handset, which includes the physical devices of the wireless handset that generate data. In one exemplary embodiment, the adaptation layer of the wireless handset includes an audio sampling and audio data generation device, a video sampling and video data generation device, and a control data generation device, such as a keypad or voice recognition system.</p>
<p id="p-0039" num="0038">Multiplexing system <b>204</b> can receive the audio data, video data, and control data, and can assemble the classes of data into predetermined service data packets. The size of these predetermined service data packets will be determined in part by the amount of bandwidth available to connect the wireless device to a base station, the quality of audio and video and control data selected, processor capacity, and by other parameters of the system. Thus, the number of slots in a transmission data packet and the number slots required for audio data, video data, and control data will be determined in part by bandwidth and the processing capacity of the processor.</p>
<p id="p-0040" num="0039">Digital image rate controller <b>206</b> receives data from audio data processor <b>110</b> and video data processor <b>112</b>, transmission protocol system <b>212</b>, and multiplex system <b>204</b> and generates control data to control the generation of digital image data from a digital imager <b>106</b>. In one exemplary embodiment, digital image rate controller <b>206</b> can decrease the number of frames per second of data generated by digital imager <b>106</b> so as to reduce or eliminate the amount of data overflow in a digital image buffer. Likewise, digital image rate controller <b>206</b> can receive data from video data processor <b>112</b> that indicates that video data received from digital imager <b>106</b> is not being processed by video data processor <b>112</b> due to the current processor load created by processing of audio data. Digital image rate controller <b>206</b> can then generate control commands that cause digital imager <b>106</b> to generate less frames of video data per second so that video data processor <b>112</b> can process all of the frames of data generated. In this manner, video data processor <b>112</b> may utilize the maximum amount of processor capabilities on baseband processor <b>102</b> as such processor capacity changes over time as a result of changes in audio data processed by audio data processor <b>110</b>.</p>
<p id="p-0041" num="0040">Audio sample rate controller <b>208</b> is coupled to multiplex system <b>204</b>, transmission protocol system <b>212</b>, logical channel controller <b>202</b>, and audio data processor <b>110</b>, and generates audio sample rate control data for use with audio sampler <b>104</b>. Audio sample rate controller <b>208</b> is similar to digital image rate controller <b>206</b> in that it can adjust the rate of audio sample generation to take advantage of available processor capacity of baseband processor <b>102</b>, such as when video data has been given transmission and processor priority, so that audio data can be processed and transmitted on an as-available basis.</p>
<p id="p-0042" num="0041">Framing system <b>210</b> is coupled to multiplex system <b>204</b> and logical channel controller <b>202</b>, and arranges audio, video, and control data in predetermined packets or data units. In one exemplary embodiment, framing system <b>210</b> can create service data units and protocol data units for each logical channel from the adaptation layer, and can also interface with multiplex system <b>204</b> to assemble slots of data into transmission data packets. For example, a transmission data packet may include a protocol data unit that is made up of one or more service data units, and each service data unit may be made up of one or more protocol data units from the adaptation layer. Framing system <b>210</b> is used to control packet size and arrangement.</p>
<p id="p-0043" num="0042">In one exemplary embodiment, framing system <b>210</b> can process data as it is assembled into packets so as to ensure that the data does not replicate the flag slot data that is used to delimit a Transmission Data Packet. If the flag data sequence is “01111110,” then framing system <b>210</b> can process data so that any sequence of “01111110” in the data is broken up, such as by replacing it with “011111010,” such that a zero is inserted after every sequence of five ones. Framing system <b>210</b> can also scan incoming data and replace sequences of “011111010” in the data with “01111110.”</p>
<p id="p-0044" num="0043">Transmission protocol system <b>212</b> receives predetermined transmission protocol data for use in allocating processor and transmission capacity. In one exemplary embodiment, transmission protocol system <b>212</b> includes error control functionality, multiplex code functionality that contains predetermined tabular data for assigning logical channels and structures in accordance with predetermined audio and video processing and transmission capacity, and other suitable data for controlling the transmission of audio and video data.</p>
<p id="p-0045" num="0044">In operation, system <b>200</b> is used to control the handling of audio, video, and control data in a processor between the point where the data is received at the processor and the point where the data is transmitted from the processor to a transceiver for transmission over a wireless channel. System <b>200</b> thus controls the generation of audio and video data, such as sampling rates and digital image generation rates, monitors audio and video data processing effectiveness to determine if data overflow or other non-processing of data occurs, and controls the assembling of process data into data packets for transmission. Controller <b>200</b> thus is used to allocate processor and transmission capacity in a wireless handset, where such processing and transmission capacities may be constrained by the physical requirements of wireless handsets.</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram of a system <b>300</b> for storing data in accordance with an exemplary embodiment of the present invention. System <b>300</b> includes data buffer system <b>114</b>, transmission buffer system <b>302</b>, and channel buffer system <b>304</b>, each of which can be implemented in hardware, software, or a suitable combination of hardware and software, and which can be allocated data memory locations in a data memory device.</p>
<p id="p-0047" num="0046">Transmission buffer system <b>302</b> is used to store transmission data packets as they are assembled by controller <b>108</b>. In one exemplary embodiment, transmission buffer system <b>302</b> includes a predetermined number of slots of data, where each slot includes a predetermined number of bits of data. Transmission buffer system <b>302</b> receives data from channel buffer system <b>304</b>, and controller <b>108</b>, and stores the data in the sequence received in response to control signals from controller <b>108</b>. Transmission buffer system <b>302</b> then transfers the data to a suitable digital transceiver for transmission over a wireless channel. Transmission buffer system <b>302</b> can also be used to receive an incoming data packet for subsequent allocation to channels in channel buffer system <b>304</b>.</p>
<p id="p-0048" num="0047">Channel buffer system <b>304</b> includes a plurality of channels “a” through “n” that are used to logically separate channels of data, such as audio data, video data, and control data. The channels stored in channel buffer system <b>304</b> can include predetermined channel sizes that are based upon wireless channel bandwidth, processor capacity, and other suitable data. In one exemplary embodiment, a first channel is allocated for audio data and includes an optional sequence number field that is used to determine the sequence number of a service data packet, a payload data field that is used to hold a predetermined number of bits of payload data, and a control record check field that is used to store a control record check value based upon the data stored in the remainder of the channel. In this manner, the protocol data unit stored within the channel is comprised of a plurality of other data fields. Channel buffer system <b>304</b> thus allows audio, video, and control data to be stored as it is accumulated and further provides the stored data for assembly by transmission buffer system <b>302</b>. Channel buffer system <b>304</b> can include a suitable number of logical channels, such as an audio channel, an audio overflow channel, a video channel, a video overflow channel, a data channel, a data overflow channel, and other suitable channels.</p>
<p id="p-0049" num="0048">In operation, system <b>300</b> allows audio data, video data, and control data to be stored after processing and assembled for transmission in a data transmission packet. System <b>300</b> allows data priority for processing and transmission to be adjusted between audio and video data, such that a wireless handset user can controllably change the priority to be given to the audio data, the video data, and that control data can override the audio data and video data as needed.</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram of a system <b>400</b> for controlling transmission protocol in accordance with an exemplary embodiment of the present invention. System <b>400</b> includes transmission protocol system <b>212</b>, multiplex code system <b>402</b>, error control system <b>404</b>, packet marker system <b>406</b>, and flag system <b>408</b>, each of which can be implemented in hardware, software, or a suitable combination of hardware and software, and which can be one or more software systems operating on a baseband processor of a wireless handset.</p>
<p id="p-0051" num="0050">Multiplex code system <b>402</b> is used to process predetermined data that identifies logical channel structure for data to be processed in data transmission packets. In one exemplary embodiment, multiplex code system <b>402</b> includes a table having the following structure:</p>
<p id="p-0052" num="0051">
<tables id="TABLE-US-00002" num="00002">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="6">
<colspec colname="1" colwidth="28pt" align="center"/>
<colspec colname="2" colwidth="49pt" align="left"/>
<colspec colname="3" colwidth="28pt" align="center"/>
<colspec colname="4" colwidth="28pt" align="center"/>
<colspec colname="5" colwidth="42pt" align="center"/>
<colspec colname="6" colwidth="42pt" align="left"/>
<thead>
<row>
<entry namest="1" nameend="6" align="center" rowsep="1"/>
</row>
<row>
<entry/>
<entry>Multiplex</entry>
<entry>Element</entry>
<entry/>
<entry>Subelement</entry>
<entry/>
</row>
<row>
<entry/>
<entry>Entry</entry>
<entry>List</entry>
<entry>Nesting</entry>
<entry>List</entry>
</row>
<row>
<entry>Row</entry>
<entry>Descriptor</entry>
<entry>Size</entry>
<entry>Depth</entry>
<entry>Size</entry>
<entry>Description</entry>
</row>
<row>
<entry namest="1" nameend="6" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry>1</entry>
<entry>{LCN1, RC</entry>
<entry>1</entry>
<entry>0</entry>
<entry>0</entry>
<entry>All audio</entry>
</row>
<row>
<entry/>
<entry>UCF}</entry>
</row>
<row>
<entry>2</entry>
<entry>{LCN2, RC</entry>
<entry>1</entry>
<entry>0</entry>
<entry>0</entry>
<entry>All Video</entry>
</row>
<row>
<entry/>
<entry>UCF}</entry>
</row>
<row>
<entry>3</entry>
<entry>{LCN2, RC},</entry>
<entry>2</entry>
<entry>0</entry>
<entry>0</entry>
<entry>All audio,</entry>
</row>
<row>
<entry/>
<entry>{LCN1, RC3</entry>
<entry/>
<entry/>
<entry/>
<entry>2+ video</entry>
</row>
<row>
<entry/>
<entry>UCF}</entry>
</row>
<row>
<entry>4</entry>
<entry>{LCN1, RC},</entry>
<entry>2</entry>
<entry>0</entry>
<entry>0</entry>
<entry>All video,</entry>
</row>
<row>
<entry/>
<entry>{LCN2, RC3</entry>
<entry/>
<entry/>
<entry/>
<entry>2+ audio</entry>
</row>
<row>
<entry/>
<entry>UCF}</entry>
</row>
<row>
<entry namest="1" nameend="6" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0053" num="0052">In this exemplary embodiment, the multiplex code system <b>402</b> table includes a plurality of rows each of which includes a multiplex entry descriptor, an element list size, a nesting depth, and a sub-element list size. In the exemplary embodiment shown, the multiplex entry descriptor for the third row indicates that the transmission data packet should include a complete audio protocol data unit having three slots worth of data and then two slots of a video protocol data unit having five slots of data, which will fill the remainder of the transmission data packet. The table row identifier can be included in the header slot data.</p>
<p id="p-0054" num="0053">In this exemplary embodiment, the transmission data packet includes eight slots of data, where three of these slots are used for header and flag storage. Thus, of the remaining five slots in the eight slot field, the data shown in exemplary row one would allocate three slots for the audio data and two slots for video data. The number of slots of audio data can be correlated to the quality of audio data selected and the available bandwidth for the wireless handset. The video data is therefore transmitted as available, assuming that full audio rate data conversion is being used. For example, if audio data generation drops to zero, such as during a pause in a conversation, then the size of the audio field would likewise drop to zero and the entire five slots could be used to transmit video data.</p>
<p id="p-0055" num="0054">Error control system <b>404</b> generates control record check data to be used by the receiving end to verify that a received field contains uncorrupted data. In one exemplary embodiment, error control system <b>404</b> interfaces with framing system <b>210</b> and multiplex system <b>204</b> to perform control record check processing on service data units of logical channel data received from an adaptation layer. Error control system <b>404</b> uses predetermined error checking algorithms and returns a number that is used by the receiving end, which performs the same error checking algorithm on received blocks of data to determine whether any data has become corrupted.</p>
<p id="p-0056" num="0055">Packet marker system <b>406</b> is used to control packet field data in a transmission data packet to indicate if an audio or video or control data packet has been split in a transmission data packet, such that the next transmission data packet includes the remainder of the transmission data packet that was split. For example, in a sequence of three transmission data packets shown below, the video data packets have been assigned priority and the audio data packet is being transmitted on an as available basis. Thus,</p>
<p id="p-0057" num="0056">
<tables id="TABLE-US-00003" num="00003">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="217pt" align="left"/>
<thead>
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry>[FLAG][HEADER, PM=0][VIDEO1][VIDEO2][VIDEO3]][AUDIO1]</entry>
</row>
<row>
<entry>[AUDIO2][FLAG]</entry>
</row>
<row>
<entry>[FLAG][HEADER, PM=1][VIDEO1][VIDEO2][VIDEO3]][VIDEO4]</entry>
</row>
<row>
<entry>[VIDEO5][FLAG]</entry>
</row>
<row>
<entry>[FLAG][HEADER, PM=1][VIDEO1][VIDEO2][AUDIO3]][AUDIO4]</entry>
</row>
<row>
<entry>[AUDIO5][FLAG]</entry>
</row>
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0058" num="0057">The first transmission data packet includes a video data packet having three slots of data such that the audio data packet must take up the remainder two slots. The second transmission data packet includes a video data packet having five slots, such that the audio data packet is not completed in the second data transmission packet. The third data transmission packet includes a video data having two slots, such that the remainder three slots of audio data can be transmitted in the data packet. Packet marker system <b>406</b> tracks the completion of the audio data such that a packet marker data field in the header data for each data transmission packet or other suitable packet marker data indicates that an incomplete audio data packet is still awaiting transmission.</p>
<p id="p-0059" num="0058">Flag system <b>408</b> inserts predetermined flag data at the beginning and end of a data transmission packet. This flag data can have a predetermined structure, such as “01111110,” where flag system <b>408</b> or other suitable systems also scans service data packets for adaptation layer data to ensure that the similar sequence does not occur. Where a similar sequence occurs, flag system <b>408</b> or other suitable systems insert a zero after five ones have been transmitted. The receiving end removes the zero for payload data in the data transmission packet between the flag header and other flag.</p>
<p id="p-0060" num="0059">In operation, system <b>400</b> is used to control transmission protocol in a wireless handset so as to allow audio and video data to be transmitted within the physical parameters of a wireless handset. System <b>400</b> includes a table of predetermined transmission protocol format data, and a header having a table row identifier that allows the protocol data to be determined by the sending and receiving entities without transmission of actual protocol parameters.</p>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram of a system <b>500</b> for controlling the multiplexing of audio data, video data, and control data in a wireless handset in accordance with an exemplary embodiment of the present invention. System <b>500</b> includes multiplex system <b>204</b>, data adaptation layer system <b>502</b>, video adaptation layer system <b>504</b>, audio adaptation layer system <b>506</b>, and multiplex layer system <b>508</b>, each of which can be implemented in hardware, software, or a suitable combination of hardware and software, and which can be one or more software systems operating on a baseband processor of a wireless handset device.</p>
<p id="p-0062" num="0061">Data adaptation layer system <b>502</b> receives control data and assembles the control data into an adaptation layer protocol data unit. Data adaptation layer system <b>502</b> can be framed or unframed, such that the control data is transmitted in accordance with the frames used by baseband processor <b>102</b>, or in an unframed, superframe, or other suitable mode.</p>
<p id="p-0063" num="0062">Video adaptation layer system <b>504</b> is used to receive processed video data and to assemble the processed video data into protocol data units for transmission. In one exemplary embodiment, video adaptation layer system <b>504</b> includes a 16-bit control record check error detection algorithm and supports optional sequence numbering that can be used to detect missing and misdelivered protocol data units. Variable length service data units can also be transmitted. In one exemplary embodiment, video adaptation layer system <b>504</b> allows one or more video service data units to be transmitted in a video protocol data unit. For example, a video protocol unit may include four video data octets, where the number of octets is dictated by the bandwidth and the processing capacity of the baseband processor. Each video service unit may be four or less octets, such as when video data is not required to change due to a constancy of the digital image received by the digital imager. In this exemplary embodiment, one or more frames of video data may be transmitted in a protocol data unit.</p>
<p id="p-0064" num="0063">Audio adaptation layer system <b>506</b> receives digitally encoded audio data and assembles the digital data into a protocol data unit for transmission. Audio adaptation layer system <b>506</b> includes an 8-bit control record check for error detection and supports optional sequence numbering that can be used to detect missing and misdelivered octets in the protocol data units.</p>
<p id="p-0065" num="0064">Multiplex layer system <b>508</b> assembles protocol data units from data adaptation layer <b>502</b>, video adaptation layer <b>504</b>, and audio adaptation layer <b>506</b> into transmission data packets. Multiplex layer system <b>508</b> ensures that flag data is included at the beginning of the first and last slot, and that header data having suitable header fields such as the multiplex table row number and the header error correction and packet marker fields are included in the transmission data packet.</p>
<p id="p-0066" num="0065">In operation, system <b>500</b> is used to assemble data packets for transmission. System <b>500</b> interfaces with the adaptation layer, which is the layer in which data from audio, video, and control sources is assembled into data packets, and these data packets are then assembled into a transmission data packet.</p>
<p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. 6</figref> is a diagram of a system <b>600</b> for providing framing in accordance with an exemplary embodiment of the present invention. System <b>600</b> includes framing system <b>210</b>, protocol data unit system <b>602</b>, and service data unit system <b>604</b>, each of which can be implemented in hardware, software, or a suitable combination of hardware and software, and which can be one or more software systems operating on a baseband processor of a wireless handset device.</p>
<p id="p-0068" num="0067">Protocol data unit system <b>602</b> assembles data packets for exchange between the multiplex layer and the underlying physical layer, such as between controller <b>108</b> and audio data processor <b>110</b> and video data processor <b>112</b> of <figref idref="DRAWINGS">FIG. 1</figref>. Protocol data unit system <b>602</b> frames the data packet with high-level data link control (“HDLC”) flags in accordance with ISO/IEC 3309 and performs HDLC zero-bit insertion for transparency. Protocol data unit system <b>602</b> can receive data packets from the physical layer, buffer the data, and assemble the data into packets for the multiplex layer, and can receive data packets from the multiplex layer, buffer the data, and assemble the data into packets for the physical layer.</p>
<p id="p-0069" num="0068">Service data unit system <b>604</b> assembles data packets for exchange between the adaptation layer and the multiplex layer, such as in system <b>500</b> of <figref idref="DRAWINGS">FIG. 5</figref>. The data packets assembled by the service data unit system <b>604</b> map data from specific audio, video, or data devices, such that suitable devices may be readily accomodated within the system. Service data unit system <b>604</b> can receive data packets from the adaptation layer, buffer the data, and assemble the data into packets for the multiplex layer, and can receive data packets from the multiplex layer, buffer the data, and assemble the data into packets for the adaptation layer.</p>
<p id="p-0070" num="0069">In operation, system <b>600</b> controls framing for data communications between the physical layer, the multiplex layer, and the adaptation layer for multimedia data in a wireless handset. System <b>600</b> determines and includes other suitable data in the frames as required, such as HDLC flagging and zero-bit insertion. In this manner, system <b>600</b> can conform the data frames to applicable standards.</p>
<p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart of a method <b>700</b> for setting priority in a wireless handset for processing of audio and video data in accordance with an exemplary embodiment of the present invention. Method <b>700</b> can be used to set priority for audio over video, or video over audio.</p>
<p id="p-0072" num="0071">Method <b>700</b> begins at <b>702</b> where priority control data is received. The priority control data can be a default data setting, can be user-entered, or can be other suitable priority control data. The method then proceeds to <b>704</b> where it is determined whether audio data or video data should have priority, including the level of priority to be given to the audio or video data. If it is determined at <b>704</b> that audio is to have priority over video, the method proceeds to <b>706</b>.</p>
<p id="p-0073" num="0072">At <b>706</b>, the multiplex table entry corresponding to the appropriate audio priority entry is selected. For example, the processing and transmission of audio data can be given 100% priority, non-exclusive priority, or adjustable levels of audio data priority can be provided to allow the user to select a suitable setting. The method then proceeds to <b>708</b>.</p>
<p id="p-0074" num="0073">At <b>708</b>, the video encoder data rate is set. For example, the video encoder data rate can be adjustable from one frame a second, to <b>30</b> frames a second, to a sub-number of frames per second, such as in a snapshot mode. The video encoder rate is then adjusted and the method proceeds to <b>710</b>.</p>
<p id="p-0075" num="0074">At <b>710</b>, audio processing priority is set. For example, the processor can receive suitable control data that causes the processor to perform all audio data processing prior to performing any video data processing. Other suitable audio processing priority methods can be used, such as setting the number of processing cycles that audio data will receive. The method then proceeds to <b>718</b>.</p>
<p id="p-0076" num="0075">If it is determined at <b>704</b> that video data has priority, then the method proceeds to <b>712</b> where a multiplex table entry is set to the corresponding video priority. For example, the video data can be given 100% priority, or priority ranging between 100% and 50%. The method then proceeds to <b>714</b> where the audio data sample rate is set. The audio data sample rate is set in correlation to the amount of audio processor capacity that is anticipated to be available. The method then proceeds to <b>716</b> where video data processing priority is set on the processor. The method then proceeds to <b>718</b>.</p>
<p id="p-0077" num="0076">At <b>718</b>, audio and video data are processed in accordance with predetermined priority settings. The method then proceeds to <b>720</b> where it is determined whether a priority change has been entered, such as when a user has selected to send video data from a 100% audio mode, or other suitable changes. If it is determined that a priority change has not been received at <b>720</b>, the method returns to <b>718</b>. Otherwise, the method returns to <b>702</b>.</p>
<p id="p-0078" num="0077">In operation, method <b>700</b> is used to set and adjust priority for audio data and video data processing and transmission in a wireless handset unit. Method <b>700</b> allows levels of audio or data processing capabilities, such as <b>100</b>% audio, 100% video, or intermediate levels of audio and video, where audio data can be given priority over video, and audio and video data sampling rates can be adjusted. Method <b>700</b> thus allows wireless handset audio and video data to be adjusted in accordance with wireless handset physical requirements, such as power levels, transmission bandwidth, or other suitable information.</p>
<p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. 8</figref> is a diagram of a flowchart of a method <b>800</b> for assembling transmission data packets in accordance with an exemplary embodiment of the present invention. Method <b>800</b> allows control data to be provided with priority over audio data or video data, such as data that is required for adjusting wireless handset transceiver characteristics, keypad control data entry, or other suitable control data.</p>
<p id="p-0080" num="0079">Method <b>800</b> begins at <b>802</b> where video data, audio data, and control data are received. The data can be received from an application layer, such as a cell phone microphone and analog to digital converter, a digital imager, a keypad, a voice recognition software system, or other suitable application layer systems. The data may then be converted into suitable protocol data units, service data units, data packets, or other suitable data structures. The method then proceeds to <b>804</b> where the data is stored in channel buffers. In one exemplary embodiment, the video data, audio data, and control data each have a dedicated channel buffer. The method then proceeds to <b>806</b>.</p>
<p id="p-0081" num="0080">At <b>806</b>, it is determined whether the control data buffer is full. For example, control data may be transmitted periodically to control cell phone power levels or other suitable information. Likewise, a user may enter control data from a wireless handset keypad such as to change the priority to be given to audio and video data processing. If it is determined at <b>806</b> that the control buffer is not full, the method proceeds to <b>808</b> where it is determined whether a control override has been received. For example, a control override may be received when control data must be sent periodically, such as in accordance with a timing burst or sounding burst in a wireless data transmission system. If it is determined that a control override has not been received, the method proceeds to <b>810</b> where audio and video channel data are processed and assembled. The method then returns to <b>802</b>.</p>
<p id="p-0082" num="0081">If it is determined at <b>806</b> that the control buffer is full, or at <b>808</b> that a control override has been received, the method proceeds to <b>812</b> where control channel data is assembled. A flag data packet, such as an 8-bit data packet or octet in this exemplary embodiment, is then assembled at <b>814</b> in the data transmit buffer at the beginning and end of the data transmit buffer. A header data packet, such as an 8-bit data packet or octet, is then stored at <b>816</b> after the first flag buffer, and the method proceeds to <b>818</b>.</p>
<p id="p-0083" num="0082">At <b>818</b>, control data units, such as 8-bit data packets or octets, are stored in the transmit buffer in accordance with a predetermined multiplex table entry. For example, when control data has priority, a multiplex table entry may be selected that identifies the correct structure for the data transmission packet. The method then proceeds to <b>820</b> where the data is transmitted and data buffers are cleared. The method then returns to <b>802</b>.</p>
<p id="p-0084" num="0083">In operation, method <b>800</b> allows control data to be sent regardless of the priority given to audio and video data so as to ensure that wireless handset operations can continue without interruption. Method <b>800</b> allows the audio and video data to be temporarily interrupted for transmission of control data, and then to be resumed without loss of data and corresponding interruption of service.</p>
<p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart of a method <b>900</b> for transmitting audio and video data in accordance with an exemplary embodiment of the present invention. Method <b>900</b> can be used where audio data processing and transmission is given priority over video data processing and transmission, and can be readily adapted for use where the priority given to audio and video data is reversed by switching “audio” for “video” and “video” for “audio,” where appropriate.</p>
<p id="p-0086" num="0085">Method <b>900</b> begins at <b>902</b> where audio and video data are received. The method then proceeds to <b>904</b> where the data is stored in corresponding channel buffers. The method then proceeds to <b>906</b>. If it is determined at <b>906</b> that an audio buffer is full, then the method proceeds to <b>910</b>, otherwise the method proceeds to <b>908</b> where it is determined whether a time limit has been exceeded. In this exemplary embodiment, a certain amount of audio data is transmitted every period, such as background noise data or other suitable data. At <b>908</b> it is determined whether this period of time has been exceeded. If it is determined at <b>906</b> that the audio buffer is full or at <b>908</b> that the time limit has been exceeded, the method proceeds to <b>910</b>. Otherwise, the method returns to <b>902</b>.</p>
<p id="p-0087" num="0086">At <b>910</b>, a flag octet is stored in the transmit buffer at the beginning and end of the data transmission packet. The method then proceeds to <b>912</b> where a header octet is stored in the second slot position of the data transmission packet. The method then proceeds to <b>914</b>.</p>
<p id="p-0088" num="0087">At <b>914</b>, the audio data unit is stored in the transmit buffer. For example, the audio data unit may include a predetermined maximum number of slots, such as five, when there are nine total slots in the transmit buffer between the header and flag slots. In this exemplary embodiment, four additional slots have remained for video data. The method then proceeds to <b>916</b> where the video data is stored in the available slots. The method then proceeds to <b>918</b> where the buffer data is transmitted and the audio buffer is cleared. The method then proceeds to <b>920</b>.</p>
<p id="p-0089" num="0088">At <b>920</b> it is determined whether video buffer overflow has occurred. For example, video data may be generated at a rate that exceeds the rate at which the video data can be transmitted. Likewise, constraints on processing power may result in video data that has a less efficient format than the video data may have if it is processed fully. If it is determined at <b>920</b> that video buffer overflow has not occurred, the method proceeds to <b>922</b> where the transmitted octets are cleared from the buffer and the method returns to <b>902</b>. If it is determined that video buffer overflow has occurred at <b>920</b>, the method proceeds to <b>924</b> where the video buffer is cleared and the video encoder rate is adjusted to decrease the amount of video data being processed. The method then returns to <b>902</b>.</p>
<p id="p-0090" num="0089">In operation, method <b>900</b> allows audio data to be processed and transmitted in preference to video data, and also allows video data rate to be adjusted to compensate for differences in the video data rate and the amount of bandwidth available to transmit video data. Method <b>900</b> can also be used for transmitting video in preference to audio, with the noted substitutions and modifications.</p>
<p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. 10</figref> is a flowchart of a method <b>1000</b> for processing audio data and video data in accordance with an exemplary embodiment of the present invention. Method <b>1000</b> can be used to process audio data and video data in a wireless handset unit which has limited processing capacity and power.</p>
<p id="p-0092" num="0091">Method <b>1000</b> begins at <b>1002</b> where audio data and video data are received. The method then proceeds to <b>1004</b> where it is determined whether audio data or video data has priority. The priority can also be relative, such that the audio data has relative priority over video data but not complete priority. If it is determined at <b>1004</b> that audio data has relative priority over video data, the method proceeds to <b>1006</b>.</p>
<p id="p-0093" num="0092">At <b>1006</b>, the audio data is processed to completion. For example, the processor may receive predetermined amounts of audio data and may process the audio data until it has been fully compressed and encoded for transmission. The method then proceeds to <b>1008</b> where the processed audio data is stored for transmission, such as in a service data unit system or protocol data unit system. The method then proceeds to <b>1010</b> where the video data is processed to the remaining amount of processor capacity. For example, the processor may work in cycles and the amount of video data required for processing may exceed the amount of cycle times left. In this exemplary embodiment, the video data is processed until the number of processor cycles remaining is exceeded and then the method proceeds <b>1012</b>.</p>
<p id="p-0094" num="0093">At <b>1012</b>, the processed video data is stored for transmission. The method then proceeds to <b>1014</b> where it is determined whether video data overflow has occurred. In one exemplary embodiment, the video data that remains unprocessed may be stored in a buffer such that additional video data is stored in the buffer until the buffer is full. If it is determined that video data overflow has not occurred, the method returns to <b>1002</b>, otherwise the method proceeds to <b>1016</b> where the digital image generation rate is adjusted, such as by changing the number of image screen scans per second that are generated by a digital image generation chip. The method then returns to <b>1002</b>.</p>
<p id="p-0095" num="0094">If it is determined at <b>1004</b> that video data has priority, the method proceeds to <b>1018</b> where video data is processed to completion, such as to compress the data, and encode the data into a predetermined data transmission format. The method then proceeds to <b>1020</b> where the processed video data is stored for transmission.</p>
<p id="p-0096" num="0095">At <b>1022</b> the audio data is processed to processor capacity, such as for a remaining number of processor cycles in a period. The method then proceeds to <b>1024</b> where the processed audio data is stored for transmission. The method then proceeds to <b>1026</b> where it is determined whether audio data overflow has occurred. If no audio data overflow has occurred, the method returns to <b>1002</b>, otherwise the method proceeds to <b>1028</b> where audio data sample rate is adjusted to decrease the amount of audio data generated. Likewise, the amount of audio data can be increased just as the amount of digital image data can be increased after step <b>1014</b> before it returns to <b>1002</b>.</p>
<p id="p-0097" num="0096">In operation, method <b>1000</b> allows audio data and video data processing priority to be set so that one has priority over the other. Method <b>1000</b> also allows video digital image rate scanning and audio sample rates to be adjusted to produce a suitable amount of data in accordance with processor capacity availability and requirements.</p>
<p id="p-0098" num="0097">Although exemplary embodiments of a system and method for processing and transmitting audio and video data in a wireless handset have been described in detail herein, those skilled in the art will also recognize that various substitutions and modifications can be made to the systems and methods without departing from the scope and spirit of the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A system for processing audio and video data for a wireless handset comprising:
<claim-text>a controller generating priority data;</claim-text>
<claim-text>a plurality of channel buffers, each representing a logically separate channel of data; and</claim-text>
<claim-text>a transmission buffer receiving the priority data and data from two or more of the channel buffers and storing the data from the channel buffers, where a number of channel buffers to receive data from and a sequence in which the data received from the channel buffers is stored in the transmission buffer is determined by the priority data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the plurality of channel buffers further comprises an audio data buffer.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the plurality of channel buffers further comprises a video data buffer.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the plurality of channel buffers further comprises a control data buffer.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the controller generates priority data based on transmission channel bandwidth.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the controller generates priority data based on processor capacity of a wireless handset processor.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the plurality of channel buffers further comprises:
<claim-text>an audio data buffer;</claim-text>
<claim-text>a video data buffer; and</claim-text>
<claim-text>a control data buffer; and</claim-text>
<claim-text>wherein the controller generates priority data based on transmission channel bandwidth and on processor capacity of a wireless handset processor that changes the amount and sequence of data from the audio data buffer, the video data buffer, and the control data buffer that is stored in the transmission buffer.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the controller receives user control data and uses the user control data to generate the priority data.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein the controller receives user control data and uses the user control data to generate the priority data that changes the amount and sequence of data from the audio data buffer, the video data buffer, and the control data buffer that is stored in the transmission buffer.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref> further comprising priority data associated with each channel buffer, wherein audio data can have a lower priority than video data or control data.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A method for processing audio and video data for a wireless handset comprising:
<claim-text>generating priority data;</claim-text>
<claim-text>storing data in a plurality of channel buffers;</claim-text>
<claim-text>determining a number of channel buffers to receive data from based on the priority data;</claim-text>
<claim-text>determining an amount of data to be received from each channel buffer; and</claim-text>
<claim-text>storing the data from each selected channel buffer in a transmission buffer.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref> wherein storing data in the plurality of channel buffers further comprises storing the data in an audio data buffer.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref> wherein storing data in the plurality of channel buffers further comprises storing the data in a video data buffer.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref> wherein storing data in the plurality of channel buffers further comprises storing the data in a control data buffer.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref> wherein generating priority data comprises generating priority data based on transmission channel bandwidth.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref> wherein generating priority data comprises generating priority data based on processor capacity of a wireless handset processor.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. A method for processing audio and video data for a wireless handset comprising:
<claim-text>generating priority data;</claim-text>
<claim-text>storing data in one or more of an audio data buffer, a video data buffer, and a control data buffer;</claim-text>
<claim-text>determining a number of channel buffers to receive data from;</claim-text>
<claim-text>determining a sequence of data from the audio data buffer, the video data buffer, and the control data buffer that is to be stored in a transmission buffer based on the priority data; and</claim-text>
<claim-text>storing the data from each selected channel buffer in the transmission buffer.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref> further comprising:
<claim-text>receiving user-entered control data; and</claim-text>
<claim-text>generating the priority data from the user-entered control data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref> further comprising:
<claim-text>receiving user control data; and</claim-text>
<claim-text>generating priority data that changes the amount and sequence of data from the audio data buffer, the video data buffer, and the control data buffer that is stored in the transmission buffer from the user control data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref> wherein determining the sequence of data from the audio data buffer, the video data buffer, and the control data buffer that is to be stored in the transmission buffer based on the priority data further comprises allowing only null data from one of the audio data buffer, the video data buffer, or the control data buffer to be stored in the transmission buffer if the associated buffer is empty, priority is allocated only to the associated buffer, and data is present in the other buffers.</claim-text>
</claim>
</claims>
</us-patent-grant>
