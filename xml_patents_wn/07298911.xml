<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298911-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298911</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11432434</doc-number>
<date>20060512</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>7-276989</doc-number>
<date>19950929</date>
</priority-claim>
<priority-claim sequence="02" kind="national">
<country>JP</country>
<doc-number>7-276990</doc-number>
<date>19950929</date>
</priority-claim>
<priority-claim sequence="03" kind="national">
<country>JP</country>
<doc-number>7-281028</doc-number>
<date>19951027</date>
</priority-claim>
</priority-claims>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>36</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382233</main-classification>
<further-classification>382248</further-classification>
</classification-national>
<invention-title id="d0e97">Video coding and video decoding apparatus</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4616259</doc-number>
<kind>A</kind>
<name>Moran et al.</name>
<date>19861000</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>348510</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>4951140</doc-number>
<kind>A</kind>
<name>Ueno et al.</name>
<date>19900800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>3484131</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5032927</doc-number>
<kind>A</kind>
<name>Watanabe et al.</name>
<date>19910700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>386101</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5231491</doc-number>
<kind>A</kind>
<name>Holoch</name>
<date>19930700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>348469</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5233422</doc-number>
<kind>A</kind>
<name>Kondo et al.</name>
<date>19930800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>348558</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5274453</doc-number>
<kind>A</kind>
<name>Maeda</name>
<date>19931200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>348584</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>5303044</doc-number>
<kind>A</kind>
<name>Richards</name>
<date>19940400</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>348445</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5363213</doc-number>
<kind>A</kind>
<name>Coward et al.</name>
<date>19941100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382299</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5444492</doc-number>
<kind>A</kind>
<name>Kihara</name>
<date>19950800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>348445</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>5479264</doc-number>
<kind>A</kind>
<name>Ueda et al.</name>
<date>19951200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>386111</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>5528704</doc-number>
<kind>A</kind>
<name>Parker et al.</name>
<date>19960600</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382299</main-classification></classification-national>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>5638130</doc-number>
<kind>A</kind>
<name>Linzer</name>
<date>19970600</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>348445</main-classification></classification-national>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>5677727</doc-number>
<kind>A</kind>
<name>Gotoh et al.</name>
<date>19971000</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>348 1401</main-classification></classification-national>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>5801776</doc-number>
<kind>A</kind>
<name>Tamura et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>37524018</main-classification></classification-national>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>5883678</doc-number>
<kind>A</kind>
<name>Yamaguchi et al.</name>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>3483901</main-classification></classification-national>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>6130913</doc-number>
<kind>A</kind>
<name>Yamaguchi et al.</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>37524025</main-classification></classification-national>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>6292585</doc-number>
<kind>B1</kind>
<name>Yamaguchi et al.</name>
<date>20010900</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382232</main-classification></classification-national>
</citation>
<citation>
<nplcit num="00018">
<othercit>A.K. Jain, “Fundamentals of Digital Image Processing,” Prentice Hall, Chapter 11, Section 11.9, (pp. 548-551), 1989.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>9</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382232</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382233</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382238</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382243</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382248</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382239</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382236</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>37524018</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348 1401</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348 1408</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>386111</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>235456</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>235449</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>347248</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>347249</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>64</number-of-drawing-sheets>
<number-of-figures>126</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>10972718</doc-number>
<kind>00</kind>
<date>20041026</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7116827</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>11432434</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<division>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>10262873</doc-number>
<kind>00</kind>
<date>20021003</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>6879724</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>10972718</doc-number>
</document-id>
</child-doc>
</relation>
</division>
<division>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>09382771</doc-number>
<kind>00</kind>
<date>19990825</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>6546138</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>10262873</doc-number>
</document-id>
</child-doc>
</relation>
</division>
<division>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>09069851</doc-number>
<kind>00</kind>
<date>19980430</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>6154495</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>09382771</doc-number>
</document-id>
</child-doc>
</relation>
</division>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>08722943</doc-number>
<kind>00</kind>
<date>19960930</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>5883678</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>09069851</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20060204112</doc-number>
<kind>A1</kind>
<date>20060914</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Yamaguchi</last-name>
<first-name>Noboru</first-name>
<address>
<city>Yashio</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Watanabe</last-name>
<first-name>Toshiaki</first-name>
<address>
<city>Yokohama</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Ida</last-name>
<first-name>Takashi</first-name>
<address>
<city>Kawasaki</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="004" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Kuratate</last-name>
<first-name>Takaaki</first-name>
<address>
<city>Kobe</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Oblon, Spivak, McClelland, Maier &amp; Neustadt, P.C.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Kabushiki Kaisha Toshiba</orgname>
<role>03</role>
<address>
<city>Kawasaki-shi</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Do</last-name>
<first-name>Anh Hong</first-name>
<department>2624</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A video encoding apparatus is provided with a resolution converting section, an encoding section, and a transmitting section. The resolution converting section enlarges or reduces a binary picture which represents the shape of an object. The encoding section encodes a binary picture reduced by the resolution converting section. The reduction ratio used by the resolution converting section is encoded, and the transmitting section transmits this encoded reduction ratio along with encoded data on the binary picture. The amount of encoded data produced from the encoding section is controlled by changing the enlargement/reduction ratio used by the resolution converting section.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="92.79mm" wi="224.03mm" file="US07298911-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="220.47mm" wi="136.99mm" orientation="landscape" file="US07298911-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="270.76mm" wi="178.82mm" orientation="landscape" file="US07298911-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="260.18mm" wi="144.78mm" orientation="landscape" file="US07298911-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="233.00mm" wi="195.41mm" file="US07298911-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="246.89mm" wi="174.07mm" orientation="landscape" file="US07298911-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="246.21mm" wi="165.95mm" orientation="landscape" file="US07298911-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="238.08mm" wi="193.97mm" file="US07298911-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="240.20mm" wi="178.56mm" file="US07298911-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="209.30mm" wi="166.20mm" file="US07298911-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="265.18mm" wi="200.32mm" file="US07298911-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="246.55mm" wi="197.95mm" file="US07298911-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="236.73mm" wi="203.03mm" file="US07298911-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="236.73mm" wi="198.46mm" file="US07298911-20071120-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="248.16mm" wi="182.03mm" file="US07298911-20071120-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="258.83mm" wi="181.44mm" file="US07298911-20071120-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="259.33mm" wi="164.59mm" file="US07298911-20071120-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="212.43mm" wi="183.47mm" file="US07298911-20071120-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="249.09mm" wi="150.20mm" orientation="landscape" file="US07298911-20071120-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="253.58mm" wi="191.85mm" file="US07298911-20071120-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="214.12mm" wi="174.50mm" orientation="landscape" file="US07298911-20071120-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00021" num="00021">
<img id="EMI-D00021" he="233.85mm" wi="168.40mm" orientation="landscape" file="US07298911-20071120-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00022" num="00022">
<img id="EMI-D00022" he="305.14mm" wi="224.11mm" file="US07298911-20071120-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00023" num="00023">
<img id="EMI-D00023" he="197.19mm" wi="155.45mm" file="US07298911-20071120-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00024" num="00024">
<img id="EMI-D00024" he="249.34mm" wi="178.90mm" file="US07298911-20071120-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00025" num="00025">
<img id="EMI-D00025" he="233.68mm" wi="151.21mm" orientation="landscape" file="US07298911-20071120-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00026" num="00026">
<img id="EMI-D00026" he="275.34mm" wi="173.82mm" file="US07298911-20071120-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00027" num="00027">
<img id="EMI-D00027" he="260.10mm" wi="135.89mm" file="US07298911-20071120-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00028" num="00028">
<img id="EMI-D00028" he="203.88mm" wi="164.93mm" orientation="landscape" file="US07298911-20071120-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00029" num="00029">
<img id="EMI-D00029" he="260.35mm" wi="186.18mm" file="US07298911-20071120-D00029.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00030" num="00030">
<img id="EMI-D00030" he="225.13mm" wi="184.91mm" file="US07298911-20071120-D00030.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00031" num="00031">
<img id="EMI-D00031" he="237.15mm" wi="164.93mm" file="US07298911-20071120-D00031.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00032" num="00032">
<img id="EMI-D00032" he="218.69mm" wi="166.20mm" file="US07298911-20071120-D00032.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00033" num="00033">
<img id="EMI-D00033" he="237.74mm" wi="178.22mm" file="US07298911-20071120-D00033.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00034" num="00034">
<img id="EMI-D00034" he="249.26mm" wi="198.63mm" file="US07298911-20071120-D00034.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00035" num="00035">
<img id="EMI-D00035" he="171.96mm" wi="156.55mm" file="US07298911-20071120-D00035.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00036" num="00036">
<img id="EMI-D00036" he="212.34mm" wi="169.33mm" file="US07298911-20071120-D00036.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00037" num="00037">
<img id="EMI-D00037" he="255.61mm" wi="182.80mm" file="US07298911-20071120-D00037.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00038" num="00038">
<img id="EMI-D00038" he="247.82mm" wi="172.13mm" orientation="landscape" file="US07298911-20071120-D00038.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00039" num="00039">
<img id="EMI-D00039" he="257.81mm" wi="192.36mm" file="US07298911-20071120-D00039.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00040" num="00040">
<img id="EMI-D00040" he="279.57mm" wi="183.47mm" file="US07298911-20071120-D00040.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00041" num="00041">
<img id="EMI-D00041" he="257.47mm" wi="171.11mm" file="US07298911-20071120-D00041.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00042" num="00042">
<img id="EMI-D00042" he="245.87mm" wi="170.26mm" file="US07298911-20071120-D00042.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00043" num="00043">
<img id="EMI-D00043" he="259.67mm" wi="182.12mm" file="US07298911-20071120-D00043.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00044" num="00044">
<img id="EMI-D00044" he="208.79mm" wi="139.11mm" file="US07298911-20071120-D00044.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00045" num="00045">
<img id="EMI-D00045" he="257.30mm" wi="179.07mm" file="US07298911-20071120-D00045.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00046" num="00046">
<img id="EMI-D00046" he="266.78mm" wi="182.12mm" file="US07298911-20071120-D00046.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00047" num="00047">
<img id="EMI-D00047" he="253.75mm" wi="194.90mm" file="US07298911-20071120-D00047.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00048" num="00048">
<img id="EMI-D00048" he="232.41mm" wi="150.79mm" file="US07298911-20071120-D00048.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00049" num="00049">
<img id="EMI-D00049" he="255.61mm" wi="145.54mm" file="US07298911-20071120-D00049.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00050" num="00050">
<img id="EMI-D00050" he="277.37mm" wi="168.99mm" file="US07298911-20071120-D00050.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00051" num="00051">
<img id="EMI-D00051" he="250.36mm" wi="157.14mm" file="US07298911-20071120-D00051.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00052" num="00052">
<img id="EMI-D00052" he="210.14mm" wi="138.01mm" file="US07298911-20071120-D00052.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00053" num="00053">
<img id="EMI-D00053" he="230.04mm" wi="127.17mm" file="US07298911-20071120-D00053.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00054" num="00054">
<img id="EMI-D00054" he="233.76mm" wi="165.95mm" file="US07298911-20071120-D00054.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00055" num="00055">
<img id="EMI-D00055" he="271.78mm" wi="124.12mm" file="US07298911-20071120-D00055.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00056" num="00056">
<img id="EMI-D00056" he="223.01mm" wi="168.66mm" file="US07298911-20071120-D00056.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00057" num="00057">
<img id="EMI-D00057" he="272.88mm" wi="182.88mm" file="US07298911-20071120-D00057.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00058" num="00058">
<img id="EMI-D00058" he="241.47mm" wi="193.97mm" orientation="landscape" file="US07298911-20071120-D00058.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00059" num="00059">
<img id="EMI-D00059" he="259.33mm" wi="179.15mm" file="US07298911-20071120-D00059.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00060" num="00060">
<img id="EMI-D00060" he="231.06mm" wi="182.88mm" file="US07298911-20071120-D00060.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00061" num="00061">
<img id="EMI-D00061" he="219.88mm" wi="166.62mm" file="US07298911-20071120-D00061.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00062" num="00062">
<img id="EMI-D00062" he="258.32mm" wi="165.95mm" file="US07298911-20071120-D00062.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00063" num="00063">
<img id="EMI-D00063" he="219.63mm" wi="160.02mm" file="US07298911-20071120-D00063.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00064" num="00064">
<img id="EMI-D00064" he="243.50mm" wi="173.74mm" orientation="landscape" file="US07298911-20071120-D00064.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading>
<p id="p-0002" num="0001">This application is a continuation of U.S. application Ser. No. 10/972,718, filed on Oct. 26, 2004, now U.S. Pat. No. 7,116,827 which is a divisional of application Ser. No. 10/262,873, filed on Oct. 3, 2002, now U.S. Pat. No. 6,879,724 which is a divisional of application Ser. No. 09/382,771, filed on Aug. 25, 1999 (now U.S. Pat. No. 6,546,138), which is a divisional of application Ser. No. 09/069,851, filed on Apr. 30, 1998 (now U.S. Pat. No. 6,154,495), which is a continuation of Ser. No. 08/722,943, filed on Sept. 30, 1996 (now U.S. Pat. No. 5,883,678), the contents of each of which is incorporated herein by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to a video coding apparatus and a video decoding apparatus for encoding a video signal at a high efficiency, transmitting and storing the coded signal, and decoding the coded signal.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">Generally, a video signal is compression-encoded before being transmitted or stored because the signal has an enormous amount of information. To encode a video signal at a high efficiency, a picture or an image of a frame is divided into a plurality of blocks in units of a predetermined number of pixels. Orthogonal transformation is performed for each block to separate the special frequency of a picture into frequency components. Each frequency component is obtained as a transform coefficient and encoded.</p>
<p id="p-0007" num="0006">As one video coding system, a video coding system belonging to a category called mid-level coding is proposed in J. Y. A. Wang et. al., “Applying Mid-level Vision Techniques for Video Data Compression and Manipulation”, M.I.T. Media Lab. Tech. Report No. 263, February 1994.</p>
<p id="p-0008" num="0007">In this system, when a picture consists of a background and an object, these background and object are separately encoded.</p>
<p id="p-0009" num="0008">To separately encode the background and the object, an alpha-map signal (indicating the background by black pixels and the object by white pixels) which is subsidiary video information representing the shape of the object and the position of the object in the frame is necessary. An alpha-map signal of the background can be uniquely obtained from the alpha-map signal of the object.</p>
<p id="p-0010" num="0009">As methods of efficiently encoding this alpha-map signal, a binary video encoding method (e.g., MMR (Modified Modified READ) encoding) or a line figure encoding method (e.g., chain encoding) is used.</p>
<p id="p-0011" num="0010">Furthermore, to reduce the amount of codes of an alpha-map, it is possible to use a method (J. Ostermann, “Object-based analysis-synthesis coding based on the source model of moving rigid 3D objects”, Signal Process. Image Comm. Vol. 6, No. 2, pp. 143-161, 1994) by which the contour lines of a shape are approximated by polygons and smoothed by spline curves or a method (Japanese Patent Application No. 5-297133) by which an alpha-map is encoded by reducing it and approximated by curves when it is enlarged.</p>
<p id="p-0012" num="0011">In the above system of separately encoding the background and the object in the frame, the amount of codes is increased by the amount of alpha-maps compared to the conventional coding method of encoding a whole frame at once. This increase in the alpha-map code amount decreases the coding efficiency.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0013" num="0012">It is an object of the present invention to provide a video coding apparatus and a video decoding apparatus capable of efficiently encoding and decoding alpha-map information which is subsidiary video information representing the shape of an object and the position of the object in the frame.</p>
<p id="p-0014" num="0013">According to the present invention, there is provided a binary picture encoding apparatus comprising a division section for dividing a rectangular region containing an object into blocks, each of the blocks having M×N pixels (M: the number of pixels included in a row array, N: the number of pixels included in a column array), an encoder for encoding the blocks of the rectangular region by a predetermined rule by applying relative address coding to at least part of the blocks, a storage for storing reproduction values corresponding to a region which is near each of the blocks, and a decoder for detecting pixels having different pixel values, the pixels having different pixel values being reduced in number by detecting the pixels together with reproduction values corresponding to the region near each of the blocks.</p>
<p id="p-0015" num="0014">According to the present invention, there is provided a binary picture decoding apparatus comprising a decoder for decoding encoded data, which is obtained by sequentially encoding blocks of an object-included rectangular region by a predetermined rule, each of the blocks having M×N pixels (M: the number of pixels included in a row array, N: the number of pixels included in a column array), a storage for storing reproduction values corresponding to a region which is near each of the blocks, a detector for detecting pixels having different pixel values, and a decoder for decoding relative addresses associated with the pixels having different pixel values, the pixels having different pixel values being detected together with reproduction values corresponding to the region near each of the blocks.</p>
<p id="p-0016" num="0015">Additional objects and advantages of the invention will be set forth in the description which follows, and in part will be obvious from the description, or may be learned by practice of the invention. The objects and advantages of the invention may be realized and obtained by means of the instrumentalities and combinations particularly pointed out in the appended claims.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0017" num="0016">The accompanying drawings, which are incorporated in and constitute a part of the specification, illustrate presently preferred embodiments of the invention and, together with the general description given above and the detailed description of the preferred embodiments given below, serve to explain the principles of the invention.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 1</figref> is a view for explaining the present invention, which illustrates an example of a video transmission system to which a video coding apparatus and a video decoding apparatus of the present invention are applied;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 2</figref> is a view for explaining the present invention, which is a block diagram showing a schematic arrangement of the whole coding apparatus of the present invention;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 3</figref> is a view for explaining the present invention, which is a block diagram showing a schematic arrangement of the whole decoding apparatus of the present invention;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram showing the arrangement of a conventional alpha-map encoder;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIGS. 5A and 5B</figref> are views showing an example of a binary picture resolution conversion circuit;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 6</figref> is a view for explaining the present invention, which illustrates an encoder of the first embodiment of the present invention;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 7</figref> is a view for explaining a conventional decoder;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 8</figref> is a view for explaining the present invention, which illustrates a decoder of the first embodiment of the present invention;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIGS. 9A to 9D</figref> are views for explaining MMR two-dimensional coding;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 10</figref> is a view showing examples of variable-length codes and examples of MMR codes used in the present invention;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 11</figref> is a flow chart for explaining an MMR coding procedure;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIGS. 12A to 12C</figref> are views for explaining the MMR coding procedure;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIGS. 13A to 13D</figref> are views for explaining the present invention, which illustrate a procedure of encoding in raster order according to the method of the present invention;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIGS. 14A and 14B</figref> are views for explaining the present invention, which illustrate an example requiring a vertical pass mode of the method of the present invention;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIGS. 15A to 15C</figref> are views for explaining the present invention, which illustrate the first example of the vertical pass mode;</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIGS. 16A to 16C</figref> are views for explaining the present invention, which illustrate the second example of the vertical pass mode;</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 17</figref> is a view for explaining the present invention, which is a flow chart for explaining a coding procedure when encoding is performed in raster order;</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 18</figref> is a view for explaining the present invention, which is a block diagram of a coding/decoding apparatus using an interframe reference line;</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIGS. 19A and 19B</figref> are views for explaining the present invention, which illustrate intraframe and interframe reference lines;</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 20</figref> is a view for explaining the present invention, which is a flow chart for explaining a coding procedure using an interframe reference line;</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 21</figref> is a view for explaining the present invention, which illustrates switching between coding modes of the present invention;</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 22</figref> is a view for explaining the present invention, which illustrates block line skip of the present invention;</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 23</figref> is a view for explaining the present invention, which is a flow chart for explaining a coding procedure using a NOT CODED mode of the present invention;</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIGS. 24A and 24B</figref> are views for explaining the present invention, which illustrate a case where a plurality of reference lines are used in the present invention;</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 25</figref> is a view for explaining the present invention, which is a flow chart of a coding procedure when two reference lines are used in the present invention;</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIGS. 26A and 26B</figref> are views for explaining the present invention, which illustrate multivalue alpha maps to be applied to the present invention;</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIGS. 27A and 27B</figref> are views for explaining the present invention, which are block diagrams for explaining arrangements to which the multivalue alpha-map coding method of the present invention is applied;</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 28</figref> is a view for explaining the present invention, which illustrates the second embodiment of the present invention;</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIGS. 29A and 29B</figref> are views for explaining the present invention, which illustrate the third embodiment of the present invention;</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIGS. 30A and 30B</figref> are views for explaining the present invention, which are block diagrams for explaining the third embodiment of the present invention;</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIGS. 31A to 31E</figref> are views for explaining alpha maps;</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. 32</figref> is a view for explaining another example of the present invention;</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 33</figref> is a view for explaining the present invention, which illustrate the fourth embodiment of the present invention;</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 34</figref> is a view for explaining the present invention, which is a block diagram showing an example of the arrangement of an apparatus for realizing the fourth embodiment of the present invention;</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. 35</figref> is a view for explaining the present invention, which illustrates macro blocks MB;</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 36</figref> is a view for explaining the fifth embodiment of the present invention;</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIGS. 37A and 37B</figref> are views for explaining the present invention, which illustrate the fifth embodiment of the present invention;</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIGS. 38A to 38D</figref> are views for explaining the present invention, which illustrate the sixth embodiment of the present invention;</p>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIGS. 39A to 39C</figref> are views for explaining the present invention, which illustrate the seventh embodiment of the present invention;</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIGS. 40A and 40B</figref> are views for explaining the present invention, which illustrate the eighth embodiment of the present invention; and</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIGS. 41A to 41C</figref> are views for explaining one application of the present invention;</p>
<p id="p-0059" num="0058"><figref idref="DRAWINGS">FIGS. 42A to 42C</figref> are views showing an example of MV detection and encoding of an alpha map, so as to explain the eighth embodiment of the present invention;</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIGS. 43A to 43C</figref> are views showing an example in which the block attribute of an alpha map is decomposed into bit planes, so as to explain the ninth embodiment of the present invention;</p>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. 44</figref> is a view showing an example in which the bit planes of the block attribute of the alpha map are encoded, so as to explain the ninth embodiment of the present invention;</p>
<p id="p-0062" num="0061"><figref idref="DRAWINGS">FIGS. 45A and 45B</figref> are views showing examples of the attribute information of a certain macro block at time n and at time n−1so as to explain the 10th embodiment of the present invention (views showing the correlation of the block attributes between the frames of the alpha map);</p>
<p id="p-0063" num="0062"><figref idref="DRAWINGS">FIGS. 46A and 46B</figref> are views showing an example of changing the size of the label at time n−1 in correspondence with the size of the label at time n, so as to explain the 10th embodiment of the present invention;</p>
<p id="p-0064" num="0063"><figref idref="DRAWINGS">FIGS. 47A and 47B</figref> are views showing interframe encoding and intraframe encoding, so as to explain the 10th embodiment of the present invention;</p>
<p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. 48</figref> is a view showing an example in which encoding is performed in units of lines, so as to explain the 10th embodiment of the present invention;</p>
<p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. 49</figref> is a view showing an example of a variable length code table for encoding each label, so as to explain the 10th embodiment of the present invention;</p>
<p id="p-0067" num="0066"><figref idref="DRAWINGS">FIGS. 50A and 50B</figref> are block diagram showing examples of the arrangements of a decoding apparatus and a coding apparatus of the present invention, respectively, so as to explain the 10th embodiment of the present invention;</p>
<p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. 51</figref> is a block diagram showing a detailed example of a coding apparatus of the present invention using vector quantization, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. 52</figref> is a block diagram showing a detailed example of a decoding apparatus of the present invention using vector quantization, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. 53</figref> is a block diagram showing the first example of an index table generator <b>1609</b> used in the system of the present invention, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. 54</figref> is a block diagram showing the second example of the index table generator <b>1609</b> used in the system of the present invention, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. 55</figref> is a block diagram showing the third example of the index table generator <b>1609</b> used in the system of the present invention, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. 56</figref> is a block diagram showing a detailed example of a type determining device <b>1616</b> used in the system of the present invention, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. 57</figref> is a flow chart showing the flow of the process of the coding apparatus of the 11th embodiment, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. 58</figref> is a flow chart showing the flow of the process of the decoding apparatus of the 11th embodiment shown in <figref idref="DRAWINGS">FIG. 52</figref>, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. 59</figref> is a view showing an example of an alpha map so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. 60</figref> is a view showing an example of an intermediate encoded/decoded state of the alpha map so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0078" num="0077"><figref idref="DRAWINGS">FIG. 61</figref> is a view showing a reference portion so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. 62</figref> is a view for explaining a reference portion obtained upon redividing a block, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0080" num="0079"><figref idref="DRAWINGS">FIG. 63</figref> is a view for explaining “RT” and “RL”, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0081" num="0080"><figref idref="DRAWINGS">FIGS. 64A and 64B</figref> are views for explaining estimation of the directions of boundary lines, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0082" num="0081"><figref idref="DRAWINGS">FIGS. 65A and 65B</figref> are views for explaining an example of calculation of an evaluation value used in the present invention, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0083" num="0082"><figref idref="DRAWINGS">FIG. 66</figref> is a view for explaining a block for determining an error allowance condition, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0084" num="0083"><figref idref="DRAWINGS">FIGS. 67A and 67B</figref> are flow charts showing coding shemes of the present invention so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. 68</figref> is a flow chart showing the processing algorithm of the type determining device <b>1616</b> used in the present invention, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0086" num="0085"><figref idref="DRAWINGS">FIG. 69</figref> is a view for explaining an algorithm used by a vector quantizer <b>1607</b> shown in <figref idref="DRAWINGS">FIG. 51</figref>, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0087" num="0086"><figref idref="DRAWINGS">FIGS. 70A to 70D</figref> are views showing examples of index tables using a type M, and “RT” and “RL” used in the present invention, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0088" num="0087"><figref idref="DRAWINGS">FIGS. 71A to 71C</figref> are block diagrams showing coding apparatuses of the present invention and switching table of the switch section thereof, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0089" num="0088"><figref idref="DRAWINGS">FIGS. 72A and 72B</figref> are block diagrams showing decoding apparatuses for decoding a code generated by the coding apparatuses shown in <figref idref="DRAWINGS">FIGS. 71A and 71B</figref>, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0090" num="0089"><figref idref="DRAWINGS">FIG. 73</figref> is a view showing an example of a VLC table used in the present invention, so as to explain the 11th embodiment of the present invention;</p>
<p id="p-0091" num="0090"><figref idref="DRAWINGS">FIGS. 74A and 74B</figref> are views respectively showing the relationship between changing pixels in encoding in units of blocks and a reference area for detecting a changing pixel b<b>1</b>, so as to explain the 11th embodiment of the present invention (views showing the relationship between changing pixels in block-based encoding and a reference area, respectively); and</p>
<p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. 75</figref> is a flow chart showing block-based encoding by MMR, so as to explain the 11th embodiment of the present invention; and</p>
<p id="p-0093" num="0092"><figref idref="DRAWINGS">FIG. 76</figref> shows an example of the alpha-map decoder shown in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0094" num="0093">The present invention relates to a video coding apparatus and a video decoding apparatus used in transmitting/receiving apparatuses (A and B in <figref idref="DRAWINGS">FIG. 1</figref>) in a video transmission system shown in <figref idref="DRAWINGS">FIG. 1</figref>. These video coding and decoding apparatuses can perform high-efficiency compression encoding and decoding for an alpha-map signal.</p>
<p id="p-0095" num="0094">In the present invention, the coding apparatus encodes an alpha-map signal while reducing the resolution and multiplexes the obtained codes together with the reduction ratio information, thereby forming an alpha-map signal to be transmitted or stored. Consequently, an alpha-map signal can be efficiently encoded.</p>
<p id="p-0096" num="0095">Also, the decoding apparatus of the present invention decodes this efficiently encoded alpha-map signal as follows. That is, the decoding apparatus separates the signal into the alpha-map coded components and the reduction ratio information, decodes the alpha-map coded components, and enlarges the decoded signal to the original resolution in accordance with the reduction ratio information, thereby restoring the alpha-map signal of the original size. This allows easy decoding of a coded picture using an alpha map.</p>
<p id="p-0097" num="0096"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of the video coding apparatus according to the present invention. As shown in <figref idref="DRAWINGS">FIG. 2</figref>, the video coding apparatus of the present invention comprises a subtracter <b>100</b>, a motion compensation prediction circuit <b>110</b>, an orthogonal transform circuit <b>120</b>, a quantizer <b>130</b>, a variable length encoder <b>140</b>, an inverse quantizer <b>150</b>, an inverse orthogonal transform circuit <b>160</b>, an adder <b>170</b>, a multiplexer <b>180</b>, and an alpha-map encoder <b>200</b>.</p>
<p id="p-0098" num="0097">The alpha-map encoder <b>200</b> encodes an input alpha map and outputs the encoded signal as an alpha-map signal to the multiplexer <b>180</b>. The encoder <b>200</b> also has a function of decoding an alpha-map signal and outputting the decoded signal as a local decoded signal.</p>
<p id="p-0099" num="0098">This alpha-map encoder <b>200</b> most particularly has a function of performing, when encoding an input alpha-map signal, processing of reducing the resolution at a given reduction ratio (magnification), encoding the alpha-map signal subjected to this resolution reduction processing, multiplexing the encoded signal and the reduction ratio information (magnification information), and outputting the multiplexed signal as an alpha-map output signal to the multiplexer <b>180</b>. As the local decoded signal, a signal obtained by performing processing by which the signal subjected to the resolution reduction processing is returned to the original resolution is used.</p>
<p id="p-0100" num="0099">The subtracter <b>100</b> calculates an error signal of a motion compensation prediction signal supplied from the motion compensation prediction circuit <b>110</b> and an input video signal. The orthogonal transform circuit <b>120</b> transforms the error signal supplied from the subtracter <b>100</b> into an orthogonal transform coefficient in accordance with the alpha-map information and outputs the coefficient.</p>
<p id="p-0101" num="0100">The quantizer <b>130</b> quantizes the orthogonal transform coefficient obtained from the orthogonal transform circuit <b>120</b>. The variable length coder <b>140</b> encodes the output from the quantizer <b>130</b> and outputs the encoded signal. The multiplexer <b>180</b> multiplexes the output encoded signal from the variable length coder <b>140</b> and the alpha-map signal, together with side information such as motion vector information, and outputs the multiplexed signal as a bit stream.</p>
<p id="p-0102" num="0101">The inverse quantizer <b>150</b> inversely quantizes the output from the quantizer <b>130</b>. The inverse orthogonal transform circuit <b>160</b> performs inverse orthogonal transformation for the output from the inverse quantizer <b>150</b> on the basis of the alpha-map signal. The adder <b>170</b> adds the output from the inverse orthogonal transform circuit <b>160</b> and the prediction signal (motion compensation prediction signal) supplied from the motion compensation prediction circuit <b>110</b> and outputs the sum to the subtracter <b>100</b>.</p>
<p id="p-0103" num="0102">The motion compensation prediction circuit <b>110</b> has a frame memory and operates on the basis of the local decoded signal supplied from the alpha-map encoder <b>200</b>, thereby storing signals of an object region and signals of a background region. The motion compensation prediction circuit <b>110</b> predicts a motion compensation value from the stored object-region pictures and outputs as a predictive value, and also predicts a motion compensation value from the stored background-region pictures and outputs as a predictive value.</p>
<p id="p-0104" num="0103">This apparatus with the above configuration is applied with a video signal and an alpha-map of the video signal.</p>
<p id="p-0105" num="0104">The alpha-map encoder <b>200</b> encodes the input alpha-map signal through a line <b>20</b> while reducing the signal at a designated resolution reduction ratio (magnification), multiplexes the encoded alpha-map signal together with the resolution reduction ratio information (magnification information), and outputs the multiplexed signal through a line <b>30</b>. Also, the alpha-map encoder <b>200</b> outputs a local decoded signal, which is obtained by decoding the encoded alpha-map signal so as to restore the original resolution, to the orthogonal transform circuit <b>120</b>, the inverse orthogonal transform circuit <b>160</b>, and the motion compensation prediction circuit <b>110</b> through a line <b>40</b>.</p>
<p id="p-0106" num="0105">When encoding an input alpha-map, this alpha-map encoder <b>200</b> performs processing of reducing the resolution at a given reduction ratio, encodes the alpha-map signal subjected to the resolution reduction processing, multiplexes the encoded signal and the reduction ratio information, and outputs the multiplexed signal as an alpha-map signal to the multiplexer <b>180</b>. This allows efficient encoding of an alpha-map signal.</p>
<p id="p-0107" num="0106">As the local decoded signal, a signal obtained by performing processing of restoring the original resolution of the signal subjected to the resolution reduction processing is used. This local decoded signal is output to the orthogonal transform circuit <b>120</b> and the inverse orthogonal transform circuit <b>160</b> through the line <b>40</b>. This permits the orthogonal transform circuit <b>120</b> and the inverse orthogonal transform circuit <b>160</b> to perform the processing by using the alpha-map of the original size.</p>
<p id="p-0108" num="0107">A video signal is divided into blocks each having a predetermined pixel size (N×N pixels) and supplied in the order of block positions to the subtracter <b>100</b> through a line <b>10</b>. The subtracter <b>100</b> calculates an error signal of this input (video signal) and the prediction signal (the output motion compensation prediction signal from the object prediction circuit <b>110</b>) and supplies the error signal to the orthogonal transform circuit <b>120</b>. The orthogonal transform circuit <b>120</b> transforms the supplied error signal into an orthogonal transform coefficient in accordance with the alpha-map information supplied through the line <b>40</b> and supplies the coefficient to the quantizer <b>130</b> where the coefficient is quantized. The transform coefficient quantized by the quantizer <b>130</b> is encoded by the variable length coder <b>140</b> and also supplied to the inverse quantizer <b>150</b>. The transform coefficient is inversely quantized by the inverse quantizer <b>150</b> and inversely transformed by the inverse orthogonal transform circuit <b>160</b>.</p>
<p id="p-0109" num="0108">The adder <b>170</b> adds the resulting signal and the motion compensation predictive value supplied from the motion compensation prediction circuit <b>110</b>. The output local decoded picture from the adder <b>170</b> is stored in the frame memory of the motion compensation prediction circuit <b>110</b>. On the basis of the local decoded signal supplied from the alpha-map encoder <b>200</b>, the motion compensation prediction circuit <b>110</b> supplies to the subtracter <b>100</b> a motion compensation predictive value of an object at a timing at which a block in an object region is processed and a motion compensation predictive value of a background portion at other timings. That is, on the basis of the local decoded signal of the alpha-map signal, the motion compensation prediction circuit <b>110</b> checks which of a video signal of a portion corresponding to a block in the object or a video signal of a portion corresponding to a block in the background is currently input to the subtracter <b>100</b>. The motion compensation prediction circuit <b>110</b> supplies to the subtracter <b>100</b> the object motion compensation prediction signal in a period during which a video signal of a portion corresponding to a block in the object is input and the background motion compensation prediction signal in a period during which a video signal of a portion corresponding to a block in the background is input.</p>
<p id="p-0110" num="0109">As a consequence, the subtracter <b>100</b> calculates the difference between the input video signal and the prediction signal corresponding to a region in the picture. If the input picture is a region corresponding to the object, an error signal with respect to the predictive value in the corresponding position of the object is calculated. If the input picture is a picture in a region of the background, an error signal with respect to the predictive value corresponding to that background position is calculated. The calculated error signal is supplied to the orthogonal transform circuit <b>120</b>. The orthogonal transform circuit <b>120</b> transforms the supplied error signal into an orthogonal transform coefficient in accordance with the alpha-map information supplied through the line <b>40</b> and supplies the coefficient to the quantizer 130 where the coefficient is quantized.</p>
<p id="p-0111" num="0110">The transform coefficient quantized by the quantizer <b>130</b> is encoded by the variable length coder <b>140</b> and supplied to the inverse quantizer <b>150</b>. The transform coefficient is inversely quantized by the inverse quantizer <b>150</b>, inversely transformed by the inverse orthogonal transform circuit <b>160</b>, and supplied to the adder <b>170</b>. The output signal from the inverse orthogonal transform circuit <b>160</b> is added to the predictive value supplied to the adder <b>170</b> via a predictive value switching circuit <b>500</b>.</p>
<p id="p-0112" num="0111">The local decoded video signal output from the adder <b>170</b> is supplied to the motion compensation prediction circuit <b>110</b>. On the basis of the local decoded signal of the alpha-map signal, the motion compensation prediction circuit <b>110</b> checks which of a signal corresponding to a block in the object or a signal corresponding to a block in the background is currently output from the adder <b>170</b>. If a signal corresponding to a block in the object is being output, the circuit <b>110</b> operates so as to store the signal in a frame memory for the object. If a signal corresponding to a block in the background is being output, the circuit <b>110</b> operates so as to store the signal in a memory for the background. Consequently, a picture consisting of only object pictures and a picture consisting of only background pictures are stored in the respective memories. The motion compensation prediction circuit <b>110</b> can calculate a predictive value by using an object picture and a predictive value of a background picture by using a picture in the background.</p>
<p id="p-0113" num="0112">As described above, the alpha-map encoder <b>200</b> encodes an input alpha map and supplies the encoded alpha-map signal to the multiplexer <b>180</b> through the line <b>30</b>.</p>
<p id="p-0114" num="0113">The multiplexer <b>180</b> is also supplied with the output transform coefficient from the variable length coder <b>140</b> through the line <b>40</b>. The multiplexer <b>180</b> multiplexes the coded values of these alpha-map signal and transform coefficient thus supplied, together with side information such as motion vector information, and outputs the multiplexed signal through the line <b>50</b>. The output signal is a coded bit stream as the final output of this video coding apparatus.</p>
<p id="p-0115" num="0114">The foregoing are the configuration and the operation of the coding apparatus. To obtain an error signal of a picture, motion compensation prediction is performed by using an object picture and a background picture. To this end, the apparatus checks in accordance with an alpha map whether the current block position of a picture being processed is a position in an object region or a position in a background region. If the current block position of the picture being processed is an object region position, the apparatus calculates the error by using a predictive value obtained from the object picture. If the current block position of the picture being processed is a background region position, the apparatus calculates the error by using a predictive value obtained from the background picture.</p>
<p id="p-0116" num="0115">In performing predicting operations for the object and the background, the motion compensation prediction circuit is made hold pictures in the respective corresponding regions, from a picture obtained from the error, in accordance with the alpha map, and these pictures are used in the respective predicting operations. Accordingly, optimum motion compensation prediction can be performed for each of the object and the background. This makes high-quality picture compression encoding and decoding feasible.</p>
<p id="p-0117" num="0116">Also, in the present invention, an alpha map is encoded while its resolution is reduced, and the obtained codes and the reduction ratio information are together multiplexed to obtain an alpha-map signal to be transmitted or stored. Therefore, the alpha-map signal can be efficiently encoded and this allows efficient encoding of the shape information of the object.</p>
<p id="p-0118" num="0117">In reproducing the alpha-map signal, the alpha-map coded components and the reduction ratio information are separated. The alpha-map coded components are decoded and enlarged to the original resolution in accordance with the reduction ratio information. Consequently, the alpha map of the original size can be restored and this allows easy decoding of a coded picture using an alpha map.</p>
<p id="p-0119" num="0118"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram showing the decoding apparatus of the present invention. As shown in <figref idref="DRAWINGS">FIG. 3</figref>, this decoding apparatus comprises a demultiplexer <b>300</b>, a variable length decoder <b>310</b>, an inverse quantizer <b>320</b>, an inverse orthogonal transform circuit <b>330</b>, an adder <b>340</b>, a motion compensation prediction circuit <b>350</b>, and an alpha-map decoder <b>400</b>.</p>
<p id="p-0120" num="0119">The demultiplexer <b>300</b> separates an input coded bit stream into an alpha-map signal and a coded signal of a picture. The alpha-map decoder <b>400</b> reconstructs an alpha map by decoding the alpha-map signal separated by the demultiplexer <b>300</b>. In this embodiment, the alpha-map decoder <b>400</b> has a function of separating a supplied alpha-map signal into alpha-map components and reduction ratio information (magnification information), decoding the alpha-map components, enlarging the resolution on the basis of the reduction ratio information, and restoring the alpha map with the original resolution.</p>
<p id="p-0121" num="0120">The variable length decoder <b>310</b> decodes the coded signal of a picture separated by the demultiplexer <b>300</b>. The inverse quantizer <b>320</b> returns the decoded signal to the original coefficient by performing inverse quantization. The inverse orthogonal transform circuit <b>330</b> returns the coefficient to a predictive error signal by performing inverse orthogonal transformation in accordance with the alpha map. The adder <b>340</b> adds to this predictive error signal a motion compensation predictive value from the motion compensation prediction circuit <b>350</b> and outputs the sum as a reproduction video signal. This reproduction video signal is the final output from the decoding apparatus.</p>
<p id="p-0122" num="0121">The motion compensation prediction circuit <b>350</b> stores the reproduction video signal output from the adder <b>340</b> into a frame memory in accordance with the alpha map, thereby obtaining an object picture and a background picture. In addition, the motion compensation prediction circuit <b>350</b> obtains an object motion compensation prediction signal and a background motion compensation prediction signal from these stored pictures.</p>
<p id="p-0123" num="0122">In the decoding apparatus with the above configuration, a coded bit stream is supplied to the demultiplexer <b>300</b> through a line <b>70</b> and separated into codes pertaining to an alpha-map signal and variable length codes of a video signal by separating individual information. The codes relating to an alpha-map signal are supplied to the alpha-map decoder <b>400</b> through a line <b>80</b>. The variable length codes of a video signal are supplied to the variable length decoder <b>310</b>. The alpha-map decoder <b>400</b> decodes the codes pertaining to an alpha-map signal into the alpha-map signal and outputs the signal to the inverse orthogonal transform circuit <b>330</b> and the motion compensation prediction circuit <b>350</b>. That is, the alpha-map decoder <b>400</b> separates the supplied alpha-map signal into the alpha-map components and the reduction ratio information and decodes the alpha-map components. Also, the decoder <b>400</b> restores the alpha map with the original resolution by enlarging the resolution of the decoded signal on the basis of the reduction ratio information and outputs the alpha map to the inverse orthogonal transform circuit <b>330</b> and the motion compensation prediction circuit <b>350</b>.</p>
<p id="p-0124" num="0123">Meanwhile, the variable length decoder <b>310</b> decodes the codes supplied from the demultiplexer <b>300</b> and supplies the decoded codes to the inverse quantizer <b>320</b> where the codes are inversely quantized. The transform coefficient obtained by the inverse quantization is inversely transformed by the inverse orthogonal transform circuit <b>330</b>, in accordance with an alpha map supplied through a line <b>90</b>, and supplied to the adder <b>340</b>. The adder <b>340</b> adds the signal subjected to the inverse orthogonal transform by the inverse orthogonal transform circuit <b>330</b> and the motion compensation prediction signal supplied from the motion compensation prediction circuit <b>350</b>, thereby obtaining a reconstructed picture.</p>
<p id="p-0125" num="0124">In the present invention, the coding apparatus encodes an alpha map while reducing the resolution of the map and multiplexes the obtained codes together with the reduction ratio information to form an alpha-map signal to be transmitted or stored. Accordingly, an alpha-map signal can be efficiently encoded and this allows efficient encoding of the shape information of an object.</p>
<p id="p-0126" num="0125">Also, when decoding the alpha-map signal thus compression-encoded with a high efficiency, the decoding apparatus separates the signal into the alpha-map coded components and the reduction ratio information, decodes the alpha-map coded components, and enlarges the decoded signal to the original resolution in accordance with the reduction ratio information. Consequently, the alpha-map of the original size can be restored and this allows easy decoding of a coded picture using an alpha map.</p>
<p id="p-0127" num="0126">The important parts in the present invention are the alpha-map encoder <b>200</b> in the coding apparatus and the alpha-map decoder <b>400</b> in the decoding apparatus, and the characteristic feature of the invention resides in that these circuits are given a function of reducing and enlarging the resolution at a desired magnification. Therefore, this function will be described in detail below.</p>
<p id="p-0128" num="0127">That is, the main components of the present invention are the alpha-map encoder <b>200</b> and the alpha-map decoder <b>400</b>. The rest of the arrangement can be accomplished by using the technique of a system of coding a picture with an arbitrary shape described in Japanese Patent Application No. 7-97073 already filed by the present inventors and so a detailed description thereof will be omitted.</p>
<p id="p-0129" num="0128">A practical configuration of the alpha-map encoder <b>200</b> as one major element of the present invention will be described below with reference to <figref idref="DRAWINGS">FIGS. 4 to 6</figref>. A practical configuration of the alpha-map decoder <b>400</b> as another major element of the present invention will be described below with reference to <figref idref="DRAWINGS">FIGS. 7 and 8</figref>.</p>
<p id="p-0130" num="0129"><figref idref="DRAWINGS">FIG. 4</figref> shows a method proposed in Japanese Patent Application No. 5-297133. In the alpha-map encoder <b>200</b>, a resolution conversion circuit <b>210</b> as a means for converting the resolution reduces an alpha-map signal supplied through the line <b>20</b>, thereby decreasing the number of samples to be encoded. The reduced signal is supplied to a binary picture encoder <b>220</b> through a line <b>21</b> and encoded by MMR or chain encoding. The encoded signal is supplied to the multiplexer <b>180</b> through the line <b>30</b>.</p>
<p id="p-0131" num="0130">The alpha-map signal reduced by the resolution conversion circuit <b>210</b> is also supplied to a resolution conversion circuit <b>230</b> through the line <b>21</b>. The signal is enlarged to the number of samples of the original signal supplied to the alpha-map encoder <b>200</b> through the line <b>20</b>. The enlarged signal is output through the line <b>40</b>.</p>
<p id="p-0132" num="0131"><figref idref="DRAWINGS">FIGS. 5A and 5B</figref> illustrate an example of the reduction/enlargement conversion by the resolution conversion circuits <b>210</b> and <b>230</b>. This conversion will be described below on the basis of literature, Ogami ed.,: “Image Processing Handbook”, p. 630, Shokodo.</p>
<p id="p-0133" num="0132">In <figref idref="DRAWINGS">FIG. 5A</figref>, Pex is a pixel position after the conversion and indicates a real-number pixel position as shown. Accordingly, an input signal is divided into eight regions on the basis of the distances of the signal to integral-number pixel positions A, B, C, and D, and a pixel value IP of Pex is calculated from pixel values IA to ID of A to D by using logical expressions shown in <figref idref="DRAWINGS">FIG. 5B</figref>.</p>
<p id="p-0134" num="0133">The purpose of the invention shown in <figref idref="DRAWINGS">FIG. 4</figref> is to reduce the amount of codes while permitting an error produced when an alpha map is reduced or enlarged. If the reduction/enlargement ratio is fixed, however, it is impossible to trade off the error of an alpha-map signal for the amount of codes.</p>
<p id="p-0135" num="0134"><figref idref="DRAWINGS">FIG. 6</figref> shows the configuration of the alpha-map encoder <b>200</b> of the present invention. As shown in <figref idref="DRAWINGS">FIG. 6</figref>, the alpha-map encoder <b>200</b> of the present invention comprises resolution conversion circuits <b>210</b> and <b>230</b>, a binary picture encoder <b>220</b>, and a multiplexer <b>240</b>.</p>
<p id="p-0136" num="0135">The resolution conversion circuit <b>210</b> is a conversion circuit for resolution reduction conversion and encodes an alpha map at a reduction ratio corresponding to a given enlargement ratio. The resolution conversion circuit <b>230</b> is a conversion circuit for resolution enlargement conversion and encodes an alpha map at an enlargement ratio corresponding to the given enlargement ratio.</p>
<p id="p-0137" num="0136">The resolution conversion circuit <b>230</b> returns the alpha map subjected to the resolution reduction conversion by the resolution conversion circuit <b>210</b> to the original size. The alpha map returned to its original size by this resolution conversion circuit <b>230</b> is supplied as an alpha-map local decoded signal to the orthogonal transform circuit <b>120</b> and the inverse orthogonal transform circuit <b>160</b> through the line <b>40</b>.</p>
<p id="p-0138" num="0137">The binary picture encoder <b>220</b> performs binary picture encoding for the alpha-map signal subjected to the resolution reduction conversion by the resolution conversion circuit <b>210</b> and outputs the encoded signal. The multiplexer <b>240</b> multiplexes the binary picture encoded output and information of the given enlargement ratio and outputs the multiplexed signal.</p>
<p id="p-0139" num="0138">In the alpha-map encoder <b>200</b> with the above arrangement, the resolution conversion circuit <b>210</b> reduction-encodes an input alpha map through the line <b>20</b> at a designated enlargement ratio and outputs the encoded alpha-map signal through the line <b>30</b>. The resolution conversion circuit <b>230</b> decodes the reduction-encoded alpha-map signal to the original resolution and outputs the obtained local decoded signal to the orthogonal transform circuit <b>120</b> and the inverse orthogonal transform circuit <b>160</b> through the line <b>40</b>.</p>
<p id="p-0140" num="0139">That is, the trade-off mentioned above can be accomplished by supplying setting information indicating a desired reduction/enlargement ratio to the alpha-map encoder <b>200</b> through a line <b>60</b>. The reduction/enlargement ratio setting information signal supplied through the line <b>60</b> is supplied to the resolution conversion circuits <b>210</b> and <b>230</b> and the binary picture encoder <b>220</b>. In this manner the amount of generated codes of an alpha-map signal can be controlled. Also, the multiplexer <b>240</b> multiplexes the reduction/enlargement ratio code (setting information signal) supplied through the line <b>60</b> and the encoded alpha-map signal and outputs the multiplexed signal to the line <b>30</b>. This signal is supplied as the alpha-map coded signal to the multiplexer <b>180</b> as the final output stage of the video encoding apparatus.</p>
<p id="p-0141" num="0140"><figref idref="DRAWINGS">FIG. 7</figref> shows the concept of an alpha-map decoder as a counterpart of the alpha-map encoder shown in <figref idref="DRAWINGS">FIG. 4</figref>. <figref idref="DRAWINGS">FIG. 8</figref> shows a practical arrangement of the alpha-map encoder <b>400</b> of the present invention.</p>
<p id="p-0142" num="0141">As shown in <figref idref="DRAWINGS">FIGS. 7 and 8</figref>, the alpha-map decoder <b>400</b> comprises a binary picture decoder <b>410</b>, a resolution conversion circuit <b>420</b>, and a demultiplexer <b>430</b>. The demultiplexer <b>430</b> demultiplexes an input alpha-map signal, which is demultiplexed by the demultiplexer <b>300</b> of the video decoding apparatus, into codes of an alpha-map signal and codes of a reduction/enlargement ratio. The binary picture decoder <b>410</b> returns the alpha-map signal codes to the binary picture in accordance with the reduction/enlargement ratio codes demultiplexed by the demultiplexer <b>430</b>. The resolution conversion circuit <b>420</b> performs resolution enlargement conversion for the binary picture in accordance with the reduction/enlargement ratio codes demultiplexed by the demultiplexer <b>430</b> and outputs the converted signal.</p>
<p id="p-0143" num="0142">In <figref idref="DRAWINGS">FIG. 8</figref>, codes supplied to the alpha-map decoder <b>400</b> through a line <b>80</b> are separated into codes of an alpha-map signal and codes of a reduction/enlargement ratio by the demultiplexer <b>430</b>. The alpha-map signal codes and the reduction/enlargement ratio codes are output through lines <b>81</b> and <b>82</b>.</p>
<p id="p-0144" num="0143">The binary picture decoder <b>410</b> reconstructs the reduced alpha-map signal from the alpha-map signal codes supplied through the line <b>81</b> and the reduction/enlargement ratio codes supplied through the line <b>82</b>, and supplies the reconstructed signal to the resolution conversion circuit <b>420</b> through a line <b>83</b>. The resolution conversion circuit <b>420</b> reproduces the alpha-map signal by enlarging the reduced alpha-map signal to the original size in accordance with the reduction/enlargement ratio codes supplied through the line <b>82</b>, and outputs the reproduced signal through the line <b>90</b>.</p>
<p id="p-0145" num="0144">In the present invention, binary picture encoding is used as compression encoding performed for an alpha-map signal. Details of this binary picture encoding will be described as the second embodiment of the present invention with reference to <figref idref="DRAWINGS">FIGS. 9A to 10</figref>. This embodiment relates to the binary picture encoder <b>220</b> in the first embodiment.</p>
<p id="p-0146" num="0145"><figref idref="DRAWINGS">FIG. 10</figref> is a view showing the comparison of codes obtained by variable length encoding used in the present invention and codes obtained by well-known MMR encoding. That is, <figref idref="DRAWINGS">FIG. 10</figref> compares MMR codes representing specific state information with variable length codes representing the same state information. For example, P indicates a pass mode which is “0001” in MMR encoding and “0000 001” in the present invention. V<b>0</b>, V<b>1</b>, V<b>2</b>, V<b>3</b>, V<b>4</b>, and V<b>5</b> indicate vertical modes: V<b>0</b> indicates the same position in a line below; V<b>1</b>, a shift of one pixel in a line below; V<b>2</b>, a shift of two pixels in a line below; V<b>3</b>, a shift of three pixels in a line blow; V<b>4</b>, a shift of four pixels in a line below; and V<b>5</b>, a shift of five pixels in a line below. V<b>0</b>, V<b>1</b>, V<b>2</b>, V<b>3</b>, V<b>4</b>, and V<b>5</b> are represented by “1”, “01S”, “0000 1S”, “0000 01S”, no correspondence, no correspondence, respectively, in MMR encoding, and represented by “01”, “1S”, “001S”, “0001 S”, “0000 1S”, “0000 01S”, and “0000 0001S”, respectively, in the present invention. H indicates a horizontal mode which is “001” in MMR encoding and “0000 1” in the present invention. The present invention additionally has an ESC code which is represented by “0000 00001”. In <figref idref="DRAWINGS">FIG. 10</figref>, “S” in these codes is a sign bit indicating which of a<b>1</b> and b<b>1</b> is left or right.</p>
<p id="p-0147" num="0146"><figref idref="DRAWINGS">FIGS. 9A to 9D</figref> are views for explaining two-dimensional encoding of a binary picture used in MMR encoding.</p>
<p id="p-0148" num="0147">The two-dimensional encoding in the second embodiment will be described by taking encoding of the positions of five changed pixels on a reference line and an encoding line, as shown in <figref idref="DRAWINGS">FIG. 9A</figref>, as an example. If the distance between a<b>1</b> and b<b>1</b> is three pixels or less, the distance is encoded in the vertical mode (V). In other cases, the horizontal mode (H) is used.</p>
<p id="p-0149" num="0148">In <figref idref="DRAWINGS">FIGS. 9A to 9D</figref>, “a<b>0</b>” is a starting changed pixel on the encoding line, and “a<b>1</b>” is a first changed pixel on the right side of “a<b>0</b>” on the encoding line. “a<b>2</b>” is a changed pixel next to “a<b>1</b>” on the encoding line, and “b<b>1</b>” is a first changed pixel on the reference line on the right side of “a<b>0</b>” and having a color opposite to that of “a<b>0</b>”. “b<b>2</b>” is a changed pixel next to “b<b>1</b>” on the reference line. In this example the procedure of MMR encoding is as follows.</p>
<p id="p-0150" num="0149">[1] As shown in <figref idref="DRAWINGS">FIG. 9B</figref>, if the changed pixel b<b>2</b> on the reference line is on the left side of the first changed pixel a<b>1</b> on the encoding line, the pass mode (P) which means a pass of pixels of one line is set, and the position of the starting changed pixel a<b>0</b> on the encoding line is moved immediately below b<b>2</b>.</p>
<p id="p-0151" num="0150">[2] If the positional relationship is as shown in <figref idref="DRAWINGS">FIG. 9C</figref>, the pass mode is not set because the changed pixel b<b>2</b> is not on the left side of a<b>1</b>. In addition, since the distance between a<b>1</b> and b<b>1</b> is three pixels or less, the vertical mode (V) is set, the distance is encoded, and a<b>0</b> is moved to the position of a<b>1</b>.</p>
<p id="p-0152" num="0151">[3] In other cases as in <figref idref="DRAWINGS">FIG. 9D</figref>, the horizontal mode (H) is set, a length a<b>0</b>−a<b>1</b> and a length a<b>1</b>−a<b>2</b> are encoded, and a<b>0</b> is moved to the position of a<b>2</b>.</p>
<p id="p-0153" num="0152">Each of the above mode information is encoded by using the variable length codes shown in <figref idref="DRAWINGS">FIG. 10</figref>, and the run length in the horizontal mode is encoded by MH (Modified Huffman) (Television Society ed., “Image Information Compression”, Ohmu K.K.) This is an example of encoding using MMR encoding.</p>
<p id="p-0154" num="0153">In the method of this embodiment, on the other hand, if the distance between a<b>1</b> and b<b>1</b> is M (=integer) pixels or less in the relationship between the reference line and the encoding line shown in <figref idref="DRAWINGS">FIGS. 9A to 9D</figref>, the vertical mode (V) is set. If this distance between a<b>1</b> and b<b>1</b> is N (=integer: M≧N) pixels or less, the distance is encoded by variable length encoding. If the distance is larger than N pixels, the distance is encoded by using an ESC code (escape code) and a fixed length code.</p>
<p id="p-0155" num="0154">This fixed length code has log<sub>2 </sub>(M−N+1) bits if the value of (M−N+1) is a power of 2. <figref idref="DRAWINGS">FIG. 10</figref> shows an example of variable length codes when N=5. Also, the number of pixels in the horizontal direction in a reduced picture of an alpha-map signal to be encoded by a binary picture encoder <b>220</b> is known. For example, if this number of pixels in the horizontal direction is “128”, the maximum value of log<sub>2 </sub>(M−N+1) is 7 bits, and so the value of M can be changed by adding 3-bit additional information.</p>
<p id="p-0156" num="0155">In MMR encoding, the run length is MH-encoded in the horizontal mode, and the run length frequency distribution varies in accordance with the number of pixels in the horizontal direction of an alpha-map signal. Accordingly, the run length can also be fixed-length-encoded in accordance with the number of pixels in the horizontal direction of an alpha-map signal (if the number of pixels in the horizontal line is “128”, the run length is fixed-length-encoded by 7 bits).</p>
<p id="p-0157" num="0156">If the correlation between frames is high in encoding of a motion picture, the binary picture encoder <b>220</b> is constituted by a two-dimensional encoder <b>221</b>, a line memory <b>222</b>, and a frame memory <b>223</b> as shown in <figref idref="DRAWINGS">FIG. 28</figref>. A picture in the preceding line is held in the line memory <b>222</b>, and an alpha-map encoded in the preceding frame is stored in the frame memory <b>223</b>. When the two-dimensional encoder <b>221</b> performs encoding by referring not only to the preceding line stored in the line memory <b>222</b> but also to lines in the preceding frame stored in the frame memory <b>223</b>, the encoding efficiency is in some instances raised.</p>
<p id="p-0158" num="0157">Also, a reference line in the preceding frame can be motion-compensated by using motion vectors used in the motion compensation prediction circuits <b>110</b> and <b>350</b> shown in <figref idref="DRAWINGS">FIGS. 2 and 3</figref>.</p>
<p id="p-0159" num="0158">In the method of this embodiment as described above, in the relationship between the reference line and the encoding line shown in <figref idref="DRAWINGS">FIGS. 9A to 9D</figref>, if the distance between a<b>1</b> and b<b>1</b> is M (=integer) pixels or less, the distance is encoded in the vertical mode (V). If this distance between a<b>1</b> and b<b>1</b> is N (=integer: M≧N) pixels or less, the distance is encoded by using a variable length code. If the distance is larger than N pixels, the distance is encoded by using an ESC code (escape code) and a fixed length code. Consequently, encoding can be performed at a higher compression ratio than when MMR encoding is used.</p>
<p id="p-0160" num="0159">Another example by which compression encoding can be performed at a higher efficiency will be described below.</p>
<p id="p-0161" num="0160"><figref idref="DRAWINGS">FIG. 11</figref> is a flow chart showing the procedure of well-known MMR encoding as a binary picture encoding method. That is, the pixel position information of the starting changed pixel a<b>0</b> on the encoding line is initialized (S<b>101</b>). The first changed pixel a<b>1</b> to the right of the position of a<b>0</b> on the encoding line is detected (S<b>102</b>). The first changed pixel b<b>1</b> on the reference line on the right side of the position “a<b>0</b>” and having a color opposite to that of a pixel in the position “a<b>0</b>” is detected and the changed pixel b<b>2</b> next to the position “b<b>1</b>” on the reference line is detected (S<b>103</b>). Whether the pixel positional relationship between b<b>2</b> and a<b>1</b> is b<b>2</b>&lt;a<b>1</b> is checked (S<b>104</b>). If b<b>2</b>&lt;a<b>1</b>, the pass mode (P) is set, the pixel position information of a<b>0</b> is set to the pixel position information of b<b>2</b> (S<b>105</b> and S<b>106</b>), and the flow returns to the processing in step S<b>103</b>.</p>
<p id="p-0162" num="0161">If it is determined in step S<b>104</b> that b<b>2</b>&lt;a<b>1</b> does not hold, whether |a<b>1</b>−b<b>1</b>|≦N(N is a certain threshold) is checked (S<b>107</b>). If |a<b>1</b>−b<b>1</b>|≦N, the vertical mode (V) is set, the pixel position of a<b>0</b> is moved to the pixel position of a<b>1</b> (S<b>108</b> and S<b>109</b>), and the flow advances to processing in step S<b>110</b>. In step S<b>110</b>, whether a<b>0</b> is a position corresponding to “WIDTH” (the number of pixels in the direction of width of a picture) is checked. If NO in step S<b>110</b>, the flow returns to the processing in step S<b>102</b>. If it is determined in step S<b>110</b> that a<b>0</b> is the position corresponding to “WIDTH”, whether the end of the picture is reached is checked (S<b>111</b>). If the end of the picture is not reached, the flow returns to the processing in step S<b>101</b>. If it is determined in step S<b>111</b> that the end of the picture is reached, the processing is completed.</p>
<p id="p-0163" num="0162">If it is determined in step S<b>107</b> that |a<b>1</b>−b<b>1</b>|≦N does not hold, a<b>2</b> is detected (S<b>112</b>), the horizontal mode (H) is set, the pixel position of “a<b>0</b>” is set to the pixel position of “a<b>2</b>” (S<b>113</b> and S<b>114</b>), and the flow advances to the processing in step S<b>110</b>. In step S<b>110</b>, whether “a<b>0</b>” is “WIDTH” is checked. If NO in step S<b>110</b>, the flow returns to the processing in step S<b>102</b>.</p>
<p id="p-0164" num="0163">As shown in <figref idref="DRAWINGS">FIG. 12A</figref>, “WIDTH” is the number of pixels in one horizontal line in one frame (the number of pixels in one raster scan line). That is, the processing of MMR encoding progresses in units of lines; the encoding is performed by executing encoding processing for each raster scan line.</p>
<p id="p-0165" num="0164">As in <figref idref="DRAWINGS">FIG. 12A</figref>, an alpha-map signal to which the encoding processing of the present invention is applied, i.e., a binary picture for distinguishing between the object and the background, is in most cases a simple figure in which the number of changing points in each raster scan line is at most 2. When encoding is performed for each raster scan line as in the case of MMR encoding shown in <figref idref="DRAWINGS">FIG. 11</figref>, although changed pixels to be encoded are only those in the boundary between the object and the background, the pixel in the right end of the frame must also be encoded as a changed pixel. Accordingly, the method is inefficient in respect of the amount of compressed codes.</p>
<p id="p-0166" num="0165">In the method of the present invention herein explained, therefore, “a<b>1</b>” or “b<b>1</b>” is detected in raster scan order, as shown in <figref idref="DRAWINGS">FIGS. 13A to 13D</figref>, rather than in a line. Consequently, only changed pixels in the boundary can be encoded. When encoding is performed in units of lines as in MMR encoding, “a<b>1</b>” or “b<b>1</b>” is an address from the left end of the corresponding line. In the method of the present invention, however, encoding is performed by detecting “a<b>1</b>” or “b<b>1</b>” in raster scan order. Accordingly, “a<b>1</b>” and “b<b>1</b>” are defined as follows.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>a</i><sub>1</sub><i>=abs</i><sub>—</sub><i>a</i><sub>1</sub>−(<i>int</i>)(<i>abs</i><sub>—</sub><i>a</i><sub>0</sub>/WIDTH)*WIDTH<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>B</i><sub>1</sub><i>=abs</i><sub>—</sub><i>B</i><sub>1</sub>−((<i>int</i>)(<i>abs</i><sub>—</sub><i>a</i><sub>0</sub>/WIDTH)−1)*WIDTH<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0167" num="0166">In the above equations, abs_a<b>1</b>(abs_b<b>1</b>,abs_a<b>0</b>) is an address in raster order from the upper left corner of the frame. “*” means multiplication, and “(int)(x)” means rounding off the digits after the decimal point of x. As represented by the crosshatched regions in <figref idref="DRAWINGS">FIGS. 13C and 13D</figref>, the reference line is a region of the number of pixels corresponding to “WIDTH” starting from a pixel in the position a<b>0</b>. <figref idref="DRAWINGS">FIG. 13C</figref> shows the reference line of <figref idref="DRAWINGS">FIG. 13A</figref>, and <figref idref="DRAWINGS">FIG. 13D</figref> shows the reference line of <figref idref="DRAWINGS">FIG. 13B</figref>. In the method of the present invention, therefore, encoding is performed as shown in <figref idref="DRAWINGS">FIGS. 14A and 14B</figref> by using the pass mode code P, the horizontal mode code H, and run length codes of white and black pixels. P is the pass mode code contained in a two-dimensional encoding table. H is the horizontal mode code also contained in the two-dimensional encoding table. The white and hatched rectangles following these codes represent run length codes of white and black pixels. However, if encoding is performed in raster order as described above for a picture shown in <figref idref="DRAWINGS">FIG. 14A</figref>, a run length exceeding the number (WIDTH) of constituent pixels in the horizontal line of the picture is generated as shown in <figref idref="DRAWINGS">FIG. 14B</figref>, since there is no changed pixel over a plurality of lines in the picture. In the method of the present invention, therefore, to avoid this inconvenience, the vertical pass mode code V is additionally prepared as a code for passing lines in the vertical direction.</p>
<p id="p-0168" num="0167">If the maximum run length exceeds the constituent pixel number WIDTH in the horizontal direction of a picture, the vertical pass mode (V) is applied. The vertical pass mode code V designates a pass of lines in the vertical direction. Therefore, even when the run length is larger than a value equivalent to “WIDTH”, the run length cannot be expressed if it appears in the next line. To avoid this event, an escape code from the horizontal mode (run length encoding) is prepared. In this vertical pass mode, the maximum value of a run length used in the horizontal mode is the pixel number WIDTH in the horizontal direction. If a run length has a value equivalent to WIDTH, an escape code from the horizontal mode (run length encoding) is used as a code representing the run length.</p>
<p id="p-0169" num="0168"><figref idref="DRAWINGS">FIGS. 15A to 15C</figref> illustrate examples of the vertical pass mode. In an example shown in <figref idref="DRAWINGS">FIG. 15A</figref>, the vertical pass mode is formed by using an escape code from run length encoding and a vertical mode code. In a case like that shown in <figref idref="DRAWINGS">FIG. 15B</figref> in which a<b>1</b> appears in a line which jumps a whole line from the line of a<b>0</b>, the length of a white run can be expressed by using the pass mode even if the run length is larger than the constituent pixel number WIDTH in the horizontal direction of a picture. Therefore, no encoding needs to be performed in the vertical pass mode. In an example shown in <figref idref="DRAWINGS">FIG. 15C</figref>, a<b>1</b> appears in a line skipping whole three lines from the line of a<b>0</b>. If this is the case, a code (VP) of the vertical pass mode for designating a jump (i.e., a pass) of the corresponding number of lines is prepared in a variable length code table, and encoding is performed by using this vertical pass mode code VP. That is, the number of lines to be passed is expressed in the vertical mode, and information represented by this code VP is equivalent to “horizontal mode (H)+maximum run length”. Note that as shown in <figref idref="DRAWINGS">FIG. 15C</figref>, instead of expressing the number of lines to be passed in the vertical mode, the address (SP(a<b>1</b>)) of the next changed pixel can be encoded.</p>
<p id="p-0170" num="0169">In an alpha-map signal to which the encoding method of the present invention is applied, i.e., a binary picture for distinguishing between the object and the background, no changed pixels are in many instances present in the first several lines as shown in <figref idref="DRAWINGS">FIG. 16A</figref>. Since the vertical pass mode VP can be used in the present invention, for the picture as shown in <figref idref="DRAWINGS">FIG. 16A</figref> the vertical pass mode is applied from the leading position of a frame as shown in <figref idref="DRAWINGS">FIG. 16B</figref> or <b>16</b>C. Consequently, the amount of codes can be reduced. In an example shown in <figref idref="DRAWINGS">FIG. 16B</figref>, the number of lines to be passed is expressed by using a vertical mode code V<b>0</b>. In this example, four vertical mode codes V<b>0</b> are arranged because the number of lines to be passed is 4. A line in which a<b>1</b> appears is represented by “H+ white run length” by using a white run length from the leading position of the line to a<b>1</b> and the horizontal mode code H. In addition, the line is expressed in the form of
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0170">“V0”+“V0”+“V0”+“V0”+“H”+“run length code indicating the number of white pixels”+“run length code indicating the number of black pixels”
<br/>
by arranging black pixels between a<b>1</b> and a<b>2</b>.
</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0171" num="0171">In an example shown in <figref idref="DRAWINGS">FIG. 16C</figref>, the address (SP(a<b>1</b>)) of the first changed pixel in the frame is encoded. A line is expressed in the form of “SP(a<b>1</b>)+run length code indicating the number of black pixels”. Therefore, high-efficiency compression encoding can be performed by applying this method to encoding of an alpha-map signal.</p>
<p id="p-0172" num="0172">In the above examples, (a<b>1</b>−a<b>0</b>) and (a<b>2</b>−a<b>1</b>) are run-length-encoded in the horizontal mode. This merely succeeds the expression method in the horizontal mode of MMR. Therefore, the present invention proposes an encoding system in which if only (a<b>1</b>−a<b>0</b>) can be run-length-encoded in the horizontal mode and a<b>2</b> can be encoded in another mode (e.g., the vertical mode), this a<b>2</b> is encoded in another method.</p>
<p id="p-0173" num="0173"><figref idref="DRAWINGS">FIG. 17</figref> is a flow chart for explaining an encoding procedure when this system is applied. In this processing, the pixel position information of the starting changed pixel a<b>0</b> on the encoding line is initialized (S<b>201</b>). The first changed pixel a<b>1</b> to the right of the position “a<b>0</b>” on the encoding line is detected (S<b>202</b>). The first changed pixel b<b>1</b> on the reference line on the right side of the position “a<b>0</b>” and having a color opposite to that of a pixel in the position “a<b>0</b>” is detected and the changed pixel b<b>2</b> appearing next to the position “b<b>1</b>” on the reference line is detected (S<b>203</b>). Whether b<b>1</b> is detected is checked (S<b>204</b>). If b<b>1</b> is detected, whether the number of pixels between a<b>0</b> and a<b>1</b> is smaller than 2*WIDTH is checked (S<b>205</b>). If the number of pixels is smaller than 2*WIDTH, whether b<b>2</b>&lt;a<b>1</b> is checked (S<b>206</b>). If b<b>2</b>&lt;a<b>1</b>, the pass mode (P) is set, the pixel position information of a<b>0</b> is set to the pixel position information of b<b>2</b> (S<b>207</b> and S<b>208</b>), and the flow returns to the processing in step S<b>203</b>.</p>
<p id="p-0174" num="0174">On the other hand, if it is determined in step S<b>206</b> that b<b>2</b>&lt;a<b>1</b> does not hold, whether |a<b>1</b>−b<b>1</b>|≦9 is checked (S<b>209</b>). If |a<b>1</b>−b<b>1</b>|≦9, the vertical mode (V) is set, the pixel position of a<b>0</b> is set to the pixel position of a<b>1</b> (S<b>210</b> and S<b>211</b>), and the flow advances to processing in step S<b>212</b>. In step S<b>212</b>, whether the end of the picture is reached is checked. If the end of the picture is reached, the processing is completed. If the end of the picture is not reached, the flow returns to the processing in step S<b>202</b>.</p>
<p id="p-0175" num="0175">If it is determined in step S<b>209</b> that |a<b>1</b>−b<b>1</b>|≦9 does not hold, a<b>2</b> is detected, and whether the number of pixels between a<b>1</b> and a<b>2</b> is smaller than the horizontal constituent pixel number “WIDTH” of the picture is checked (S<b>214</b>). If YES in step S<b>214</b>, the vertical mode is set (S<b>215</b>), a<b>0</b> is set to a<b>2</b> (S<b>216</b>), and the flow advances to the determination processing in step S<b>212</b>.</p>
<p id="p-0176" num="0176">If it is determined in step S<b>214</b> that the number of pixels between a<b>1</b> and a<b>2</b> is not smaller than the horizontal constituent pixel number “WIDTH” of the picture, the vertical pass mode is set (S<b>217</b>), a<b>0</b> is set to a<b>2</b> (S<b>218</b>), and the flow advances to the determination processing in step S<b>212</b>.</p>
<p id="p-0177" num="0177">If it is determined in step S<b>205</b> that the number of pixels between a<b>0</b> and a<b>1</b> is not smaller than 2*WIDTH, a<b>2</b> is detected (S<b>219</b>), the vertical pass mode is set (S<b>217</b>), and a<b>0</b> is set to a<b>2</b> (S<b>218</b>). Thereafter, the flow advances to the determination processing in step S<b>212</b>. Consequently, an encoding system is realized in which if only (a<b>1</b>−a<b>0</b>) can be run-length-encoded in the horizontal mode and a<b>2</b> can be encoded in another mode (e.g., the vertical mode), this a<b>2</b> is encoded in another mode.</p>
<p id="p-0178" num="0178">A practical example in which lines in a preceding frame are used as reference lines and the encoding processing efficiency is improved by using the correlation between frames will be described below.</p>
<p id="p-0179" num="0179"><figref idref="DRAWINGS">FIG. 18</figref> is a block diagram of a coding/decoding apparatus according to the present invention. In <figref idref="DRAWINGS">FIG. 18</figref>, an encoder/decoder <b>2000</b> outputs coded picture data and decodes and outputs input coded picture data. A line memory <b>2100</b> holds picture information in units of lines each corresponding to one raster scan. That is, the line memory <b>2100</b> holds picture information of intraframe reference lines and picture information of interframe reference lines. Reference numeral <b>2200</b> denotes a selector; <b>2300</b><i>a </i>and <b>2300</b><i>b</i>, frame memories for holding frame pictures; and <b>2400</b>, a motion compensation prediction circuit.</p>
<p id="p-0180" num="0180">The frame memories <b>2300</b><i>a </i>and <b>2300</b><i>b </i>hold picture data of the current frames. The motion compensation prediction circuit <b>2400</b> performs motion compensation prediction for the picture data from the frame memory <b>2300</b><i>b </i>and outputs the picture data subjected to the motion compensation prediction.</p>
<p id="p-0181" num="0181">In accordance with an output mode switch signal from the encoder/decoder <b>2000</b>, the selector <b>2200</b> selects one of the output picture data from the motion compensation prediction circuit <b>2400</b> and the picture data from the frame memory <b>2300</b><i>a </i>and outputs the selected data to the line memory <b>2100</b>. The line memory <b>2100</b> holds the picture data obtained via the selector <b>2200</b> in units of lines and transfers the data to the encoder/decoder <b>2000</b>. The encoder/decoder <b>2000</b> encodes or decodes this picture data in units of lines.</p>
<p id="p-0182" num="0182">In this system with the above arrangement, the encoder/decoder <b>2000</b> encodes input picture information in raster scan order while referring to the contents of the line memory <b>2100</b> and outputs the encoded information from an output OUT. Also, the encoder/decoder <b>2100</b> decodes coded information and stores the decoded information in the frame memories <b>2300</b><i>a </i>and <b>2300</b><i>b</i>. The decoded picture information in the frame memories <b>2300</b><i>a </i>and <b>2300</b><i>b </i>is read out to the selector <b>2200</b> or to the motion compensation prediction circuit <b>2400</b> where the information is subjected to motion compensation prediction and then supplied to the selector <b>2200</b>.</p>
<p id="p-0183" num="0183">Inputs to the selector <b>2200</b> are switched in accordance with a mode switch signal (intraframe/interframe) supplied from the encoder/decoder <b>2000</b> through a line <b>10</b>. The picture information is supplied from the frame memories <b>2300</b><i>a </i>and <b>2300</b><i>b </i>to the line memory <b>2100</b> via the selector <b>2200</b>. Consequently, the line memory <b>2100</b> sequentially stores intraframe reference lines or interframe reference lines selectively input in accordance with the mode switch signal (intraframe/interframe).</p>
<p id="p-0184" num="0184">The frame memories <b>2300</b><i>a </i>and <b>2300</b><i>b </i>store the decoded pixel values of a frame of interest and the pixel values of a decoded reference frame obtained by encoding/decoding processing by the encoder/decoder <b>2000</b>. Note that the motion-compensated signal obtained by the motion compensation prediction circuit <b>2400</b> can also be used as the interframe reference line.</p>
<p id="p-0185" num="0185">Crosshatched portions in <figref idref="DRAWINGS">FIGS. 19A and 19B</figref> indicate examples of intraframe and interframe reference lines when encoding is performed in raster order. <figref idref="DRAWINGS">FIG. 19A</figref> shows an intraframe reference line which will be referred to as “ABOVE LINE” hereinafter. <figref idref="DRAWINGS">FIG. 19B</figref> shows an interframe reference line which is set as illustrated with respect to the same a<b>0</b> as in a reference frame or an address a<b>0</b> after motion compensation. This interframe reference line will be referred to as “PREVIOUS LINE” hereinafter.</p>
<p id="p-0186" num="0186">Mode information for switching reference lines is separately encoded in units of block lines consisting of a plurality of lines by the encoder/decoder <b>2000</b>.</p>
<p id="p-0187" num="0187"><figref idref="DRAWINGS">FIG. 20</figref> is a flow chart showing the encoding procedure of this embodiment. The encoder/decoder <b>2000</b> first initializes the pixel position information of the starting changed pixel a<b>0</b> on the encoding line (S<b>301</b>) and then checks whether the mode of the line to which the starting pixel a<b>0</b> belongs is an intraframe mode (INTRA) (S<b>302</b>). If the mode is the intraframe mode (INTRA), “ABOVE LINE” is read into the line memory <b>2100</b> (S<b>302</b>). If the mode is not the intraframe mode (INTRA), “PREVIOUS LINE” is read into the line memory <b>2100</b> in <figref idref="DRAWINGS">FIG. 18</figref> (S<b>309</b>).</p>
<p id="p-0188" num="0188">Subsequently, the encoder/decoder <b>2000</b> detects a<b>1</b> (S<b>304</b>), detects b<b>1</b> and b<b>2</b> (S<b>305</b>), and checks whether the pixel positional relationship between b<b>2</b> and a<b>1</b> is b<b>2</b>&gt;a<b>1</b> (S<b>306</b>). If b<b>2</b>&lt;a<b>1</b>, the encoder/decoder <b>2000</b> sets the pass mode (P) and sets the pixel position information of a<b>0</b> to the pixel position information of b<b>2</b> (S<b>307</b> and S<b>308</b>), and the flow returns to the processing in step S<b>304</b>.</p>
<p id="p-0189" num="0189">If it is determined in step S<b>306</b> that the pixel positional relationship between b<b>2</b> and a<b>1</b> is not b<b>2</b>&lt;a<b>1</b>, the encoder/decoder <b>2000</b> checks whether |a<b>1</b>−b<b>1</b>|≦N(N is a certain threshold) (S<b>310</b>). If |a<b>1</b>−b<b>1</b>|≦N, the encoder/decoder <b>2000</b> sets the vertical mode (V) and sets the pixel position of a<b>0</b> in the pixel position of a<b>1</b> (S<b>311</b> and S<b>312</b>), and the flow advances to processing in step S<b>313</b>. In step S<b>313</b>, the encoder/decoder <b>2000</b> checks whether a<b>0</b> is a position corresponding to “WIDTH” (the number of pixels in the direction of width of a picture). If NO in step S<b>313</b>, the flow returns to the processing in step S<b>304</b>. If it is determined in step S<b>313</b> that a<b>0</b> is a position corresponding to “WIDTH”, the encoder/decoder <b>2000</b> checks whether the end of the picture is reached (S<b>314</b>). If the end of the picture is not reached, the flow returns to the processing in step S<b>301</b>. If it is determined in step S<b>314</b> that the end of the picture is reached, the encoder/decoder <b>2000</b> completes the processing.</p>
<p id="p-0190" num="0190">If it is determined in step S<b>310</b> that |a<b>1</b>−b<b>1</b>|≦N does not hold, the encoder/decoder <b>2000</b> detects a<b>2</b> (S<b>315</b>), sets the horizontal mode (H), and sets the pixel position of “a<b>0</b>” to the pixel position of “a<b>2</b>” (S<b>316</b> and S<b>317</b>). Thereafter, the flow advances to the processing in step S<b>313</b>.</p>
<p id="p-0191" num="0191">That is, in the above procedure, if the mode of the line to which the starting pixel a<b>0</b> belongs is the intraframe mode (INTRA), “ABOVE LINE” is read into the line memory <b>2100</b> shown in <figref idref="DRAWINGS">FIG. 18</figref>. If the mode is an interframe mode (INTER), “PREVIOUS LINE” is read into the line memory <b>2100</b>. If “PREVIOUS LINE” as the reference line is exactly the same as the encoding line or the error between the lines is very small, “NOT CODED” is performed, i.e., the signal of the reference line is directly copied without encoding the encoding line. Since the signal of the reference line is directly copied without encoding the encoding line if “PREVIOUS LINE” as the reference line is exactly the same as the encoding line or the error between the lines is very small, the amount of generated codes can be reduced.</p>
<p id="p-0192" num="0192"><figref idref="DRAWINGS">FIG. 21</figref> shows an example of mode switching performed in units of block lines for an alpha map of an image of a person when the above system is used. A block line indicates a block constituted by a plurality of adjacent lines. Block lines <b>0</b> and <b>1</b> occupied by a portion corresponding to the top of the head and its vicinity are in the “INTRA” line mode. Block lines <b>2</b> to <b>4</b> occupied by a portion corresponding to the face are in the “NOT CODED” line mode since the differences between the lines are small. Block lines <b>5</b> to <b>8</b> occupied by a portion corresponding to the shoulders and the chest and their vicinities are in the “INTRA” line mode.</p>
<p id="p-0193" num="0193"><figref idref="DRAWINGS">FIG. 22</figref> explains a practical example in which encoding of block lines in the “NOT CODED” mode is skipped when encoding is performed in raster order.</p>
<p id="p-0194" num="0194">In the present invention, mode switching is performed in accordance with the attribute (“INTRA”/“INTER”/“NOT CODED”) of a line to which the starting pixel a<b>0</b> belongs. However, a<b>1</b> does not necessarily exist on the same line as a<b>0</b> when encoding is performed in raster order. Accordingly, whether a<b>1</b> is on the same line as a<b>0</b> in decoding is unknown.</p>
<p id="p-0195" num="0195">As shown in <figref idref="DRAWINGS">FIG. 22</figref>, therefore, when a<b>0</b> is the last changed pixel on the block line of interest and the mode of the next block line is the “NOT CODED” (no encoding), the processing skips to the next block line in a “CODED” (encoding) mode by using a skip code SK. The first pixel on the block line to which the processing skipped is set as new a<b>0</b>, and all regions in this block line are encoded. Assume that a<b>0</b> is present on a block line B<b>1</b>, the mode of the block line B<b>1</b> is “INTER”, three block lines B<b>2</b> to B<b>4</b> in the “NOT CODED” mode follow the block line B<b>1</b>, and a block line B<b>5</b> in the “INTER” mode follows the block line B<b>4</b>. In this case a<b>0</b> is moved as new a<b>0</b> to the leading position of the block line B<b>5</b>, and the processing skips from a<b>0</b> to new a<b>0</b> by using the code SK, thereby setting all of the block lines B<b>1</b> to B<b>4</b> in the “CODED” mode, i.e., encoding these block lines. A variable length code of the code SK is designed together with variable length codes of “vertical mode”/“horizontal mode”/“pass mode”.</p>
<p id="p-0196" num="0196"><figref idref="DRAWINGS">FIG. 23</figref> is a flow chart showing the encoding procedure described above, in which the portion enclosed within the dotted lines in <figref idref="DRAWINGS">FIG. 17</figref> is altered.</p>
<p id="p-0197" num="0197">The pixel position information of the starting changed pixel a<b>0</b> on the encoding line is initialized (S<b>201</b>). Whether the mode of the line to which the starting pixel a<b>0</b> belongs is the intraframe (INTRA) mode is checked (S<b>1201</b>). If the mode is the intraframe (INTRA) mode, “ABOVE LINE” is read into the line memory <b>2100</b> shown in <figref idref="DRAWINGS">FIG. 18</figref> (S<b>1202</b>). If the mode is not the intraframe (INTRA) mode, “PREVIOUS LINE” is read into the line memory <b>2100</b> (S<b>1203</b>). Subsequently, whether the line to which a<b>0</b> belongs is “NOT CODED LINE”, i.e., a line not to be encoded, is checked (S<b>1204</b>). If the line is a line not to be encoded, the flow advances to the processing in step S<b>201</b>. If the line is a line to be encoded, a<b>1</b> is detected (S<b>202</b>), b<b>1</b> and b<b>2</b> are detected (S<b>203</b>), and the flow advances to the processing in step S<b>204</b>.</p>
<p id="p-0198" num="0198">As described above, encoded signals in the preceding frame are decoded and stored, and whether the region of a picture being encoded approximates to the state of a picture in an encoded region is checked by referring to the signals of the preceding frame. If the region being encoded approximates to the encoded region, the picture in the region is not encoded. Instead, signals in the decoded frame are copied to the frame being encoded, the copied portion is skipped, and the region to be encoded next is encoded. Consequently, the processing efficiency can be improved because encoding of the copied portion is skipped.</p>
<p id="p-0199" num="0199">A practical example in which the amount of codes to be generated is reduced by improving the performance of prediction by using a plurality of reference lines will be described below.</p>
<p id="p-0200" num="0200"><figref idref="DRAWINGS">FIGS. 24A and 24B</figref> are views for explaining the relationship between the encoding line and the reference line in the present invention. Before the explanation, c<b>1</b> and c<b>2</b> are redefined as follows.
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0000">
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0201">c<b>1</b>: the first changed pixel on the right side of a<b>0</b> and having a color opposite to that of a<b>0</b></li>
        <li id="ul0004-0002" num="0202">c<b>2</b>: the next changed pixel of c<b>1</b></li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0201" num="0203">In the present invention, when a<b>1</b> is encoded the displacements of b<b>1</b> and a<b>1</b> are predicted from the displacements of c<b>1</b> and b<b>1</b>. diff obtained by the following equation is encoded in the vertical mode.
<ul id="ul0005" list-style="none">
    <li id="ul0005-0001" num="0000">
    <ul id="ul0006" list-style="none">
        <li id="ul0006-0001" num="0204">diff=b<sub>1</sub>−a<sub>1</sub>+f(b<sub>1</sub>−c<sub>1</sub>)</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0202" num="0205">In the above equation, f(x) is a prediction function for estimating the displacements of b<b>1</b> and a<b>1</b>. Also, the following equations are examples of prediction functions by which the predictive value is set to 0 when the absolute values of the displacements of c<b>1</b> and b<b>1</b> are smaller than a threshold th, in order to prevent a decrease in the prediction efficiency resulting from micro-noise.</p>
<p id="p-0203" num="0206">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="offset" colwidth="42pt" align="left"/>
<colspec colname="1" colwidth="91pt" align="left"/>
<colspec colname="2" colwidth="84pt" align="left"/>
<thead>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry/>
<entry>f(x) = 0</entry>
<entry>(abs(x) &lt; th)</entry>
</row>
<row>
<entry/>
<entry>f(x) = sign(x)</entry>
<entry>(abs(x) ≧ th)</entry>
</row>
<row>
<entry/>
<entry>sign(x) = −1</entry>
<entry>(x = 0)</entry>
</row>
<row>
<entry/>
<entry>sign(x) = 0</entry>
<entry>(x = 0)</entry>
</row>
<row>
<entry/>
<entry>sign(x) = 1</entry>
<entry>(x &gt; 0)</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0204" num="0207">Note that if c<b>2</b> is closer to the left end than b<b>1</b> or if abs(b<b>1</b>−c<b>1</b>) is larger than a certain threshold, encoding is performed in the regular vertical mode.</p>
<p id="p-0205" num="0208"><figref idref="DRAWINGS">FIG. 25</figref> is a flow chart showing the encoding procedure of this practical example. The first vertical mode is a conventional vertical mode, and the second vertical mode is a vertical mode using two reference lines, which is a new mode used by the present invention.</p>
<p id="p-0206" num="0209">In this processing, the pixel position information of the starting changed pixel a<b>0</b> on the encoding line is initialized (S<b>401</b>). The first changed pixel a<b>1</b> to the right of the position “a<b>0</b>” on the encoding line is detected (S<b>402</b>). The first changed pixel b<b>1</b> on the reference line on the right side of the position “a<b>0</b>” and having a color opposite to that of a pixel in the position “a<b>0</b>” is detected and the changed pixel b<b>2</b> appearing next to the position “b<b>1</b>” on the reference line is detected (S<b>403</b>). Whether b<b>1</b> is smaller than a<b>1</b> is checked (S<b>404</b>). If b<b>1</b> is smaller than a<b>1</b>, the pass mode (P) is set (S<b>405</b>), the pixel position information of a<b>0</b> is set to the pixel position information of b<b>2</b> (S<b>406</b>), and the flow returns to the processing in step S<b>403</b>.</p>
<p id="p-0207" num="0210">If it is determined in step S<b>405</b> that b<b>1</b> is not smaller than a<b>1</b>, c<b>1</b> and c<b>2</b> are detected (S<b>407</b>), and whether c<b>2</b> is smaller than b<b>1</b> is checked (S<b>408</b>). If c<b>2</b> is smaller than b<b>1</b>, whether |a<b>1</b>−b<b>1</b>|≦N is checked (S<b>409</b>). If |a<b>1</b>−b<b>1</b>|≦N, the first vertical mode (V) is set (S<b>410</b>), the pixel position of a<b>0</b> is set to the pixel position of a<b>1</b> (S<b>411</b>), and the flow advances to processing in step S<b>412</b>.</p>
<p id="p-0208" num="0211">In step S<b>412</b>, whether the position of a<b>0</b> corresponds to the value of WIDTH as the number of pixels in the horizontal direction is checked. If NO in step S<b>412</b>, the flow returns to the processing in step S<b>402</b>. If YES in step S<b>412</b>, the flow advances to step S<b>413</b> to check whether the end of the picture is reached. If the end of the picture is reached, the processing is completed. If the end of the picture is not reached, the flow returns to the processing in step S<b>401</b>.</p>
<p id="p-0209" num="0212">On the other hand, if it is determined in step S<b>408</b> that c<b>2</b>&lt;b<b>1</b> does not hold, whether |diff|≦N is checked (S<b>418</b>). If NO in step S<b>418</b>, a<b>2</b> is detected (S<b>414</b>), the horizontal mode is set (S<b>415</b>), and a<b>0</b> is set to a<b>2</b> (S<b>416</b>). The flow then advances to the processing in step S<b>412</b>. If it is determined in step S<b>418</b> that |diff|≦N, the second vertical mode is set (S<b>419</b>), a<b>0</b> is set to a<b>2</b> (s<b>420</b>), and the flow advances to the processing in step S<b>412</b>.</p>
<p id="p-0210" num="0213">On the other hand, if it is determined in step S<b>409</b> that |a<b>1</b>−b<b>1</b>|≦N does not hold, a<b>2</b> is detected (S<b>414</b>), the horizontal mode is set (S<b>415</b>), and a<b>0</b> is set to a<b>2</b> (S<b>417</b>). The flow then advances to the processing in step S<b>412</b>.</p>
<p id="p-0211" num="0214">By the above processing, the performance of prediction can be improved by using a plurality of reference lines. The amount of codes to be generated can be reduced by this improvement of the prediction performance.</p>
<p id="p-0212" num="0215">As one application of high-efficiency compression encoding according to the method of the present invention, a practical example of encoding of multivalue alpha maps, rather than the binary ones as described above, will be described below. <figref idref="DRAWINGS">FIGS. 26A and 26B</figref> are views for explaining multivalue alpha maps.</p>
<p id="p-0213" num="0216"><figref idref="DRAWINGS">FIG. 26A</figref> shows an alpha map in which, in order to prevent discontinuity in the boundary when the object and the background are synthesized, the weighting of the synthesis is expressed by multiple values. <figref idref="DRAWINGS">FIG. 26B</figref> shows an alpha map when a portion of a caption is semitransparently synthesized (semitransparent superposition).</p>
<p id="p-0214" num="0217">Assuming the signal of the object is So, the signal of the background is Sb, and the value of weighting (Alpha Value) is a, a synthetic signal is represented by an equation below. In this equation Alpha Value is expressed by 8 bits.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Sc</i>=((255<i>−a</i>)*<i>Sb+So</i>)/255<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0215" num="0218">To encode this alpha map, as shown in <figref idref="DRAWINGS">FIG. 27A</figref>, shape information (Shape) representing whether the value of the alpha map is 0 and alpha value information (Alpha Value) which is gray scale information (gradation information) of each pixel in the alpha map are separately encoded. That is, as illustrated in <figref idref="DRAWINGS">FIG. 27B</figref>, the shape information Shape is supplied to a shape coding unit <b>2500</b> for practicing the binary picture coding method of the present invention. There the shape information Shape is encoded by the binary picture coding method of the present invention. In accordance with the reproduction signal of the information Shape, an alpha value coding unit <b>2600</b> for encoding a multivalue picture encodes the alpha value information Alpha Value.</p>
<p id="p-0216" num="0219">In this manner it is possible to encode multivalue alpha maps, rather than binary ones.</p>
<p id="p-0217" num="0220">As the third embodiment of the present invention, a code amount reducing technique when the region occupied by the object in a whole frame is very small will be described below with reference to <figref idref="DRAWINGS">FIGS. 29A to 30B</figref>.</p>
<p id="p-0218" num="0221">In a case where the region occupied by the object in a while frame is very small as shown in <figref idref="DRAWINGS">FIG. 29A</figref>, the amount of codes is sometimes reduced by encoding an alpha-map signal of the small region containing the object, as shown in <figref idref="DRAWINGS">FIG. 29B</figref>, rather than an alpha-map signal of the whole frame. If this is the case, the size of the small region and the positional relationship in the frame must be known. Therefore, the position address of an upper left corner S of a small region, which represents the position of the small region, and the dimensions (h, v) of the small region in the (horizontal, vertical) directions are additionally encoded as additional information. Furthermore, to reduce the amount of codes of S and (h, v), the small region is so set as to be an integral multiple of a block which is a processing unit of encoding enclosed within the broken lines in <figref idref="DRAWINGS">FIG. 29A</figref>. Consequently, S and (h, v) can be expressed by block addresses.</p>
<p id="p-0219" num="0222"><figref idref="DRAWINGS">FIGS. 30A and 30B</figref> are block diagrams for explaining the flow of the above processing. <figref idref="DRAWINGS">FIG. 30A</figref> is a block diagram of a transmitter, and <figref idref="DRAWINGS">FIG. 30B</figref> is a block diagram of a receiver.</p>
<p id="p-0220" num="0223">The transmitter consists of an object region detector <b>500</b>, an alpha-map encoder <b>200</b>, and a multiplexer <b>510</b>. The object region detector <b>500</b> detects the region of the object from an alpha map, i.e., detects the alpha-map signal of the small region and the values of S and (h, v).</p>
<p id="p-0221" num="0224">The alpha-map encoder <b>200</b> encodes the alpha map of the small region. Details of the encoder <b>200</b> have already been described. The multiplexer <b>510</b> multiplexes the encoded alpha-map and the output values of S and (h, v) from the object region detector <b>500</b> and outputs the multiplexed signal.</p>
<p id="p-0222" num="0225">The receiver comprises a demultiplexer <b>520</b>, an alpha-map decoder <b>400</b>, and an alpha-map restoration circuit <b>530</b>. The demultiplexer <b>520</b> demultiplexes the bit stream into the alpha-map signal of the small region and the coded components of the values of S and (h, v). The alpha-map decoder <b>400</b> decodes the alpha-map signal of the small region to obtain the alpha map of the original size. The alpha-map restoration circuit <b>530</b> restores the values of S and (h, v) from the coded components of the values of S and (h, v).</p>
<p id="p-0223" num="0226">In the above configuration, an alpha-map signal of a whole frame is supplied to the object region detector <b>500</b> through a line <b>20</b>. The detector <b>500</b> supplies an alpha-map signal of the small region as shown in <figref idref="DRAWINGS">FIG. 29B</figref> to the alpha-map encoder <b>200</b> through a line <b>22</b>. Also, the detector <b>500</b> encodes the values of S and (h, v) and supplies the encoded values to the alpha-map encoder <b>200</b> and the multiplexer <b>510</b> through a line <b>23</b>.</p>
<p id="p-0224" num="0227">The multiplexer <b>510</b> multiplexes the encoded alpha-map signal of the small region supplied through a line <b>24</b> and the encoded values of S and (h, v) supplied through the line <b>23</b> and outputs the multiplexed signal through a line <b>30</b>.</p>
<p id="p-0225" num="0228">Meanwhile, the codes supplied to the demultiplexer <b>520</b> through a line <b>80</b> are demultiplexed into codes pertaining to the alpha-map signal of the small region and codes pertaining to S and (h, v), and these codes are output through lines <b>84</b> and <b>86</b>, respectively. The alpha-map restoration circuit <b>530</b> restores the alpha-map signal of the whole frame from the reconstructed alpha-map signal of the small region supplied through a line <b>85</b> and the values of S and (h, v) supplied through the line <b>86</b> and outputs the restored signal through a line <b>90</b>.</p>
<p id="p-0226" num="0229">As a result, when the region occupied by the object in a whole frame is very small as shown in <figref idref="DRAWINGS">FIG. 29A</figref>, the amount of codes can be reduced by encoding an alpha-map signal of the small region containing the object as shown in <figref idref="DRAWINGS">FIG. 29B</figref>, rather than an alpha-map signal of the whole frame.</p>
<p id="p-0227" num="0230">As the fourth embodiment, a technique which smooths an oblique discontinuity occurring due to sampling conversion (enlargement/reduction conversion) will be described below with reference to <figref idref="DRAWINGS">FIGS. 4</figref>, <b>33</b>A and <b>33</b>B, and <b>34</b>.</p>
<p id="p-0228" num="0231">When a binary picture is repeatedly reduced and enlarged, oblique lines or curved lines easily loose their smoothness. Since an alpha-map signal is binary picture information, the signal readily brings about this phenomenon when repeatedly reduced and enlarged. In addition, an alpha-map signal is used to extract or identify a portion of interest in a frame. Therefore, the loss of smoothness leads to degradation of image quality. Accordingly, a technique by which this problem of the loss of smoothness is eliminated is necessary.</p>
<p id="p-0229" num="0232">This embodiment relates to a binary picture processing method which smooths an oblique discontinuity occurring due to sampling conversion (enlargement/reduction conversion) in the arrangement shown in <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0230" num="0233"><figref idref="DRAWINGS">FIGS. 33A and 33B</figref> are views for explaining smoothing processing. <figref idref="DRAWINGS">FIG. 33A</figref> shows a binary picture of an original size, and <figref idref="DRAWINGS">FIG. 33B</figref> shows a binary picture obtained by reducing the picture in <figref idref="DRAWINGS">FIG. 33A</figref>. In <figref idref="DRAWINGS">FIGS. 33A and 33B</figref>, an object region is indicated by full circles and a background region is indicated by open circles.</p>
<p id="p-0231" num="0234">In this embodiment, to smooth an oblique discontinuity occurring when a resolution conversion circuit <b>210</b> or a resolution conversion circuit <b>230</b> performs sampling conversion (enlargement/reduction conversion) in the configuration shown in <figref idref="DRAWINGS">FIG. 4</figref>, the upper, lower, left, and right pixels, i.e., the adjacent pixels, of each pixel (open circle) in the background region are checked. If two or more of these adjacent pixels are pixels (full circles) in the object region, the pixel of interest in the background region is incorporated into the object region.</p>
<p id="p-0232" num="0235">That is, assume that the pixel to be checked in the background region is either of pixels in positions indicated by double circles in <figref idref="DRAWINGS">FIG. 33B</figref>. In this case two adjacent pixels are pixels (full circles) in the object region. Therefore, the pixel (i.e., the pixel to be checked) in the position indicated by the double circle is changed into a full-circle pixel, i.e., a pixel in the object region. Assuming a full-circle pixel is “1” and an open-circle pixel is “0”, the pixel (pixel value “0”) in the position indicated by the double circle is replaced by a pixel value “1”.</p>
<p id="p-0233" num="0236">More specifically, as illustrated <figref idref="DRAWINGS">FIG. 34</figref>, two frame memories <b>621</b> and <b>622</b> are prepared as devices for performing the above picture processing, and binary picture data to be smoothed is held in these frame memories <b>621</b> and <b>622</b>. One frame memory is used as a memory for holding the picture to be checked, and the other is used as a working memory. A controller <b>623</b> controls these frame memories <b>621</b> and <b>622</b> as follows and performs arithmetic processing as follows by using the contents held in the frame memories <b>621</b> and <b>622</b>.</p>
<p id="p-0234" num="0237">When binary picture data is input, the controller <b>623</b> stores this binary picture data in the holding memory for a picture to be checked and the working memory (S<b>1</b>). The controller <b>623</b> sets each pixel of the picture held in the holding memory for the picture to be checked, as the pixel to be checked, and checks the values of four adjacent pixels of that pixel (S<b>2</b>). The controller <b>623</b> checks whether the value of the pixel to be checked is “0” and two or more of the four adjacent pixels have a value “1” (S<b>3</b>). If two or more adjacent pixels have “1”, the controller <b>623</b> rewrites the value of the pixel to be checked by “1” (S<b>4</b>). This rewrite operation is done by replacing the value in the corresponding pixel position in the working memory with “1”.</p>
<p id="p-0235" num="0238">When completely processing all pixels, the controller <b>623</b> reads out the corrected binary picture data from the working memory (S<b>5</b>) and outputs the data as smoothed binary picture data. When this processing is completed, the binary picture data which has lost its smoothness restores the smoothness of the contour. For binary picture data whose smoothness is largely lost, the above processing is repeated a plurality of number of times. That is, the controller <b>623</b> copies the corrected binary picture data stored in the working memory to the holding memory for the picture to be checked (S<b>6</b>), and again performs the processing from step S<b>2</b>. When the ratio and the number of times of compression and enlargement are determined, the degree of the loss of smoothness can be known in the system. Therefore, the controller <b>623</b> repeats the above processing by determining an appropriate repetitive number in accordance with the situation, reads out binary picture data from the working memory as the processed binary picture data, and outputs the readout data as the final processed data.</p>
<p id="p-0236" num="0239">As a consequence, even binary picture data whose smoothness is largely lost can be corrected to have <b>8</b><i>a </i>smooth contour. Accordingly, when the picture processing means shown in <figref idref="DRAWINGS">FIG. 34</figref> is provided in the output stage of the resolution conversion circuit <b>210</b> in the configuration shown in <figref idref="DRAWINGS">FIG. 4</figref>, binary picture data with a smooth contour can be supplied to the subsequent stage.</p>
<p id="p-0237" num="0240">Although various examples have been described above, the gist of the embodiments is that the resolution of an alpha map required to realize object scalability is reduced when the alpha map is encoded, and the obtained codes and the reduction ratio information are together multiplexed to form an alpha-map signal to be transmitted or stored. Consequently, the alpha-map signal can be efficiently encoded and this allows efficient encoding of the shape information of the object.</p>
<p id="p-0238" num="0241">In reproducing the alpha-map signal, the coded components of the alpha map and the reduction ratio information are separated. The coded components of the alpha map are decoded and enlarged to the original resolution in accordance with the reduction ratio information. Accordingly, the alpha map of the original size can be restored. This allows easy decoding of a coded picture using an alpha map.</p>
<p id="p-0239" num="0242">In the present invention, the processing can be performed in units of block lines. Therefore, as shown in <figref idref="DRAWINGS">FIG. 32</figref>, codes of alpha maps can be transmitted in units of block lines and decoded in units of block lines on the receiver side.</p>
<p id="p-0240" num="0243">That is, general MMR detects changed pixels only in horizontal lines of a picture. In the first to fourth embodiments, on the other hand, MMR is used but changed pixels of a picture are detected across a plurality of lines in raster scan order. Accordingly, the processing can be performed in units of block lines. Consequently, as shown in <figref idref="DRAWINGS">FIG. 32</figref>, codes of alpha maps can be transmitted in units of block lines and decoded in units of block lines on the receiver side.</p>
<p id="p-0241" num="0244">Each of the above embodiments is a method of encoding a whole frame or individual block lines in encoding of an alpha map necessary to realize object scalability which is a function of a coding system capable of reproducing (reconstructing) a picture in units of partial images with arbitrary shapes. That is, each embodiment is a method of encoding an alpha map expressed by binary pictures by using a coding method based on MMR (Modified Modified READ) which is a coding system of FAX. MMR is basically a coding system whose unit is a line.</p>
<p id="p-0242" num="0245">On the other hand, in the existing picture coding systems such as MPEG which is a standard coding system for motion pictures, a general approach is to divide a whole frame into macro blocks MB each consisting of 16×16 pixels and perform encoding in units of macro blocks MB. Therefore, in these systems it is desirable to perform encoding of alpha maps in units of macro blocks MB. However, the macro block MB is a portion of a frame. Accordingly, if the macro blocks MB are encoded one after another on the basis of MMR which is a coding system whose unit is a line, the coding efficiency may be decreased.</p>
<p id="p-0243" num="0246">A coding technique, therefore, capable of efficiently performing encoding and decoding in units of macro blocks will be described below.</p>
<p id="p-0244" num="0247">As the fifth embodiment, the first method of performing encoding and decoding in units of macro blocks according to the present invention will be described below with reference to <figref idref="DRAWINGS">FIGS. 35</figref>, <b>36</b>, and <b>37</b>A and <b>37</b>B. System configurations required in this embodiment can be basically the same as the configurations shown in <figref idref="DRAWINGS">FIGS. 2 and 3</figref>. It is only necessary to design the system such that encoding is performed by the alpha-map encoder <b>200</b> shown in <figref idref="DRAWINGS">FIG. 2</figref> and decoding is performed by the alpha-map decoder <b>400</b> shown in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0245" num="0248"><figref idref="DRAWINGS">FIG. 76</figref> shows an example of the alpha-map decoder <b>400</b>. Alpha-map decoder <b>400</b> includes a divider unit <b>401</b>, and decoder <b>402</b>, and a switching device <b>403</b>.</p>
<p id="p-0246" num="0249"><figref idref="DRAWINGS">FIG. 35</figref> shows a frame of an alpha map divided into macro blocks MB each constructed by a predetermined number of pixels, i.e., 16×16 pixels. In <figref idref="DRAWINGS">FIG. 35</figref>, the square measures indicate the boundaries between the blocks, and each measure is the macro block MB.</p>
<p id="p-0247" num="0250">Since an alpha map indicates information of the object by using binary numbers in units of pixels, each pixel is black or white. Therefore, as shown in <figref idref="DRAWINGS">FIG. 35</figref>, the contents of the macro blocks MB in an alpha-map frame are classified into three categories, “all_white”, “all_black”, and “others”.</p>
<p id="p-0248" num="0251">In the case of a frame as shown in <figref idref="DRAWINGS">FIG. 35</figref> which is an alpha map of an image of a person, the background is “white” and the person is “black”. The macro blocks MB are constructed by macro blocks MBwh indicating the background, macro blocks MBbk indicating the person, and macro blocks MBot containing both the background and the person. Portions requiring encoding are the macro blocks MBot. As is apparent from <figref idref="DRAWINGS">FIG. 35</figref>, the macro blocks MBot are macro blocks containing the contour of an object OJ. That is, it is only necessary to apply the MMR-based coding method to macro blocks shown in <figref idref="DRAWINGS">FIG. 36</figref>. The macro blocks MBot exist in the region of the contour of the person and contain both the background and the person.</p>
<p id="p-0249" num="0252">When the methods of the first to fourth embodiments are applied to macro blocks MB as shown in <figref idref="DRAWINGS">FIGS. 37A and 37B</figref>, changed pixels detected are those in positions indicated by full circles in <figref idref="DRAWINGS">FIG. 37A</figref>. In the subsequent drawings, each macro block MB is illustrated as a block constructed by 8×8 pixels for the sake of simplicity.</p>
<p id="p-0250" num="0253">When the macro blocks MB are encoded in raster scan order from the upper left corner of a frame and decoded in raster scan order after being received, a pixel group (“top reference”) in contact with the upper edge of a macro block MB being encoded or decoded and a pixel group (“left reference”) in contact with the left edge of the macro block MB have known values on both of the transmitter and the receiver sides as shown in <figref idref="DRAWINGS">FIG. 37B</figref>. That is, since the processing is performed in raster scan order, “top reference” and “left reference” are the information of the adjacent macro blocks MB already processed and therefore have known values.</p>
<p id="p-0251" num="0254">When macro blocks MB are processed one after another in raster scan order, if pixels contacting the left edge of a macro block MB being processed are changed pixels such as those indicated by the full circles in <figref idref="DRAWINGS">FIG. 37A</figref>, these pixels must be encoded as changed pixels. This is extremely redundant information compared to information encoded in units of frames.</p>
<p id="p-0252" num="0255">To eliminate this redundancy, therefore, in the present invention a change of pixels on the left edge of the macro block MB from the value of “left reference” on the same line is detected and the first changed pixel having a color opposite to “pred_color” in a reference region is defined as “b<b>1</b>”. Consequently, the changed pixels are those in positions indicated by the full circles in <figref idref="DRAWINGS">FIG. 37B</figref>, and this greatly reduces redundant changed pixels compared to the case shown in <figref idref="DRAWINGS">FIG. 37A</figref>. “pred_color” includes “a<b>0</b>_color” (previous line) and “ref_color” (current line).</p>
<p id="p-0253" num="0256">The “current line” is a line to which the starting changed pixel “a<b>0</b>” belongs, and the “previous line” is a line one line above the “current line”. “a<b>0</b>_color” is the value (black or white (a black value or a white value)) of the starting changed pixel “a<b>0</b>”, and “ref_color” is the value of “left reference” on the same line as “current line”.</p>
<p id="p-0254" num="0257">The “top reference” indicates pixels in contact with the upper edge of the macro block MB shown in <figref idref="DRAWINGS">FIG. 37B</figref>. “left reference” indicates pixels in contact with the left edge of the macro block MB in <figref idref="DRAWINGS">FIG. 37B</figref>.</p>
<p id="p-0255" num="0258">In a case where a square region including the object is to be encoded, if the upper or the left edge of the macro block MB is in contact with the upper or the left end of the square region, all values of “top reference” and “left reference” are “white”.</p>
<p id="p-0256" num="0259">In each of the first to fourth embodiments, the method of predicting a change of the relative address by using the reproduced values of a plurality of lines is described. If this is the case, it is necessary to store “top reference” and “left reference” of a plurality of lines. It is also possible to sequentially encode the macro blocks MB from the one in the lower right corner. In this case the reproduced values contacting the lower and the right edges of the macro block MB are used.</p>
<p id="p-0257" num="0260">When motion compensation prediction is applied, the motion compensation prediction circuits <b>110</b> and <b>350</b> in the arrangements shown in <figref idref="DRAWINGS">FIGS. 2 and 3</figref> can generate a motion compensation predictive value for an alpha-map signal as well as for a picture signal. Since identical signals need only be obtained for each of “top reference” and “left reference” on the transmitter and receiver sides, motion compensation predictive values can be used as “top reference” and “left reference”. Also, as described in the first to fourth embodiments, relative address encoding with respect to motion compensation predictive values can be applied.</p>
<p id="p-0258" num="0261">The foregoing is an example of the processing in which macro blocks MB are compression-encoded one after another in raster scan order and decoded in raster scan order (order of x-direction scan in x-y scan). However, when macro blocks MB are compression-encoded and decoded one after another, the compression processing can be performed more efficiently, depending on the state of a picture, when performed in the vertical direction (in order of y-direction scan in x-y scan) than when performed in raster scan order. Therefore, it is useful to realize a method capable of selectively performing processing in raster order or in the vertical direction in accordance with the state of a picture. This method will be described below as the sixth embodiment.</p>
<p id="p-0259" num="0262">The sixth embodiment of the present invention will be described below with reference to <figref idref="DRAWINGS">FIGS. 38A to 38D</figref>. System configurations required in this embodiment can also be basically the same as the configurations shown in <figref idref="DRAWINGS">FIGS. 2 and 3</figref>. That is, it is only necessary to design the system such that encoding is performed by the alpha-map encoder <b>200</b> shown in <figref idref="DRAWINGS">FIG. 2</figref> and decoding is performed by the alpha-map decoder <b>400</b> shown in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0260" num="0263"><figref idref="DRAWINGS">FIG. 38B</figref> shows the scan order (scan from the left to the right (horizontal scan Sh)) in the first to fifth embodiments. <figref idref="DRAWINGS">FIG. 38A</figref> shows an example of changed pixels (pixels indicated by the full circles) detected by scan in this scan order. In this case twelve changed pixels are detected even by the use of the changed pixel detection method in the fifth embodiment. In this embodiment, therefore, as shown in <figref idref="DRAWINGS">FIG. 38D</figref>, changed pixels are detected in order of longitudinal scan (scan from the top to the bottom (vertical scan Sv)) by switching the row addresses and column addresses in the macro block MB. Consequently, the number of changed pixels detected is reduced from 12 in the scan method of <figref idref="DRAWINGS">FIG. 38B</figref> to 8 as shown in <figref idref="DRAWINGS">FIG. 38C</figref>. In this way the number of changed pixels can be reduced by changing the scan direction depending on the state of a picture.</p>
<p id="p-0261" num="0264">In the present invention, the amount of generated codes is reduced when the number of changed pixels is reduced for the same change amount between changed pixels. Therefore, the generated code amount in the scan order shown in <figref idref="DRAWINGS">FIG. 38D</figref> is smaller than that in <figref idref="DRAWINGS">FIG. 38B</figref>.</p>
<p id="p-0262" num="0265">Accordingly, the code amount can sometimes be reduced by adaptively switching the scan order in <figref idref="DRAWINGS">FIG. 38B</figref> and the scan order in <figref idref="DRAWINGS">FIG. 38D</figref>. If this is the case, to allow the decoding side to reconstruct data, it is necessary to encode and add information identifying the scan order to the data. On the basis of this information identifying the scan order, decoding is performed while the directions are switched.</p>
<p id="p-0263" num="0266">As described above, when macro blocks MB are compression-encoded and decoded one after another, the compression encoding can sometimes be performed more efficiently when performed in the vertical direction (in order of y-direction scan in x-y scan) than when performed in raster scan order, depending on the state of a picture. Therefore, the above embodiment realizes a system capable of selectively performing the processing in raster scan order or in the vertical direction in accordance with the state of a picture.</p>
<p id="p-0264" num="0267">It is, however, in some instances also possible to reduce the amount of codes by processing macro blocks MB, as square blocks, after rearranging them into wide rectangular blocks, instead of directly processing them in the form of a square block. This method will be described below as the seventh embodiment.</p>
<p id="p-0265" num="0268">The seventh embodiment of the present invention will be described below with reference to <figref idref="DRAWINGS">FIGS. 39A to 39C</figref>. System configurations required in this embodiment can also be basically the same as the configurations shown in <figref idref="DRAWINGS">FIGS. 2 and 3</figref>. It is only necessary to design the system such that encoding is performed by the alpha-map encoder <b>200</b> shown in <figref idref="DRAWINGS">FIG. 2</figref> and decoding is performed by the alpha-map decoder <b>400</b> shown in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0266" num="0269">In this embodiment, the values of “top reference” and “left reference” in the fifth embodiment are not used in order to independently encode macro blocks MB.</p>
<p id="p-0267" num="0270"><figref idref="DRAWINGS">FIG. 39A</figref> is a view for explaining the scan order of this embodiment. A square block of n×n pixels constituting the macro block MB as shown on the left side of <figref idref="DRAWINGS">FIG. 39A</figref> is formed into a raster-scanned rectangular block by alternately switching the scan directions of lines as shown on the right side of <figref idref="DRAWINGS">FIG. 39A</figref>. That is, the square block is horizontally scanned from the upper left pixel to the right along the line (S<b>1</b>). When the right end is reached, the scan moves to pixels on a line below, and the pixels are horizontally scanned from the right end to the left end along the line (S<b>2</b>). When the left end is reached, the scan moves to pixels on a line below, and the pixels are horizontally scanned from the left end to the right end along the line (S<b>3</b>). In this manner the scan is performed zigzag. One line is doubled by connecting two scanned lines, i.e., the number of lines is decreased in the vertical direction (column direction), thereby forming a rectangular block. More specifically, of the zigzag-scanned lines S<b>1</b>, S<b>2</b>, S<b>3</b>, S<b>4</b>, S<b>5</b>, S<b>6</b>, . . . , the uppermost line is formed by connecting the line S<b>2</b> to the line S<b>1</b>, the next line is formed by connecting the lines S<b>3</b> and S<b>4</b>, the next line is formed by connecting the lines S<b>5</b> and S<b>6</b>, and so on.</p>
<p id="p-0268" num="0271">By scanning a square block in this way so that the square block is rearranged into a wide rectangular block, the number of changed pixels is reduced from 10 in the square block to 5 in the rectangular block in the case of <figref idref="DRAWINGS">FIG. 39B</figref>.</p>
<p id="p-0269" num="0272">In this processing, however, the correlation between changed pixels is decreased. Therefore, if variable length codes designed for square blocks are used in encoding, the amount of codes is sometimes increased. If this is the case, it is only necessary to newly design rectangular block variable length codes and prepare them in the form of a table for rectangular blocks and perform encoding by using this rectangular block variable length code table.</p>
<p id="p-0270" num="0273">Also, in a case shown in <figref idref="DRAWINGS">FIG. 39C</figref>, the number of changed pixels remains unchanged even by the use of this embodiment, as can be seen from the drawing. On the contrary, the amount of generated codes increases if a square block is converted into a rectangular block, since the correlation between changed pixels is decreased.</p>
<p id="p-0271" num="0274">Pictures can take various states. Therefore, the amount of generated codes can sometimes be reduced by adaptively switching between a square block and a rectangular block, and so this embodiment is sufficiently significant.</p>
<p id="p-0272" num="0275">Even in the processing of macro blocks MB, it is in many instances inefficient to directly compress blocks with the macro block size. For example, when every line in a macro block MB assumes the same state of a picture such as when only a vertical belt-like line exists in a picture, data can be faithfully reproduced without decreasing the resolution even if the data is compressed while lines are thinned. An optimum method for a picture like this will be described below as the eighth embodiment.</p>
<p id="p-0273" num="0276">The eighth embodiment of the present invention will be described below with reference to <figref idref="DRAWINGS">FIGS. 6</figref>, <b>8</b>, and <b>40</b>A and <b>40</b>B. System configurations required in this embodiment can also be basically the same as the configurations shown in <figref idref="DRAWINGS">FIGS. 2 and 3</figref>. It is only necessary to design the system such that encoding is performed by the alpha-map encoder <b>200</b> shown in <figref idref="DRAWINGS">FIG. 2</figref> and decoding is performed by the alpha-map decoder <b>400</b> shown in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0274" num="0277">This embodiment solves the problem when the method of encoding a binary picture after reducing the picture used in the first embodiment is applied to processing whose unit is a macro block MB.</p>
<p id="p-0275" num="0278">As described above, an encoder and a decoder can be basically the same as those used in the first embodiment. In this embodiment, the configuration shown in <figref idref="DRAWINGS">FIG. 6</figref> already described above is used as an alpha-map encoder <b>200</b>, and the configuration shown in <figref idref="DRAWINGS">FIG. 8</figref> already described above is used as an alpha-map decoder <b>400</b>. Accordingly, the operations of individual components and the flows of signals are previously described in detail in the first embodiment and so a detailed description thereof will be omitted.</p>
<p id="p-0276" num="0279"><figref idref="DRAWINGS">FIGS. 40A and 40B</figref> are views showing examples of reduction of a binary picture. <figref idref="DRAWINGS">FIG. 40A</figref> shows examples of reduction using the method explained in the first embodiment. <figref idref="DRAWINGS">FIG. 40A</figref> shows examples of reduction using a reduction filter. More specifically, <figref idref="DRAWINGS">FIG. 40A</figref> illustrates reduction in which a conversion ratio CR is “1” (the state of no reduction), reduction in which the conversion ratio CR is “½” (the state of ½ reduction), and reduction in which the conversion ratio CR is “¼” (the state of ¼ reduction). Each state shows the result when a square block is directly thinned in the form of a square block.</p>
<p id="p-0277" num="0280"><figref idref="DRAWINGS">FIG. 40B</figref> shows examples of reduction in the vertical direction using the line thinning explained in the seventh embodiment. That is, <figref idref="DRAWINGS">FIG. 40B</figref> illustrates reduction in which the conversion ratio CR is “1” (the state of no reduction), reduction in which the conversion ratio CR is “½” (the state of ½ reduction), and reduction in which the conversion ratio CR is “¼” (the state of ¼ reduction). Each state shows the result when a square block is thinned and converted into a rectangular block.</p>
<p id="p-0278" num="0281">The conversion ratio CR is the reduction ratio supplied through the line <b>60</b> in the alpha-map encoder <b>200</b> shown in <figref idref="DRAWINGS">FIG. 6</figref>. In the first embodiment or MMR, if the value of the difference between the addresses of the changed pixel “b<b>1</b>” and the changed pixel “a<b>1</b>” is a threshold or less, a run with a length (a<b>1</b>−a<b>0</b>) and a run with a length (a<b>2</b>−a<b>1</b>) are encoded (horizontal mode).</p>
<p id="p-0279" num="0282">Also, since encoding is performed in units of macro blocks MB, the types of run lengths which can be generated are uniquely determined with respect to the value of each CR. When a square block is directly reduced in the form of a square block by thinning the data in both the horizontal and vertical directions as shown in <figref idref="DRAWINGS">FIG. 40A</figref>, the run length frequency distribution greatly changes due to a change in the conversion ratio CR. Therefore, the coding efficiency can be improved by performing variable length encoding in accordance with each CR by preparing variable length codes for run lengths in accordance with the CR.</p>
<p id="p-0280" num="0283">When the maximum run length is the number of horizontal pixels in a frame (macro block MB) as in the first embodiment, even a maximum number of types of run lengths is 17 (0 to 16). Therefore, the load of a memory for storing a variable length code table is small even when a plurality of variable length codes are prepared.</p>
<p id="p-0281" num="0284">In the example shown in <figref idref="DRAWINGS">FIG. 40B</figref>, since the correlation between changed pixels decreases when the conversion ratio CR is decreased, a variation in the relative address frequency distribution changes in accordance with a change in the conversion ratio CR. Accordingly, the amount of generated codes can be reduced by optimally switching variable length codes in accordance with CR. Note that even a maximum number of types of absolute values of relative addresses is 16 (0 to 15), and so the load of a memory is small even when a plurality of variable length code tables are prepared.</p>
<p id="p-0282" num="0285">In the example shown in <figref idref="DRAWINGS">FIG. 40A</figref>, the maximum values of the absolute values of the numbers of relative addresses that can be generated are different. Accordingly, the threshold for switching to the horizontal mode can be switched in accordance with CR. Also, the amount of codes can be controlled by adaptively switching the conversion ratios CR or the reduction methods (e.g., the forms shown in <figref idref="DRAWINGS">FIGS. 40A and 40B</figref>) for each macro block MB in accordance with the state of a picture.</p>
<p id="p-0283" num="0286">In the first to eighth embodiments described above, even in alpha-map coding performed in units of macro blocks, alpha maps can be encoded and decoded with no large increase in the amount of codes.</p>
<p id="p-0284" num="0287">Next, a motion picture transmission system to which a motion picture coding/decoding apparatus of the present invention is applied will be described below as one application of the invention with reference to <figref idref="DRAWINGS">FIGS. 41A to 41C</figref>.</p>
<p id="p-0285" num="0288">As shown in <figref idref="DRAWINGS">FIG. 41A</figref>, an input motion picture signal from a camera <b>1002</b> attached to a personal computer (PC) <b>1001</b> is encoded by a motion picture coding apparatus incorporated into the PC <b>1001</b>. The output coded data from the motion picture coding apparatus is multiplexed with information of voice or data, transmitted by radio by a radio transceiver <b>1003</b>, and received by another radio transceiver <b>1004</b>.</p>
<p id="p-0286" num="0289">The signal received by the radio transceiver <b>1004</b> is decomposed into the coded data of the motion picture signal and the information of voice or data. The coded data of the motion picture signal is decoded by a motion picture decoding apparatus incorporated into a workstation (EWS) <b>1005</b> and displayed on a display of the EWS <b>1005</b>.</p>
<p id="p-0287" num="0290">An input motion picture signal from a camera <b>1006</b> attached to the EWS <b>1005</b> is encoded in the same manner as above by a motion picture coding apparatus incorporated into the EWS <b>1005</b>. The coded data of the motion picture signal is multiplexed with information of voice or data, transmitted by radio by the radio transceiver <b>1004</b>, and received by the radio transceiver <b>1003</b>. The signal received by the radio transceiver <b>1003</b> is decomposed into the coded data of the motion picture signal and the information of voice or data. The coded data of the motion picture signal is decoded by a motion picture decoding apparatus incorporated into the PC <b>1001</b> and displayed on a display of the PC <b>1001</b>.</p>
<p id="p-0288" num="0291"><figref idref="DRAWINGS">FIG. 41B</figref> is a block diagram schematically showing the arrangement of the motion picture coding apparatus incorporated into the PC <b>1001</b> and the EWS <b>1005</b> shown in <figref idref="DRAWINGS">FIG. 41A</figref>. <figref idref="DRAWINGS">FIG. 41C</figref> is a block diagram schematically showing the arrangement of the motion picture decoding apparatus incorporated into the PC <b>1001</b> and the EWS <b>1005</b> shown in <figref idref="DRAWINGS">FIG. 41A</figref>.</p>
<p id="p-0289" num="0292">The motion picture coding apparatus shown in <figref idref="DRAWINGS">FIG. 41B</figref> comprises an information source encoder <b>1102</b> which is supplied with a picture signal from a picture input unit <b>1101</b> such as a camera and has an error robust processor <b>1103</b>, and a transmission path encoder <b>1104</b>. The information source encoder <b>1101</b> performs discrete cosine transformation (DCT) for a prediction residue signal and quantizes the generated DCT coefficient. The transmission path encoder <b>114</b> performs variable length encoding, error detection for coded data, and error correction encoding. The output coded data from the transmission path encoder <b>1104</b> is supplied to the radio transceiver <b>1105</b> and transmitted. The processing in the information source encoder <b>1101</b> and the variable length encoding in the transmission path encoder <b>1104</b> are performed by using the processing methods explained in the embodiments of the present invention.</p>
<p id="p-0290" num="0293">The motion picture decoding apparatus shown in <figref idref="DRAWINGS">FIG. 41C</figref> comprises a transmission path decoder <b>1202</b> and an information source decoder <b>1203</b>. The transmission path decoder <b>1202</b> is supplied with the coded data received by a radio transceiver <b>1201</b> and performs processing which is the reverse of the processing performed by the transmission path encoder <b>1104</b>. The information source decoder <b>1203</b> is supplied with the output signal from the transmission path decoder <b>1202</b> and performs processing which is the reverse of the processing performed by the information source encoder <b>1102</b>. The information source decoder <b>1203</b> has an error robust processor <b>1204</b>. The picture decoded by the information source decoder <b>1203</b> is output by a picture output unit <b>1205</b> such as a display.</p>
<p id="p-0291" num="0294">The decoding operations in these decoders are performed by using the processing methods as explained in the embodiments of the present invention.</p>
<p id="p-0292" num="0295">In the present invention, the amount of codes of alpha maps can be greatly reduced. Accordingly, the background and the object can be separately encoded with no large decrease in the encoding efficiency compared to conventional encoding methods.</p>
<p id="p-0293" num="0296">A ninth embodiment for Encoding Motion Vector (MV) for Alpha Map will be described hereinafter.</p>
<p id="p-0294" num="0297">In the above-described “Second Embodiment”, a method of encoding a video image using the correlation between frames has been described in which the line of a previous frame is used as a reference line, and the correlation between the frames is used to increase the encoding processing efficiency. This method is used for processing in units of MB lines (in one line unit in the line direction of a macro block). As is apparent, even with processing in units of MB lines, the generality is maintained.</p>
<p id="p-0295" num="0298">An embodiment will be described below in which encoding using the correlation between frames is performed in units of macro blocks, thereby increasing the encoding processing efficiency.</p>
<p id="p-0296" num="0299">In this embodiment, the correlation between a motion compensation prediction (MC) signal of an alpha map and the signal of the MB (macro block) is evaluated in units of MBs. If the evaluation value is smaller than a predetermined threshold value, the MC signal is copied to the MB (to be referred to as copy encoding hereinafter). If the evaluation value is larger than the threshold value, the MB is encoded using the binary picture coding method of the present invention.</p>
<p id="p-0297" num="0300">In performing copy encoding, when the correlation between the “MV (motion vector) of the alpha map” and the “MV (motion vector) of a Y (luminance) signal” is very high, the MV obtained on the basis of the Y signal is used without any processing. With this operation, copy encoding is enabled without using the amount of codes for the “MV of the alpha map”.</p>
<p id="p-0298" num="0301">Japanese Patent Application No. 8-116542 discloses an invention in which a signal obtained by blending an alpha map and a Y signal (this processing is generally referred to as alpha blending) is used to detect an MV (motion vector), thereby detecting a common MV (this MV (motion vector) will be represented as MVYA hereinafter) for the alpha map and the Y signal.</p>
<p id="p-0299" num="0302">More specifically, when MC (motion compensation prediction) of the alpha map is performed using the “MVYA” as a common motion vector for the alpha map and the Y signal, no MV information is necessary for copy encoding of the alpha map. That is, the information of the motion vector of the alpha map is unnecessary in copy encoding of the alpha map.</p>
<p id="p-0300" num="0303">In this case, however, although the amount of codes of the alpha map is reduced, no optimum MV for the Y signal is detected. Therefore, an MV error value (the error value of the motion compensation prediction signal of the alpha map) of the Y signal may increase to decrease the encoding efficiency in the entire encoding system.</p>
<p id="p-0301" num="0304">This corresponds to a case in which an optimum motion vector MVY for the Y signal is detected, or a case in which an optimum motion vector MVA for the alpha map is detected. In such a case, the encoding efficiency inevitably decreases.</p>
<p id="p-0302" num="0305">More specifically, the encoding efficiency may decrease in a case shown in <figref idref="DRAWINGS">FIG. 42A</figref> or <b>42</b>B. Of these examples, in the case shown in <figref idref="DRAWINGS">FIG. 42A</figref>, the optimum motion vector MVY for the Y signal is detected. A description will be made while paying attention to the partial image of a certain macro block at a certain point of time. A position indicated by the motion vector MVY for the Y signal, which is detected in the previous frame, matches a position where the partial image appears in the subsequent frame. The error evaluation value used here means an error value in a pixel value contained in an object.</p>
<p id="p-0303" num="0306"><figref idref="DRAWINGS">FIG. 42B</figref> shows a case in which the optimum motion vector MVA for the alpha map is detected. A description will be made while paying attention to the contents of the alpha map at a certain macro block at a certain point of time. A position indicated by the motion vector MVA for the contents of the alpha map, which is detected in the previous frame, matches a position where the contents of the alpha map appear in the subsequent frame. The error value used here means the number of mismatched pixels of the alpha map.</p>
<p id="p-0304" num="0307">The vector MVYA is an MV (motion vector) similar to the vector MVA rather than the vector MVY. For this reason, comparing to a case in which the optimum value MVA is used, the amount of codes of alpha map encoding rarely increases.</p>
<p id="p-0305" num="0308">On the other hand, even when the vector “MVY” used as a common MV, copy encoding is not selected because the MC error (motion compensation prediction error) of the alpha map increases, so the alpha map encoding efficiency is not increased.</p>
<p id="p-0306" num="0309">To solve the above problem, as shown in <figref idref="DRAWINGS">FIG. 42C</figref>, a difference MVDA between the optimum motion vector MVA for the alpha map and the optimum motion vector MVY for the luminance signal is obtained, and the obtained difference MVDA is efficiently encoded. By calculating the difference between the vectors MVA and MVY and encoding the difference, the alpha map encoding efficiency can be increased without decreasing the encoding efficiency of the Y signal (luminance signal).</p>
<p id="p-0307" num="0310">If the value MVDA as the difference between the vectors MVA and MVY has a large value, the amount of codes in binary picture encoding of the block may be smaller than the amount of codes of the motion vector. In addition, since the value MVDA is a difference vector from the vector MVY, the dynamic range is small.</p>
<p id="p-0308" num="0311">When the maximum value of the search range of the vector MVDA is limited to be smaller than the search range of the vector MVY, the amount of codes of the vector MVDA may be traded off for that in binary picture encoding. When the search range of the vector MVDA is limited, the encoding table for the vector MVDA is smaller than the encoding table for encoding the vector MVY (what is actually encoded is the prediction error of the vector MVY, and the dynamic range of this prediction error is twice that of the vector MVY). Therefore, the encoding efficiency is further increased by designing a small variable length code table for the vector MVDA.</p>
<p id="p-0309" num="0312">To practice the ninth embodiment, the optimum motion vector MVA for the alpha map must be detected. A detailed example of this detection operation will be described.</p>
<p id="p-0310" num="0313">Assume that the vector MVY for the Y signal (the optimum motion vector for the Y signal) has already been sent. The vector MVDA corresponding to the difference between the vectors MVA and MVY is detected around a position indicated by the vector MVY. As described above, copy encoding of the alpha map is executed when the MC error (motion compensation prediction error) of the alpha map becomes smaller than a predetermined threshold value. The error is evaluated from the central position to the outside, and the vector MVDA at a position where the error becomes smaller than the threshold value for the first time is used.</p>
<p id="p-0311" num="0314">The smallest MVDA is detected and used. Generally, as the value MVDA is smaller, a short code is assigned, so that the vector MVDA is efficiently encoded.</p>
<p id="p-0312" num="0315">Encoding of the motion vector has been described above. A method of encoding the attribute information of a macro block in units of frames is also available. This method will be described below as the 10th embodiment. (10th Embodiment)</p>
<p id="p-0313" num="0316">An embodiment in which the attribute information of each macro block is encoded in units of frames will be described as the 10th embodiment.</p>
<p id="p-0314" num="0317"><figref idref="DRAWINGS">FIG. 38</figref> in the sixth embodiment shows the attribute of each block (macro block MB) in block-based binary picture encoding of the present invention. The attribute information of the block (MB) must be encoded independently of the binary picture encoding information.</p>
<p id="p-0315" num="0318"><figref idref="DRAWINGS">FIG. 43A</figref> is a view as reillustration of <figref idref="DRAWINGS">FIG. 38</figref>. Referring to <figref idref="DRAWINGS">FIG. 43A</figref>, a macro block indicating only a “white” portion is represented by MBwh, a macro block indicating both the background and the person is represented by MBot, and a macro block indicating only a “black” portion is represented by MBbk. The macro block MBwh of only the “white” portion is labeled as “0”, the macro block MBot of both the background and the person is labeled as “1”, and the macro block MBbk of only the “black” portion is labeled as “3”. <figref idref="DRAWINGS">FIG. 43A</figref> represents block type information shown in <figref idref="DRAWINGS">FIG. 43B</figref>. The block type information is the attribute information of an MB.</p>
<p id="p-0316" num="0319">There are three labels such as “0”, “1”, and “3”, and each information can be expressed by two bits. That is, a decimal digit “0” is expressed by “00” in binary notation; “1”, by “01”; and “3”, by “11”.</p>
<p id="p-0317" num="0320">Since the block type information can be expressed in two bits, this information can be decomposed into the upper bit (MSB) and the lower bit (LSB), as shown in <figref idref="DRAWINGS">FIG. 43C</figref>. In <figref idref="DRAWINGS">FIG. 43C</figref>, Bpo indicates that the original block type information is (MB attribute information); Bpl, the bit plane of lower bits (LSBs) obtained by decomposing the information Bpo into bit planes; and Bpm, the bit plane of upper bits (MSBs) obtained by decomposing the information Bpo.</p>
<p id="p-0318" num="0321">Generally, when the block attribute information of the alpha map, which represents whether a block indicates an object, as shown in <figref idref="DRAWINGS">FIG. 43A</figref>, is labeled as in <figref idref="DRAWINGS">FIG. 43B</figref>, and the information is decomposed into the upper and lower bit planes Bpl and Bpm in <figref idref="DRAWINGS">FIG. 43C</figref>, “0” and “1” tend to gather in both the bit planes. That is, the correlation can be kept in both the MSB and the LSB.</p>
<p id="p-0319" num="0322"><figref idref="DRAWINGS">FIG. 44</figref> is a view showing an example in which each bit plane shown in <figref idref="DRAWINGS">FIG. 43C</figref> is encoded by block-based MMR of the present invention. As shown in <figref idref="DRAWINGS">FIG. 44</figref>, when each bit plane is encoded by highly efficient binary picture encoding, the amount of codes of the block attribute information can be largely reduced as compared to that in encoding in units of blocks.</p>
<p id="p-0320" num="0323">In addition, the binary picture encoding method of encoding the attribute of a block is made identical to the binary picture encoding method of encoding each block, thereby relaxing the complexity of the entire encoding system.</p>
<p id="p-0321" num="0324">The detailed example of the method of encoding the block attribute information has been described above. Another method of encoding the block attribute information will be described next.</p>
<p id="p-0322" num="0325"><figref idref="DRAWINGS">FIGS. 45A and 45B</figref> are views showing examples of the attribute information of a certain macro block at time n and at time n−1. As shown in <figref idref="DRAWINGS">FIG. 42A</figref>, a square region is set such that the upper left portion of the object contacts the boundary portion of the region. In this case, similar labeling is performed for both the alpha maps of frames in a short time, like the example of the block attribute information at time n shown in <figref idref="DRAWINGS">FIG. 45A</figref> and the example of the block attribute information at time n−1 shown in <figref idref="DRAWINGS">FIG. 45B</figref>. The correlation of labeling between the frames is high. Therefore, when the label of the current frame is encoded using the label of a frame which has already been encoded, the encoding efficiency is largely increased.</p>
<p id="p-0323" num="0326">In some cases, the size of the region at time n is different from that at time n−1. In this case, with procedures shown in, e.g., <figref idref="DRAWINGS">FIGS. 46A and 46B</figref>, the size of the region at time n−1 is made to match that at time n. For example, when the macro block at time n is larger by one row and smaller by one column than that at time n−1, the rightmost column of the macro block at time n−1 is cut, and thereafter, the lowermost row is copied to its lower portion to increase the size by one row. <figref idref="DRAWINGS">FIG. 46B</figref> is a view showing this state.</p>
<p id="p-0324" num="0327">When the macro block at time n−1 is smaller by one column and larger by one row than that at time n, the lowermost row is cut, and thereafter, the rightmost column is copied to its adjacent portion to increase the size by one column.</p>
<p id="p-0325" num="0328">When the size changes, the sizes are made to match in this manner. The method of matching the sizes is not limited to that described above. For the descriptive convenience, the label of the macro block at time n−1 whose size is equal to that at time n will be represented as the label at time n−1 ′ hereinafter.</p>
<p id="p-0326" num="0329"><figref idref="DRAWINGS">FIG. 47A</figref> is a view showing the difference between the attribute information of the macro block at time n and that at time n−1 ′, i.e., the difference between the labels of corresponding pixels. In <figref idref="DRAWINGS">FIG. 47A</figref>, “S” represents that the “labels match each other”, and “D” represents that the “labels do not match each other”.</p>
<p id="p-0327" num="0330"><figref idref="DRAWINGS">FIG. 47B</figref> is a view showing the differences between the labels at adjacent pixel positions in the attribute information of the macro block at time n. For a label at the left end, the difference with respect to the label at the right-end pixel position one line above the label at the left end is obtained. For a label at the upper left pixel position, the difference with respect to “0” is obtained. For the descriptive convenience, the method shown in <figref idref="DRAWINGS">FIG. 47A</figref> will be referred to as interframe encoding, and the method shown in <figref idref="DRAWINGS">FIG. 47B</figref> will be referred to as intraframe encoding hereinafter.</p>
<p id="p-0328" num="0331">As is apparent from <figref idref="DRAWINGS">FIGS. 47A and 47B</figref>, the ratio of “S” in interframe encoding is higher than that in intraframe encoding. Since interframe encoding can perform prediction at a higher probability, reduction of the amount of codes can be achieved.</p>
<p id="p-0329" num="0332"><figref idref="DRAWINGS">FIG. 49</figref> is a view showing an example of a variable length encoding table for encoding each label.</p>
<p id="p-0330" num="0333">When a label to be encoded matches the predictive value (interframe: the label of the previous frame, intraframe: the adjacent label) (in case of “S”), encoding is performed by one-bit codes. When the label does not match the predictive value (in case of “D”), encoding is performed by two-bit codes. With this method, the amount of codes can be reduced.</p>
<p id="p-0331" num="0334">In interframe encoding, the ratio of “S” is high. Therefore, the encoding efficiency can be further increased by encoding a plurality of labels at once.</p>
<p id="p-0332" num="0335"><figref idref="DRAWINGS">FIG. 48</figref> is a view showing an example in which whether all the differences between the labels in one line are “S” is represented by a one-bit code. In this case, only the labels of lines where all the differences are not “S” are encoded. Therefore, the amount of codes is largely reduced.</p>
<p id="p-0333" num="0336">When the correlation between frames is extremely small, the encoding efficiency may be lower than that in intraframe encoding. In this case, switching between intraframe encoding using one-bit codes and interframe encoding is enabled such that intraframe encoding can also be performed. The frame which is to be encoded first is subjected to intraframe encoding because it has no label to be referred to, as a matter of course. At this time, no code for switching between interframe encoding and intraframe encoding is needed.</p>
<p id="p-0334" num="0337"><figref idref="DRAWINGS">FIGS. 50A and 50B</figref> are block diagrams of the system of this embodiment, and the flow of the process will be described with reference to <figref idref="DRAWINGS">FIGS. 50A and 50B</figref>.</p>
<p id="p-0335" num="0338">In <figref idref="DRAWINGS">FIGS. 50A and 50B</figref>, parts enclosed by broken lines are associated with this embodiment. <figref idref="DRAWINGS">FIG. 50A</figref> shows a coding apparatus comprising an object region detector <b>3100</b>, a block forming circuit <b>3110</b>, a labeling circuit <b>3120</b>, a block encoder <b>3130</b>, a label memory <b>3140</b>, a size changing circuit <b>3150</b>, a label encoder <b>3160</b>, and a multiplexer (MUX) <b>3170</b>.</p>
<p id="p-0336" num="0339">The object region detector <b>3100</b> detects, on the basis of an input alpha-map signal, a square region for a portion including an object in the alpha-map signal, and outputs the alpha-map signal of the square region together with information associated with the size of the square region. The block forming circuit <b>3110</b> forms macro blocks from the alpha-map signal of the square region. The labeling circuit <b>3120</b> determines the attributes (MBwh (only white), MBot (mixture of white and black), and MBbk (only black)) of the alpha-map signal contents in the macro blocks in units of blocks of the alpha-map signal which has been divided into macro blocks, and assigns a label (“0”, “1”, or “3”) corresponding to each attribute.</p>
<p id="p-0337" num="0340">For a macro block with label “1” (MBot), the block encoder <b>3130</b> encodes the alpha-map signal in the macro block. The label memory <b>3140</b> accumulates label information supplied from the labeling circuit <b>3120</b> and region size information supplied from the object region detector <b>3100</b> through a label memory output line <b>3020</b> and also supplies the accumulated label information and size information to the size changing circuit <b>3150</b>.</p>
<p id="p-0338" num="0341">The size changing circuit <b>3150</b> changes the size of the label information at time n−1 in correspondence with the size at time n, on the basis of the label information and size information of the frame at time n−1which are supplied from the label memory <b>3140</b>, and the frame size information at time n, which is supplied from the object region detector <b>3100</b>. The label encoder <b>3160</b> encodes the label information supplied from the labeling circuit <b>3120</b> by using the label information changed in size as a predictive value.</p>
<p id="p-0339" num="0342">The multiplexer <b>3170</b> multiplexes the encoded information obtained by the label encoder <b>3160</b>, encoded information supplied from the block encoder <b>3130</b>, and the size information supplied from the object region detector <b>3100</b> and outputs the information.</p>
<p id="p-0340" num="0343">In the coding apparatus with this arrangement, the square region including the object is detected by the object region detector <b>3100</b> from the alpha-map signal supplied through a line <b>3010</b>. Information associated with the size of this square region is output through the line <b>3020</b>. The alpha-map signal in the region is supplied to the block forming circuit <b>3110</b>. The block forming circuit <b>3110</b> forms the macro blocks of the alpha-map signal in this region. The alpha-map signal divided into macro blocks is supplied to the labeling circuit <b>3120</b> and the block encoder <b>3130</b>.</p>
<p id="p-0341" num="0344">The labeling circuit <b>3120</b> determines the attributes (MBwh, MBot, and MBbk) in units of macro blocks and assigns a label (“0”, “1”, or “3”) corresponding to each attribute. This label information is supplied to the block encoder <b>3130</b>, the label memory <b>3140</b>, and the label encoder <b>3160</b>.</p>
<p id="p-0342" num="0345">The block encoder <b>3130</b> encodes the alpha-map signal in the block when the label is “1” (MBot). The encoded information is supplied to the multiplexer <b>3170</b>. The label memory <b>3140</b> accumulates the label information supplied from the labeling circuit <b>3120</b> and the region size information supplied through the label memory output line <b>3020</b> and outputs the label information and size information to the size changing circuit <b>3150</b> through a label memory output line <b>3030</b>.</p>
<p id="p-0343" num="0346">The size changing circuit <b>3150</b> changes in size the label information at the time n−1 in correspondence with the size at time n, on the basis of the label information and size information of the frame at time n−1which is supplied through the label memory output line <b>3030</b>, and the size information at time n, which is supplied through the line <b>3020</b>, and supplies the size-changed label information at time n−1 to the label encoder <b>3160</b>. The label encoder <b>3160</b> encodes the label information supplied from the labeling circuit <b>3120</b> by using the label information supplied from the size changing circuit <b>3150</b> as a predictive value, and supplies the encoded information to the multiplexer <b>3170</b>. The multiplexer <b>3170</b> multiplexes the encoded information supplied from the block encoder <b>3130</b> and the label encoder <b>3160</b> and the size information supplied through the line <b>3020</b> and outputs the information through a line <b>3040</b>.</p>
<p id="p-0344" num="0347">The arrangement and function of the coding apparatus have been described above. The arrangement and function of a decoding apparatus will be described next.</p>
<p id="p-0345" num="0348">The decoding apparatus shown in <figref idref="DRAWINGS">FIG. 50B</figref> comprises a demultiplexer (DMUX) <b>3200</b>, a label decoder <b>3210</b>, a size changing circuit <b>3220</b>, a label memory <b>3230</b>, and a block decoder <b>3240</b>. The demultiplexer <b>3200</b> demultiplexes encoded information supplied through a line <b>3050</b>. The label decoder <b>3210</b> reconstructs the label information at time n by using the label information at time n−1, which has been changed in size and supplied from the size changing circuit <b>3220</b>.</p>
<p id="p-0346" num="0349">The size changing circuit <b>3220</b> acts like the size changing circuit <b>3150</b>. The size changing circuit <b>3220</b> changes the size of the label information at time n−1 in correspondence with the size at time n, on the basis of the label information and size information of the frame at time n−1, which are supplied from the label memory <b>3230</b>, and the frame size information at time n, which is demultiplexed and supplied from the demultiplexer <b>3200</b>. The label memory <b>3230</b> acts like the label memory <b>3140</b>. The label memory <b>3230</b> accumulates the label information decoded and supplied from the label decoder <b>3210</b> and the region size information supplied from the demultiplexer <b>3200</b> and supplies the accumulated label information and size information to the size changing circuit <b>3220</b>.</p>
<p id="p-0347" num="0350">The block decoder <b>3240</b> reconstructs the alpha-map signal in units of blocks in accordance with the reconstructed label information supplied from the label decoder <b>3210</b>.</p>
<p id="p-0348" num="0351">The function of the decoding apparatus with the above arrangement will be described. The demultiplexer <b>3200</b> demultiplexes the encoded information supplied through the line <b>3050</b> and supplies the information to the block decoder <b>3240</b> and the label decoder <b>3210</b>, and at the same time, outputs the size information through a line <b>3060</b>. The label decoder <b>3210</b> reconstructs the label information at time n by using the label information at time n−1, which has been changed in size and supplied from the size changing circuit <b>3220</b>, as a predictive value.</p>
<p id="p-0349" num="0352">The reconstructed label information is supplied to the block decoder <b>3240</b> and the label memory <b>3230</b>. The block decoder <b>3240</b> reconstructs the alpha-map signal in units of blocks in accordance with the reconstructed label information supplied from the label decoder <b>3210</b>. The size changing circuit <b>3220</b> and the label memory <b>3230</b> perform the same operations as those of the size changing circuit <b>3150</b> and the label memory <b>3230</b>, respectively, and a detailed description thereof will be omitted.</p>
<p id="p-0350" num="0353">The coding apparatus which assigns labels to the alpha map in units of macro blocks and encodes the labels of the macro blocks of the current frame by using the labels of the macro blocks of an already encoded frame, and the decoding apparatus have been described above. Similar labels are assigned to the macro blocks of alpha maps in frames close to each other along the time axis. In such a case, the correlation of labels between the frames is high. When the labels of the already encoded frame are used to encode the labels of the current frame, the encoding efficiency can be largely increased.</p>
<p id="p-0351" num="0354">An encoding system using vector quantization will be described as the 11th embodiment. In this embodiment, to efficiently encode an alpha map, the alpha map is divided into square blocks, and encoding is performed in units of blocks. A reference pattern extracted from part of an already encoded block is used to generate an index table for vector quantization in units of blocks. The index table is used to encode the alpha map by vector quantization.</p>
<p id="p-0352" num="0355"><figref idref="DRAWINGS">FIG. 51</figref> is a block diagram showing a detailed example of an encoder of the present invention, which uses vector quantization. This encoder comprises a memory <b>1605</b>, a vector quantizer <b>1607</b>, an index table generator <b>1609</b>, and a vector inverse quantizer <b>1613</b>.</p>
<p id="p-0353" num="0356">The memory <b>1605</b> holds an alpha map whose already encoded portion is decoded. The index table generator <b>1609</b> generates an index table <b>1612</b> of various pixel patterns on the basis of the information held in the memory <b>1605</b>. In this table, each pixel pattern of a plurality of macro blocks is made to correspond to an index number. The vector quantizer <b>1607</b> obtains, on the basis of an input alpha-map signal <b>1606</b> and the index table <b>1612</b> output from the index table generator <b>1609</b>, an index <b>1614</b> of one of the pixel patterns in the index table <b>1612</b>, which has a small error with respect to the alpha-map signal <b>1606</b>. The vector quantizer <b>1607</b> outputs the index <b>1614</b>.</p>
<p id="p-0354" num="0357">The vector inverse quantizer <b>1613</b> obtains a pixel pattern corresponding to the index <b>1614</b> by using the index <b>1614</b> output from the vector quantizer <b>1607</b> and the index table <b>1612</b> output from the index table generator <b>1609</b>, and at the same time, supplies the obtained pixel pattern to the memory <b>1605</b> as a decoded alpha map <b>1615</b>.</p>
<p id="p-0355" num="0358">The decoder with the above arrangement of the this embodiment is arranged at the portion of the alpha-map encoder <b>200</b> of the video coding apparatus shown in <figref idref="DRAWINGS">FIG. 2</figref>. An alpha-map signal is input to this encoder, and the index <b>1614</b> obtained upon vector quantization of this alpha-map signal is output from the encoder. The alpha-map frame is divided into blocks, as shown in <figref idref="DRAWINGS">FIG. 59</figref>. The blocks are sequentially encoded in an order from the upper left block. A region <b>5</b>-<b>1</b> indicated by horizontal lines is an object region. The portion except for the object region is a background region <b>5</b>-<b>2</b>.</p>
<p id="p-0356" num="0359"><figref idref="DRAWINGS">FIG. 60</figref> is a view showing an intermediate encoded state of the frame. In <figref idref="DRAWINGS">FIG. 60</figref>, a portion <b>5</b>-<b>3</b> enclosed by a thick line represents an already encoded portion, and a block <b>5</b>-<b>4</b> is being encoded currently. As shown in <figref idref="DRAWINGS">FIG. 61</figref>, to encode the current block <b>5</b>-<b>4</b>, adjacent pixel strings are used as a top reference pattern <b>5</b>-<b>10</b> and a left reference pattern <b>5</b>-<b>11</b>.</p>
<p id="p-0357" num="0360">The pixel values of the top reference pattern <b>5</b>-<b>10</b> are represented as T<b>1</b>, T<b>2</b>, . . . , and TB from the left side. The pixel values of the left reference pattern <b>5</b>-<b>11</b> are represented as L<b>1</b>, L<b>2</b>, . . . , and LB from the upper side. “B” is the number of pixels (block size) of one side of the block.</p>
<p id="p-0358" num="0361">Referring back to <figref idref="DRAWINGS">FIG. 51</figref>, the encoder of the present invention comprises the memory <b>1605</b>, the vector quantizer <b>1607</b>, the index table generator <b>1609</b>, and the vector inverse quantizer <b>1613</b>. The memory <b>1605</b> holds an alpha map whose already encoded portion is decoded. The alpha-map signal <b>1606</b> is input to the vector quantizer <b>1607</b>. Top and left reference patterns <b>1608</b> of the already encoded portion are sequentially read out from the memory <b>1605</b> and sent to the index table generator <b>1609</b>.</p>
<p id="p-0359" num="0362">On the basis of the reference patterns <b>1608</b>, the index table generator <b>1609</b> generates the index table <b>1612</b> used for vector quantization (“Multi-dimensional Signal Processing of TV Image”, Nikkan Kogyo Shinbunsha, 1988, pp. 261-262) and sends the index table <b>1612</b> to the vector quantizer <b>1607</b> and the vector inverse quantizer <b>1613</b>.</p>
<p id="p-0360" num="0363">The index table makes each pixel pattern of the plurality of macro blocks correspond to an index number.</p>
<p id="p-0361" num="0364">The vector quantizer <b>1607</b> obtains the index <b>1614</b> of one of the pixel patterns of the index table <b>1612</b> output from the index table generator <b>1609</b>, which has a small error with respect to the alpha-map signal <b>1606</b>. The index <b>1614</b> is also output and sent to the vector inverse quantizer <b>1613</b>.</p>
<p id="p-0362" num="0365">The vector inverse quantizer <b>1613</b> obtains a pixel pattern corresponding to the index <b>1614</b> by using the index table <b>1612</b>. The obtained pixel pattern is sent from the vector inverse quantizer <b>1613</b> to the memory <b>1605</b> as the decoded alpha map <b>1615</b>.</p>
<p id="p-0363" num="0366">A detailed example of the index table generator <b>1609</b> will be described referring to <figref idref="DRAWINGS">FIGS. 53 to 55</figref>.</p>
<p id="p-0364" num="0367">In the index table generator <b>1609</b> having an arrangement shown in <figref idref="DRAWINGS">FIG. 53</figref>, when one of prepared types is designated, the index table corresponding to the designated type is generated. The index table generator <b>1609</b> comprises a type determining section <b>1616</b> for designating a type to be used, a generator <b>1619</b> for generating an index table, and a memory <b>1621</b> for holding the generated index table.</p>
<p id="p-0365" num="0368">In the index table generator <b>1609</b> having this arrangement, the reference patterns <b>1608</b> are sent to the type determining section <b>1616</b>.</p>
<p id="p-0366" num="0369">Several pixel patterns with different tendencies can be selected. When a desired pixel pattern is designated, the type determining section <b>1616</b> determines to use the designated one of the several prepared types and sends the information of a type <b>1617</b> and the information of a parameter <b>1618</b> to the generator <b>1619</b>. The generator <b>1619</b> generates an index table <b>1620</b> corresponding to the designated type upon receiving the information and causes the memory <b>1621</b> to temporarily hold the generated index table <b>1620</b>. An index table <b>1622</b> is properly output in the encoding process.</p>
<p id="p-0367" num="0370"><figref idref="DRAWINGS">FIG. 68</figref> is a flow chart showing the algorithm of processing of the type determining section <b>1616</b>.</p>
<p id="p-0368" num="0371">S<b>1</b>: First, the type determining section <b>1616</b> determines whether the pixel value T<b>1</b> of the top reference pattern <b>5</b>-<b>10</b> described in <figref idref="DRAWINGS">FIG. 61</figref> equals the pixel value L<b>1</b> of the left reference pattern <b>5</b>-<b>11</b>. If YES in step S<b>1</b>, the flow advances to step S<b>2</b>; otherwise, the flow advances to step S<b>4</b>.</p>
<p id="p-0369" num="0372">S<b>2</b>: The pixel string in the row direction of the macro block is viewed from the left side. The first pixel having a value different from the previous pixel value is represented by RT. The pixel string in the column direction is viewed from the upper side. The first pixel having a value different from the previous pixel value is represented by RL. When “RT” equals “B” (the number of pixels of one side of the macro block (block size)), and “RL” equals “B”, the flow advances to step S<b>5</b>; otherwise, the flow advances to step S<b>3</b>. The values RT and RL will be described in more detail. The pixel values are sequentially checked in the order of T<b>1</b>, T<b>2</b>, T<b>3</b>, . . . . If a pixel value Tk is different from the value T<b>1</b>, RT is represented as k-<b>1</b>. If all the pixel values up to the last pixel TB in the row direction of the macro block equal the pixel value T<b>1</b>, RL=B (“B” is the block size described in <figref idref="DRAWINGS">FIG. 61</figref>). In <figref idref="DRAWINGS">FIG. 63</figref> (B=16), for example, RT=10.</p>
<p id="p-0370" num="0373">Similarly, “RL” is associated with the pixel values L<b>1</b>, L<b>2</b>, . . . . In <figref idref="DRAWINGS">FIG. 63</figref>, RL=6.</p>
<p id="p-0371" num="0374">S<b>3</b>: When “RT” equals “B”, or when “RL” equals “B”, the flow advances to step S<b>6</b>; otherwise, the flow advances to step S<b>7</b>.</p>
<p id="p-0372" num="0375">S<b>4</b>: When “RT” equals “B”, and when “RL” equals “B”, the flow advances to step S<b>8</b>; otherwise, the flow advances to step S<b>9</b>.</p>
<p id="p-0373" num="0376">S<b>5</b>: Type M=1. The flow advances to step S<b>10</b>.</p>
<p id="p-0374" num="0377">S<b>6</b>: Type M=2. The flow advances to step S<b>10</b>.</p>
<p id="p-0375" num="0378">S<b>7</b>: Type M=3. The flow advances to step S<b>10</b>.</p>
<p id="p-0376" num="0379">S<b>8</b>: Type M=4. The flow advances to step S<b>10</b>.</p>
<p id="p-0377" num="0380">S<b>9</b>: Type M=5. The flow advances to step S<b>10</b>.</p>
<p id="p-0378" num="0381">S<b>10</b>: An index table is prepared on the basis of “M”, “RT”, and “RL”.</p>
<p id="p-0379" num="0382">When this algorithm is used, the parameters <b>1618</b> output from the type determining section <b>1616</b> in <figref idref="DRAWINGS">FIG. 53</figref> are RT and RL. The type determining section <b>1616</b> has an arrangement shown in <figref idref="DRAWINGS">FIG. 56</figref>. The arrangement shown in <figref idref="DRAWINGS">FIG. 56</figref> comprises a determining section <b>1623</b> and an RT/RL detector <b>1624</b>.</p>
<p id="p-0380" num="0383">The reference patterns <b>1608</b> are input to the determining section <b>1623</b> and the RT/RL detector <b>1624</b>. The RT/RL detector detects RT and RL, which are output as the parameters <b>1618</b> and also sent to the determining section <b>1623</b>. The determining section <b>1623</b> determines the type <b>1617</b> on the basis of the algorithm shown in <figref idref="DRAWINGS">FIG. 68</figref> and outputs the type <b>1617</b>.</p>
<p id="p-0381" num="0384"><figref idref="DRAWINGS">FIGS. 70A to 70D</figref> are views showing examples of the index table using the type M and RT and RL.</p>
<p id="p-0382" num="0385">When M=1, all the pixel values of the top reference pattern and the left reference pattern equal each other. Therefore, several predetermined index tables are prepared from pixel patterns without any boundary line crossing the top and left sides, as shown in <figref idref="DRAWINGS">FIG. 70A</figref>.</p>
<p id="p-0383" num="0386">In <figref idref="DRAWINGS">FIG. 70A</figref>, a hatched portion has values equal to the pixel value T<b>1</b>. More specifically, when T<b>1</b> is present in the object region, the hatched portion indicates the object, and the white portion indicates the background. When T<b>1</b> is present in the background region, the hatched portion indicates the background, and the white portion indicates the object.</p>
<p id="p-0384" num="0387">When M=2, a boundary line crosses the top reference pattern or the left reference pattern, and all the pixel values of the pattern without any boundary line equal each other.</p>
<p id="p-0385" num="0388"><figref idref="DRAWINGS">FIG. 70B</figref> shows examples in which a boundary line crosses the left reference pattern (RL&lt;B). The boundary line is drawn from the starting point, i.e., a point separated from the uppermost point of the left side by RL, and the angle of the boundary line is changed. When the boundary line crosses the top reference pattern, the boundary line extends from the starting point, i.e., a point separated from the leftmost point of the top side by RT.</p>
<p id="p-0386" num="0389">When M=3, a boundary line crosses the top side and the left side at points separated from the upper left corner by RT and RL, respectively, as shown in <figref idref="DRAWINGS">FIG. 70C</figref>.</p>
<p id="p-0387" num="0390">When M=4, the boundary line is present between T<b>1</b> and L<b>1</b>. The boundary line is drawn from the starting point, i.e., the point at the upper left corner, as shown in <figref idref="DRAWINGS">FIG. 70D</figref>. When a plurality of lines are used as the top and left reference patterns, as shown in <figref idref="DRAWINGS">FIG. 64B</figref>, the direction of the boundary line can be estimated as indicated by a dotted line in <figref idref="DRAWINGS">FIG. 64A</figref>. Therefore, the pixel pattern can be generated using the estimated boundary line.</p>
<p id="p-0388" num="0391"><figref idref="DRAWINGS">FIG. 53</figref> shows the first detailed example of the index table generator <b>1609</b> as described above. <figref idref="DRAWINGS">FIG. 54</figref> shows the index table generator <b>1609</b>.</p>
<p id="p-0389" num="0392">The index table generator <b>1609</b> having an arrangement shown in <figref idref="DRAWINGS">FIG. 54</figref> comprises the type determining section <b>1616</b>, memories <b>1625</b> to <b>1627</b>, and a switch <b>1628</b>. This index table generator <b>1609</b> generates index tables according to the respective types before the encoding process and stores the index tables in the memories <b>1625</b> to <b>1627</b> in units of types. Each of the memories <b>1625</b> to <b>1627</b> exclusively stores an index table.</p>
<p id="p-0390" num="0393">The switch <b>1628</b> selects one of the memories <b>1625</b> to <b>1627</b> to make use of the index table stored in the selected memory.</p>
<p id="p-0391" num="0394">In the index table generator <b>1609</b> having the above arrangement, the type <b>1617</b> is determined by the type determining section <b>1616</b> on the basis of the reference patterns <b>1608</b>, as in the example shown in <figref idref="DRAWINGS">FIG. 53</figref>. In the second example, however, the parameter <b>1618</b> is not output from the type determining section <b>1616</b>. The index tables formed according to the respective types before the encoding process are held in the different memories <b>1625</b> to <b>1627</b>.</p>
<p id="p-0392" num="0395">The switch <b>1628</b> is changed over in accordance with the type <b>1617</b>, and the index table <b>1622</b> according to the type <b>1617</b> is output.</p>
<p id="p-0393" num="0396">In the second example, although a lot of memories are needed unlike the example shown in <figref idref="DRAWINGS">FIG. 53</figref>, calculation for generating indices is unnecessary.</p>
<p id="p-0394" num="0397">Still the arrangement of the third example of the index table generator <b>1609</b> will be described below.</p>
<p id="p-0395" num="0398"><figref idref="DRAWINGS">FIG. 55</figref> is a block diagram showing the third example of an index table generator comprising an evaluating section <b>1629</b>, a memory <b>1630</b>, a switch <b>1632</b>, and a memory <b>1634</b>. The third example performs no type determination unlike the above examples. Instead, an evaluation value representing the degree of continuity of the boundary lines of reference patterns and a predetermined pixel pattern is obtained and used.</p>
<p id="p-0396" num="0399">As shown in <figref idref="DRAWINGS">FIG. 65B</figref>, the pixel values T<b>1</b>, T<b>2</b>, . . . of the top reference pattern are compared with pixel values H<b>1</b>, H<b>2</b>, . . . of the pixel pattern at the upper end, and the pixel values L<b>1</b>, L<b>2</b>, . . . of the left reference pattern are compared with pixel values V<b>1</b>, V<b>2</b>, . . . of the pixel string at the left end. The sum of the number of i={1, 2, 3, . . . , B} which satisfies Ti=Hi and the number of j={1, 2, 3, . . . , B} which satisfies Lj=Vj is obtained as an evaluation value.</p>
<p id="p-0397" num="0400">In <figref idref="DRAWINGS">FIG. 65A</figref>, Ti=Hi and Lj=Vj are satisfied when i=1, 2, 3, and j=1, 2, 3, 6, 7, 8. Therefore, the evaluation value is “9”.</p>
<p id="p-0398" num="0401">Referring back to <figref idref="DRAWINGS">FIG. 55</figref>, the memory <b>1630</b> holds various pixel patterns in advance, including those shown in <figref idref="DRAWINGS">FIGS. 70A to 70D</figref>. The evaluating section <b>1629</b> obtains the evaluation value representing the degree of continuity of the boundary lines of the reference patterns and a pixel pattern (supplied from the memory <b>1630</b>). The switch <b>1632</b> controls an output from the memory <b>1630</b>. The memory <b>1634</b> holds information supplied through the switch <b>1632</b>. The switch <b>1632</b> is opened/closed in accordance with an opening/closing signal output from the evaluating section <b>1629</b> in correspondence with the evaluation value.</p>
<p id="p-0399" num="0402">The reference patterns <b>1608</b> read out from the memory <b>1605</b> as one of the constituent elements of the coding apparatus are sent to the evaluating section <b>1629</b>. Various pixel patterns <b>1631</b> held in advance in the memory <b>1630</b>, including those shown in <figref idref="DRAWINGS">FIGS. 70A</figref> to <b>70</b>D, are sequentially sent to the evaluating section <b>1629</b> and the switch <b>1632</b>.</p>
<p id="p-0400" num="0403">The evaluating section <b>1629</b> obtains the above-described evaluation value for the reference patterns <b>1608</b> and the pixel pattern <b>1631</b>. When the evaluation value is smaller than a predetermined value, the evaluating section <b>1629</b> sends a switching signal <b>1633</b> to the switch <b>1632</b> so that the switch <b>1632</b> is connected.</p>
<p id="p-0401" num="0404">In this case, the pixel pattern <b>1631</b> is recorded in the memory <b>1634</b> and set in the index table. When the evaluation value is larger than the predetermined value, the switching signal <b>1633</b> is sent to the switch <b>1632</b> so that the switch <b>1632</b> is disconnected. The pixel pattern <b>1631</b> is not sent to the memory <b>1634</b>.</p>
<p id="p-0402" num="0405">When evaluation of a predetermined number of pixel patterns prepared in the memory <b>1630</b> is completed, indices are sequentially added to the pixel patterns recorded in the memory <b>1634</b>, and the index table <b>1622</b> is output. The evaluation may be ended when a predetermined number of pixel patterns are recorded in the memory <b>1634</b>.</p>
<p id="p-0403" num="0406">Alternatively, a predetermined number of pixel patterns may be sequentially selected from those in the memory <b>1630</b> in the order of decreasing the evaluation value. In this case, the predetermined number of pixel patterns <b>1631</b> and their evaluation values are recorded in the memory <b>1634</b>.</p>
<p id="p-0404" num="0407">When the evaluation value of a pixel pattern which is currently being evaluated is larger than the smallest one of the recorded evaluation values, the two pixel patterns may be exchanged.</p>
<p id="p-0405" num="0408">In the example shown in <figref idref="DRAWINGS">FIG. 55</figref>, although the relatively large memory <b>1630</b> is needed, calculation for type determination is advantageously unnecessary.</p>
<p id="p-0406" num="0409">Of the examples shown in <figref idref="DRAWINGS">FIGS. 53 to 55</figref>, an appropriate arrangement may be employed in accordance with the allowance for calculation and memory capacity in the application system.</p>
<p id="p-0407" num="0410">The index table generator <b>1609</b> shown in <figref idref="DRAWINGS">FIG. 51</figref> has been described above.</p>
<p id="p-0408" num="0411"><figref idref="DRAWINGS">FIG. 69</figref> is a flow chart showing the algorithm of the vector quantizer <b>1607</b> shown in <figref idref="DRAWINGS">FIG. 51</figref>. C(i) represents the allowance condition of the error of the original image of an input alpha map and a pixel pattern. For example, a block consisting of B×B pixels is “divided into 16, i.e., (B/4)×(B/4) pixel blocks (<figref idref="DRAWINGS">FIG. 66</figref>), and the sum of the absolute values of the errors of the respective pixels of the original image and a pixel pattern i does not exceed α, where α is a threshold value. The sum of the absolute values of the errors of the respective pixels corresponds to the number of mismatched pixels. In other words, α is determined such as 0 pixel, one pixel, two pixels, . . . , B 2/16 pixels.</p>
<p id="p-0409" num="0412">Unless this condition is satisfied, the pixel pattern is not selected. In addition, “E” is the sum of the absolute values of the errors of the B×B pixels as a whole. The flow chart shown in <figref idref="DRAWINGS">FIG. 69</figref> will be described.</p>
<p id="p-0410" num="0413">S<b>11</b>: The index is set as i=0. The flow advances to step S<b>12</b>.</p>
<p id="p-0411" num="0414">S<b>12</b>: If the pixel pattern i satisfies C(i), the flow advances to step S<b>15</b>; otherwise, the flow advances to step S<b>13</b>.</p>
<p id="p-0412" num="0415">S<b>13</b>: The index is set as i=1.</p>
<p id="p-0413" num="0416">S<b>14</b>: If the pixel pattern i satisfies C(i), the flow advances to step S<b>15</b>; otherwise, the flow advances to step S<b>16</b>.</p>
<p id="p-0414" num="0417">S<b>15</b>: Mini=i. The flow advances to step S<b>23</b>.</p>
<p id="p-0415" num="0418">S<b>16</b>: A sufficiently large value is substituted into MinE, thereby setting Mini=1. The flow advances to step S<b>17</b>.</p>
<p id="p-0416" num="0419">S<b>17</b>: (i+1) is substituted into i. The flow advances to step S<b>18</b>.</p>
<p id="p-0417" num="0420">S<b>18</b>: If the pixel pattern i satisfies C(i), the flow advances to step S<b>19</b>; otherwise, the flow advances to step S<b>21</b>.</p>
<p id="p-0418" num="0421">S<b>19</b>: If E is smaller than MinE, the flow advances to step S<b>20</b>; otherwise, the flow advances to step S<b>21</b>.</p>
<p id="p-0419" num="0422">S<b>20</b>: E is substituted into MinE, thereby setting Mini=i. The flow advances to step S<b>21</b>.</p>
<p id="p-0420" num="0423">S<b>21</b>: If i equals a last value N of the index, the flow advances to step S<b>22</b>; otherwise, the flow returns to step S<b>17</b>.</p>
<p id="p-0421" num="0424">S<b>22</b>: If Mini=−1, no index is determined for the block, and the processing is ended; otherwise, the flow advances to step S<b>23</b>.</p>
<p id="p-0422" num="0425">S<b>23</b>: Mini is output as the index for the block, and the processing is ended.</p>
<p id="p-0423" num="0426">In this algorithm, the pixel pattern “0” or the pixel pattern “1” is determined immediately when C(i) is satisfied, without calculating “E”.</p>
<p id="p-0424" num="0427">With this arrangement, when a code shorter than other indices is assigned to the index of the pattern “0” or “1”, the amount of codes can be reduced. For example, a pixel pattern of a block corresponding to an object region, or a pixel pattern of a block corresponding to a background region is assigned to “0” or “1”.</p>
<p id="p-0425" num="0428">For a block where no index is determined, another encoding method other than vector quantization (VQ) may be used to encode the block, as shown in the flow chart of <figref idref="DRAWINGS">FIG. 67A</figref>.</p>
<p id="p-0426" num="0429">In the flow chart of <figref idref="DRAWINGS">FIG. 67A</figref>, the block for which no index is determined is encoded by vector quantization (VQ) first (S<b>24</b>). If an index is determined, the processing is ended (S<b>25</b>). Otherwise, the flow advances to step S<b>26</b>. In step S<b>26</b>, encoding is performed by MMR, and the processing is ended.</p>
<p id="p-0427" num="0430">In a case of using an inter mode of performing coding by copying a prediction signal motion-compensated every small region, the encoding is performed in accordance with the flow chart of <figref idref="DRAWINGS">FIG. 67B</figref>. In other words, the block is encoded by the inter coding method. When the block encoded by the inter coding method is used, the processing is ended. When it is not used, the block is coded by the vector quantization.</p>
<p id="p-0428" num="0431"><figref idref="DRAWINGS">FIG. 71A</figref> is a block diagram showing a coding apparatus for performing the processing based on the flowchart of <figref idref="DRAWINGS">FIG. 67A</figref>. The coding apparatus shown in <figref idref="DRAWINGS">FIG. 71A</figref> comprises a vector quantizer <b>1642</b>, an MMR encoder <b>1643</b>, a switching section <b>1644</b>, and a multiplexer <b>1646</b>. In this coding apparatus, the alpha-map signal <b>1606</b> is input to the vector quantizer <b>1642</b> and the MMR encoder <b>1643</b>. The vector quantizer <b>1642</b> has the same arrangement as shown in <figref idref="DRAWINGS">FIG. 51</figref>. The index <b>1614</b> as an output from the vector quantizer <b>1642</b> is sent to the switching section <b>1644</b>. Simultaneously, a switching signal <b>1645</b> is sent to the switching section <b>1644</b> and the multiplexer <b>1646</b>.</p>
<p id="p-0429" num="0432">The MMR encoder <b>1643</b> encodes the alpha-map signal <b>1606</b> by MMR, so that an MMR code <b>1647</b> is sent to the switching section <b>1644</b>. The switching section <b>1644</b> receives the MMR code <b>1647</b> as an output from the MMR encoder <b>1643</b> and the index <b>1614</b> as an output from the vector quantizer <b>1642</b>. The switching section <b>1644</b> is switched in accordance with the switching signal <b>1645</b> so that one of the MMR code <b>1647</b> and the index <b>1614</b> is selected.</p>
<p id="p-0430" num="0433">The switching signal <b>1645</b> supplied to the switching section <b>1644</b> is output from the MMR encoder <b>1643</b>. The MMR encoder <b>1643</b> operates such that, as an alpha-map code <b>1648</b>, the index <b>1614</b> is selected when the index <b>1614</b> is determined or the MMR code <b>1647</b> is selected when no index is determined.</p>
<p id="p-0431" num="0434">The index <b>1614</b> or the alpha-map code <b>1648</b> selected and output from the switching section <b>1644</b> is, sent to the multiplexer <b>1646</b> for multiplexing the signal. The multiplexer <b>1646</b> multiplexes the index <b>1614</b> or the alpha-map code <b>1648</b> with the switching signal <b>1645</b> obtained from the vector quantizer <b>1642</b> and outputs the signal as a code <b>1649</b>.</p>
<p id="p-0432" num="0435">In this example, when MMR is selected, the decoded alpha map <b>1615</b> of the block is sent from the MMR encoder <b>1643</b> to the memory <b>1605</b> in the vector quantizer. A detailed example of the MMR encoder <b>1643</b> will be described hereinafter.</p>
<p id="p-0433" num="0436"><figref idref="DRAWINGS">FIG. 71B</figref> is a block diagram showing a coding apparatus for performing the processing based on the flowchart of <figref idref="DRAWINGS">FIG. 67B</figref>. This coding apparatus further includes an inter encoder <b>1661</b> and a determining circuit <b>1662</b> for determining which the inter encoder <b>1661</b> or the vector quantizer <b>1642</b> should be employed. The switching section <b>1644</b> is switched by the output of the determining circuit <b>1662</b> in accordance with the table of <figref idref="DRAWINGS">FIG. 71C</figref>. In other words, when the determining circuit <b>1662</b> receives the signal S<b>1</b> of the inter encoder <b>1661</b>, it turns on the switch n<b>1</b> to input the inter-encoded signal to the multiplexer <b>1646</b>. When the determining circuit <b>1662</b> receives the signal S<b>2</b> of the vector quantizer <b>1642</b>, it turns on the switch n<b>2</b> to input the vector-quantized signal to the multiplexer <b>1646</b>. When the signals S<b>1</b> and S<b>2</b> are not output, it turns on the switch n<b>3</b> to input the MMR coded signal to the multiplexer <b>1646</b>.</p>
<p id="p-0434" num="0437">The MMR encoder <b>1643</b> is described in detail hereinafter.</p>
<p id="p-0435" num="0438"><figref idref="DRAWINGS">FIG. 74A</figref> is a view showing the relationship between changing pixels in encoding in units of blocks. <figref idref="DRAWINGS">FIG. 74B</figref> is a view showing a reference area for detecting a pixel b<b>1</b>.</p>
<p id="p-0436" num="0439">In MMR encoding, i.e., block-based encoding, encoding of changing pixels may be simplified. The following processing may be performed by changing the scan order, as in the sixth embodiment, or may be applied to reduced blocks, as in the eighth embodiment.</p>
<p id="p-0437" num="0440">Simplified changing pixels are encoded in the following manner.</p>
<p id="p-0438" num="0441">Assume that the addresses of changing pixels ai (i=0 to 1) and b<b>1</b> from the upper left corner of the frame are represented by abs_ai (i=0 to 1) and abs_b<b>1</b>. Values r_ai (i=0 to 1) and r_b<b>1</b> are obtained by the following equations:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>r−a</i>0=<i>abs</i><sub>—</sub><i>a</i>0−(<i>int</i>)(<i>abs</i><sub>—</sub><i>a</i>0/WIDTH)*WIDTH<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>r−a</i>1<i>=abs</i><sub>—</sub><i>a</i>0−(<i>int</i>)(<i>abs</i><sub>—</sub><i>a</i>0/WIDTH)*WIDTH*WIDTH<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>r−b</i>1<i>=abs</i><sub>—</sub><i>a</i>0−(<i>int</i>)(<i>abs</i><sub>—</sub><i>a</i>0/WIDTH)*WIDTH<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0439" num="0442">In the above equations, “*” means multiplication, “(int)(x)” means rounding off the digits after the decimal point of x, and “WIDTH” is the number of pixels in the horizontal direction of the block.</p>
<p id="p-0440" num="0443">When encoding the value “r_a<b>1</b>−r_b<b>1</b>” or “r_a<b>1</b>−r_a<b>0</b>”, a reproduced value can be obtained.</p>
<p id="p-0441" num="0444"><figref idref="DRAWINGS">FIG. 75</figref> is a flow chart of block-based encoding by MMR. The encoding process will be described in accordance with this flow chart. First, the position of the starting changing pixel is initialized (S<b>501</b>). The pixel value at the initial position (the upper left pixel of the block) is encoded by one-bit codes (S<b>502</b>). At the initial position, the reference changing pixel B<b>1</b> is detected (S<b>503</b>).</p>
<p id="p-0442" num="0445">If the changing pixel b<b>1</b> is not detected, the vertical mode cannot be used because no changing pixel is present in the reference area. Therefore, the vertical pass mode is set to “TRUE”. When the changing pixel b<b>1</b> is detected, the vertical mode can be used, so that the vertical pass mode is set to “FALSE”.</p>
<p id="p-0443" num="0446">Setting of the initial state is ended, and the process shifts to the encoding loop process.</p>
<p id="p-0444" num="0447">The changing pixel a<b>1</b> is detected (S<b>505</b>). It is determined whether the changing pixel a<b>1</b> is detected (S<b>506</b>). If NO in step S<b>506</b>, the end code (EOMB) of the encoding process, which represents the end of encoding, is encoded (S<b>507</b>) because no changing pixel is present anymore.</p>
<p id="p-0445" num="0448">If YES in step S<b>506</b>, the vertical pass mode is determined (S<b>508</b>). If the vertical pass mode is “TRUE”, encoding in the vertical pass mode is performed (S<b>516</b>). If the vertical pass mode is “FALSE”, the changing pixel b<b>1</b> is detected (S<b>509</b>).</p>
<p id="p-0446" num="0449">It is determined whether the changing pixel b<b>1</b> is detected (S<b>510</b>). If NO in step S<b>510</b>, the flow advances to the step of the horizontal mode (SS<b>13</b>). If YES in step S<b>510</b>, it is determined whether the absolute value of “r_a<b>1</b>−r_b<b>1</b>” is larger than a threshold value (VTH) (S<b>511</b>). If NO in step S<b>511</b>, the flow advances to the step of the vertical mode (S<b>512</b>). If YES in step S<b>511</b>, the flow advances to the step of the horizontal mode (S<b>513</b>).</p>
<p id="p-0447" num="0450">In the step of the horizontal mode (S<b>513</b>), the value “r_a<b>1</b>−r_a<b>0</b>” is encoded. It is determined whether the value “r_a<b>1</b>−r_a<b>0</b>” is smaller than “WIDTH” (S<b>514</b>). If NO in step S<b>514</b>, the vertical pass mode is set to “TRUE” (S<b>515</b>), and the flow advances to the step of the vertical pass mode (S<b>516</b>). Upon completion of the step of the vertical pass mode (S<b>516</b>), the vertical pass mode is set to “FALSE”.</p>
<p id="p-0448" num="0451">After one of the vertical mode, the horizontal mode, and the vertical pass mode is ended (after encoding up to the pixel a<b>1</b> is ended), the position of the pixel a<b>1</b> is set as the position of the next pixel a<b>0</b> (S<b>518</b>), and the flow returns to step S<b>505</b>.</p>
<p id="p-0449" num="0452"><figref idref="DRAWINGS">FIG. 73</figref> shows an example of a VLC table.</p>
<p id="p-0450" num="0453">When the vertical pass mode is “TRUE”, there are only three codes, i.e., V<b>0</b>, H, and EOMB. In accordance with the vertical pass mode, the VLC can be switched. When the vertical pass mode is “TRUE”, the code EOMB is generated only when the changing pixel a<b>0</b> is present at the upper left position (initial position) of the block. In this case, the code of “0” in <figref idref="DRAWINGS">FIG. 73</figref> is used.</p>
<p id="p-0451" num="0454">When not vector quantization but only MMR encoding is used, the above-described example may be directly applied to the alpha-map encoder <b>200</b> shown in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0452" num="0455">In addition to the encoding method such as MMR, a block for which no index is determined can be encoded by a method in which the macro block is redivided into small blocks, and vector quantization is performed again, as shown in <figref idref="DRAWINGS">FIG. 62</figref>. In <figref idref="DRAWINGS">FIG. 62</figref>, a macro block of a standard size is further divided into small blocks each having a size b=B/2.</p>
<p id="p-0453" num="0456">In this case, encoding is performed in the order of “A B C D” or “A C B D” such that the reference portion of each block can be encoded first.</p>
<p id="p-0454" num="0457">Redivision of the block is performed until the error falls within the allowance. With this operation, the number of indices increases to increase the amount of codes accordingly. However, the error can be suppressed within the allowance.</p>
<p id="p-0455" num="0458">The detailed example of the coding apparatus has been described above. Finally, the flow chart of the coding apparatus as a whole is shown in <figref idref="DRAWINGS">FIG. 57</figref>.</p>
<p id="p-0456" num="0459">S<b>27</b>: An index table is generated in accordance with reference patterns.</p>
<p id="p-0457" num="0460">S<b>28</b>: Vector quantization is performed using the generated index table, and the processing is ended.</p>
<p id="p-0458" num="0461">The processing is performed in the above manner.</p>
<p id="p-0459" num="0462"><figref idref="DRAWINGS">FIG. 52</figref> is a block diagram showing a detailed example of a decoding apparatus. The circuit shown in <figref idref="DRAWINGS">FIG. 52</figref> comprises a vector inverse quantizer <b>1636</b> for performing vector inverse quantization, a memory <b>1637</b> for holding information obtained upon vector inverse quantization, and an index table generator <b>1639</b> for generating an index table. This circuit is arranged at the portion of the alpha-map decoder <b>400</b> in the video decoding apparatus shown in <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0460" num="0463">An index <b>1635</b> is input to the vector inverse quantizer <b>1636</b>. The memory <b>1637</b> holds an already decoded alpha map, and a reference pattern <b>1638</b> is sent from the memory <b>1637</b> to the index table generator <b>1639</b>. The index table generator <b>1639</b> is the same as that of the coding apparatus.</p>
<p id="p-0461" num="0464">A generated index table <b>1640</b> is sent to the vector inverse quantizer <b>1636</b>. A decoded alpha map <b>1641</b> is sent from the vector inverse quantizer <b>1636</b> to the memory <b>1637</b>.</p>
<p id="p-0462" num="0465"><figref idref="DRAWINGS">FIG. 58</figref> is a flow chart showing the flow of the process of the decoding apparatus shown in <figref idref="DRAWINGS">FIG. 52</figref>. This flow chart will be described. The index table generator <b>1639</b> generates an index table in accordance with reference patterns (S<b>29</b>). The vector inverse quantizer <b>1636</b> performs vector inverse quantization of the index <b>1635</b> by using the generated index table (S<b>30</b>), and the processing is ended.</p>
<p id="p-0463" num="0466"><figref idref="DRAWINGS">FIG. 72A</figref> shows a decoding apparatus for decoding a code generated by the coding apparatus shown in <figref idref="DRAWINGS">FIG. 71A</figref>. This decoding apparatus comprises a demultiplexer <b>1651</b> for demultiplexing a signal obtained by multiplexing a switching signal <b>1652</b> with an alpha-map code <b>1653</b>, a switching section <b>1655</b> for switching the circuit in accordance with the switching signal <b>1652</b> demultiplexed by the demultiplexer <b>1651</b> to input a signal to a vector inverse quantizer <b>1654</b> or an MMR decoder <b>1657</b>, the vector inverse quantizer <b>1654</b> for performing vector inverse quantization of the alpha-map code <b>1653</b> demultiplexed by the demultiplexer <b>1651</b> and supplied through the switching section <b>1655</b>, and a switching section <b>1656</b> for switching the circuit in accordance with the switching signal <b>1652</b> to output a signal from the vector inverse quantizer <b>1654</b> or the MMR decoder <b>1657</b>.</p>
<p id="p-0464" num="0467">In this arrangement, a code <b>1650</b> as the multiplexed signal of the switching signal <b>1652</b> and the alpha-map code <b>1653</b> is input to the demultiplexer <b>1651</b>. The demultiplexer <b>1651</b> demultiplexes the code <b>1650</b> into the switching signal <b>1652</b> and the alpha-map code <b>1653</b>. The switching signal <b>1652</b> is sent to the switching sections <b>1655</b> and <b>1656</b>. The alpha-map code <b>1653</b> is sent to the switching section <b>1656</b>.</p>
<p id="p-0465" num="0468">The switching section <b>1656</b> sends the alpha-map code <b>1653</b> to the vector inverse quantizer <b>1654</b> or the MMR decoder <b>1657</b> in accordance with the switching signal <b>1652</b>. Upon receiving the alpha-map code <b>1653</b>, the vector inverse quantizer <b>1654</b> or the MMR decoder <b>1657</b> reconstructs an alpha map <b>1658</b>. The alpha map <b>1658</b> is output through the switching section <b>1655</b>.</p>
<p id="p-0466" num="0469"><figref idref="DRAWINGS">FIG. 72B</figref> shows a decoding apparatus for decoding a code generated by the coding apparatus shown in <figref idref="DRAWINGS">FIG. 71B</figref>. In the decoding apparatus, an inter decoder <b>1663</b> is added to the decoding apparatus of <figref idref="DRAWINGS">FIG. 72A</figref>. According to the decoding apparatus, when the code <b>1650</b> as the multiplexed signal of the switching signal <b>1652</b> and the alpha-map code <b>1653</b> is demultiplexed by the demultiplexer <b>1651</b>, the switching signal <b>1652</b> is sent to the switching sections <b>1655</b> and <b>1656</b> and the alpha-map code <b>1653</b> is sent to the switching section <b>1656</b>.</p>
<p id="p-0467" num="0470">The switching section <b>1656</b> sends the alpha-map code <b>1653</b> to the vector inverse quantizer <b>1654</b>, the MMR decoder <b>1657</b> or the inter decoder <b>1663</b> in accordance with the switching signal <b>1652</b>. Upon receiving the alpha-map code <b>1653</b>, the vector inverse quantizer <b>1654</b>, the MMR decoder <b>1657</b> or the inter decoder <b>1663</b> reconstructs an alpha map <b>1658</b>. The alpha map <b>1658</b> is output through the switching section <b>1655</b>.</p>
<p id="p-0468" num="0471">The detailed example of the decoding apparatus as the 11th embodiment has been described above.</p>
<p id="p-0469" num="0472">As has been described above, according to the present invention, the alpha map can be efficiently encoded. Since the amount of codes of the alpha map can be reduced, the background and the object can be independently encoded without largely decreasing the encoding efficiency.</p>
<p id="p-0470" num="0473">Although various embodiments have been described above, the present invention is not limited to the above embodiments, and various changes and modifications can be made.</p>
<p id="p-0471" num="0474">According to the present invention, since the amount of codes of the alpha map can be reduced, the background and the object can be independently encoded without largely decreasing the encoding efficiency, unlike the conventional encoding method.</p>
<p id="p-0472" num="0475">Additional advantages and modifications will readily occur to those skilled in the art. Therefore, the invention in its broader aspects is not limited to the specific details, representative devices, and illustrated examples shown and described herein. Accordingly, various modifications may be made without departing from the spirit or scope of the general inventive concept as defined by the appended claims and their equivalents.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A video decoding apparatus comprising:
<claim-text>a divider unit configured to divide encoded video data corresponding to a rectangular region containing an object into a plurality of macro blocks, each macro block of the macro blocks having M×N pixels, where M indicates the number of pixels included in a row array, and N indicates the number of pixels included in a column array;</claim-text>
<claim-text>a decoder configured to decode the encoded video data for each of the blocks by scanning each macro block in a horizontal direction or a vertical direction; and</claim-text>
<claim-text>a switching device configured to switch a scanning direction between the horizontal direction and the vertical direction, wherein</claim-text>
<claim-text>the encoded video data includes scanning direction information, and</claim-text>
<claim-text>the switching device is configured to switch the scanning direction in accordance with the scanning direction information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. A video decoding apparatus comprising:
<claim-text>a divider unit configured to divide encoded video data corresponding to a rectangular region containing an object into a plurality of macro blocks, each of the macro blocks having M×N pixels, where M indicates the number of pixels included in a row array, and N indicates the number of pixels included in a column array; and</claim-text>
<claim-text>a decoder configured to decode the encoded video data for each of the macro blocks by scanning each of the macro blocks in a scanning direction which is adaptively switched between a horizontal direction and a vertical direction in units of macro blocks, wherein</claim-text>
<claim-text>the encoded video data includes scanning direction information, and</claim-text>
<claim-text>the decoder is configured to switch the scanning direction in accordance with the scanning direction information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. A video decoding apparatus for decoding encoded video data corresponding to a video frame including an object and divided into a plurality of macro blocks, comprising:
<claim-text>a decoder configured to decode the encoded video data for each of the macro blocks by scanning each of the macro blocks in a scanning direction which is adaptively switched between a horizontal direction and a vertical direction in units of macro blocks, wherein</claim-text>
<claim-text>the encoded video data includes scanning direction information, and</claim-text>
<claim-text>the decoder is configured to switch the scanning direction in accordance with the scanning direction information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A video encoding apparatus for encoding a video signal corresponding to a video frame including an object and divided into a plurality of macro blocks, comprising:
<claim-text>means for encoding a macro block of the plurality of macro blocks by scanning the macro block in a horizontal direction or a vertical direction to generate encoded video data; and</claim-text>
<claim-text>means for switching a scanning direction between the horizontal direction and the vertical direction, wherein</claim-text>
<claim-text>the encoded video data includes scanning direction information, and</claim-text>
<claim-text>the switching means switches the scanning direction in accordance with the scanning direction information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A video decoding apparatus comprising:
<claim-text>means for dividing encoded video data corresponding to a rectangular region containing an object into a plurality of macro blocks, each of the macro blocks having M×N pixels, where M indicates the number of pixels included in a row array, and N indicates the number of pixels included in a column array; and</claim-text>
<claim-text>means for decoding the encoded video data for each of the macro blocks by scanning each of the macro blocks in a scanning direction which is adaptively switched between a horizontal direction and a vertical direction in units of macro blocks, wherein</claim-text>
<claim-text>the encoded video data includes scanning direction information, and</claim-text>
<claim-text>the decoding means switches the scanning direction in accordance with the scanning direction information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A video decoding apparatus for decoding encoded video data corresponding to a video frame including an object and divided into a plurality of macro blocks, comprising:
<claim-text>means for decoding the encoded video data for each of the macro blocks by scanning each of the macro blocks in a scanning direction which is adaptively switched between a horizontal direction and a vertical direction in units of macro blocks, wherein</claim-text>
<claim-text>the encoded video data includes scanning direction information, and</claim-text>
<claim-text>the decoding means switches the scanning direction in accordance with the scanning direction information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A video decoding method comprising:
<claim-text>dividing encoded video data corresponding to a rectangular region containing an object into a plurality of macro blocks, each macro block of the macro blocks having M×N pixels, where M indicates the number of pixels included in a row array, and N indicates the number of pixels included in a column array;</claim-text>
<claim-text>decoding the encoded video data for each of the macro blocks by scanning the macro block in a horizontal direction or a vertical direction; and</claim-text>
<claim-text>switching a scanning direction between the horizontal direction and the vertical direction, wherein</claim-text>
<claim-text>the encoded video data includes scanning direction information, and</claim-text>
<claim-text>the switching step switches the scanning direction in accordance with the scanning direction information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A video decoding method comprising:
<claim-text>dividing encoded video data corresponding to a rectangular region containing an object into a plurality of macro blocks, each of the macro blocks having M×N pixels, where M indicates the number of pixels included in a row array, and N indicates the number of pixels included in a column array; and</claim-text>
<claim-text>decoding the encoded video data for each of the macro blocks by scanning each of the macro blocks in a scanning direction which is adaptively switched between a horizontal direction and a vertical direction in units of macro blocks, wherein</claim-text>
<claim-text>the encoded video data includes scanning direction information, and</claim-text>
<claim-text>the decoding includes switching the scanning direction in accordance with the scanning direction information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A video decoding method for decoding encoded video data corresponding to a video frame including an object and divided into a plurality of macro blocks, comprising:
<claim-text>decoding the encoded video data for each of the macro blocks by scanning each of the macro blocks in a scanning direction which is adaptively switched between a horizontal direction and a vertical direction in units of macro blocks, wherein</claim-text>
<claim-text>the encoded video data includes scanning direction information, and</claim-text>
<claim-text>the decoding includes switching the scanning direction in accordance with the scanning direction information.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
