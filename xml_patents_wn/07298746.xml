<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298746-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298746</doc-number>
<kind>B1</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10127372</doc-number>
<date>20020422</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>815</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>12</main-group>
<subgroup>56</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>370394</main-classification>
</classification-national>
<invention-title id="d0e53">Method and system for reassembling and parsing packets in a network environment</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4766534</doc-number>
<kind>A</kind>
<name>DeBenedictis</name>
<date>19880800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5315708</doc-number>
<kind>A</kind>
<name>Eidler et al.</name>
<date>19940500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711119</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5396490</doc-number>
<kind>A</kind>
<name>White et al.</name>
<date>19950300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370474</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5440545</doc-number>
<kind>A</kind>
<name>Buchholz et al.</name>
<date>19950800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370426</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5528761</doc-number>
<kind>A</kind>
<name>Ooba et al.</name>
<date>19960600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5553242</doc-number>
<kind>A</kind>
<name>Russell et al.</name>
<date>19960900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>5561807</doc-number>
<kind>A</kind>
<name>Verplanken et al.</name>
<date>19961000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>719314</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5745694</doc-number>
<kind>A</kind>
<name>Egawa et al.</name>
<date>19980400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5815516</doc-number>
<kind>A</kind>
<name>Aaker et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714807</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>5826082</doc-number>
<kind>A</kind>
<name>Bishop et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>5937169</doc-number>
<kind>A</kind>
<name>Connery et al.</name>
<date>19990800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>5974518</doc-number>
<kind>A</kind>
<name>Nogradi</name>
<date>19991000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711173</main-classification></classification-national>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>6018516</doc-number>
<kind>A</kind>
<name>Packer</name>
<date>20000100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370231</main-classification></classification-national>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>6044468</doc-number>
<kind>A</kind>
<name>Osmond</name>
<date>20000300</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>713201</main-classification></classification-national>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>6091733</doc-number>
<kind>A</kind>
<name>Takagi et al.</name>
<date>20000700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>370401</main-classification></classification-national>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>6195703</doc-number>
<kind>B1</kind>
<name>Blumenau et al.</name>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709238</main-classification></classification-national>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>6208650</doc-number>
<kind>B1</kind>
<name>Hassell et al.</name>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370392</main-classification></classification-national>
</citation>
<citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>6212190</doc-number>
<kind>B1</kind>
<name>Mulligan</name>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>6233615</doc-number>
<kind>B1</kind>
<name>Van Loo</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>6247060</doc-number>
<kind>B1</kind>
<name>Boucher et al.</name>
<date>20010600</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709238</main-classification></classification-national>
</citation>
<citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>6298280</doc-number>
<kind>B1</kind>
<name>Coile et al.</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>709227</main-classification></classification-national>
</citation>
<citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>6304906</doc-number>
<kind>B1</kind>
<name>Bhatti et al.</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>6327622</doc-number>
<kind>B1</kind>
<name>Jindal et al.</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>6341129</doc-number>
<kind>B1</kind>
<name>Schroeder et al.</name>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>6363421</doc-number>
<kind>B2</kind>
<name>Barker et al.</name>
<date>20020300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>6411986</doc-number>
<kind>B1</kind>
<name>Susai et al.</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>6453360</doc-number>
<kind>B1</kind>
<name>Muller et al.</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>6480489</doc-number>
<kind>B1</kind>
<name>Muller et al.</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>6483840</doc-number>
<kind>B1</kind>
<name>Vogel</name>
<date>20021100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370401</main-classification></classification-national>
</citation>
<citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>6490281</doc-number>
<kind>B1</kind>
<name>Abler et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370394</main-classification></classification-national>
</citation>
<citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>6526056</doc-number>
<kind>B1</kind>
<name>Rekhter et al.</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>6532487</doc-number>
<kind>B1</kind>
<name>Perks</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>6549516</doc-number>
<kind>B1</kind>
<name>Albert et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>6549540</doc-number>
<kind>B1</kind>
<name>Ward</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370412</main-classification></classification-national>
</citation>
<citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>6549961</doc-number>
<kind>B1</kind>
<name>Kloth</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>6606315</doc-number>
<kind>B1</kind>
<name>Albert et al.</name>
<date>20030800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00037">
<document-id>
<country>US</country>
<doc-number>6606316</doc-number>
<kind>B1</kind>
<name>Albert et al.</name>
<date>20030800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00038">
<document-id>
<country>US</country>
<doc-number>6625650</doc-number>
<kind>B2</kind>
<name>Stelliga</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00039">
<document-id>
<country>US</country>
<doc-number>6628654</doc-number>
<kind>B1</kind>
<name>Albert et al.</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00040">
<document-id>
<country>US</country>
<doc-number>6633560</doc-number>
<kind>B1</kind>
<name>Albert et al.</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00041">
<document-id>
<country>US</country>
<doc-number>6650641</doc-number>
<kind>B1</kind>
<name>Albert et al.</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00042">
<document-id>
<country>US</country>
<doc-number>6687222</doc-number>
<kind>B1</kind>
<name>Albert et al.</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00043">
<document-id>
<country>US</country>
<doc-number>6704278</doc-number>
<kind>B1</kind>
<name>Albert et al.</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00044">
<document-id>
<country>US</country>
<doc-number>6714985</doc-number>
<kind>B1</kind>
<name>Malagrino et al.</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00045">
<document-id>
<country>US</country>
<doc-number>6724767</doc-number>
<kind>B1</kind>
<name>Chong et al.</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370412</main-classification></classification-national>
</citation>
<citation>
<patcit num="00046">
<document-id>
<country>US</country>
<doc-number>6728748</doc-number>
<kind>B1</kind>
<name>Mangipudi et al.</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00047">
<document-id>
<country>US</country>
<doc-number>6735169</doc-number>
<kind>B1</kind>
<name>Albert et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00048">
<document-id>
<country>US</country>
<doc-number>6742045</doc-number>
<kind>B1</kind>
<name>Jordan et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00049">
<document-id>
<country>US</country>
<doc-number>6775692</doc-number>
<kind>B1</kind>
<name>Albert et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00050">
<document-id>
<country>US</country>
<doc-number>6781992</doc-number>
<kind>B1</kind>
<name>Rana et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370394</main-classification></classification-national>
</citation>
<citation>
<patcit num="00051">
<document-id>
<country>US</country>
<doc-number>6788704</doc-number>
<kind>B1</kind>
<name>Lindsay</name>
<date>20040900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00052">
<document-id>
<country>US</country>
<doc-number>6836462</doc-number>
<kind>B1</kind>
<name>Albert et al.</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00053">
<document-id>
<country>US</country>
<doc-number>6839811</doc-number>
<kind>B2</kind>
<name>Fujiyama</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00054">
<document-id>
<country>US</country>
<doc-number>6891839</doc-number>
<kind>B2</kind>
<name>Albert et al.</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00055">
<document-id>
<country>US</country>
<doc-number>6937606</doc-number>
<kind>B2</kind>
<name>Basso et al.</name>
<date>20050800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370412</main-classification></classification-national>
</citation>
<citation>
<patcit num="00056">
<document-id>
<country>US</country>
<doc-number>6973097</doc-number>
<kind>B1</kind>
<name>Donzis et al.</name>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00057">
<document-id>
<country>US</country>
<doc-number>7065086</doc-number>
<kind>B2</kind>
<name>Basso et al.</name>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00058">
<document-id>
<country>US</country>
<doc-number>7072981</doc-number>
<kind>B1</kind>
<name>O'Rourke et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00059">
<document-id>
<country>US</country>
<doc-number>2001/0034792</doc-number>
<kind>A1</kind>
<name>Swildens</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00060">
<document-id>
<country>US</country>
<doc-number>2001/0052006</doc-number>
<kind>A1</kind>
<name>Barker et al.</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00061">
<document-id>
<country>US</country>
<doc-number>2001/0055317</doc-number>
<kind>A1</kind>
<name>Kajizaki et al.</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00062">
<document-id>
<country>US</country>
<doc-number>2002/0016856</doc-number>
<kind>A1</kind>
<name>Tallegas et al.</name>
<date>20020200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00063">
<document-id>
<country>US</country>
<doc-number>2002/0087694</doc-number>
<kind>A1</kind>
<name>Daoud et al.</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00064">
<document-id>
<country>US</country>
<doc-number>2002/0129127</doc-number>
<kind>A1</kind>
<name>Romero et al.</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00065">
<document-id>
<country>US</country>
<doc-number>2002/0141401</doc-number>
<kind>A1</kind>
<name>Albert et al.</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00066">
<document-id>
<country>US</country>
<doc-number>2003/0009561</doc-number>
<kind>A1</kind>
<name>Sollee</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00067">
<document-id>
<country>US</country>
<doc-number>2003/0014525</doc-number>
<kind>A1</kind>
<name>De Lima et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00068">
<document-id>
<country>US</country>
<doc-number>2003/0093496</doc-number>
<kind>A1</kind>
<name>O'Connor et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00069">
<document-id>
<country>US</country>
<doc-number>2003/0149690</doc-number>
<kind>A1</kind>
<name>Kudlacik et al.</name>
<date>20030800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00070">
<document-id>
<country>US</country>
<doc-number>2004/0162901</doc-number>
<kind>A1</kind>
<name>Mangipudi et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00071">
<document-id>
<country>US</country>
<doc-number>2005/0010754</doc-number>
<kind>A1</kind>
<name>Brendel</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00072">
<document-id>
<country>US</country>
<doc-number>2006/0080446</doc-number>
<kind>A1</kind>
<name>Bahl</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00073">
<othercit>Dykstra; <i>Gigabit Ethernet Jumbo Frames: and why you should care</i>; http://sd<sub>—</sub>wareonearth.com/˜phil/jumbo.html (Dec. 20, 1999).</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00074">
<othercit>Hornig, <i>Network Working Group RFC: 894; DARPA Internet Program Protocol Specification </i>(Apr. 1984).</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00075">
<othercit>Information Sciences Institute, University of Southern California, <i>Internet Protocol RFC: 791; DARPA Internet Program Protocol Specification </i>(Sep. 1981).</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00076">
<othercit>Information Sciences Institute, University of Southern California, <i>Transmission Control Protocol RFC: 793; DARPA Internet Program Protocol Specification </i>(Sep. 1981).</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00077">
<othercit>Postel, <i>Network Working Group RFC: 879; DARPA Internet Program Protocol Specification </i>(Nov. 1983).</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00078">
<othercit>Saunders, Stephen et al.; “The Policy Makers”; Data Communications; pp. 34-35 and 36-56 (even only).</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00079">
<othercit>Postel, “RFC 792—ICMP,” 1981, pp. 1-4.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00080">
<othercit>Mogul et al., “RFC 1191—Path MTU Discovery,” 1990, pp. 1-3.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>370389</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370392</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370397</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370394</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709227-229</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>14</number-of-figures>
</figures>
<us-related-documents>
<continuation-in-part>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>10098957</doc-number>
<kind>00</kind>
<date>20020211</date>
</document-id>
<parent-status>PENDING</parent-status>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>10127372</doc-number>
</document-id>
</child-doc>
</relation>
</continuation-in-part>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>60355922</doc-number>
<kind>00</kind>
<date>20020211</date>
</document-id>
</us-provisional-application>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>De La Iglesia</last-name>
<first-name>Erik</first-name>
<address>
<city>Mountain View</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Gomez</last-name>
<first-name>Miguel</first-name>
<address>
<city>Fremont</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Puri</last-name>
<first-name>Rahoul</first-name>
<address>
<city>Los Altos</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="004" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Chou</last-name>
<first-name>Chien C.</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="005" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Tran</last-name>
<first-name>Kiet</first-name>
<address>
<city>Saratoga</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Howrey LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Extreme Networks</orgname>
<role>02</role>
<address>
<city>Santa Clara</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Levitan</last-name>
<first-name>Dmitry</first-name>
<department>2616</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A packet reassembly system includes a buffer for storing information elements included in one or more incoming packets, a memory for storing validity indicators corresponding to the information elements, a first logic circuit capable of setting the validity indicators based on the information elements stored in the buffer, and a second logic circuit capable of determining the contiguity of the information elements stored in the buffer based on the settings of the validity indicators.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="126.41mm" wi="155.53mm" file="US07298746-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="212.09mm" wi="141.90mm" file="US07298746-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="218.19mm" wi="161.71mm" file="US07298746-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="207.52mm" wi="164.76mm" file="US07298746-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="212.01mm" wi="156.38mm" file="US07298746-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="205.91mm" wi="162.48mm" file="US07298746-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<p id="p-0002" num="0001">This application claims the benefit of U.S. Provisional Application No. 60/355,922, entitled “Network Switch”, filed Feb. 11, 2002, and is a continuation-in-part of U.S. patent application Ser. No. 10/098,957 entitled “Switching System”, filed Feb. 11, 2002. Both of these applications are fully incorporated by reference herein as though set forth in full.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">RELATED APPLICATIONS</heading>
<p id="p-0003" num="0002">This application is related to U.S. patent application Ser. No. 10/073,483, entitled “Method Of And System For Allocating Resources To Resource Requests Based On Application Of Persistence Policies,” filed Feb. 11, 2002; U.S. patent application Ser. No. 10/075,051, entitled “Method Of And System For Allocating Resources To Resource Requests Based On Application Of Persistence Policies,” filed Feb. 12, 2002; U.S. Patent Application No. To Be Determined, BSTZ Ref. No. 02717.P056, entitled “Method Of And System For Allocating Resources To Resource Requests,” filed Feb. 11, 2002; U.S. patent application Ser. No. 10/073,538, entitled “Method And System For Maintaining Temporal Consistency Of Resources And Data In A Multiple-Processor Packet Switch,” filed Feb. 11, 2002; U.S. patent application Ser. No. 10/073,638, entitled “Method And System For Managing Traffic In A Packet Network Environment,” filed Feb. 11, 2002; U.S. patent application Ser. No. 10/073,484, entitled “Method And System For Translating Packet Sizes In A Network,” filed Feb. 11, 2002. Each of the foregoing applications is owned in common by the assignee hereof, and each is hereby fully incorporated herein by reference as though set forth in full.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">1. Field of the Invention</p>
<p id="p-0005" num="0004">The present invention generally relates to communication networks, and more particularly, to packet networks for carrying information between hosts such as computers.</p>
<p id="p-0006" num="0005">2. Related Art</p>
<p id="p-0007" num="0006">Computer networks are often described with the aid of layered reference models for depicting the movement of information between host computers connected to the network. The layers help to segregate information and network functions into manageable units. The general functions of each layer are often based on an international standard called Open System Interconnection (OSI). OSI sets forth seven processing layers through which information may pass when received by a host in order to be presentable to a non-user. Similar, transmission of information from a host to the network may pass through those seven processing layers in reverse order.</p>
<p id="p-0008" num="0007">Another layered reference model that is widely implemented is called TCP/IP (Transmission Control Protocol/Internet Protocol). A more complete definition of TCP/IP is given in RFC793, “Transmission Control Protocol”, and RFC791, “Internet Protocol”, published by the Defense Advanced Research Projects Agency (DARPA), hereby incorporated by reference.</p>
<p id="p-0009" num="0008">A TCP/IP connection is managed by TCP, which uses sequence numbers, a maximum segment size (MSS), and a sliding window as flow control mechanisms.</p>
<p id="p-0010" num="0009">When a TCP/IP connection is established, both the client and server transmit their respective 32-bit initial sequence numbers (ISN) as well as a maximum segment size (MSS). The server acknowledges receipt of the client's data by sending an acknowledge (ACK) to the client. Establishing a connection allows the client to send a segment of data to the server. A segment includes one or more packets. The beginning of the client's segment is referenced by the client's ISN. The server is responsible for acknowledging segments by sending an acknowledge number equal to the client's ISN plus the length of the contiguous data received.</p>
<p id="p-0011" num="0010">During connection establishment, the server opens a “window” allowing the client to send up to the number of bytes of data specified by that window to the server. The maximum number of bytes sent per data packet is defined by the MSS. The relative positions of the payload bytes within a packet is defined by the sequence number of the packet.</p>
<p id="p-0012" num="0011">When packets are received out-of-order, the server is expected to reassemble the packets into a contiguous stream, using the sequence number of each packet as an index. The server is also expected to acknowledge the client properly.</p>
<p id="p-0013" num="0012">In many networked devices running TCP or other similar transport protocols, this reassembly process is carried out in software, using linked list data structures to check for contiguity. Software approaches for reassembling and parsing contiguous packets are useful in some applications. However, conventional software implementations sometimes lack the necessary speed and performance for other applications. Thus, there is a need for an improved approach to the function of packet reassembly and parsing in a packet switched network.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0014" num="0013">It is an advantage of the present invention to provide an improved system and method for reassembling packets into a contiguous stream. It is also an advantage of the invention to provide an improved system and method for parsing information from incoming packet traffic.</p>
<p id="p-0015" num="0014">According to an embodiment of the invention, a system is provided for handling packet traffic. The system includes a buffer for storing information elements included in one or more packets, a memory for storing validity indicators corresponding to the information elements, a first logic circuit capable of setting the validity indicators based on the sequence space of a packet, and a second logic circuit capable of determining the contiguity of the information elements stored in the buffer based on the settings of the validity indicators.</p>
<p id="p-0016" num="0015">In accordance with a further embodiment of the invention, a method is provided for reassembling one or more packets. In this process, a data payload of a packet is stored in a buffer. The data unit is located in the buffer according to a sequence number associated with the packet. Next, an array of validity indicators, stored in a memory, is set. The validity indicators correspond positionally and directly to the data unit. The array of validity indicators is then scanned to determine whether the reassembly process is complete.</p>
<p id="p-0017" num="0016">The use of validity indicators to track data in an assembly buffer significantly reduces the amount of time required to determine packet contiguity. In addition, through the use of validity indicators, the data payload can be parsed for tokens prior to complete contiguity being achieved. This allows for faster processing of messages.</p>
<p id="p-0018" num="0017">Other systems, methods, features and advantages of the invention will be or will become apparent to one with skill in the art upon examination of the following figures and detailed description. It is intended that all such additional systems, methods, features and advantages be included within this description, be within the scope of the invention, and be protected by the accompanying claims.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0019" num="0018">The components in the figures are not necessarily to scale, emphasis instead being placed upon illustrating the principles of the invention. In the figures, like reference numerals designate corresponding parts throughout the different views.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram illustrating an exemplary system in accordance with an embodiment of the present invention.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram illustrating details of the reassembly engine shown in <figref idref="DRAWINGS">FIG. 1</figref>, in accordance with a further embodiment of the invention.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIGS. 3</figref><i>a</i>-<i>b </i>illustrate examples of HTTP messages that can be handled by the system of <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 4</figref> is block diagram of an exemplary system in accordance with another embodiment of the present invention.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 5</figref> is a block diagram illustrating details of the EMU shown in <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIGS. 6</figref><i>a</i>-<i>b </i>illustrate an exemplary buffer data structure usable in the buffer memory shown in <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIGS. 7</figref><i>a</i>-<i>b </i>illustrate exemplary fields included in the summary area of the buffer data structure.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIGS. 8</figref><i>a</i>-<i>c </i>are tables defining exemplary control fields included in the summary area of the buffer data structure.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 9</figref> illustrates an exemplary encoding scheme for validation bits stored in the validation area of the buffer data structure of <figref idref="DRAWINGS">FIGS. 6</figref><i>a</i>-<i>b. </i></p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0029" num="0028">The following detailed description is not meant to limit the scope of the invention, but instead provides examples of packet switching systems and methods that more fully illustrate the principles of the invention.</p>
<p id="p-0030" num="0029">Turning now to the drawings, and in particular to <figref idref="DRAWINGS">FIG. 1</figref>, there is illustrated a system <b>100</b> in accordance with an exemplary embodiment of the present invention. The system <b>100</b> includes a switch <b>102</b> connected to one or more hosts <b>108</b>, <b>110</b>, such as clients and/or servers located on a network. The switch <b>102</b> allows the hosts <b>108</b>, <b>110</b> to communicate with one another using a packet-based communication protocol, such as TCP/IP. Each connection may be physically distinct, or logically distinct while using the same physical connection mechanism.</p>
<p id="p-0031" num="0030">Generally, the switch <b>102</b> receives incoming packets from the hosts <b>108</b>, <b>110</b> and synthesizes output packets that have been formatted to improve throughput and overall system performance or perform some service or function such as NAT (Network Address Translation). In particular, the switch <b>102</b> can perform processing functions such as those described in the related application entitled “Switching System” (U.S. patent application Ser. No. 10/098,957), which is hereby incorporated by reference.</p>
<p id="p-0032" num="0031">Included in the switch <b>102</b> is a packet reassembly engine <b>104</b> for processing packet traffic entering the switch <b>102</b>. The reassembly engine <b>104</b> reassembles incoming packet data to ensure that the data is contiguous and without gaps so that further processing by the switch <b>102</b> can occur. In addition, the reassembly engine <b>104</b> can be configured to detect tokens and the like before incoming messages are completely reassembled. This serves to reduce processing latency and improve overall throughput of the switch <b>102</b>.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram illustrating details of the packet reassembly engine <b>104</b>. The reassembly engine <b>104</b> includes a buffer <b>202</b>, a first logic circuit <b>204</b>, validity bit storage <b>206</b>, a second logic circuit <b>208</b>, a summary bit storage <b>210</b>, a contiguity checker <b>212</b>, and a token parser <b>214</b>. The buffer <b>202</b> stores one or more information elements included in incoming packets. The information elements can each represent a suitable chuck of data, such as a segment or byte included in the incoming data stream. The buffer <b>202</b> can be a circular buffer or queue.</p>
<p id="p-0034" num="0033">The first logic circuit <b>304</b> sets validity bits stored in the validity memory <b>206</b>. The settings of the validity bits are based on the information elements stored in the buffer <b>202</b> Preferably, there is a validity bit corresponding to each information element location in the buffer <b>202</b>. The validity bit is set when an information element is stored at the respective location in the buffer <b>202</b>, indicating that the location in the buffer contains valid data.</p>
<p id="p-0035" num="0034">The second logic circuit <b>208</b> sets summary values that correspond to the validity bits. Each summary value can correspond to plural validity bits. Preferably, each summary value corresponds to eight validity bits in memory <b>206</b>. The summary values can be two-bit values stored in the memory <b>210</b>. The first bit of the summary value indicates whether complete contiguity exists for the information elements corresponding to the eight validity bits, i.e., all of the validity bits in the byte are set. The second bit of the summary value indicates that a predetermined token terminates within the eight information elements stored in the corresponding buffer locations.</p>
<p id="p-0036" num="0035">This 2-bit encoding scheme for the summary values permits the contents of the assembly buffer to be pre-scanned for tokens prior to the occurrence of completed reassembly. Further details of an exemplary 2-bit encoding scheme usable with engine <b>104</b> is described herein connection with <figref idref="DRAWINGS">FIGS. 4-9</figref>.</p>
<p id="p-0037" num="0036">The contiguity checker <b>212</b> can be a logic circuit, software component or any suitable combination of hardware/software components for determining the contiguity of the information elements stored in the buffer <b>202</b>. The contiguity of the elements is determined based on the settings of the validity bits stored in memory <b>206</b>. If a validity bit is set, this indicates that the corresponding location in the buffer <b>202</b> contains valid data. By scanning the memory <b>206</b> to determine which validity bits are set, the contiguity checker <b>212</b> can determine the degree and completeness of contiguity of a message being reassembled by the engine <b>104</b>.</p>
<p id="p-0038" num="0037">The token parser <b>214</b> can be a logic circuit or suitable hardware software component for determining whether a predetermined token is stored in the buffer <b>202</b>. The token parser <b>214</b> makes this determination based on the summary values stored in memory <b>210</b>.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 3</figref><i>a </i>illustrates an exemplary sequence of hypertext transfer protocol (HTTP) messages <b>300</b> that can be handled by the system of <figref idref="DRAWINGS">FIG. 1</figref>. A first HTTP message <b>302</b> is followed by a second HTTP message <b>306</b>, as shown in <figref idref="DRAWINGS">FIG. 3</figref><i>a</i>. The HTTP messages <b>302</b>, <b>306</b> are separated by end-of-message tokens <b>304</b>, <b>308</b> respectively. The end-of-message tokens <b>304</b>, <b>308</b> can be HTTP standard terminators, as specified in RFC 2616.</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 3</figref><i>b </i>shows a second exemplary HTTP message <b>320</b> that can be handled by the systems disclosed herein. The HTTP message <b>320</b> is a standard format that includes an HTTP header <b>322</b> having appended thereto a payload <b>330</b>. The HTTP header <b>322</b> is terminated by an end-of-message token <b>328</b>. A payload length token <b>324</b> is included within the HTTP header <b>322</b>.</p>
<p id="p-0041" num="0040">The reassembly engine <b>104</b> can be implemented using one or more field programmable gate arrays (FPGAs), application specific integrated circuits (ASICs), or application specific standard products (ASSPs).</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram of an exemplary system <b>400</b> in accordance with a further embodiment of the present invention. Packet reassembly, in accordance with the invention, is performed by an external memory unit (EMU) <b>410</b> included in the system <b>400</b>. The system <b>400</b> includes a switch <b>401</b> connected to one or more client hosts <b>403</b> and one or more server hosts <b>405</b>, such as computers. The switch <b>401</b> allows the client <b>403</b> and server <b>405</b> to communicate with one another using a packet-based communication protocol, such as TCP/IP.</p>
<p id="p-0043" num="0042">The processing engines included in the switch <b>401</b> use internal messages to pass semaphores, e.g. a generation count and transaction label (tlabel), among themselves to coordinate operations and maintain temporal coherence for connections handled by the switch <b>401</b>.</p>
<p id="p-0044" num="0043">Generally, the packet switch <b>401</b> takes ingress traffic, classifies such traffic, performs rewrites, and then forwards that traffic. Similarly, packets are directed to the switch <b>401</b> by packet filters or forwarding entries configured into a host switch (not shown) with respect to virtual IP (VIP) addresses allocated to the switch <b>401</b>. Traffic from the host switch arrives at the packet switch <b>401</b>, is classified according to headers and content policies, undergoes rewrites by way of header construction, and then egresses back through the host switch.</p>
<p id="p-0045" num="0044">The switch <b>401</b> architecture addresses layer 4 (L4)-layer 7 (L7) networking services, as referenced to the OSI seven layer model. These services can include services such as content-enabled server load-balancing (SLB) at gigabit Ethernet media rates. While emphasis is on content services, support is also provided for L4 (non-content) services, including SLB, at the same media rates.</p>
<p id="p-0046" num="0045">The switch <b>401</b> can operate as a reverse-proxy between clients and servers, thus it can terminate both client-side and server-side TCP connections. The switch <b>401</b> can be implemented in the form of an intelligent processing card, which can be deployed as an appliance or as a blade in a gigabit Ethernet chassis switch (not shown).</p>
<p id="p-0047" num="0046">The switch <b>401</b> is configured with forwarding data so that egress server traffic can reach the appropriate physical server hosts. Console and data access can be provided through administrative serial and Ethernet ports (not shown) included in the switch <b>401</b>. These can be used for configuration and status reports.</p>
<p id="p-0048" num="0047">The switch <b>401</b> includes a policy engine (PE) <b>402</b>, a binding lookup table (BLT) <b>404</b>, a packet manager (PM) <b>406</b>, a backplane interface <b>408</b>, a crawler <b>409</b>, the EMU <b>410</b>, a central processing unit (CPU) subsystem <b>412</b>, a gigabit media access controller (GMAC) <b>414</b>, and a physical interface <b>416</b>. The switch <b>401</b> also includes a number of storage devices. Theses devices include one or more first-in-first-out (FIFO) memories <b>418</b> for storing server transmission control block (sTCB) pointers and switch internet protocol (IP) addresses (TIPs) and TCP port numbers (TPOs), a policy engine content addressable memory (PECAM) <b>420</b>, a key reduction CAM (KRCAM) <b>422</b>, one or more FIFOs <b>424</b> for storing flow TCB (fTCB) pointers and client (cTCB) pointers, a TCB database (DB) <b>426</b>, a crawler database <b>428</b>, and an EMU buffer <b>430</b>.</p>
<p id="p-0049" num="0048">The storage devices <b>418</b>-<b>430</b> are generally depicted in their preferred technologies in <figref idref="DRAWINGS">FIG. 4</figref>. However, alternative memory technologies, such as EEPROMs, RAMs, optical storage devices, or any other suitable storage means can be used to implement the storage devices <b>418</b>-<b>430</b>.</p>
<p id="p-0050" num="0049">The policy engine <b>402</b>, BLT <b>404</b>, packet manager <b>408</b>, backplane interface <b>408</b>, crawler <b>409</b>, and EMU <b>410</b> can be implemented using any suitable combination of hardware and/or software components, and are preferably implemented in hardware using one or more field programmable gate arrays (FPGAs), such as the family of components with part numbers prefixed EP-20K, available from Altera, Inc. In addition or in the alternative, the above components can be implemented using one or more application specific integrated circuits (ASICs) or application specific standard products (ASSPs).</p>
<p id="p-0051" num="0050">The functionality of the packet switch <b>401</b> is comprised of two partitions: a TCP/IP stack for packet handling and traffic management, and a proxy service for content analysis and policy selection. This functionality can be thought of as a protocol stack and an application running over that stack.</p>
<p id="p-0052" num="0051">The TCP/IP protocol stack functionality is comprised of the backplane interface <b>408</b> for ingress packet pre-filtering and header classification, the BLT <b>404</b>, which provides a traffic stream flow table, the PM <b>406</b>, which includes a TCP/IP protocol state machine and rewrite engine, and the EMU <b>410</b>, which provides a protocol reassembly manager and preliminary parser.</p>
<p id="p-0053" num="0052">The proxy service partition includes the PE <b>402</b>, which provides a server load-balancing policy engine and related scheduling and server tables.</p>
<p id="p-0054" num="0053">The GMAC <b>414</b> and physical interface <b>416</b> include commercially-available components for implementing media access control (MAC) and physical layer protocols, such as gigabit Ethernet, for communicating with the hosts <b>403</b>, <b>405</b> over a network. Two physical interfaces can be supported. The first is a 1000 BaseT copper interface, which connects to the physical interface <b>416</b>. The full line rate is supported. The second interface is a backplane interface. This interface is full duplex and supports 1000 BaseT both into and out of the GMAC <b>414</b>. If the packet switch <b>401</b> is deployed in a host switch then the backplane interface can be active. If the switch <b>401</b> is deployed as an appliance, then the CAT5 interface is active.</p>
<p id="p-0055" num="0054">In addition to or alternatively, the physical interface can include components for interfacing to an optical network.</p>
<p id="p-0056" num="0055">In addition to its functions described above, the backplane interface <b>408</b> can, based on protocol, channel incoming packets to the CPU <b>412</b>. During normal operation only control packets are channeled to the CPU <b>412</b>. The backplane interface <b>408</b> accepts outgoing packets from the CPU <b>412</b> or from the PM <b>406</b>. In addition, packets may be transferred by direct memory access (DMA) directly from the CPU <b>412</b> subsystem. The backplane interface <b>408</b> also translates each packet from the internal formats used in switch <b>401</b> to the format used by the GMAC <b>414</b>.</p>
<p id="p-0057" num="0056">The CPU subsystem <b>412</b> can include a conventional complement of devices (CPU, RAM, ROM, Flash, etc). It communicates with the other components in the switch <b>401</b> through a 32 bit/50 MHz PCI interface. The primary interface to the user is the RS232, which supports a user console (not shown). The CPU card handles functions such as diagnostics, health checks, configuration and initialization of the switch <b>401</b>, and the like.</p>
<p id="p-0058" num="0057">The BLT <b>404</b> maintains a list of open TCP logical connections in the KRCAM <b>422</b>. The search key to the CAM <b>422</b> is a five-tuple extracted from incoming IP packets. The five-tuple includes the source IP address, destination IP address, source TCP port, destination TCP port, and IP protocol field. As packets pass from the backplane interface <b>408</b> to the PM <b>406</b>, they are examined by the BLT <b>404</b> and the five-tuple is extracted. The five-tuple is then applied to the KRCAM <b>422</b>. The contents of the KRCAM <b>422</b> includes fTCB pointers to TCB data structures, which describe the state of the TCP connection. If the packet five-tuple hits, i.e., refers to an existing connection, then a TCB pointer from the KRCAM <b>422</b> is passed to the PM <b>406</b> so that the corresponding TCB can be accessed in the TCB database <b>426</b> during handling of the packet.</p>
<p id="p-0059" num="0058">The cTCB and fTCB pointers, which are not currently in use are stored in the two FIFOs <b>424</b>. These FIFOs are pre-loaded by the CPU <b>412</b> at boot time. The number of supported key-address pairs in the CAM is twice the total number of connections supported by the switch <b>401</b>.</p>
<p id="p-0060" num="0059">In addition to the 24-bit TCB pointers, the FIFO RAM holds an additional 8-bit generation count (GEN CNT) field in the high order byte of each FIFO entry. The GEN CNT is a semaphore passed forward to both the PE <b>402</b> and the PM <b>406</b> for use in other blocks. It is incremented every time the TCB pointer is recycled back into the FIFO <b>424</b> (rolling over after 256 recycles). This allows the BLT <b>404</b> to recycle the pointers into the appropriate resource pool when the PM <b>406</b> is tearing down a connection (doing DELETE requests).</p>
<p id="p-0061" num="0060">As connections are torn down or timed out by the PM <b>406</b>, the associated TCB pointers are removed from the key reduction CAM <b>422</b>. The TCB pointers are recycled by returning then to the appropriate FIFO in BLT <b>404</b>. Server TCB pointers are forwarded to the PE <b>402</b>, which manages the pool of available sTCB indexes (pointers).</p>
<p id="p-0062" num="0061">The purpose of the crawler <b>409</b> is to determine whether a specified time period has elapsed since the last activity seen on a connection. An activity can include a previous timeout detected by the crawler.</p>
<p id="p-0063" num="0062">To accomplish this function, there is a separate crawler entry for each server TCB and for each client TCB in the crawler database <b>428</b>. A state machine continually walks through the crawler DB <b>428</b> and examines each crawler entry to determine whether a timeout period has elapsed (i.e., it times out the connection).</p>
<p id="p-0064" num="0063">There can be a predetermined number of timeout intervals supported by the crawler <b>410</b>. These values can be stored in registers that are set by the CPU <b>412</b> at configuration time. If a new crawler entry is updated before the timeout period expires, then the entry is overwritten and any evidence of the previous values is discarded.</p>
<p id="p-0065" num="0064">There are two interfaces between the PM <b>406</b> and the crawler <b>409</b>. The first is a command interface, which the PM <b>406</b> uses to directly read or write the crawler entries. This is the interface used to instruct the crawler <b>409</b> to perform its timeout function on a specific client or server TCB. The second interface is a FIFO, which the crawler <b>409</b> uses to notify the PM <b>406</b> that a specified timeout period has elapsed for a specified TCB. The commands, which are accepted by the crawler <b>409</b> are shown in the table below:</p>
<p id="p-0066" num="0065">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="1" colwidth="28pt" align="left"/>
<colspec colname="2" colwidth="189pt" align="left"/>
<thead>
<row>
<entry namest="1" nameend="2" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry>Init</entry>
<entry>Marks a crawler entry as valid. This command also specifies</entry>
</row>
<row>
<entry/>
<entry>which timeout interval should be used for the timeout function.</entry>
</row>
<row>
<entry>Get</entry>
<entry>Returns the current contents of the crawler entry to the PM 406</entry>
</row>
<row>
<entry/>
<entry>via the command interface.</entry>
</row>
<row>
<entry>Update</entry>
<entry>The difference between an update and an init is that the crawler</entry>
</row>
<row>
<entry/>
<entry>uses the control bits in the crawler entry (as opposed to</entry>
</row>
<row>
<entry/>
<entry>initializing them).</entry>
</row>
<row>
<entry>Delete</entry>
<entry>This marks the crawler entry as invalid. When the crawler</entry>
</row>
<row>
<entry/>
<entry>state machine next encounters this entry it will notify the PM</entry>
</row>
<row>
<entry/>
<entry>406 and the PM 406 will invalidate the corresponding TCB</entry>
</row>
<row>
<entry/>
<entry>entry.</entry>
</row>
<row>
<entry namest="1" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0067" num="0066">If the crawler times out a connection it uses the FIFO interface to send a marker to the PM <b>406</b>. The marker indicates which type of timeout period was selected and which TCB timed out. However, it is possible that when the timeout is detected, the FIFO from the crawler <b>409</b> to the PM <b>406</b> is full. In this case the crawler state machine will wait until its next pass through the crawler memory <b>428</b> to deposit the timeout. State is kept in the crawler <b>410</b> to indicate that the timeout already occurred.</p>
<p id="p-0068" num="0067">Anytime that an L5 packet is handled and the TCB is fetched, the corresponding crawler entry is fetched. At the same time, the crawler state machine continues to walk through memory <b>428</b>. Once a crawler entry has been read by the PM <b>406</b>, the crawler state machine is prevented from updating that entry and from placing any timeout indicator associated with that entry in the crawler <b>109</b> to the PM <b>406</b> FIFO. Thus, the PM <b>406</b> can know that the entry, which it read, is valid until it is written back to crawler memory. This eliminates situations involving the timeout of a connection while a packet is being handled. During this time, other crawler entries are examined and timeouts that are associated with other entries may be written to the crawler <b>410</b> and to the PM 406 FIFO.</p>
<p id="p-0069" num="0068">In operation, the switch <b>401</b> receives ingress traffic that is delivered from the host switch to the backplane interface <b>408</b>, where such traffic is exposed to basic checks and header classifications. Most incoming traffic is forwarded to the PM <b>406</b> for TCP/IP protocol processing. In transit to the PM <b>406</b>, traffic headers are snooped by BLT <b>404</b> to provide lookup indexes, which include TCB references and service indexes. Any traffic referencing a non-content-enabled service can be signaled to the policy engine <b>402</b> to get a server binding.</p>
<p id="p-0070" num="0069">Client traffic arriving at the TCP/IP stack is initially classified as to which service is being requested (service index) and who is making the request (client identifier). For L4 situations, these values are used directly in the proxy service for policy considerations. For L5-7 (content-enabled) services, these initial values are qualified inside the proxy service according to configured content rules, and a final set of values is computed and used for policy considerations.</p>
<p id="p-0071" num="0070">At the PM <b>406</b>, a packet header is presented to the protocol state machine against the state given in the corresponding TCB that was identified by BLT <b>404</b>. Relevant data is extracted from the packet header and applied to the TCB and then the header is stripped from the packet. A header rewrite is achieved by regenerating it on the egress side of the PM <b>406</b> from the corresponding TCB. If any content inspection is necessary, the packet body is forwarded to EMU <b>410</b> for reassembly and eventual presentation to the proxy service. In such cases, the packet body is not transmitted out of the switch <b>401</b> until a server binding has been made.</p>
<p id="p-0072" num="0071">If a policy selection is necessary (e.g. for the head of a new traffic flow) the PM <b>406</b> is notified by the proxy service. The request to the proxy service is generated by the BLT <b>404</b> for L4 services, and the EMU <b>410</b> for L5-L7 services.</p>
<p id="p-0073" num="0072">The EMU <b>410</b> reassembles a TCP data stream and determines if there is sufficient data to present to the proxy service for content analysis and policy selection. To do this it ensures that the data is contiguous and without gaps and that the start of the data is aligned with the expected TCP sequence number.</p>
<p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. 5</figref> is a block diagram illustrating details of the EMU <b>410</b> shown in <figref idref="DRAWINGS">FIG. 4</figref>. The EMU includes five primary components: the command processor <b>602</b>, the SDRAM Subsystem <b>604</b>, the CA event processor <b>606</b>, the PM event processor <b>608</b> and the Post-Purge Engine <b>610</b>. Each of the latter three components functions independently under the supervision of the command processor <b>602</b>. The command processor interfaces with all other EMU control blocks and maintains the command buffer <b>612</b>, which is a FIFO for the switch posts and commands. During a data post, the command processor controls the merge datapath <b>614</b> and the merge staging buffer <b>616</b>.</p>
<p id="p-0075" num="0074">The SDRAM subsystem <b>604</b> includes a 16-way arbiter <b>620</b> and an SDRAM physical interface <b>622</b>. Arbitration for SDRAM access is performed on a priority mechanism favoring vital threads over deferred events. The CA event processor <b>606</b> retrieves buffer identities from the deferred event queue <b>624</b><i>a</i>-<i>b </i>corresponding to buffers containing completed headers. The associated data staging engine <b>626</b><i>a</i>-<i>b </i>buffers all data movement necessary to post these headers to the content analyzer <b>442</b>.</p>
<p id="p-0076" num="0075">The PM event processor <b>606</b> posts deferred acknowledgements, buffer reads, and notices of completed elements to the switch. Each of these deferred events is stored in the associated deferred event queue <b>624</b><i>a</i>-<i>b </i>and any data reads are managed by the associated data staging engine.</p>
<p id="p-0077" num="0076">All the switch commands to the EMU <b>410</b> are buffered in the command buffer <b>612</b> and processed by the command processor <b>602</b>. This buffer is 8 kbytes in size and serves to allow the EMU <b>410</b> to absorb long-latency commands. The relevant commands from the switch are Reset Buffer, Initialize Buffer, Read Buffer, Post to Buffer, Post with Deferred ACK and Purge Buffer Entity.</p>
<p id="p-0078" num="0077">During a Post, the command processor <b>602</b> passes the post data into the merge datapath <b>614</b>, where it is combined with the overlap data in the merge staging buffer <b>616</b> and prepared for an update to the buffer.</p>
<p id="p-0079" num="0078">The EMU SDRAM subsystem <b>604</b> includes of a 128-bit physical interface <b>622</b> and a 16-port arbiter <b>620</b>. The arbiter <b>620</b> uses single-cycle turnaround to allow arbitration for access while the previous access is completing. Data staging and merging is performed by the SDRAM controller <b>630</b>. A priority matrix is established (at compile time) that determines the relative priority of each subunit requiring SDRAM access. Refresh cycles occur transparently.</p>
<p id="p-0080" num="0079">The EMU CA event processor <b>606</b> is responsible for passing completed headers to the content analyzer <b>442</b>. Completed buffers will have the corresponding buffer number posted as an entry in the CA deferred event queue <b>624</b><i>a</i>. The CA event processor <b>606</b> extracts entries from the queue <b>624</b><i>a </i>and performs the necessary memory operations to prepare the header for transmission to the content analyzer <b>442</b>. In order to accommodate a CA Fast Bypass (transmitting a header directly to the content analyzer as it is posted from the switch, the CA event processor <b>606</b> arbitrates for ownership of the CA I280 interface.</p>
<p id="p-0081" num="0080">The EMU PM event processor <b>608</b> is responsible for posting header data, deferred acknowledgements, and notification of completed elements to the switch. As with the CA event processor <b>606</b>, events to be processed are extracted from the corresponding deferred event queue <b>624</b><i>b</i>. However, no bypass mechanism exists. This allows the PM event processor <b>608</b> to maintain control of the 1880 bus to the switch. Posts to the switch are scanned for entity length and content length. If identified, these lengths are rewritten to the corresponding buffer by the length engine <b>636</b>.</p>
<p id="p-0082" num="0081">The EMU post-purge engine <b>610</b> is a multi-threaded entity responsible for managing the header assembly, contiguity checking, header completeness checking and state transitions of a connection. It operated entirely in the 100 MHz domain and is triggered by the EMU command processor <b>602</b>.</p>
<p id="p-0083" num="0082">During a post from the switch, the post-purge engine <b>610</b> will calculate the offsets of the relevant staging information for header assembly and load the relevant connection information. The summary memory is fetched, updated, and scanned for contiguity and completeness. When the data post from the merge datapath <b>614</b> is complete, the post-purge engine <b>610</b> is also responsible for cataloging all end signatures found and adjusting the summary memory. During a Purge operation, no staging data is prepared, but the contiguity and completeness is evaluated and updated.</p>
<p id="p-0084" num="0083">The control registers <b>638</b> include values settable and readable by the PM <b>406</b> to control operation and check the status of the EMU <b>410</b>, respectively. The PCI interface <b>640</b>, DMA buffer <b>642</b> and engine <b>644</b> permit direct memory access (DMA) to the buffer <b>430</b> by the PM <b>406</b> in predefined situations.</p>
<p id="p-0085" num="0084">The data structure for connection information stored in the buffer <b>430</b> is shown in <figref idref="DRAWINGS">FIGS. 7</figref><i>a</i>-<i>b</i>. The buffer <b>430</b> includes a summary area for each connection handled by the switch <b>401</b>. Each summary area consists of a length rewrite field, a buffer control field and a contiguity bit field. The length rewrite field is a fast-rewrite field containing the length of the payload associated with the current header, a valid bit indicating if a payload was present in the header and a generation count obtained from the TCB storage at the time the length was identified. The generation count prevents any temporal discrepancies arising from connections that are reset while a data post to the PM <b>406</b> is in progress.</p>
<p id="p-0086" num="0085">The generation count is associated with a connection. Because events processed by the EMU <b>410</b> are deferred, it is possible that a deferred event queue entry exists for a buffer, which has been reset and allocated to a new connection. The BLT <b>404</b> increments the generation count for every new connection. When deferred events are to be processed, the generation count is checked against the current generation count in the buffer. Events for buffers which no longer are valid are dropped.</p>
<p id="p-0087" num="0086">The PE <b>402</b> accepts service index and client identifier values from the BLT <b>404</b> (for L4) and applies the service policies. For SLB, this involves establishing the physical server binding according to these general rules:
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0087">a) check client history for similar requests from the same client; apply any such discovered binding (for stickiness), and</li>
        <li id="ul0002-0002" num="0088">b) apply scheduling rules for the appropriate server grouping to select and bind a physical server.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0088" num="0089">The PE <b>402</b> adjusts server usage counts and informs the protocol stack of the PM <b>406</b> of the server selection. The PM <b>406</b> can then forward the saved TCP data in the EMU <b>410</b> to the selected server.</p>
<p id="p-0089" num="0090">If the packet passed from backplane interface <b>408</b> to the PM <b>406</b> is associated with a new connection, then there will be no entry in the KRCAM <b>422</b>. In this case, the BLT <b>404</b> references the PECAM <b>420</b> with a three-tuple extracted from the packet as it passes between the PM <b>406</b> and the backplane <b>408</b>. The three-tuple includes the destination IP address, destination port, and IP protocol field. The output of the PECAM <b>420</b> is a service index used to determine:
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0000">
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0091">a) whether this new connection can be supported by the proxy;</li>
        <li id="ul0004-0002" num="0092">b) whether the connection is requesting an L4 (non-content aware) or L5 (content aware) service; and</li>
        <li id="ul0004-0003" num="0093">c) which particular service is being requested by the packet.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0090" num="0094">If the client is requesting a supported service, a new pointer to a TCB (L4 or L5) is extracted from the appropriate FIFO <b>424</b> and sent to the PM <b>406</b>. In the case of an L4 connection, the information about the service requested is sent to the PE <b>402</b>. If the new connection is an L5 connection all information is sent to the PM <b>406</b>.</p>
<p id="p-0091" num="0095">The BLT <b>404</b> can also be directed by the PM <b>406</b> to add a server→client connection to the KRCAM <b>422</b> once a connection is established. To obtain these directives, the BLT <b>404</b> snoops the bus used to send outgoing packets from the PM <b>406</b> to backplane interface <b>408</b>. In this case there is no associated service information and the entry to the KRCAM <b>422</b> is a new entry.</p>
<p id="p-0092" num="0096">When a connection is terminated the BLT <b>404</b> is informed by the PM <b>406</b>. As with the server→client adds, these directives are snooped on the outgoing PM to backplane interface bus. When the BLT <b>404</b> is notified of a connection termination, it removes the corresponding KRCAM entry and returns the TCB pointer to the appropriate FIFO (L4 or L5).</p>
<p id="p-0093" num="0097">The policy engine <b>402</b> receives L4 service requests from the BLT <b>404</b>. The server description and proxy TIP/TPO databases provide the five-tuple associated with the proxy to server connection (Source Internet Protocol (IP) Address, Destination IP Address, Source Port Number, Destination Port Number, Protocol). If the connection is L5, then a pointer to a server TCB (sTCB) is allocated from the sTCB FIFO <b>418</b>. This points to the TCB data structure stored in the TCB database that describes the server to client connection.</p>
<p id="p-0094" num="0098">The layer 4 TCP protocol encapsulates layer 5 messages, which can use a number of different HTTP methods (GET, HEAD, POST, etc). HTTP is the “payload” of the layer 4 message. POST methods may also contain layer 5 payload in the form of binary or ASCII data. As used herein, “payload” refers to the payload of a POST method. HTTP is a character-based protocol, which consists of a text header terminated with an end-of-header token. HTTP payload, if present, follows this token. The HTTP header is analyzed by the system to determine if the object following an end-of-message token is payload or a new header. If the HTTP header contains the keyword-value pair “Content-Length, Payload-Length”, then a payload of length payload-length follows the header.</p>
<p id="p-0095" num="0099">Because the PM <b>406</b> does not maintain the contiguity information, the EMU <b>410</b> provides the acknowledgement service when instructed to do so. As the reassembly buffer, the storage area within the EMU <b>410</b> for HTTP headers and payload, fills up, the TCP window is reduced until the client is not permitted to send more data. Only after the buffer contents have been bound to a server, sent to that server, and acknowledged by that server can the buffer be cleared and the TCP window reopened. The PM <b>406</b> and the EMU <b>410</b> cooperate to manage the appropriate window size.</p>
<p id="p-0096" num="0100">The term “buffer” is used to describe the memory space associated with each layer 5 connection. The term “reassembly buffer” denotes the portion of the buffer used to reassembly layer 5 messages. The remaining portion of the buffer stores control data and assorted processing data.</p>
<p id="p-0097" num="0101">Layer 5 messages (HTTP) are reassembled and checked for payload material before they are sent to the CA <b>442</b>. This task, as well as tracking the completeness of message payloads, is the responsibility of the EMU <b>410</b>.</p>
<p id="p-0098" num="0102">An array of external memory included in the EMU buffer <b>430</b> serves as an assembly area for message fragments that can arrive in any order and possibly overlap each other. The EMU <b>410</b> accepts these message fragments, assembles them in the correct order, and determines when a message is complete. In operation, the EMU <b>410</b> supports the assembly of messages from the same number of concurrent client connections as there are client TCBs allocated by the CPU <b>412</b>. The EMU <b>410</b> accepts message packets at line rate from the switch and is able to extract all necessary information within three minimal packet spacing time. It is assumed that each connection requires a SYN and ACK to establish the TCP/IP threeway handshake before any message data can be sent. These message packets can be anywhere from one byte to the MSS in size and address any portion of the 32-bit sequence number space. Each connection is allocated a contiguous reassembly buffer of 1536 bytes (<figref idref="DRAWINGS">FIG. 6</figref><i>a</i>), which is larger than the largest MSS value of 1460 bytes. The start of the reassembly buffer is locked to the sequence number associated with the start of the connection. As the message or message fragment enters the EMU <b>410</b>, the contiguous portion of the message (possibly including fragments from previous message fragments) is parsed to determine if a complete HTTP header is present. The EMU <b>410</b> then sends the PM a deferred acknowledgment, if the PM so requests, indicating what sequence number the switch should acknowledge to the client.</p>
<p id="p-0099" num="0103">A typical client-server connection will cause the following sequence of events in the EMU <b>410</b>. The client SYN received by the switch <b>401</b> causes a buffer reset to be launched into the EMU <b>410</b>, clearing the necessary memory. The client TCP datagram (HTTP) is posted to the EMU <b>410</b> by the switch upon receipt. The EMU analyzes the contents of the buffer and, if it finds a terminated contiguous element, sends this element to the content analyzer <b>442</b>. The client is then bound to a server using the results of the content analysis and a connection to the server established. Upon completion of the three-way handshake, the switch issues a read command for the data stored in the EMU buffer <b>430</b>. The EMU <b>410</b> sends the data element from the buffer <b>430</b> to the switch. When the server has acknowledged the element, the switch <b>401</b> issues a purge command, clearing the element from the buffer <b>430</b>. The EMU begins scanning for the next element in the buffer <b>430</b>.</p>
<p id="p-0100" num="0104">The EMU <b>410</b> acts as a passive agent accepting commands from other engines in the switch <b>401</b>. Each command may generate a response to the switch and possibly a transaction to the content analyzer <b>442</b>. Upon every internal message post from the switch components, the EMU <b>410</b> determines the length of the largest leftwise contiguous portion of the message and informs the components (if requested) to acknowledge the client up to that point.</p>
<p id="p-0101" num="0105">IP packets arriving from the client or server may arrive out of order, overlap previous packets, or arrive twice. Out of order packets will result in gaps between portions of the message as it is being reassembled. The packets and associated payload (if any) are reassembled by the EMU <b>410</b> into a complete message before that message can be passed to the content analyzer <b>442</b> for parsing.</p>
<p id="p-0102" num="0106">The EMU logic is configured to identify the start of the message, the end of the message, and whether all packets in between are present and correctly reassembled. The length of any payload is extracted from the message header as the end of a payload is not demarcated with any special sequence. Because portions of messages from different connections may be arriving at the same time, the EMU <b>410</b> allocates storage for each message and identifies the correct positioning of the incoming message fragment. When a message has been completely recovered, the EMU passes this message to the content analyzer <b>442</b> and, upon request, to the other engines in the switch <b>401</b> for transport to the target server.</p>
<p id="p-0103" num="0107">Additionally, the EMU <b>410</b> maintains a leftwise contiguity pointer such that the switch <b>401</b> can send the appropriate acknowledgment signal to the client when message fragments are received. The switch <b>401</b> maintains leftwise contiguity as long as message fragments arrive in order. When the first out-of-order fragment arrives, the switch <b>401</b> requires the EMU <b>410</b> to calculate the leftwise contiguity for that connection. Reassembly of a layer 5 stream requires the identification of two conditions: completeness and termination.</p>
<p id="p-0104" num="0108">Completeness is identified by having a contiguous segment of data that is correctly terminated. Identifying termination requires a series of tests to determine in what manner the length of the message is specified. Message length is determined by identifying one of three conditions: chunked transfer encoding, content length header, or lack of a content length header. Refer to RFC 2616, “Hypertext Transfer Protocol,” for a complete discussion of the determination of message length. Although message termination requires the determination of payload length, header identification does not. It is thus possible to send a complete header to the content analyzer <b>442</b> before verifying that a completed message has been assembled.</p>
<p id="p-0105" num="0109">As illustrated in <figref idref="DRAWINGS">FIG. 6</figref><i>a</i>, each connection is allocated a 2K page of physical memory to assemble incoming message and hold all necessary connection state information. Part of this connection state is a 128 byte summary area (summary memory) used to identify completeness and termination. The 2K page also contains a 192 byte validation area which maps directly to a 1536 byte assembly area. The assembly area contains all message packets that have been received as part of the connection. Packets are placed into this area based on the packet sequence number to assure correct reassembly.</p>
<p id="p-0106" num="0110">The validation memory is a one-to-one mapping of the assembly area such that each bit of validation represents one byte of assembly. In this manner, holes in the assembly area are detected by unset bits in the validation bit fields.</p>
<p id="p-0107" num="0111">Likewise, the summary memory contains a contiguity array, which is mapped one-to-one onto the validation memory. This contiguity array encodes every eight bits of validation memory into 2-bit summary values (<figref idref="DRAWINGS">FIG. 9</figref>). These summary values (states) can be parsed quickly to determine header completeness.</p>
<p id="p-0108" num="0112">The summary memory also contains all necessary state information regarding the connection. This includes the sequence number, which is associated with the beginning of the message. This number is locked to the buffer by the switch before any message fragments are accepted.</p>
<p id="p-0109" num="0113">Because the assembly area functions as a circular queue, the summary area also contains pointers to the beginning of the queue and the length of any completed header found. If a payload is identified, the summary area also contains the length of the payload.</p>
<p id="p-0110" num="0114">To conserve the switch memory bandwidth, the client and server TCBs for each connection are also stored within the 2K page. Every data post from the switch contains these TCBs that are immediately copied into a holding area for each connection. When a deferred event is processed, the TCB is retrieved from memory and validated by checking the generation count. This prevents a deferred event whose connection has been reset from completing. Because no transactions entering the EMU <b>410</b> can be stalled while all transactions leaving the EMU <b>410</b> are deferred, the EMU must maintain queues of deferred events. These queues are able to sustain an entry for every connection. The EMU <b>410</b> maintains an internal queue of 1024 entries, and pages entries into memory when this capacity is exceeded.</p>
<p id="p-0111" num="0115">A buffer area allocated to a connection is addressed by the TCB index corresponding to the connector. The summary area maintains pointers identifying the start of a message in the circular queue, the most leftwise contiguous point of the message, whether or not and end has been detected and the content length (if identified). When a message fragment arrives, its sequence number is translated into a queue insertion pointer and the fragment data entered into the message storage area. A complete message header is observed when two consecutive Carriage Return, Line Feeds (CRLFx2) are detected and all intervening bytes from the start point are valid. There can be any number of CRLFx2 in the message payload, but the first CRLFx2 always identifies the end of the header. Once a complete header is detected, it is copied to the CA <b>442</b>. After a binding is created, the header message in the receive buffer is copied to a server. Once the proper acknowledgments are performed, the buffer header is flushed. At that time, a new start point will be set corresponding to the beginning of the next header, its payload, or the continuation of the payload.</p>
<p id="p-0112" num="0116">It should be noted that although RFC 2616 specifies a CRLFx2 signature to terminate a header, actual implementations vary. The EMU <b>410</b> can also accept LFCRx2, LFx2 and CRx2 signatures.</p>
<p id="p-0113" num="0117">Message headers are scanned for payload on the way to the switch. This is necessary to prevent the need for rescan during pipelined requests. If a message payload is detected, its length is recorded in the summary area and a subsequent purging of the message header will cause the payload length to be compared with the contiguity of the validation and summary areas. If the payload is complete, a deferred event informing the switch of this condition is queued. Otherwise, the assembly area keeps accepting packets until the payload is complete or the buffer has been filled. There may be more message payload than buffer space. During this time the payload will circulate through the buffer and a counter continues to track all the payload. At no time will the buffer be overrun because the advertised window size cannot be larger than the space available in the buffer. After receiving each message or message fragment, the EMU may generate a deferred acknowledgment signal to the switch indicating to which point the message can be acknowledged by analyzing the leftwise contiguity of the message.</p>
<p id="p-0114" num="0118">If a large cookie is present in the header, the assembly buffer could fill before the end of the header arrives. Under this condition, the EMU will send the entire buffer to the content analyzer. The EMU will mark the buffer as a partial header and send all but the last 32 bytes to the switch after a binding has been created by SLB. The 32 bytes must be kept to catch the “content-length” string or CRLFx2, which might cross the 1536 byte boundary.</p>
<p id="p-0115" num="0119">In order to recognize the headers in a raw input data stream, a string parsing system is implemented that defines the characteristics of a complete header. The parser uses filtering protocols to identify complete headers in the incoming packet stream and established pointers to them. The information is stored in a summary memory for quick retrieval and the packets are then stored in individual assembly areas located in the buffer memory. This scheme allows for the assembly of individual packets that can arrive in any sequence into a contiguous header, the identification of the header and payload elements (without having to reparse the stream in the buffer memory) and handling of the possibility of multiple requests within one message.</p>
<p id="p-0116" num="0120">The following discussion details the operation of the EMU <b>410</b> as an operational structure of switch <b>401</b>. Implementation of the functions of the EMU <b>410</b> as an element of the switch should not be seen as limiting. The EMU functionality can be embodied as a separate structure, unaffiliated with the other engines and components included in the switch <b>401</b>.</p>
<p id="p-0117" num="0121">During typical operation, the PM <b>406</b> posts one or more message segments to the EMU <b>410</b> and receives a deferred acknowledgment, if one was requested. Upon detection of a completed header, the EMU <b>410</b> posts the header to the CA <b>442</b> subsequently analyzes the header and informs the PE <b>402</b> as to which group of servers can accept the header. The PE <b>402</b> selects a server and passes the properties of the said server to the PM <b>406</b>. When the PM <b>406</b> has established a connection to the required server, the PM <b>406</b> requests the header from the EMU <b>410</b> and sends it to this server. When an acknowledgment is received, the PM <b>406</b> instructs the EMU <b>410</b> to purge the header and the cycle repeats.</p>
<p id="p-0118" num="0122">The PM messages to the EMU <b>410</b> begin with a 4-bit command, the buffer address, the post sequence number and the length of the message header and data. In response to these messages, the EMU starts memory reads from the summary data of the specified buffer.</p>
<p id="p-0119" num="0123">The EMU <b>410</b> processes all requests for packet processing or header data as deferred events. When a deferred event is processed, the TCB is retrieved from the copy stored in EMU memory and validated by checking the generation count. This prevents a deferred event whose connection has been reset from completing.</p>
<p id="p-0120" num="0124">The EMU buffer <b>430</b> contents are presented to the policy service once a completed header is identified, or when the buffer <b>430</b> is completely filled. To support TCP acknowledge (ACK) generation, the EMU <b>410</b> also provides feedback to the PM <b>406</b> about the current contiguity of the received data buffer.</p>
<p id="p-0121" num="0125">As packets arrive, their sequence numbers identify their position in the buffer memory relative to the start point. The switch shipped this sequence number with the packet data to the EMU. As the packet is streamed into the EMU, its contents are analyzed by a parser and summarized. As packets arrive, they may carry complete or partial objects. If an object straddles two packets, then when both packets are received and assembled, the Buffer Management Unit must be able to identify the object. This is accomplished by reading sufficient locations in the buffer memory before and after the incoming packet to handle any alignment of the longest object. Thus, loading a new packet into the buffer memory requires a READ, WRITE x N operation. The parser will string search the packet plus the look-ahead and look-behind locations for keywords. The buffer manager organizes the buffer pointers and manages the summary information. The contiguity of the entire message buffer is being evaluated as the packet and associated before and after information is being parsed. By integrating the insertion point and length of the incoming packet with the previous message fragments, the acknowledgment pointer is obtained and passed to the switch as a deferred acknowledgment (if requested). The EMU does not guarantee immediate delivery of the deferred acknowledgment. The switch will generate its own acknowledgements as long as the incoming message packets are contiguous. As soon as a single packet is noncontiguous, the switch will request deferred acknowledgements from the EMU for all future packets associated with that connection. The EMU maintains four request queues, which are arbitrated by a priority mechanism. These are the ACK Queue for posting deferred acknowledgements to the switch, the CA Queue for posting completed headers to the content analyzer, the Data Queue for posting header and payload data to the switch (upon request) and the Partial Payload Queue for alerting the switch that a portion of a long payload element has been assembled and is ready for transport.</p>
<p id="p-0122" num="0126">The switch posts to the EMU are stored in the buffer memory. Posts consisting of complete HTTP headers can be scheduled for posting to the content analyzer immediately. However, partial headers must first be assembled and checked for completeness. The EMU must track partial headers and payloads that span multiple buffers.</p>
<p id="p-0123" num="0127">Layer 5 streams from the switch cannot be stalled. To do otherwise will cause back pressure to be applied to the network with a corresponding decrease of system efficiency. In order to accomplish this, there must be an input queue with sufficient depth to absorb the stream in real time. The interface to buffer memory is effectively multi-ported by quadrupling the bandwidth of the switch to the EMU interface. Because all reads and writes for the switch post will be to the same 2K page, the precharge and column accesses are amortized. After derating the memory system performance to account for refreshes and alignment issues, the buffer memory will be able to sustain twice the switch to the EMU transfer bandwidth. Write transactions are treated as having precedence over read transactions. When a read is in process and a write transaction begins, the read transaction is suspended until the write can be completed. Under specific circumstances, an interrupted read may be squashed and rescheduled in favor of a higher priority operation. Reads are prioritized by length as the probability of an interruption increases with read length.</p>
<p id="p-0124" num="0128">The receive buffer assembles header sections into one contiguous header string. As IP packets arrive, the IP and TCP headers are stripped by the switch. The remaining HTTP header and optional payload are passed to the EMU where the receive buffer places the sections into a buffer according to the sequence number offset. A leftwise contiguous pointer indicates the most leftwise contiguous point in the buffer from the start point. This pointer is returned to the switch to ACK the client if a deferred acknowledgement is requested.</p>
<p id="p-0125" num="0129">While still in the input path, the incoming packet is merged and aligned with the before and after data from the assembly buffer and scanned for all relevant strings. The input path also discards any portions of the incoming packet that would be placed outside the physical limits of the reassembly buffer. As the data stream from the switch enters the EMU, the summary entry is accessed. The first data word from the switch transfer contains the buffer index, sequence number and length fields.</p>
<p id="p-0126" num="0130">The EMU performs two memory reads to calculate all necessary information about this transfer. As soon as the first word of the incoming packet arrives, the EMU retrieves the physical offset of the start pointer (a pointer to the beginning of the circular reassembly queue) and the summary information from the buffer specified. As soon as the start pointer physical offset becomes available, the physical addresses of the merge data (before and after data used for scanning) are calculated along with the addresses of the corresponding validation memory. A final memory read is required to retrieve the validation bits for the most leftwise contiguous portion of the message.</p>
<p id="p-0127" num="0131">If the incoming packet fills a hole in the validation memory, then the most leftwise contiguous point could be anywhere in the buffer. The summary parse engine is responsible for parsing the summary information, incorporating the information from the incoming packet, and determining the exact location of the most leftwise contiguous point of the message. This summary parser is also responsible for detecting header completion in a subsequent operation.</p>
<p id="p-0128" num="0132">During the transfer of a complete header (with or without complete payload), the input path will detect that the input stream is being written to the start pointer of a message buffer and contains one of the defined key works for an HTTP datagram (GET, POST, and the like.). The subsequent bytes of the header are scanned for the CRLFx2 marker. If the latter marker is found then the header is complete. To increase throughput, the switch data posts which appear to be complete headers (start with a key word and addresses the beginning of a buffer) are speculatively written to the content analyzer if the unit is not busy. Failure to obtain a completed header will result in the transfer to CA being aborted. The message data (whether complete or not) is still inserted into the reassembly buffer. When the last fragment of a completed header is receiver, the buffer address of the completed entry is entered into the CA queue. At the earliest possible time, the header will be sent to the content analyzer. As with any post from the switch, a deferred acknowledgment signal is returned if requested. The header buffer will now continue to accumulate any additional data and await a data read and eventual purge signal from the switch. Completed partial payloads are handled in the same manner except that no information is passed to the content analyzer. Deferred acknowledgments may be stalled or aborted if an incoming message fragment matches the acknowledgment signal being sent.</p>
<p id="p-0129" num="0133">The 2 KB SDRAM buffer is divided into five segments. The first is a 128 byte scratch area containing TCB entry corresponding to the message being assembled. Storing a pointer to the TLB would be more memory efficient, but this would require the switch to retrieve the TLB for every acknowledgment signal. A 64 byte queue area provides storage for up to 16 deferred events. The queue managers track FIFO pointers that determine which buffer will be used for the next FIFO read or write. The queue area is followed by the 128 byte summary area, which contains all state and relevant information regarding the connection. A 192 byte validation area contains the valid bits associated with the reassembly area. The reassembly area is a circular queue of 1536 bytes. <figref idref="DRAWINGS">FIGS. 6</figref><i>a</i>-<i>b </i>shows the buffer memory footprint for a single 2K page.</p>
<p id="p-0130" num="0134">The EMU maintains two deferred event queues that manage four types of deferred events. The CA Queue manages completed headers. The CA disposal engine retrieves events from the CA Queue and causes the header from the corresponding buffer to be read and transmitted to the content analyzer. The PM Queue manages deferred acknowledgements, requests for a data and completed partial elements (headers or payloads). The PM disposal engine is responsible for retrieving events from the PM queue and correctly dispatching them. Both disposal engines operate only when memory bandwidth is available. The queue managers are also responsible for maintaining up to 1024 internal deferred events before paging events into memory. Events are paged in groups of eight into the queue memory areas of the memory buffers. Paging begins when a queue reaches 75% capacity and must be able to sustain one deferred event entering each queue every 672 nS, the minimum packet interval.</p>
<p id="p-0131" num="0135">Each summary area consists of a reserved area, a length rewrite field, a buffer control field and a contiguity bit field. The reserved area consists of three 16 byte words reserved for future usage. These words are considered fast rewrite fields because by only contain one item of information, it is not necessary to use a read-modify-write cycle to update the memory. The length rewrite field is a fast-rewrite field containing the length of the payload associated with the current header, a valid bit indicating if a payload was present in the header and a generation count obtained from the TCB Storage at the time the length was identified. This generation count prevents any problems arising from connections that were reset while a data post to the switch was in progress. The 16 byte buffer control field contains all the state associated with the connection. Finally, the contiguity bit field contains an encoding of the validation memory from which contiguity and completeness can be determined. This field is used twice during a switch data post to the EMU. First, the leftwise contiguity is determined by calculating the address of the last validation bits. This can be accomplished without having received the first data word of the post. When the post has completed, the summary bits are updated and a new scan determines if a completed header is present.</p>
<p id="p-0132" num="0136"><figref idref="DRAWINGS">FIGS. 7</figref><i>a</i>-<i>b </i>detail the fields of the EMU Summary Area.</p>
<p id="p-0133" num="0137">The Post Length Rewrite Mailbox is used by the PM Event Processor to write the length of the last entity that was read by the switch. For a subsequent Purge operation, this length is used to invalidate data in the assembly buffer.</p>
<p id="p-0134" num="0138">The Payload Length Rewrite Mailbox is used by the PM Event Processor to write the length of the “content-Length” variable if identified in a header that was read by the switch. For a subsequent Purge operation, this length is used to initialize the Payload Tracker and change the state of the buffer to a payload entity.</p>
<p id="p-0135" num="0139">This value is the TCP sequence number that corresponds to the beginning of the entity currently being assembled. It is initialized by a Lock-SN command from the switch and incremented during a Purge Operation.</p>
<p id="p-0136" num="0140">Because all events processed by the EMU <b>410</b> are deferred, it is possible that a deferred event queue entry exists for a buffer that has been reset and may contain new data. The switch is responsible for incrementing the Generation Count (GC) for every new connection. When deferred events are extracted by either event processor, the generation count is checked against the current Generation Count in the buffer. Events for buffers that no longer are valid are dropped.</p>
<p id="p-0137" num="0141">The Start Pointer Physical Address (SPPA) is the physical offset of the start pointer within the assembly buffer. This value is initialized to 12′h200 upon reset and increments towards 12′h7FF with wraparound to 12′h200. During a purge operation, the SPPA is advanced by the length of the entity being purged.</p>
<p id="p-0138" num="0142">The End Pointer (EP) points to the 8-byte word that contains the end sequence of a completed header. This address can then be used to load the last words of header data and determine the actual end point. This value should be considered invalid unless a header has been identified.</p>
<p id="p-0139" num="0143">The Payload Tracker is used to track long payloads of HTTP headers. When the payload has been identified by the post to the switch of the associated header, the Post-Purge Engine will set its termination condition to be either a filled buffer or contiguity to the payload tracker.</p>
<p id="p-0140" num="0144">Left-Wise Contiguity (LWC) is determined after every Post or Purge operation. It is the value used to generate the Acknowledge Sequence Number during a deferred acknowledgement. Contiguity is measured relative the SPA value.</p>
<p id="p-0141" num="0145">General Status (GS) is used by the Post-Purge Engine to determine the next state of a buffer after every Post or Purge operation. The bit fields are defined as shown in <figref idref="DRAWINGS">FIG. 8</figref><i>a. </i></p>
<p id="p-0142" num="0146">Principle Status (PS) is used by all the EMU components to determine the condition of a connection buffer. The bit fields are defined as shown in <figref idref="DRAWINGS">FIG. 8</figref><i>b</i>. The object class field is a 3-bit field that is set during the connection setup (Lock SN) operation from the value of the CSI passed to the EMU <b>410</b> from the switch <b>401</b>. As shown in <figref idref="DRAWINGS">FIG. 8</figref><i>c</i>, three object classes are supported. The use of the SSL and Immediate Post classes require proper configuration of the EMU SSL Length and EMU Immediate Post Length registers.</p>
<p id="p-0143" num="0147">The summary memory contiguity coding maps two contiguity bits onto every eight bytes of buffer memory. The buffer memory uses the validation bits to determine whether each bit is a valid datum. It is possible for an HTTP datagram to arrive in one byte fragments sent only every other byte. Thus, each byte of the partial message must be uniquely tagged. The summary memory stores a special coding of the eight validation bits representing each eight bytes of buffer memory. The summary encoding must recognize if each 8 byte word contains valid data, if an end is present and whether this end is in a contiguous block. Table <figref idref="DRAWINGS">FIG. 9</figref> shows the encoding format of the contiguity bits in the summary memory.</p>
<p id="p-0144" num="0148">The Validation Memory contains a valid bit for every byte of memory in the reassembly area. This memory is updated during every Post and Purge operation.</p>
<p id="p-0145" num="0149">The Reassembly area holds all the data being assembled from the switch posts. Due to the size of this memory, it is not cleared during a Purge Operation.</p>
<p id="p-0146" num="0150">As the EMU receives a data post from the switch, the buffer address is used immediately to start an access to the summary memory. Because the offset and message length also arrives in the first TPCI clock, the buffer accesses for the before and after data are started as soon as the start pointer physical address is loaded. As the summary data streams in, the EMU determines the point of leftwise contiguity of the buffer. The contiguity bits are also scanned to determine if a complete header exists as soon as the data post has been parsed. This condition is met by having a valid start pointer (check validation bits for start pointer) and any number of contiguity bits valued b′01 (Complete) followed by b′11 (Complete End). Completed headers are scheduled for transmission to the content analyzer. The packet data is written to the buffer memory regardless or whether the header is complete or not. The incoming packet is merged with the relevant before and after data and passed into a line rate parser. If the summary status indicates a partial header is being assembled, the completed header is not copied to the content analyzer. A partial header that reaches the maximum buffer size without the detection of an end is treated as a partial payload. In the event a payload has been detected, a completed end is defined as having received the same number of bytes as is stored in the Content Length field. Partial payloads that fill the buffer (and long headers which fill the buffer) result in a “Partial Payload” post from the EMU to the switch.</p>
<p id="p-0147" num="0151">While various embodiments of the invention have been described, it will be apparent to those of ordinary skill in the art that many more embodiments and implementations are possible that are within the scope of this invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of reassembling a plurality of information elements included in one or more packets that may be received in any order, comprising:
<claim-text>providing a buffer having a plurality of locations, each location capable of storing an information element;</claim-text>
<claim-text>providing a plurality of flags, in a memory, in one-to-one correspondence with the plurality of locations in the buffer, each flag to indicate whether an information element is stored or not at the corresponding location in the buffer;</claim-text>
<claim-text>storing a plurality of information elements in the buffer according to one or more sequence numbers, associated with the one or more packets, that determine a correct order, wherein the sequence number for a packet determines the location in the buffer where any information element included in the packet is stored, so that the information elements, if received in a different order, are placed in the correct order;</claim-text>
<claim-text>for each information element stored in the buffer, setting the flag corresponding to the location in the buffer where the data element is stored to indicate storage of an information element at the location; and</claim-text>
<claim-text>scanning information derived from the plurality of flags in the memory to determine whether reassembly is complete.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein each of the information elements is a byte.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein each of the flags is a bit.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of scanning includes:
<claim-text>determining a contiguity of the plurality of information elements stored in the buffer based on the corresponding plurality of flags in the memory.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>setting an encoded value as a function of at least one of the flags; and</claim-text>
<claim-text>determining whether a token, comprising one or more of the information elements, is stored in the buffer based on the encoded value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the encoded value is a single or multibit value stored in memory.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the encoded value corresponds to a plurality of flags stored in the memory.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A system for handling packet traffic, comprising:
<claim-text>a buffer for storing a plurality of information elements included in one or more packets that may be received in any order, the buffer having a plurality of locations, the plurality of information elements being stored according to one or more sequence numbers, associated with the one or more packets, that determine a correct order, wherein the sequence number for a packet determines the location in the buffer where any information element included in the packet is stored, so that the information elements, if received in a different order are placed in the correct order;</claim-text>
<claim-text>a memory for storing a plurality of validity indicators in-one-to-one correspondence with the plurality of locations of the buffer, each such validity indicator to indicate whether an information element is stored or not at the corresponding location of the buffer;</claim-text>
<claim-text>a first logic circuit capable of setting the validity indicators based on storage of the information elements at the corresponding locations of the buffer; and</claim-text>
<claim-text>a second logic circuit capable of determining a contiguity of the information elements stored in the buffer based on the settings of the validity indicators.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the information elements are bytes.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the validity indicators are bits.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising:
<claim-text>a second memory for storing a summary value;</claim-text>
<claim-text>a third logic circuit for setting the summary value as a function of one or more of the validity indicators; and</claim-text>
<claim-text>a fourth logic circuit for determining whether a token, comprising one or more of the information elements, is stored in the buffer based on the summary value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the summary value is a single or multibit value stored in the second memory.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the buffer includes a circular buffer.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A system for handling packet traffic, comprising:
<claim-text>means for storing a plurality of information elements included in one or more packets, which may be received in any order, at a plurality of locations according to one or more sequence numbers, associated with the one or more packets, that determine a correct order, a sequence number for a packet determining the location where any information element included in the packet is stored, so that the information elements, if received in a different order, are placed in the correct order;</claim-text>
<claim-text>means for storing a plurality of validity indicators that are in one-to-one correspondence with the plurality of locations, wherein each of the validity indicators is to indicate whether an information element is stored or not at the corresponding location;</claim-text>
<claim-text>means for setting the validity indicators based on storage of the information elements in the corresponding locations; and</claim-text>
<claim-text>means for determining a contiguity of the stored information elements based on the settings of the validity indicators.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:
<claim-text>means for setting a summary value as a function of one or more of the validity indicators; and</claim-text>
<claim-text>means for determining whether a token, comprising one or more of the information elements, is present among the stored information elements based on the summary value.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. A method of reassembling a plurality of information elements that may be received in any order comprising:
<claim-text>providing a memory having a plurality of locations, each for storing an information element;</claim-text>
<claim-text>providing a plurality of indicators in one-to-one correspondence with the plurality of locations, each such indicator to indicate whether an information element is stored or not at the corresponding location in the memory;</claim-text>
<claim-text>storing a plurality of information elements in the memory according to sequence numbers, associated with the information elements, that determine a correct order wherein the sequence number for an information element determines the location in the memory where the information element is stored, so that the information elements, if received in a different order, are placed in the correct order;</claim-text>
<claim-text>for each information element stored in the memory, setting the indicator for the corresponding location to indicate storage of the information element at that location; and</claim-text>
<claim-text>determining if reassembly is complete by examining contiguity of one or more of the locations in the memory based on settings of the corresponding indicators.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref> wherein the determining step comprises:
<claim-text>deriving encoded information for each of one or more groups of locations in the memory; and</claim-text>
<claim-text>determining contiguity of one or more groups of locations in the memory based on settings of the encoded information for the corresponding one or more groups of locations in the memory.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref> further comprising determining whether an end of message is present in a group of locations based on settings of the encoded information corresponding to that group of locations.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref> further comprising determining contiguity for all locations in the group preceding the end of message based on settings of the encoded information corresponding to that group of locations.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref> wherein each of the plurality of information elements has an order in a message, the method further comprising storing the plurality of information elements in the memory in the same order as in the message.</claim-text>
</claim>
</claims>
</us-patent-grant>
