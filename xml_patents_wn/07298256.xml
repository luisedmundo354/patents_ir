<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298256-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298256</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11043169</doc-number>
<date>20050127</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2004-163328</doc-number>
<date>20040601</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>172</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>10</class>
<subclass>L</subclass>
<main-group>21</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>10</class>
<subclass>L</subclass>
<main-group>11</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>08</class>
<subclass>B</subclass>
<main-group>1</main-group>
<subgroup>08</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>Q</subclass>
<main-group>7</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>34053911</main-classification>
<further-classification>34053912</further-classification>
<further-classification>34053915</further-classification>
<further-classification>704274</further-classification>
</classification-national>
<invention-title id="d0e71">Crisis monitoring system</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6151571</doc-number>
<kind>A</kind>
<name>Pertrushin</name>
<date>20001100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704209</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>7062443</doc-number>
<kind>B2</kind>
<name>Silverman et al.</name>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704274</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2005/0258958</doc-number>
<kind>A1</kind>
<name>Lai</name>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>34053915</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>JP</country>
<doc-number>2001-080833</doc-number>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>JP</country>
<doc-number>2002-133558</doc-number>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>JP</country>
<doc-number>2004-048164</doc-number>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>16</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>3405391-53932</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>340  33-  332</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3401462</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>340500-5381</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>7042001</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704274</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>14</number-of-drawing-sheets>
<number-of-figures>21</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20050264425</doc-number>
<kind>A1</kind>
<date>20051201</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Sato</last-name>
<first-name>Nobuo</first-name>
<address>
<city>Kokubunji</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Obuchi</last-name>
<first-name>Yasunari</first-name>
<address>
<city>Kodaira</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Antonelli, Terry, Stout &amp; Kraus, LLP.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Hitachi, Ltd.</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Lee</last-name>
<first-name>Benjamin C.</first-name>
<department>2612</department>
</primary-examiner>
<assistant-examiner>
<last-name>Mehmood</last-name>
<first-name>Jennifer</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Provided is a crisis monitoring system that detects a crisis by identifying a person's emotion from his/her utterance includes an input unit to which an audio signal is inputted, a recording unit which records information necessary to judge a crisis situation, and a control unit which controls the input unit and the recording unit. The recording unit records emotion attribute information, which includes a feature of a specific emotion in an audio signal, and the control unit determines a person's emotion by comparing an audio signal inputted to the input unit with the emotion attribute information, and executes a predetermined emergency processing when it is judged that the determined emotion indicates a crisis situation.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="92.20mm" wi="169.33mm" file="US07298256-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="112.10mm" wi="172.72mm" file="US07298256-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="131.91mm" wi="199.90mm" file="US07298256-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="140.46mm" wi="168.49mm" file="US07298256-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="239.61mm" wi="126.75mm" file="US07298256-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="215.31mm" wi="164.51mm" file="US07298256-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="241.30mm" wi="166.79mm" file="US07298256-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="260.77mm" wi="186.35mm" file="US07298256-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="255.27mm" wi="189.48mm" file="US07298256-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="143.93mm" wi="182.46mm" file="US07298256-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="137.33mm" wi="180.42mm" file="US07298256-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="149.52mm" wi="127.68mm" file="US07298256-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="252.39mm" wi="159.43mm" file="US07298256-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="101.85mm" wi="179.49mm" file="US07298256-20071120-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="242.32mm" wi="186.44mm" file="US07298256-20071120-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CLAIM OF PRIORITY</heading>
<p id="p-0002" num="0001">The present application claims priority from Japanese application P2004-163328 filed on Jun. 1, 2004, the content of which is hereby incorporated by reference into this application.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">This invention relates to a crisis monitoring system. In particular, the invention relates to a system that judges whether a person is in trouble or not from his/her utterance.</p>
<p id="p-0004" num="0003">Molesters frequent in confined public spaces. In order to avoid being molested in an elevator, for instance, a person should stand by the operation panel of the elevator, and if a suspicious-looking person gets on the elevator, be watchful of this person's behavior, so he/she can stop the elevator with the use of the operation panel and escape as soon as he/she senses harm from this person.</p>
<p id="p-0005" num="0004">A crisis monitoring system has been proposed to deal with such situations (JP 2001-80833 A). According to this technique, an image pickup camera picks up an image of the interior of an elevator car, an image identifying unit identifies the image picked up by the camera, and a car interior state identifying unit identifies a state in the elevator car. An anomaly judging unit judges, from results provided by the image identifying unit and the car interior state identifying unit, whether there is a disturbance in the elevator car or not. When a disturbance is detected, an anomaly judging unit notifies the caretaker office of the building of the disturbance.</p>
<p id="p-0006" num="0005">Another technique that has been proposed obtains an acoustic wave issued from a preselected monitoring object as an acoustic signal, which is analyzed by an acoustic analyzing module of a sound recognition unit (JP 2002-133558 A). The results of the analysis are processed by a signal analyzing module to obtain analysis information on the target. When the obtained analysis information exceeds a given level, image signals and acoustic signals of the living quarters being recorded for monitoring are sent over the Internet to a monitoring device, which is set up in a remote place from the monitored space to play images and sounds of the monitored space.</p>
<p id="p-0007" num="0006">Still another related technique is a break-in notifying system in which sensors placed on doors to and from a house, steps of a staircase in the house, a carpet on the floor, and the like sense an intruder and transmit radio waves to a server (or a phone) in the house to notify the server of the break-in (JP 2004-48164 A). Receiving the radio waves, the server sends a break-in notification to a predetermined address via a communication line. The break-in notifying system enables a user away from his/her home to know of a break-in and to deal with it promptly.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0008" num="0007">According to the conventional techniques, none of the techniques are helpful to a person trapped with a molester in a confined public space where is little room to move away from the molester, and the victim cannot expect to be heard by anyone if he/she yells for help. Further, it is difficult for the victim to escape from the scene. As the countermeasure, in the case of an elevator, there is no other method than to stand by the operation panel and other such method for avoiding harm from the molestation. Therefore, the only thing the victim of the molestation can do is to operate the operation panel or use the emergency call and wait for the elevator to stop.</p>
<p id="p-0009" num="0008">This invention has been made in view of the above, and it is therefore an object of this invention to provide a crisis monitoring system that detects a crisis by identifying a person's emotion from his/her utterance.</p>
<p id="p-0010" num="0009">A crisis monitoring system according to an embodiment of this invention to judge whether a person is in a crisis situation, includes an input unit to which an audio signal is inputted, a recording unit which records information necessary to judge a crisis situation, and a control unit which controls the input unit and the recording unit, and is characterized in that the recording unit records emotion attribute information, which includes a feature of a specific emotion in an audio signal, and characterized in that the control unit determines a person's emotion by comparing an audio signal inputted to the input unit with the emotion attribute information, and executes a predetermined emergency processing when it is judged that the determined emotion indicates a crisis situation.</p>
<p id="p-0011" num="0010">The embodiment of this invention can detect a crisis in a public space visited by many people by picking up a person's utterance which is made upon encountering a crisis and by analyzing his/her emotion, as opposed to monitoring specific users who desire to use such monitoring services.</p>
<p id="p-0012" num="0011">On the other hand, the embodiment of this invention can also monitor only users who desire crisis monitoring by using in combination a crisis monitoring equipment, which monitors the users to watch for a crisis, and a crisis monitoring terminal, which starts up monitoring by the crisis monitoring equipment.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0013" num="0012">The present invention can be appreciated by the description which follows in conjunction with the following figures, wherein:</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a crisis monitoring system according to a first embodiment of this invention;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart of monitoring processing by a crisis monitoring equipment according to the first embodiment;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 3</figref> is a configuration diagram of a condition database according to the first embodiment;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 4</figref> is a flow chart of processing by a crisis monitoring terminal according to the first embodiment;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 5</figref> is a flow chart of emotion detecting processing according to the first embodiment;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 6</figref> is a flow chart of emotion detecting processing by the crisis monitoring terminal according to the first embodiment;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 7</figref> is an explanatory diagram of an emotion database according to the first embodiment;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 8</figref> is an explanatory diagram of a crisis sound database according to the first embodiment;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 9</figref> is an explanatory diagram of personal information management table according to the first embodiment;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 10</figref> is a block diagram of a crisis monitoring system according to a second embodiment of this invention;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 11</figref> is a block diagram of a management equipment according to the second embodiment;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 12</figref> is a flow chart of monitoring processing by the management equipment according to the second embodiment;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 13</figref> is a configuration diagram of a management condition database according to the second embodiment;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 14</figref> is a block diagram of a crisis monitoring system according to a third embodiment of this invention;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 15</figref> is a flow chart of processing by a crisis-monitoring, portable terminal according to the third embodiment;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 16</figref> is a flow chart of processing by a crisis monitoring server according to the third embodiment;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 17</figref> is a configuration diagram of a monitoring area setting screen according to the third embodiment;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 18</figref> is a configuration diagram of a personal data setting screen according to the third embodiment;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 19</figref> is an explanatory diagram of a monitoring area database according to the third embodiment;</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 20</figref> is a configuration diagram of a monitoring state display screen according to the third embodiment; and</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 21</figref> is a configuration diagram of a present condition database according to the third embodiment.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0035" num="0034">Embodiments of this invention will be described below with reference to the accompanying drawings.</p>
<heading id="h-0006" level="1">First Embodiment</heading>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a crisis monitoring system according to a first embodiment of this invention.</p>
<p id="p-0037" num="0036">A crisis monitoring terminal <b>100</b> is a terminal which transmits a signal to start up a crisis monitoring equipment <b>110</b>, and is carried around by a user who desires crisis monitoring. The crisis monitoring terminal <b>100</b> is composed of an input unit <b>101</b>, a recording unit <b>102</b>, a control unit <b>103</b>, a communication unit <b>104</b> and an output unit <b>105</b>.</p>
<p id="p-0038" num="0037">The input unit <b>101</b> is constituted of a touch panel or a switch, and receives an input to operate the crisis monitoring terminal <b>100</b>. The input unit <b>101</b> may also be equipped with a microphone through which a user's voice is inputted, a camera by which an image is inputted, or a keyboard or a mouse with which data is inputted.</p>
<p id="p-0039" num="0038">The recording unit <b>102</b> is constituted of a hard disk or a memory. The recording unit <b>102</b> stores a main program to request observation and a personal information management table <b>900</b> which contains user's personal information as shown in <figref idref="DRAWINGS">FIG. 9</figref>.</p>
<p id="p-0040" num="0039">The control unit <b>103</b> has a CPU to execute the main program stored in the recording unit <b>102</b> and to request the crisis monitoring equipment <b>110</b> to observe.</p>
<p id="p-0041" num="0040">The communication unit <b>104</b> communicates with the crisis monitoring equipment <b>110</b> over radio (or by infrared rays). The communication unit <b>104</b> may also be communicable with other external devices.</p>
<p id="p-0042" num="0041">The output unit <b>105</b> is constituted of a liquid crystal display to display various data concerning crisis monitoring, and/or a speaker to output sounds.</p>
<p id="p-0043" num="0042">The crisis monitoring equipment <b>110</b> is an apparatus which watches for a crisis in a monitoring area upon receiving a monitoring starting signal from the crisis monitoring terminal <b>100</b>, and is installed in a monitoring area (for example, elevators and like other public spaces). The crisis monitoring equipment <b>110</b> is composed of an input unit <b>111</b>, a recording unit <b>112</b>, a control unit <b>113</b>, a communication unit <b>114</b> and an output unit <b>115</b>.</p>
<p id="p-0044" num="0043">The input unit <b>111</b> is constituted of input devices such as a microphone through which a user's voice is inputted. The input unit <b>111</b> may also be equipped with a camera by which an image is inputted, and a touch panel, a keyboard or a mouse with which data is inputted.</p>
<p id="p-0045" num="0044">The recording unit <b>112</b> is constituted of a hard disk or a memory. The recording unit <b>112</b> stores a speech emotion recognition program which analyzes a voice inputted, a condition database <b>300</b> which is shown in FIG. <b>3</b>, audio data, and visual data.</p>
<p id="p-0046" num="0045">The control unit <b>113</b> has a CPU. When there is a disturbance, The control unit <b>113</b> executes an emergency processing using the speech emotion recognition program which is stored in the recording unit <b>112</b>.</p>
<p id="p-0047" num="0046">The communication unit <b>114</b> communicates with the crisis monitoring terminal <b>100</b> over radio (or by infrared rays). The communication unit <b>114</b> also communicates with a control center (omitted from the drawing) over a cable (e.g. a public switched telephone network or the Internet). The communication unit <b>114</b> may communicate with other external devices.</p>
<p id="p-0048" num="0047">The output unit <b>115</b> is constituted of a liquid crystal display to display various data concerning crisis monitoring, and/or a speaker to output sounds.</p>
<p id="p-0049" num="0048">When the crisis monitoring terminal <b>100</b> request to observe, the crisis monitoring equipment <b>110</b> monitors a monitoring area and analyzes a person's emotion from voice information received by the input unit <b>111</b>. In the case where an angry shout or a scream is observed indicating a disturbance, the crisis monitoring equipment <b>110</b> judges that an abnormal situation has occurred (e.g., molestation or robbery) and the communication unit <b>114</b> sends alerts the control center.</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart of monitoring processing by the crisis monitoring equipment <b>110</b> according to the first embodiment.</p>
<p id="p-0051" num="0050">When the crisis monitoring equipment <b>110</b> is activated (step <b>201</b>), the crisis monitoring equipment <b>110</b> first sends an inquiry signal at a given timing to perform terminal search processing, which is for finding out whether the crisis monitoring terminal <b>100</b> has entered a communicable area (the communicable area includes the monitoring area such as an elevator) or not (step <b>202</b>).</p>
<p id="p-0052" num="0051">In step <b>203</b>, When the crisis monitoring equipment <b>110</b> receives a response signal from the crisis monitoring terminal <b>100</b>, the crisis monitoring equipment <b>110</b> judges that the crisis monitoring terminal <b>100</b> has entered the communicable area (the monitoring area). And then the crisis monitoring equipment <b>110</b> starts observation of the monitoring area (step <b>207</b>).</p>
<p id="p-0053" num="0052">On the other hand, the crisis monitoring equipment <b>110</b> does not receives a response signal from the crisis monitoring terminal <b>100</b>, the crisis monitoring equipment <b>110</b> records the present condition in the recording unit <b>112</b> (step <b>204</b>). When the crisis monitoring equipment <b>110</b> does not receive response signal from the crisis monitoring terminal <b>100</b>, it means that the crisis monitoring terminal <b>100</b> has not entered the communicable area yet, or that the crisis monitoring terminal <b>100</b> has moved out of the communicable area. Alternatively, it is when the user operates the crisis monitoring terminal <b>100</b> not to want monitoring that the crisis monitoring equipment <b>110</b> receives no response signal from the crisis monitoring terminal <b>100</b>.</p>
<p id="p-0054" num="0053">The present condition is recorded in the condition database <b>300</b> of the recording unit <b>112</b>. Data recorded in the database is sent at a given timing to the control center through the communication unit <b>114</b>. The record in the condition database <b>300</b> may be sent as it is to the control center.</p>
<p id="p-0055" num="0054">Thereafter, the crisis monitoring equipment <b>110</b> judges, through termination judging processing, whether to conduct a further terminal search (step <b>205</b>). In the case where the crisis monitoring equipment <b>110</b> is to stop operating (for example, when a command to stop observation is inputted), the crisis monitoring equipment <b>110</b> stops to search the terminals (step <b>206</b>). On the other hand, in the case where the crisis monitoring equipment <b>110</b> is to continue operating, the process returns to the step <b>202</b> to continue searching for the terminal.</p>
<p id="p-0056" num="0055">Starting observation (step <b>207</b>), the crisis monitoring equipment <b>110</b> executes emotion detection processing of <figref idref="DRAWINGS">FIG. 5</figref> based on voice information which is inputted through the input unit <b>111</b>, to thereby judge whether the user is in trouble (step <b>208</b>).</p>
<p id="p-0057" num="0056">When it is judged that the user is not in any trouble, the crisis monitoring equipment <b>110</b> records the present condition in the condition database <b>300</b> (step <b>209</b>). Then the processing returns to the step <b>202</b>, where the crisis monitoring equipment <b>110</b> searches for the terminal.</p>
<p id="p-0058" num="0057">On the other hand, when it is judged that the user is in trouble, the crisis monitoring equipment <b>110</b> follows emergency response <b>311</b> set in the condition database <b>300</b> and executes an emergency processing such as alerting the control center (step <b>210</b>).</p>
<p id="p-0059" num="0058">In emergency, the control unit <b>113</b> controls the respective units to execute predetermined processing.</p>
<p id="p-0060" num="0059">In particular, the control unit <b>113</b> controls the communication unit <b>114</b> to have the unit <b>114</b> alert the control center. It is preferable for the communication unit <b>114</b> to send, at the same time as the reporting, to the control center, the present condition recorded in the recording unit <b>112</b> and the user's personal information recorded in the personal information management table <b>900</b>. The user's personal information is transmitted using known encoding processing such as public key encryption in order to prevent third parties from reading the personal information.</p>
<p id="p-0061" num="0060">The control unit <b>113</b> controls the output unit <b>115</b> to have the unit <b>115</b> play an audio or visual message saying that the control center is being alerted.</p>
<p id="p-0062" num="0061">The control unit <b>113</b> may control automatic running of the elevator. In particular, the control unit <b>113</b> controls the elevator that is in operation such that the elevator car stops and opens its doors to the closest floor, or the floor where the building manager's office is located, and controls the elevator that is not moving such that the elevator car remains unmoving and keeps its doors open.</p>
<p id="p-0063" num="0062">For automatic running of the elevator, the control unit <b>113</b> sends commands such as a halting command to an elevator controllers from the communication unit <b>114</b>. Alternatively, the control unit <b>113</b> may send a command to automatically run the elevator from the communication unit <b>114</b> to an elevator controller that is located at an elevator control center or at a security company contracted to guard the building, thereby having the external elevator controller operate the elevator.</p>
<p id="p-0064" num="0063">Such automatic running of the elevator makes it possible to stop the elevator on a given floor and rescue a user in the elevator car when, for example, the user is unable to operate the elevator. In addition, the perpetrator is prevented from operating the elevator when the elevator is run automatically.</p>
<p id="p-0065" num="0064">Preferably, the emergency processing is varied from user to user to suit wills of individual users by recording the above-described control method in the personal information management table <b>900</b>.</p>
<p id="p-0066" num="0065">The control method given in the above is merely an example, and other control methods can be employed to ensure the safety of users.</p>
<p id="p-0067" num="0066">As the emergency processing (step <b>210</b>) is completed, the crisis monitoring equipment <b>110</b> records the present condition in the recording unit <b>112</b> to update the condition database <b>300</b> (step <b>211</b>). The process then returns to the step <b>202</b>, where the crisis monitoring equipment <b>110</b> searches for the crisis monitoring terminal <b>100</b>.</p>
<p id="p-0068" num="0067">The crisis monitoring equipment <b>110</b> is set to constantly monitor the crisis monitoring terminal <b>100</b> once the crisis monitoring terminal <b>100</b> enters the communicable area. Alternatively, the crisis monitoring equipment <b>110</b> is set to automatically start monitoring when the user holding the crisis monitoring terminal <b>100</b> enters the communicable area in a specific time zone such as late at night. The crisis monitoring equipment <b>110</b> may also be set to start monitoring when a load sensor placed at where an elevator hoist cable is attached senses a weight heavier than the weight of the user. It is also possible to set the crisis monitoring equipment <b>110</b> in a manner that makes the crisis monitoring equipment <b>110</b> stop monitoring when a given period has elapsed after the crisis monitoring terminal <b>100</b> enters the communicable area. These settings may be combined with one another and various other settings are employable. What setting of the crisis monitoring equipment <b>110</b> a user prefers is set in advance in the personal information management table <b>900</b>.</p>
<p id="p-0069" num="0068">Audio data inputted through the input unit <b>111</b> is preferably stored in the recording unit <b>112</b>. The stored audio data can be used in identifying the person who has committed an offence against the user during observation. A camera may be employed to observe images. Images of the interior of the elevator car picked up by the camera are preferably stored in the recording unit <b>112</b>, so that the stored images can be used in identifying a suspect.</p>
<p id="p-0070" num="0069">However, it is advisable to quickly delete audio, visual or other data stored in the recording unit <b>112</b> in the case where monitoring is ended without detecting any trouble, since the recorded data contains a lot of personal (private) information.</p>
<p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. 3</figref> is a configuration diagram of the condition database <b>300</b>.</p>
<p id="p-0072" num="0071">The condition database <b>300</b> is placed in the recording unit <b>112</b> of the crisis monitoring equipment <b>110</b>. The condition database <b>300</b> includes a date <b>301</b>, a starting time <b>302</b>, a closing time <b>303</b>, a starting position <b>304</b>, a closing position <b>305</b>, an observation result <b>306</b>, a monitoring result <b>307</b>, a object person <b>308</b>, an room number <b>309</b>, an emergency contact address <b>310</b> and an emergency response <b>311</b>.</p>
<p id="p-0073" num="0072">A date <b>301</b> is a date when the user uses the system (in other words, when the user's condition is observed). A starting time <b>302</b> is a time the system is activated by an observation request from the crisis monitoring terminal <b>100</b>. A closing time <b>303</b> is a time the system stops operating as the crisis monitoring terminal <b>100</b> moves out of the communicable area or from other reasons.</p>
<p id="p-0074" num="0073">A starting position <b>304</b> is a location where the system is activated by an observation request from the crisis monitoring terminal <b>100</b>. A closing position <b>305</b> is a location where the system stops operating as the crisis monitoring terminal <b>100</b> moves out of the communicable area or from other reasons. In the example of <figref idref="DRAWINGS">FIG. 3</figref>, this particular user gets on the elevator on the first floor, gets off the elevator on the third floor, and then moves out of the monitoring area.</p>
<p id="p-0075" num="0074">An observation result <b>306</b> is the result of observation at step <b>207</b> in <figref idref="DRAWINGS">FIG. 2</figref>. A monitoring result <b>307</b> is the result of monitoring which is judged from the observation result <b>306</b>, and whether condition is good or bad is recorded as the monitoring result <b>307</b>.</p>
<p id="p-0076" num="0075">For instance, when it is judged that a user to be in trouble from an angry shout or a scream observed, “trouble” is recorded as the monitoring result <b>307</b>. On the other hand, when it is judged that nothing is out of ordinary in the monitoring area, “normal” is recorded as the monitoring result <b>307</b>. In the case where more than one type of observation is to be made (for example, sound observation and image observation), several types of data are recorded as the observation result <b>306</b> and judged in a comprehensive manner to produce the monitoring result <b>307</b>.</p>
<p id="p-0077" num="0076">The object person <b>308</b> is the user who has activated the crisis monitoring equipment <b>110</b>, that is the object of monitoring.</p>
<p id="p-0078" num="0077">The room number <b>309</b> is the number of the apartment where the object person <b>308</b> resides. In the case where this crisis monitoring system is installed in a public space instead of a housing complex or the like, the address of the object person is set in place of the room number <b>309</b>. An emergency contact address <b>310</b> is where the user desires to have the system make a contact in emergencies. The address of next of kin of the object person <b>308</b> or the like is recorded as the emergency contact address <b>310</b>.</p>
<p id="p-0079" num="0078">The emergency response <b>311</b> is what the user desires to have the system do in emergencies. It is not always necessary to newly set the emergency response <b>311</b> and the default setting such as calling to the control center may be employed. It is also possible to set different response for different monitoring areas (for example, inside the elevator or in the corridor). The emergency response <b>311</b> may also vary from user to user in accordance with the method recorded in the personal information management table <b>900</b>. Other various settings can be employed for the emergency response <b>311</b>.</p>
<p id="p-0080" num="0079">The room number <b>309</b>, the emergency contact address <b>310</b>, and the emergency response <b>311</b> are predetermined.</p>
<p id="p-0081" num="0080">Items to be recorded in the condition database <b>300</b> are not limited to those shown in <figref idref="DRAWINGS">FIG. 3</figref>, and an item can be removed or added as needed. Preferably, the condition database <b>300</b> holds a condition history as well as the present condition by accumulating data in the recording unit <b>112</b> instead of overwriting each time monitoring is completed. The accumulated data can be used in checking the past condition.</p>
<p id="p-0082" num="0081"><figref idref="DRAWINGS">FIG. 4</figref> is a flow chart of processing by the crisis monitoring terminal <b>100</b> according to the first embodiment.</p>
<p id="p-0083" num="0082">When the crisis monitoring terminal <b>100</b> is activated (step <b>401</b>), once inside the communicable area, the crisis monitoring terminal <b>100</b> enters a watching state in which the terminal is ready to receive an inquiry signal sent from the crisis monitoring equipment <b>110</b> (step <b>402</b>).</p>
<p id="p-0084" num="0083">When an inquiry signal from the crisis monitoring equipment <b>110</b> is received (step <b>403</b>), the crisis monitoring terminal <b>100</b> uses the communication unit <b>104</b> to send a response signal to the crisis monitoring equipment <b>110</b> and request the apparatus to start observation (step <b>406</b>).</p>
<p id="p-0085" num="0084">The crisis monitoring terminal <b>100</b> preferably sends personal information of the user recorded in the personal information management table <b>900</b>, which is placed in the recording unit <b>102</b>, along with the response signal, to the crisis monitoring equipment <b>110</b>. Sending user's information which has been registered in advance enables the crisis monitoring equipment <b>110</b> to execute, when a disturbance is detected, the emergency response <b>311</b> that suit wills of individual users. In addition, by consulting the personal information management table <b>900</b>, the crisis monitoring equipment <b>110</b> can monitor each user in a manner that corresponds to his/her condition regarding personal information desired monitoring hours.</p>
<p id="p-0086" num="0085">When an inquiry signal is not received from the crisis monitoring equipment <b>110</b> in the step <b>403</b>, the crisis monitoring terminal <b>100</b> does not send a response signal and judges whether the user has operated the terminal to end monitoring (step <b>404</b>).</p>
<p id="p-0087" num="0086">When detecting that it is operated to end monitoring, the crisis monitoring terminal <b>100</b> ends the process (step <b>405</b>). On the other hand, when the crisis monitoring terminal <b>100</b> does not detect that it is operated to end monitoring, the process returns to the step <b>402</b> where the crisis monitoring terminal <b>100</b> watch an inquiry signal from the crisis monitoring equipment <b>110</b>.</p>
<p id="p-0088" num="0087"><figref idref="DRAWINGS">FIG. 5</figref> is a flow chart of processing executed by the crisis monitoring equipment <b>110</b> to detection a user's emotion from the result of observation.</p>
<p id="p-0089" num="0088">When the emotion detecting processing is started (step <b>501</b>), the crisis monitoring equipment <b>110</b> decides an emotion from a user's voice inputted (step <b>502</b>). This emotion detection is based on person's utterance. First, the inputted voice is analyzed and emotion detecting processing shown in <figref idref="DRAWINGS">FIG. 6</figref> is applied.</p>
<p id="p-0090" num="0089">The emotion level may be used to judge a crisis. The level of an emotion can be obtained by counting how many times utterances conveying a specific emotion are made in a unit time, for instance, how many times angry words are spoken in 30 seconds. The higher the count of utterances conveying a specific emotion, the higher the level of the emotion. A higher emotion level is judged to indicate the greater seriousness of a crisis.</p>
<p id="p-0091" num="0090">In the case where the observation result can be converted into numeric values (emotion level), e.g. anger level is 60%, a crisis can be judged with a predetermined threshold as reference.</p>
<p id="p-0092" num="0091">Counting the number of times utterances conveying a specific emotion are made is merely an example of how to obtain the emotion level, and it is also possible to calculate the emotion level from a discriminant function value which is used in the emotion detection processing shown in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0093" num="0092">The emotion detected is stored as an observation result in a predetermined storage area, for example a register (step <b>503</b>). The main program reads the observation result out of the predetermined storage area to make a final judgment about whether there is a disturbance (step <b>208</b>).</p>
<p id="p-0094" num="0093">When another voice input is received, an emotion is determined based on this audio data (step <b>502</b>) and the determined emotion is stored as an observation result (step <b>503</b>). Then, processing end in step <b>504</b>.</p>
<p id="p-0095" num="0094"><figref idref="DRAWINGS">FIG. 6</figref> is a flow chart of the emotion detection processing by the crisis monitoring terminal <b>100</b> according to the first embodiment.</p>
<p id="p-0096" num="0095">To determine an emotion from his/her voice, sounds heard in the communicable area are observed and the feature of an unusual sound (for example, an angry shout, a scream or a cry) is analyzed.</p>
<p id="p-0097" num="0096">When the emotion detecting processing is started (step <b>601</b>), first, a feature amount of a voice inputted through the input unit <b>111</b> is extracted (step <b>602</b>). In the case where the feature amount is, for example, pitch, which shows highness or lowness of sound, the maximum pitch value in one utterance, the point at which the maximum pitch value is detected, the minimum pitch value, the point at which the minimum pitch value is detected, a mean pitch value and the like are extracted. In the case where the feature amount is energy, which represents the volume of sound, the maximum energy value in one utterance, the point at which the maximum energy value is detected, the minimum energy value, the point at which the minimum energy value is detected, a mean energy value and the like are extracted. Other known sound feature amounts may also be extracted.</p>
<p id="p-0098" num="0097">Instead of employing the pitch, energy, tempo or the like of one utterance as a feature amount, the amount of change in pitch, energy, tempo or the like in a unit time may serve as a feature amount.</p>
<p id="p-0099" num="0098">The extracted feature amount is classified with the use of a discriminant to thereby determine an emotion (step <b>603</b>). A discriminant value is obtained from the general feature amount of a voice such as an angry shout or a scream which is learned in a preliminary study. The discriminant function value is calculated in a manner that sets the maximum value of anger to 1 and the normal state to −1.</p>
<p id="p-0100" num="0099">The extracted voice feature amount is translated into numerical terms using the discriminant function. When the function value is a positive value, the emotion which the voice conveys is judged as anger. Whereas, the emotion is judged as neutral when the function value is a negative value. The emotion level can also be judged by reading strong anger from a large positive value of the function value and by reading solid neutral from a large negative value of the function value.</p>
<p id="p-0101" num="0100">This method described above is merely an example to identify a person's emotion from his/her voice, and other known methods such as neural network analysis and multivariate analysis may be employed instead.</p>
<p id="p-0102" num="0101">The emotion detection in the step <b>603</b> uses an emotion database <b>604</b> shown in <figref idref="DRAWINGS">FIG. 7</figref>. The emotion database <b>604</b> is a record of results obtained by conducting a preliminary study on the typical feature amount of a voice and by extracting a value using a discriminant function. A voice feature amount extracted through the voice feature extracting processing of the step <b>602</b> is compared against a corresponding feature amount recorded in the emotion database <b>604</b>, to thereby identify an emotion from a voice inputted.</p>
<p id="p-0103" num="0102">Then, in a step <b>605</b>, specifically what emotion the utterer is feeling is determined from the result of the emotion detection of the step <b>603</b>. Then, processing end in step <b>606</b>.</p>
<p id="p-0104" num="0103">How to determine an emotion is not limited to the method illustrated by the emotion detection flow chart shown in <figref idref="DRAWINGS">FIG. 6</figref>. In one alternative method, it is determined that detection of a specific emotion is made when words that are likely to convey a specific emotion, such as “Stop it!”, are recognized.</p>
<p id="p-0105" num="0104">Another alternative method uses manipulation of the input unit <b>111</b> in combination with speech emotion recognition. In this method, it is determined that a prescribed specific emotion is detected when a touch panel of the input unit <b>111</b> is touched or when a switch of the input unit <b>111</b> is operated.</p>
<p id="p-0106" num="0105">Other information than a person's voice may be monitored as long as it shows what situation a user is in. A camera may be employed to observe user's behavior and determine that the user is feeling a specific emotion when a specific motion or a specific facial expression is detected.</p>
<p id="p-0107" num="0106">Known speech emotion recognition techniques may also be employed to determine an emotion. In this case, a program to execute the technique of choice is stored in advance in the recording unit <b>112</b>.</p>
<p id="p-0108" num="0107"><figref idref="DRAWINGS">FIG. 7</figref> is an explanatory diagram of the emotion database <b>604</b>.</p>
<p id="p-0109" num="0108">The emotion database <b>604</b> stores several types of emotion data in association with variables to make it possible to identify various emotions from a voice feature amount.</p>
<p id="p-0110" num="0109">The emotion database <b>604</b> includes variable data of features of angry shout <b>701</b> and variable data of features of cry <b>702</b>. Each of the variable data, angry shout and cry, includes variable values <b>703</b> to <b>707</b>. The features of these voices are determined by the value of one or more such variables.</p>
<p id="p-0111" num="0110">Preferably, other emotions that reflect a person's mind, such as tension and a feeling of being threatened, are also detected. The emotion database <b>604</b> can include other items than those shown in <figref idref="DRAWINGS">FIG. 7</figref>, and an item is removed or added as necessary.</p>
<p id="p-0112" num="0111"><figref idref="DRAWINGS">FIG. 8</figref> is an explanatory diagram of a crisis sound database <b>800</b>.</p>
<p id="p-0113" num="0112">Many other sounds than a voice uttered by a person can be used to judge whether the person is in trouble. For instance, the system may be set to judge that a user is in trouble when a gunshot sound, a sound of glass shattering, and like other sounds that indicate a trouble are observed.</p>
<p id="p-0114" num="0113">Recorded in the crisis sound database <b>800</b> is a feature amount of a sound that could be heard in a crisis situation.</p>
<p id="p-0115" num="0114">The crisis sound database <b>800</b> includes variable data of features of shooting sound of handgun <b>801</b> and variable data of features of broken sound of glass. Each of the variable data, gunshot sound and glass broken sound, includes variable values <b>803</b> to <b>807</b>. The features of these sounds heard in a crisis situation are determined by the value of one or more such variables.</p>
<p id="p-0116" num="0115">The crisis sound database <b>800</b> can include other items than those shown in <figref idref="DRAWINGS">FIG. 8</figref>, and an item is removed or added as necessary.</p>
<p id="p-0117" num="0116"><figref idref="DRAWINGS">FIG. 9</figref> is an explanatory diagram of a personal information management table <b>900</b>.</p>
<p id="p-0118" num="0117">User's personal information and characteristics are preferably used in judging a crisis. So that the personal information management table <b>900</b> is used to judge a crisis.</p>
<p id="p-0119" num="0118">The personal information management table <b>900</b> includes a user's name <b>901</b>, a user's ID <b>902</b> allotted to each user for identification, the room number <b>903</b> in a housing complex where the user resides, and emergency contact address <b>904</b> to contact in emergencies, such as the address of user's next of kin.</p>
<p id="p-0120" num="0119">Further, the personal information management table <b>900</b> includes predetermined alert word <b>905</b> is an arbitrary keyword set in advance. Utterance of the alert word is another indicator of a crisis situation in addition to a scream let out in emergency.</p>
<p id="p-0121" num="0120">Further, the personal information management table <b>900</b> includes variable values <b>906</b> to <b>910</b> which are characteristics of the voice of the user expressed in variables. The variable values <b>906</b> to <b>910</b> are registered by measuring in advance vocal sounds the user may make in emergencies. The variable values <b>906</b> to <b>910</b> constitute a reference database used in the emotion detection processing (step <b>603</b>).</p>
<p id="p-0122" num="0121">The personal information management table <b>900</b> can include other items than those shown in <figref idref="DRAWINGS">FIG. 9</figref>, and an item is removed or added as necessary. Consulting personal information and characteristics items in judging a crisis reduces the chance of making an erroneous judgment. The information in the personal information management table <b>900</b> can also be use as information to identify a user who is victimized.</p>
<p id="p-0123" num="0122">As has been described above, the system according to the first embodiment detects a cry, an angry shout or the like in a confined public space such as an elevator by analyzing a person's emotion from his/her utterance, and reports the thus detected crisis situation. In this way, the system according to the first embodiment makes such spaces safe for its users.</p>
<p id="p-0124" num="0123">Preferably, the crisis monitoring equipment <b>110</b> constantly monitors a user while the user is using the system of this embodiment since a crisis can happen anytime. Constant monitoring, however, involves the problem of privacy violations by catching users' voices and images when they do not desire crisis monitoring. This problem is cleared by holding observation by the crisis monitoring equipment <b>110</b> until a signal from the crisis monitoring terminal <b>100</b> is received. Thus the system is made available to a user only when the user desires monitoring.</p>
<p id="p-0125" num="0124">The system that monitors for a limited period is also free from another drawback of constant monitoring, which is an increased chance of making an erroneous crisis judgment due to noise irrelevant to crisis monitoring and prolonged sound analysis time.</p>
<heading id="h-0007" level="1">Second Embodiment</heading>
<p id="p-0126" num="0125"><figref idref="DRAWINGS">FIG. 10</figref> is a block diagram of a crisis monitoring system according to a second embodiment of this invention.</p>
<p id="p-0127" num="0126">The crisis monitoring system of this embodiment monitors a crisis in a public space (e.g. a corridor in a housing complex) that is larger than spaces monitored in the first embodiment.</p>
<p id="p-0128" num="0127">Plural crisis monitoring equipments <b>110</b> are installed in a monitoring area. For instance, the plural crisis monitoring equipments <b>110</b> are placed at given intervals in a housing complex from an entrance to an elevator hall, or from an elevator hall to the door of a user's room. The crisis monitoring equipments <b>110</b> each monitor a crisis in their respective communicable areas through the processing described in the first embodiment.</p>
<p id="p-0129" num="0128">When requested from a user to observe, the crisis monitoring equipment <b>110</b> sends the present condition recorded in the recording unit <b>112</b>. The present condition is sent at a given timing from the communication unit <b>114</b> to a management equipment <b>1000</b>. The sends the present condition sent to the management equipment <b>1000</b> may be the entirety of or a part of a condition database <b>300</b>.</p>
<p id="p-0130" num="0129">The management equipment <b>1000</b> judges a crisis in the monitoring area of each crisis monitoring equipment <b>110</b> based on the present condition sent from the crisis monitoring equipment <b>110</b>. The management equipment <b>1000</b> manages records sent from the plural crisis monitoring equipments <b>110</b>, so that entire monitoring area is monitored for a crisis.</p>
<p id="p-0131" num="0130"><figref idref="DRAWINGS">FIG. 11</figref> is a block diagram of the management equipment <b>1000</b>.</p>
<p id="p-0132" num="0131">The management equipment <b>1000</b> is an apparatus that manages the plural crisis monitoring equipments <b>110</b>, and is set up in a location the entire monitoring area is managed (for example, the manager office of the complex).</p>
<p id="p-0133" num="0132">The management equipment <b>1000</b> is composed of an input unit <b>1001</b>, a recording unit <b>1002</b>, a control unit <b>1003</b>, a communication unit <b>1004</b> and an output unit <b>1005</b>.</p>
<p id="p-0134" num="0133">The input unit <b>1001</b> is constituted of an input device with which data is inputted, such as a touch panel, a switch, a keyboard or a mouse.</p>
<p id="p-0135" num="0134">The recording unit <b>1002</b> is constituted of a hard disk or a memory to store a speech emotion recognition program, which analyzes a voice inputted, a management condition database <b>1300</b> (shown in <figref idref="DRAWINGS">FIG. 13</figref>), audio data, and visual data.</p>
<p id="p-0136" num="0135">The control unit <b>1003</b> has a CPU and, when there is a disturbance, executes an emergency processing using the speech emotion recognition program which is stored in the recording unit <b>1002</b>.</p>
<p id="p-0137" num="0136">The communication unit <b>1004</b> communicates with the communication unit <b>114</b> of the crisis monitoring equipment <b>110</b> and with a control center (omitted from the drawing) over a cable (e.g. public switched telephone network or the Internet). The communication unit <b>1004</b> may also be communicable with other external devices.</p>
<p id="p-0138" num="0137">The output unit <b>1005</b> is constituted of a liquid crystal display to display various data concerning crisis monitoring, and/or a speaker to output sounds.</p>
<p id="p-0139" num="0138"><figref idref="DRAWINGS">FIG. 12</figref> is a flow chart of monitoring processing by the management equipment <b>1000</b> according to the second embodiment.</p>
<p id="p-0140" num="0139">The management equipment <b>1000</b> performs, on each crisis monitoring equipment <b>110</b>, at a given timing (e.g. periodically), monitoring equipment checking processing to check the present operative condition of the crisis monitoring equipment <b>110</b> (step <b>1202</b>). Through this processing, the crisis monitoring equipment <b>110</b> that has not received an observation request from a user is checked out to be in a stand-by state in which the crisis monitoring equipment <b>110</b> watches an observation request.</p>
<p id="p-0141" num="0140">The management equipment <b>1000</b> receives an observing signal from the crisis monitoring equipment <b>110</b> that has received an observation request from a user. It is preferable for the crisis monitoring equipment <b>110</b> to send, to the management equipment <b>1000</b>, along with the present condition, a personal information management table <b>900</b> which is user's personal information sent from a crisis monitoring terminal <b>100</b>. The transmission of user's personal information preferably employs known encoding processing such as public key encryption in order to prevent third parties from reading the personal information.</p>
<p id="p-0142" num="0141">The management equipment <b>1000</b> judges whether the user is in trouble from the present condition sent by the crisis monitoring equipment <b>110</b> (step <b>1203</b>). As the user moves from one area to another, the management equipment <b>1000</b> judges whether the user is in trouble from the present condition sent by the crisis monitoring equipment <b>110</b> that is placed at where the user is now in (step <b>1203</b>).</p>
<p id="p-0143" num="0142">When it is found that the user is not in any trouble, the management equipment <b>1000</b> records the present condition of each crisis monitoring equipment <b>110</b> in the management condition database <b>1300</b> (step <b>1204</b>). The current condition to be recorded is sent from the communication unit <b>1004</b> to the control center at a given timing. The present condition sent to the control center may be the entirety of or a part of the management condition database <b>1300</b>.</p>
<p id="p-0144" num="0143">Thereafter, the management equipment <b>1000</b> judges, through termination judging processing, whether to check the operative condition of the crisis monitoring equipments <b>110</b> further (step <b>1205</b>). In the case where the management equipment <b>1000</b> is to stop operating (e.g. when a command to stop observation is inputted), the management equipment <b>1000</b> ends the processing of checking the monitoring equipments (step <b>1206</b>). In the case where the management equipment <b>1000</b> is to continue operating, on the other hand, the processing returns to the step <b>1202</b> to keep checking the monitoring equipments.</p>
<p id="p-0145" num="0144">When it is found in the step <b>1203</b> that the user is in trouble, the management equipment <b>1000</b> follows emergency response <b>311</b> set in the condition database <b>300</b> and executes an emergency processing such as alerting the control center (step <b>1207</b>).</p>
<p id="p-0146" num="0145">In emergency, the control unit <b>1003</b> controls the respective units in a predetermined manner.</p>
<p id="p-0147" num="0146">Specifically, the control unit <b>1003</b> controls the communication unit <b>1004</b> to alert the control center. At this time, preferably, the communication unit <b>1004</b> also sends, to the control center, the present condition recorded in the recording unit <b>1002</b> and the user's personal information recorded in the personal information management table <b>900</b>. The communication unit <b>1004</b> also controls the communication unit <b>1004</b> to receive sounds and images recorded in the recording unit <b>112</b> of the crisis monitoring equipment <b>110</b> that has detected the crisis situation.</p>
<p id="p-0148" num="0147">The control unit <b>1003</b> controls the output unit <b>1005</b> to output an audio signal or visual message showing that the alert has been sent to control center.</p>
<p id="p-0149" num="0148">The control method described above is merely an example, and other control methods can be employed to ensure the safety of users.</p>
<p id="p-0150" num="0149">As the emergency processing (step <b>1207</b>) is completed, the crisis management equipment <b>1000</b> records the present condition of each crisis monitoring equipment <b>110</b> in the management condition database <b>1300</b> (step <b>1208</b>). Then the processing returns to the step <b>1202</b>, where the management equipment <b>1000</b> resumes checking on the monitoring equipments.</p>
<p id="p-0151" num="0150"><figref idref="DRAWINGS">FIG. 13</figref> is a configuration diagram of the management condition database <b>1300</b>.</p>
<p id="p-0152" num="0151">The management condition database <b>1300</b> includes a crisis monitoring equipment number <b>1301</b>, an installation floor <b>1302</b>, an installation location <b>1303</b>, an operative condition <b>1304</b> and a monitoring result <b>1305</b>. A crisis monitoring equipment number <b>1301</b> is the number allotted to each crisis monitoring equipment <b>110</b>. An installation floor <b>1302</b> is the number of the floor where each crisis monitoring equipment <b>110</b> is installed. An installation location <b>1303</b> indicates in what part of the installation floor the crisis monitoring equipment <b>110</b> is installed. The installation floor <b>1302</b> and the installation location <b>1303</b> may be combined into one to be recorded as installation location data.</p>
<p id="p-0153" num="0152">An operative condition <b>1304</b> is the present operative condition of each crisis monitoring equipment <b>110</b>. “Waiting” is recorded as the operative condition <b>1304</b> for the crisis monitoring equipment <b>110</b> that has not started observation yet. The crisis monitoring equipments <b>110</b> enter an “waiting” state when, for example, a user carrying the crisis monitoring terminal <b>100</b> is outside their communicable areas or when a user carrying the crisis monitoring terminal <b>100</b> is in their communicable areas but does not want their observation. For the crisis monitoring equipment <b>110</b> that has been requested from a user to observe, on the other hand, “observing” is recorded as the operative condition <b>1304</b>.</p>
<p id="p-0154" num="0153">A monitoring result <b>1305</b> is a judgment made on whether there is a disturbance or not from a user's voice and/or image observed by the crisis monitoring equipment <b>110</b>.</p>
<p id="p-0155" num="0154">Instead of the management equipment <b>1000</b>, each crisis monitoring equipment <b>110</b> may judge a crisis through the emotion detection processing of <figref idref="DRAWINGS">FIG. 5</figref> based on a user's voice and/or image observed. Specifically, each crisis monitoring equipments <b>110</b> sends an observation result <b>306</b> and a monitoring result <b>307</b>, which is determined based on the observation result <b>306</b>, to the management equipment <b>1000</b>.</p>
<p id="p-0156" num="0155">When the management equipment <b>1000</b> judges whether a user is in trouble, the management equipment <b>1000</b> may receive the user's voice and/or image observed by the crisis monitoring equipments <b>110</b>, and performs the emotion detection processing shown in <figref idref="DRAWINGS">FIG. 5</figref> on the received data with the use of the speech emotion recognition program stored in the recording unit <b>1002</b>. The result is recorded as the monitoring result <b>1305</b>.</p>
<p id="p-0157" num="0156">Items to be recorded in the management condition database <b>1300</b> are not limited to those shown in <figref idref="DRAWINGS">FIG. 13</figref>, and an item can be removed or added as needed.</p>
<p id="p-0158" num="0157">As has been described, the second embodiment uses the management equipment <b>1000</b> to manage the plural crisis monitoring equipments <b>110</b> for crisis monitoring. The system according to the second embodiment can thus detect a crisis in an expansive public space from an angry shout or a scream, and reports the detected crisis.</p>
<p id="p-0159" num="0158">To elaborate, a user who moves out of the communicable area of one crisis monitoring equipment <b>110</b> is immediately covered by the next crisis monitoring equipment <b>110</b> and thus continuous crisis monitoring is provided. When a crisis is detected, the movement of a user who is in trouble can be tracked and monitored by the plural crisis monitoring equipments <b>110</b> throughout the monitoring area. The system according to the second embodiment is therefore capable of making such spaces safe for its users.</p>
<p id="p-0160" num="0159">Furthermore, privacy is kept well since this system monitors only places where a user who desires monitoring passes.</p>
<heading id="h-0008" level="1">Third Embodiment</heading>
<p id="p-0161" num="0160"><figref idref="DRAWINGS">FIG. 14</figref> is a block diagram of a crisis monitoring system according to a third embodiment of this invention.</p>
<p id="p-0162" num="0161">In this embodiment, an outdoor public space (e.g. a dark alley) is monitored for a crisis.</p>
<p id="p-0163" num="0162">A crisis monitoring handheld terminal <b>1400</b> is a portable equipment which judges that a user has entered a monitoring area and watches for a crisis in the monitoring area. The crisis monitoring handheld terminal <b>1400</b> is carried by a user who desires crisis monitoring. The crisis monitoring handheld terminal <b>1400</b> may be built in one of belongings (e.g. cellular phone or wrist watch) of a user who desires crisis monitoring.</p>
<p id="p-0164" num="0163">The crisis monitoring handheld terminal <b>1400</b> is composed of an input unit <b>1401</b>, a recording unit <b>1402</b>, a control unit <b>1403</b>, a communication unit <b>1404</b>, an output unit <b>1405</b> and a GPS receiver <b>1406</b>.</p>
<p id="p-0165" num="0164">The input unit <b>1401</b> is constituted of input devices such as a microphone through which a user's voice is inputted, a camera by which an image is inputted and a touch panel, a switch, a keyboard or a mouse with which data is inputted.</p>
<p id="p-0166" num="0165">The recording unit <b>1402</b> is constituted of a hard disk or a memory. The recording unit <b>1402</b> stores a speech emotion recognition program which analyzes an audio inputted, a personal information management table <b>900</b>, which contains user's personal information, a condition database <b>300</b>, audio data, visual data, and a monitoring area database <b>1900</b>, which is shown in <figref idref="DRAWINGS">FIG. 19</figref>.</p>
<p id="p-0167" num="0166">The control unit <b>1403</b> includes a CPU and executes an emergency processing using the speech emotion recognition program which is stored in the recording unit <b>1402</b>, when the user is in trouble.</p>
<p id="p-0168" num="0167">The communication unit <b>1404</b> communicates with a crisis monitoring server <b>1410</b> via a cellular telephony network <b>1420</b>. The communication unit <b>1404</b> may also be communicable with other external devices.</p>
<p id="p-0169" num="0168">The output unit <b>1405</b> is constituted of a liquid crystal display to display various data concerning crisis monitoring, a monitoring area setting screen <b>1700</b> shown in <figref idref="DRAWINGS">FIG. 17</figref>, and a personal data setting screen <b>1800</b> shown in <figref idref="DRAWINGS">FIG. 18</figref>, and/or a speaker to output sounds.</p>
<p id="p-0170" num="0169">The GPS receiver <b>1406</b> has an antenna to receive radio wave signals transmitted from GPS satellites and measures the position of the crisis monitoring handheld terminal <b>1400</b>.</p>
<p id="p-0171" num="0170">The crisis monitoring server <b>1410</b> is a computer equipment to obtain the present condition of the user who is holding the crisis monitoring handheld terminal <b>1400</b>. A provider that provides the crisis monitoring system of the third embodiment manages the crisis monitoring server <b>1410</b>.</p>
<p id="p-0172" num="0171">The crisis monitoring server <b>1410</b> is composed of an input unit <b>1411</b>, a recording unit <b>1412</b>, a control unit <b>1413</b>, a communication unit <b>1414</b> and an output unit <b>1415</b>.</p>
<p id="p-0173" num="0172">The input unit <b>1411</b> is constituted of an input device to which an operator input data, such as a touch panel, a switch, a keyboard or a mouse.</p>
<p id="p-0174" num="0173">The recording unit <b>1412</b> is constituted of a hard disk or a memory. The recording unit <b>1412</b> stores a speech emotion recognition program, which analyzes an audio inputted, audio data, and visual data.</p>
<p id="p-0175" num="0174">The control unit <b>1413</b> includes a CPU and executes an emergency processing using the speech emotion recognition program which is stored in the recording unit <b>1412</b>, when the user is in trouble.</p>
<p id="p-0176" num="0175">The communication unit <b>1414</b> communicates with the crisis monitoring handheld terminal <b>1400</b> via the cellular telephony network <b>1420</b>. The communication unit <b>1414</b> also communicates with a control center over a cable (e.g. a public switched telephone network or the Internet). The communication unit <b>1414</b> may also be communicable with other external devices.</p>
<p id="p-0177" num="0176">The output unit <b>1415</b> is constituted of a liquid crystal display to display various data concerning crisis monitoring and content of a monitoring condition display screen <b>2000</b> shown in <figref idref="DRAWINGS">FIG. 20</figref>, and/or a speaker to output sounds.</p>
<p id="p-0178" num="0177">The cellular telephony network <b>1420</b> is used to put information outputted from the crisis monitoring handheld terminal <b>1400</b> together in the crisis monitoring server <b>1410</b>. A wireless LAN, for example, can be employed instead of the cellular telephony network <b>1420</b> as long as the replacement can make the information aggregate in the monitoring server <b>1410</b>.</p>
<p id="p-0179" num="0178"><figref idref="DRAWINGS">FIG. 15</figref> is a flow chart of monitoring processing by the crisis monitoring handheld terminal <b>1400</b>.</p>
<p id="p-0180" num="0179">When the monitoring processing is started (step <b>1501</b>), the crisis monitoring handheld terminal <b>1400</b> checks, at a given timing (e.g. periodically), the user's current position measured by the GPS receiver <b>1406</b> (step <b>1502</b>). Other known methods than the GPS location method may be used to check the position of the crisis monitoring handheld terminal <b>1400</b> as long as the apparatus' position can be determined.</p>
<p id="p-0181" num="0180">The crisis monitoring handheld terminal <b>1400</b> then judges whether it is in a monitoring area or not from the obtained position information (step <b>1503</b>). At this time, the crisis monitoring handheld terminal <b>1400</b> refers to a monitoring area that is predetermined in the monitoring area database <b>1900</b> stored in the recording unit <b>1402</b>.</p>
<p id="p-0182" num="0181">When the crisis monitoring handheld terminal <b>1400</b> judges that the terminal has entered a monitoring area, the crisis monitoring handheld terminal <b>1400</b> starts observing the user (step <b>1507</b>).</p>
<p id="p-0183" num="0182">On the other hand, when the crisis monitoring handheld terminal <b>1400</b> judges that the terminal is outside the monitoring area, the crisis monitoring handheld terminal <b>1400</b> records the present condition in the condition database <b>300</b> of the recording unit <b>1402</b> (step <b>1504</b>).</p>
<p id="p-0184" num="0183">The communication unit <b>1404</b> send, at a given timing (e.g. periodically), the present condition to the crisis monitoring server <b>1410</b> via the cellular telephony network <b>1420</b>. The present condition sent to the crisis monitoring server <b>1410</b> may be the entirety of or a part of the condition database <b>300</b>.</p>
<p id="p-0185" num="0184">Preferably, the crisis monitoring handheld terminal <b>1400</b> sends, along with the present condition, the personal information management table <b>900</b>, which contains user's personal information, to the crisis monitoring server <b>1410</b>. The user's personal information should be transmitted using known encoding processing such as public key encryption in order to prevent third parties from reading the personal information.</p>
<p id="p-0186" num="0185">The crisis monitoring handheld terminal <b>1400</b> judges whether to conduct a further position checking (step <b>1505</b>). In the case where it is detected that the crisis monitoring handheld terminal <b>1400</b> is operated to terminate monitoring, the crisis monitoring handheld terminal <b>1400</b> ends the process (step <b>1506</b>). In the case where the crisis monitoring handheld terminal <b>1400</b> is to continue operating, on the other hand, the process returns to the step <b>1502</b> to keep checking the position of the crisis monitoring handheld terminal <b>1400</b>.</p>
<p id="p-0187" num="0186">Upon starting observation (step <b>1507</b>), the crisis monitoring handheld terminal <b>1400</b> executes emotion detection processing based on audio information which is inputted through the input unit <b>1401</b> as shown in <figref idref="DRAWINGS">FIG. 5</figref>, to thereby judge whether the user is in trouble (step <b>1508</b>).</p>
<p id="p-0188" num="0187">When it is judged that the user is not in any trouble, the crisis monitoring handheld terminal <b>1400</b> records the present condition in the condition database <b>300</b> (step <b>1509</b>). The process then returns to the step <b>1502</b>, where the position of the crisis monitoring handheld terminal <b>1400</b> is checked.</p>
<p id="p-0189" num="0188">On the other hand, when it is judged that the user is in trouble, the crisis monitoring handheld terminal <b>1400</b> sends the present condition to the crisis monitoring server <b>1410</b> via the cellular telephony network <b>1420</b>.</p>
<p id="p-0190" num="0189">In emergency, the control unit <b>1403</b> controls the respective units in a prescribed manner.</p>
<p id="p-0191" num="0190">Specifically, the control unit <b>1403</b> controls the communication unit <b>1404</b> to send the present condition to the crisis monitoring server <b>1410</b>. At this time, it is preferable for the communication unit <b>1404</b> to also send the present condition recorded in the recording unit <b>1402</b> and the user's personal information recorded in the personal information management table <b>900</b> to the crisis monitoring server <b>1410</b>. The user's personal information is transmitted using known encoding processing such as public key encryption in order to prevent third parties from reading the personal information.</p>
<p id="p-0192" num="0191">The control unit <b>1403</b> controls the output unit <b>1405</b> to output an audio signal or visual message showing that the alert has been sent to control center.</p>
<p id="p-0193" num="0192">Preferably, the emergency processing may vary from user to user in accordance with the method recorded in the personal information management table <b>900</b>.</p>
<p id="p-0194" num="0193">The control method described above is merely an example, and other control methods may be employed to ensure the safety of users.</p>
<p id="p-0195" num="0194">As the emergency processing (step <b>1510</b>) is completed, the crisis monitoring handheld terminal <b>1400</b> records the present condition to update the condition database <b>300</b> (step <b>1511</b>). The process then returns to the step <b>1502</b>, where the crisis monitoring handheld terminal <b>1400</b> checks its position.</p>
<p id="p-0196" num="0195">Audio data inputted through the input unit <b>1401</b> is preferably stored in the recording unit <b>1402</b>. The stored audio data can be used in identifying the person who has committed an offence against the user during observation. A camera may be employed to observe images. Images of the interior of the elevator car picked up by the camera are preferably stored in the recording unit <b>1402</b>, so that the stored images can be used in identifying a suspect.</p>
<p id="p-0197" num="0196">However, it is advisable to quickly delete audio, visual or other data stored in the recording unit <b>1402</b> in the case where monitoring is ended without detecting any trouble, since the recorded data contains a lot of personal (private) information.</p>
<p id="p-0198" num="0197"><figref idref="DRAWINGS">FIG. 16</figref> is a flow chart of processing by the crisis monitoring server <b>1410</b>.</p>
<p id="p-0199" num="0198">When the monitoring processing is started (step <b>1601</b>), the crisis monitoring server <b>1410</b> sends an inquiry signal via the cellular telephony network <b>1420</b> at a given timing to perform apparatus search processing, which is for finding out whether the crisis monitoring handheld terminal <b>1400</b> has entered a monitoring area (step <b>1602</b>). Alternatively, the crisis monitoring handheld terminal <b>1400</b> may send a signal at a given timing to the crisis monitoring server <b>1410</b> to inform the server that the handheld terminal has entered a monitoring area.</p>
<p id="p-0200" num="0199">Upon receiving the inquiry signal from the crisis monitoring server <b>1410</b>, the crisis monitoring handheld terminal <b>1400</b> sends, when in a monitoring area, an observation request and the present condition to the crisis monitoring server <b>1410</b>. Position information of the crisis monitoring handheld terminal <b>1400</b> is periodically sent to the crisis monitoring server <b>1410</b> until the crisis monitoring handheld terminal <b>1400</b> moves out of the monitoring area.</p>
<p id="p-0201" num="0200">From the present condition and other observation data sent from the crisis monitoring handheld terminal <b>1400</b>, the crisis monitoring server <b>1410</b> analyzes the position and present condition of the user (step <b>1603</b>).</p>
<p id="p-0202" num="0201">The crisis monitoring server <b>1410</b> then judges, from the result of analyzing the observation data, whether the user is in trouble or not (step <b>1604</b>).</p>
<p id="p-0203" num="0202">When it is judged that the user is not in any trouble, the crisis monitoring server <b>1410</b> records the present condition of the crisis monitoring handheld terminal <b>1400</b> in a present condition database <b>2100</b> (step <b>1605</b>). The present condition to be recorded is sent by the communication unit <b>1414</b> to the control center at a given timing. The present condition sent to the control center may be the entirety of or a part of the present condition database <b>2100</b>.</p>
<p id="p-0204" num="0203">Thereafter, the crisis monitoring server <b>1410</b> judges, through termination judging processing, whether to conduct a further search for the crisis monitoring handheld terminal <b>1400</b> (step <b>1606</b>). In the case where the crisis monitoring server <b>1410</b> is to stop operating (for example, when a command to stop observation is inputted), the crisis monitoring server <b>1410</b> stops the monitoring processing (step <b>1607</b>). On the other hand, in the case where the crisis monitoring server <b>1410</b> is to continue operating, the processing returns to the step <b>1602</b> to continue searching for the apparatus.</p>
<p id="p-0205" num="0204">On the other hand, when it is judged in the step <b>1603</b> that the user is in trouble, the crisis monitoring server <b>1410</b> follows emergency response <b>311</b> set in the condition database <b>300</b> and executes an emergency processing such as alerting the control center, a local security company, or a contracted security company (step <b>1607</b>).</p>
<p id="p-0206" num="0205">Preferably, the communication unit <b>1414</b> sends the record in the current database <b>300</b> that has been sent from the crisis monitoring handheld terminal <b>1400</b> to the control center via the cellular telephony network <b>1420</b>.</p>
<p id="p-0207" num="0206">In emergency, the control unit <b>1413</b> controls the respective units in a prescribed manner.</p>
<p id="p-0208" num="0207">Specifically, the control unit <b>1413</b> controls the communication unit <b>1414</b> to alert the control center. At this time, preferably, the communication unit <b>1414</b> also sends, to the control center, the present condition recorded in the recording unit <b>1412</b> and the user's personal information recorded in the personal information management table <b>900</b>.</p>
<p id="p-0209" num="0208">The control unit <b>1413</b> controls the output unit <b>1415</b> to output an audio signal or visual message showing that the alert has been sent to control center.</p>
<p id="p-0210" num="0209">The control method described above is merely an example, and other control methods can be employed to ensure the safety of users.</p>
<p id="p-0211" num="0210">As the emergency processing (step <b>1608</b>) is completed, the crisis monitoring server <b>1410</b> records the present condition of each crisis monitoring equipment <b>110</b> in the present condition database <b>2100</b> (step <b>1609</b>). Then the processing returns to the step <b>1602</b>, where the crisis monitoring server <b>1410</b> searches for the apparatus.</p>
<p id="p-0212" num="0211">Instead of the crisis monitoring server <b>1410</b>, the crisis monitoring handheld terminal <b>1400</b> may judge a crisis through the emotion detection processing of <figref idref="DRAWINGS">FIG. 5</figref> based on a user's voice and/or image observed. Specifically, the crisis monitoring handheld terminal <b>1400</b> sends an observation result <b>306</b> and a monitoring result <b>307</b>, which is determined based on the observation result <b>306</b>, to the crisis monitoring server <b>1410</b>.</p>
<p id="p-0213" num="0212">When the crisis monitoring server <b>1410</b> judges whether a user is in trouble, the crisis monitoring server <b>1410</b> may receive the user's voice and/or image observed by the crisis monitoring handheld terminal <b>1400</b>, and performs the emotion detection processing shown in <figref idref="DRAWINGS">FIG. 5</figref> on the received data with the use of the speech emotion recognition program stored in the recording unit <b>1412</b>.</p>
<p id="p-0214" num="0213"><figref idref="DRAWINGS">FIG. 17</figref> is a configuration diagram of the monitoring area setting screen <b>1700</b>.</p>
<p id="p-0215" num="0214">The monitoring area setting screen <b>1700</b> is a screen to set monitoring area information and monitoring time information with the use of a GUI (graphical user interface). The monitoring area setting screen <b>1700</b> is displayed on the liquid crystal display of the output unit <b>1405</b> of the crisis monitoring handheld terminal <b>1400</b>.</p>
<p id="p-0216" num="0215">Map information <b>1701</b> of a region in which a monitoring area is set is displayed on the monitoring area setting screen <b>1700</b>. The use of a map makes it possible to set a monitoring area, even when the geographic name of an area in which the user desires monitoring is unknown, by looking up the map for the objective area. The range set as the monitoring area is displayed in a specific color to make it easy to distinguish the monitoring area from other areas.</p>
<p id="p-0217" num="0216">Also displayed on the monitoring area setting screen <b>1700</b> are the geographical name of the area set as the monitoring area, and a symbol description <b>1702</b> of the map information <b>1701</b>.</p>
<p id="p-0218" num="0217">A monitoring time period <b>1703</b> to be set is displayed on the monitoring area setting screen <b>1700</b>. Once the monitoring time period <b>1703</b> is set, monitoring is started when the crisis monitoring handheld terminal <b>1400</b> enters the monitoring area within this set time.</p>
<p id="p-0219" num="0218">Security information in neighboring region <b>1704</b> displayed on the monitoring area setting screen <b>1700</b> is information about the neighboring region shown in the map information <b>1701</b>. The security information in neighboring region <b>1704</b> shows past inappropriate actions (e.g. molestation and robbery) in the neighboring region to be consulted by the user in setting a monitoring area and a monitoring time.</p>
<p id="p-0220" num="0219">A personal computer, for example, may be used to set a monitoring area and a monitoring time instead of the crisis monitoring handheld terminal <b>1400</b>. In the case where a monitoring area is set through other terminal than the crisis monitoring handheld terminal <b>1400</b>, the set information is transferred to the crisis monitoring handheld terminal <b>1400</b> via other equipment that is connected to the crisis monitoring handheld terminal <b>1400</b> or via a communication line (e.g. the Internet).</p>
<p id="p-0221" num="0220">The monitoring area setting screen <b>1700</b> is merely an example of a measure to set such information as a monitoring area, and may be replaced by other interfaces (e.g., a command line interface) as long as a monitoring area and a monitoring time can be set.</p>
<p id="p-0222" num="0221">The crisis monitoring handheld terminal <b>1400</b> records the set information in the recording unit <b>1402</b>. In the case where plural types of set information are to be recorded, the monitoring area database <b>1900</b> shown in <figref idref="DRAWINGS">FIG. 19</figref> may be used to keep the record.</p>
<p id="p-0223" num="0222"><figref idref="DRAWINGS">FIG. 18</figref> is a configuration diagram of the personal data setting screen <b>1800</b>.</p>
<p id="p-0224" num="0223">The personal data setting screen <b>1800</b> is a screen to set personal information of the user who holds the crisis monitoring handheld terminal <b>1400</b> with the use of a GUI. The personal data setting screen <b>1800</b> is displayed on the liquid crystal display of the output unit <b>1405</b> of the crisis monitoring handheld terminal <b>1400</b>.</p>
<p id="p-0225" num="0224">The personal data setting screen <b>1800</b> includes an input field for an alert word <b>1801</b>. The alert word inputted to the input field <b>1801</b> is set in the alert word <b>905</b> included in the personal information management table <b>900</b> shown in <figref idref="DRAWINGS">FIG. 9</figref>.</p>
<p id="p-0226" num="0225">The personal data setting screen <b>1800</b> also shows an selection <b>1802</b> about whether to analyze a feature amount of the voice of the user who holds the crisis monitoring handheld terminal <b>1400</b>. When “Yes” is chosen to the selection <b>1802</b>, a sound which the user might utter in a crisis situation (e.g. a cry) is inputted through the microphone of the input unit <b>1401</b> and a feature of the sound is analyzed. The analyzed variable data is recorded in the variable values <b>906</b> to <b>910</b> of the personal information management table <b>900</b> to be used in the emotion detecting processing during observation. When “No” is chosen to the selection <b>1802</b>, the analysis of the user's voice is skipped.</p>
<p id="p-0227" num="0226">A personal computer, for example, may be used to set personal information instead of the crisis monitoring handheld terminal <b>1400</b>. In the case where personal information is set through other terminal than the crisis monitoring handheld terminal <b>1400</b>, the set information is transferred to the crisis monitoring handheld terminal <b>1400</b> via other equipment that is connected to the crisis monitoring handheld terminal <b>1400</b> or via a communication line (e.g. the Internet).</p>
<p id="p-0228" num="0227">Items that can be set on the personal data setting screen <b>1800</b> are not limited to those shown in <figref idref="DRAWINGS">FIG. 18</figref> and, when an item is added to the personal information management table <b>900</b>, a relevant item is added to the personal data setting screen <b>1800</b>.</p>
<p id="p-0229" num="0228">The personal data setting screen <b>1800</b> is merely an example of a measure to set personal information. Other interfaces (e.g. a command line interface) may be employed instead as long as an alert word can be set and a user's voice can be inputted.</p>
<p id="p-0230" num="0229"><figref idref="DRAWINGS">FIG. 19</figref> is an explanatory diagram of the monitoring area database <b>1900</b>.</p>
<p id="p-0231" num="0230">The monitoring area database <b>1900</b> includes a monitoring setting number <b>1901</b>, an address <b>1902</b>, latitude <b>1903</b> longitude <b>1904</b> and a time period <b>1905</b>. The monitoring setting number <b>1901</b> is the number assigned to each of plural monitoring areas and monitoring time periods set by the user who holds the crisis monitoring handheld terminal <b>1400</b>.</p>
<p id="p-0232" num="0231">The address <b>1902</b> is the address of a set monitoring area. The latitude <b>1903</b> is the latitude of a set monitoring area. The longitude <b>1904</b> is the longitude of a set monitoring area.</p>
<p id="p-0233" num="0232">The time period <b>1905</b> is set monitoring timings. The crisis monitoring handheld terminal <b>1400</b> starts observing upon entering a monitoring area that is determined by data set as <b>1902</b> to <b>1904</b> in a time period set as <b>1905</b> by the user who holds the crisis monitoring handheld terminal <b>1400</b>.</p>
<p id="p-0234" num="0233">The monitoring area database <b>1900</b> is thus used to manage set information in the form of a database when a user sets plural monitoring areas and monitoring time periods.</p>
<p id="p-0235" num="0234"><figref idref="DRAWINGS">FIG. 20</figref> is a configuration diagram of the monitoring condition display screen <b>2000</b>.</p>
<p id="p-0236" num="0235">The monitoring condition display screen <b>2000</b> is a screen to display the present condition of the user who holds the crisis monitoring handheld terminal <b>1400</b> with the use of a GUI. The monitoring condition display screen <b>2000</b> is displayed on the liquid crystal display of the output unit <b>1415</b> of the crisis monitoring server <b>1410</b>.</p>
<p id="p-0237" num="0236">The display screen <b>2000</b> displays map information <b>2001</b> of an area set as a monitoring area. The present condition (e.g. position information) of the user holding the crisis monitoring handheld terminal <b>1400</b> is shown on the map information <b>2001</b>. The range set as the monitoring area is displayed in a specific color to make it easy to distinguish the monitoring area from other areas.</p>
<p id="p-0238" num="0237">Also displayed on the display screen <b>2000</b> are the geographical name of the area set as the monitoring area, and a symbol description <b>2002</b> of the map information <b>2001</b>.</p>
<p id="p-0239" num="0238">Crisis-regarding data <b>2003</b> including personal information of the user who holds the crisis monitoring handheld terminal <b>1400</b>, emergency response, and the user's present condition is displayed in text on the monitoring condition display screen <b>2000</b>.</p>
<p id="p-0240" num="0239">Displaying a monitoring condition with the use of a GUI in this way enables the crisis monitoring server <b>1410</b> to obtain the present condition of the user in present time.</p>
<p id="p-0241" num="0240">The monitoring condition display screen <b>2000</b> is merely an example of a measure to display information on a user in a monitoring area, and may be replaced by other interfaces (e.g. a command line interface) as long as the replacement is capable of displaying the user's present condition.</p>
<p id="p-0242" num="0241"><figref idref="DRAWINGS">FIG. 21</figref> is a configuration diagram of the present condition database <b>2100</b>.</p>
<p id="p-0243" num="0242">The present condition database <b>2100</b> includes a user ID <b>2101</b>, a user name <b>2102</b>, a location <b>2103</b>, a operative condition <b>2104</b> and a monitoring result <b>2105</b>. The user ID <b>2101</b> is the number assigned to each crisis monitoring handheld terminal <b>1400</b>. The user name <b>2102</b> is the name of a user who holds the crisis monitoring handheld terminal <b>1400</b>, that is a monitoring subject. The location <b>2103</b> is where the crisis monitoring handheld terminal <b>1400</b> is located at present.</p>
<p id="p-0244" num="0243">The operative condition <b>2104</b> is the present operative condition of each crisis monitoring handheld terminal <b>1400</b>. “Waiting” is recorded as the operative condition <b>2104</b> for the crisis monitoring handheld terminal <b>1400</b> that has not started observation yet. Each crisis monitoring handheld terminal <b>1400</b> enters an “waiting” state when, for example, a user holding this crisis monitoring handheld terminal <b>1400</b> is outside an area he/she has set as a monitoring area, or when a user holding the crisis monitoring handheld terminal <b>1400</b> is in an area he/she has set as a monitoring area but does not want observation. When a user carrying the crisis monitoring handheld terminal <b>1400</b> enters a monitoring area and the crisis monitoring handheld terminal <b>1400</b> starts observation, “observing” is recorded as the operative condition <b>2104</b>.</p>
<p id="p-0245" num="0244">The monitoring result <b>2105</b> is a result of the judgment made on whether there is a disturbance or not from a user's voice and/or image observed by the crisis monitoring handheld terminal <b>1400</b>.</p>
<p id="p-0246" num="0245">The present condition database <b>2100</b> can include other items than those shown in <figref idref="DRAWINGS">FIG. 21</figref>, and an item is removed or added as necessary.</p>
<p id="p-0247" num="0246">As has been described above, the system according to the third embodiment, in which the crisis monitoring handheld terminal <b>1400</b> having the function of the crisis monitoring equipment <b>110</b> is built in a cellular phone or a similar handheld terminal that a user holds, can detect from an angry shout or a cry that the user makes in trouble while the user is outdoor, and reports the detected crisis. The system according to the third embodiment is therefore capable of making outdoor spaces safe for its users.</p>
<p id="p-0248" num="0247">Preferably, the crisis monitoring server <b>1410</b> constantly monitors for a crisis in a public space prone to crimes since a crisis can happen anytime. Constant monitoring, however, involves the problem of an invasion of privacy by catching users' voices and images when they do not desire crisis monitoring.</p>
<p id="p-0249" num="0248">This problem is cleared by carrying out monitoring crisis only in a monitoring area specified by a user in advance with the use of the GPS system. Thus the crisis monitoring system is made available to a user only when the user desires monitoring.</p>
<p id="p-0250" num="0249">The system that monitors for a limited period is also free from another drawback of constant monitoring, which is an increased chance of making an erroneous crisis judgment due to noise irrelevant to crisis monitoring and prolonged sound analysis time.</p>
<p id="p-0251" num="0250">While the present invention has been described in detail and pictorially in the accompanying drawings, the present invention is not limited to such detail but covers various obvious modifications and equivalent arrangements, which fall within the purview of the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A crisis monitoring apparatus to judge whether a person is in a crisis situation, comprising an input unit, a recording unit, and a control unit to judge whether a person is in a crisis situation, wherein
<claim-text>the input unit receives an audio signal,</claim-text>
<claim-text>the recording unit records emotion attribute information, which includes a feature of a specific emotion in an audio signal, as information necessary to judge a crisis situation, and</claim-text>
<claim-text>the control unit controls the input unit and the recording unit, determines a person's emotion by comparing an audio signal inputted to the input unit with the emotion attribute information, and executes a predetermined emergency processing when the determined emotion indicates a crisis situation,</claim-text>
<claim-text>wherein the recording unit records an audio signal inputted to the input unit, and</claim-text>
<claim-text>wherein the control unit:</claim-text>
<claim-text>deletes the audio signal recorded in the recording unit after a predetermined time elapses, when the determined emotion does not indicate a crisis situation; and</claim-text>
<claim-text>keeps to record the audio signal recorded in the recording unit after the predetermined time elapses, when the determined emotion indicates a crisis situation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The crisis monitoring apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a communication unit which communicates with an external device, wherein
<claim-text>the control unit starts crisis monitoring when the communication unit receives a monitoring starting instruction.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The crisis monitoring apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a locating unit which determines a location of the crisis monitoring apparatus, wherein
<claim-text>the control unit starts crisis monitoring when the locating unit detects that the crisis monitoring apparatus locates at a predetermined point.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The crisis monitoring apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising an output unit which sends notification that the determined emotion indicates a crisis situation.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The crisis monitoring apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the communication unit communicates via a mobile communications network.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A crisis monitoring system to judge whether a person is in a crisis situation, comprising a crisis monitoring apparatus and a crisis monitoring terminal, wherein
<claim-text>a crisis monitoring apparatus comprises an input unit, a recording unit and a control unit,</claim-text>
<claim-text>the input unit receives an audio signal,</claim-text>
<claim-text>the recording unit records emotion attribute information, which is information about a feature of a specific emotion in an audio signal, as information necessary to judge a crisis situation, and</claim-text>
<claim-text>the control unit controls the input unit and the recording unit, determines a person's emotion by comparing an audio signal inputted to the input unit with the emotion attribute information, and executes a predetermined emergency processing when the determined emotion indicates a crisis situation,</claim-text>
<claim-text>wherein the recording unit records an audio signal inputted to the input unit, and</claim-text>
<claim-text>wherein the control unit:</claim-text>
<claim-text>deletes the audio signal recorded in the recording unit after a predetermined time elapses, when the determined emotion does not indicate a crisis situation; and</claim-text>
<claim-text>keeps to record the audio signal recorded in the recording unit after the predetermined time elapses, when the determined emotion indicates a crisis situation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The crisis monitoring system according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein
<claim-text>the crisis monitoring apparatus further comprises a communication unit which communicates with the crisis monitoring terminal, and</claim-text>
<claim-text>the control unit starts crisis monitoring when the communication unit receives a monitoring starting instruction from the crisis monitoring terminal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The crisis monitoring system according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising a management apparatus which collects information from the crisis monitoring apparatus, wherein
<claim-text>the control unit controls to send, to the management apparatus, a message reporting that a crisis has happened, when the determined emotion indicates a crisis situation, and</claim-text>
<claim-text>the management apparatus executes a predetermined emergency processing, when the management apparatus detects a crisis situation from the information sent by the crisis monitoring apparatus.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The crisis monitoring system according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising a locating unit which locates the crisis monitoring apparatus, wherein
<claim-text>the control unit starts crisis monitoring when the locating unit detects that the crisis monitoring apparatus locates at a predetermined point.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The crisis monitoring system according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising an output unit which sends notification that the determined emotion indicates a crisis situation.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A method of monitoring a crisis for a crisis monitoring system which comprises a crisis monitoring apparatus comprising an input unit to input an audio signal, a recording unit to record emotion attribute information, which include a feature of a specific emotion in an audio signal, and a control unit to control the input unit and the recording unit, the method comprising:
<claim-text>determining a person's emotion by comparing an audio signal inputted to the input unit with the emotion attribute information,</claim-text>
<claim-text>judging whether the determined emotion indicates a crisis situation,</claim-text>
<claim-text>executing an emergency processing following a predetermined method when it is judged that the determined emotion indicates a crisis situations;</claim-text>
<claim-text>deleting the audio signal recorded in the recording unit after a predetermined time elapses, when the determined emotion does not indicate a crisis situation; and</claim-text>
<claim-text>keeping to record the audio signal recorded in the recording unit after the predetermined time elapses, when the determined emotion indicates a crisis situation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>,
<claim-text>wherein the crisis monitoring system further comprises a crisis monitoring terminal hold by a user who desires crisis monitoring, and</claim-text>
<claim-text>wherein the method further comprises starting crisis monitoring when a monitoring starting instruction is received from the crisis monitoring terminal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>,
<claim-text>wherein the crisis monitoring system further comprises a management apparatus which collects information from the crisis monitoring apparatus, and</claim-text>
<claim-text>wherein the method further comprises:</claim-text>
<claim-text>sending, to the management apparatus, a message reporting that a crisis has happened, when the determined emotion indicates a crisis situation; and</claim-text>
<claim-text>executing a predetermined emergency processing, when the management apparatus detects a crisis situation from the information sent by the crisis monitoring apparatus.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>,
<claim-text>wherein the crisis monitoring system further comprises a management apparatus which collects information from the crisis monitoring apparatus,</claim-text>
<claim-text>wherein the method further comprises:</claim-text>
<claim-text>sending, to the management apparatus, information of the audio signal inputted to the input unit;</claim-text>
<claim-text>determining a person's emotion by comparing the audio information sent from the crisis monitoring apparatus with a feature of a specific emotion in an audio signal; and</claim-text>
<claim-text>executing a predetermined emergency processing when it is judged that the determined emotion indicates a crisis situation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>,
<claim-text>wherein the crisis monitoring system further comprises a locating unit which determines a location of the crisis monitoring apparatus, and</claim-text>
<claim-text>wherein the method further comprises starting crisis monitoring when the locating unit detects a predetermined point.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>,
<claim-text>wherein the crisis monitoring system further comprises an output unit</claim-text>
<claim-text>wherein the method further comprises sending notification that the determined emotion indicates a crisis situation.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
