<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07299385-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07299385</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10900948</doc-number>
<date>20040728</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>554</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>11</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>714 57</main-classification>
</classification-national>
<invention-title id="d0e53">Managing a fault tolerant system</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5408218</doc-number>
<kind>A</kind>
<name>Svedberg et al.</name>
<date>19950400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>340507</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6006016</doc-number>
<kind>A</kind>
<name>Faigon et al.</name>
<date>19991200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714 48</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6874099</doc-number>
<kind>B1</kind>
<name>Balasubramanian et al.</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714  4</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7035953</doc-number>
<kind>B2</kind>
<name>Krontz et al.</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710302</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2003/0061322</doc-number>
<kind>A1</kind>
<name>Igarashi et al.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709223</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2003/0097588</doc-number>
<kind>A1</kind>
<name>Fischman et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713200</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2004/0236547</doc-number>
<kind>A1</kind>
<name>Rappaport et al.</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>703  2</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2005/0137832</doc-number>
<kind>A1</kind>
<name>Yemini et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>702183</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2005/0185597</doc-number>
<kind>A1</kind>
<name>Le et al.</name>
<date>20050800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370254</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2005/0198583</doc-number>
<kind>A1</kind>
<name>Martinez et al.</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715772</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2005/0210330</doc-number>
<kind>A1</kind>
<name>Platteter</name>
<date>20050900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714 25</main-classification></classification-national>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2005/0232256</doc-number>
<kind>A1</kind>
<name>White et al.</name>
<date>20051000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370360</main-classification></classification-national>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2006/0106585</doc-number>
<kind>A1</kind>
<name>Brown et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>703  1</main-classification></classification-national>
</citation>
</references-cited>
<number-of-claims>26</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>714 57</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>14</number-of-drawing-sheets>
<number-of-figures>14</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20060026451</doc-number>
<kind>A1</kind>
<date>20060202</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Voigt</last-name>
<first-name>Douglas L.</first-name>
<address>
<city>Boise</city>
<state>ID</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Hewlett-Packard Development Company, L.P.</orgname>
<role>02</role>
<address>
<city>Houston</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Bonzo</last-name>
<first-name>Bryce P</first-name>
<department>2113</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Systems and methods for managing a fault tolerant system are disclosed. In one implementation a system for managing a fault tolerant system comprises a configuration manager that receives configuration events from the fault tolerant system, a fault normalizer that receives fault events from the fault tolerant system; and a fault tolerance logic engine that constructs a model of the fault tolerant system based on inputs from the configuration manager and generates reporting events in response to inputs from the fault normalizer.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="141.90mm" wi="238.42mm" file="US07299385-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="205.82mm" wi="166.20mm" file="US07299385-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="236.47mm" wi="183.13mm" file="US07299385-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="229.70mm" wi="178.14mm" orientation="landscape" file="US07299385-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="240.28mm" wi="174.92mm" orientation="landscape" file="US07299385-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="244.77mm" wi="179.83mm" file="US07299385-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="239.95mm" wi="172.38mm" file="US07299385-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="197.02mm" wi="131.15mm" file="US07299385-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="195.66mm" wi="117.09mm" file="US07299385-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="255.44mm" wi="165.86mm" file="US07299385-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="211.50mm" wi="185.50mm" file="US07299385-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="240.79mm" wi="171.28mm" file="US07299385-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="248.58mm" wi="138.09mm" file="US07299385-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="221.57mm" wi="155.45mm" file="US07299385-20071120-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="227.08mm" wi="151.72mm" file="US07299385-20071120-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD</heading>
<p id="p-0002" num="0001">The described subject matter relates to electronic computing, and more particularly to managing a fault tolerant system.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">A disk array is a type of turnkey, high-availability system. A disk array is designed to be inherently fault tolerant with little or no configuration effort. It responds automatically to faults, repair actions, and configuration in a manner that preserves system availability. These characteristics disk arrays are achieved by encoding fault recovery and configuration change responses into embedded software, i.e., firmware that executes on the array controller. This encoding is often specific to the physical packaging of the array.</p>
<p id="p-0004" num="0003">Since the software embedded in disk arrays is complex and expensive to develop, it is desirable to foster as much reuse as possible across an array product portfolio. Different scales of systems targeted at various market segments have distinct ways of integrating of the components that make up the system.</p>
<p id="p-0005" num="0004">For example, some array controllers and disks are distributed in a single package with shared power supplies, while other array controllers are packaged separately from disks, and each controller has its own power supply. In the future, turnkey, fault tolerant systems may include loosely-integrated storage networking elements. The patterns of redundancy and common mode failure differ across these integration styles. Unfortunately these differences directly affect the logic that governs fault and configuration change responses.</p>
<p id="p-0006" num="0005">Therefore, there remains a need for systems and methods for managing a fault tolerant system.</p>
<heading id="h-0003" level="1">SUMMARY</heading>
<p id="p-0007" num="0006">In one exemplary implementation a system for modeling and managing a fault tolerant system, comprises a configuration manager that receives configuration events from the fault tolerant system; a fault normalizer that receives fault events from the fault tolerant system; and a fault tolerance logic engine that constructs a model of the fault tolerant system based on inputs from the configuration manager and generates reporting events in response to inputs from the fault normalizer.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic illustration of an exemplary implementation of a data storage system.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic illustration of an exemplary implementation of a disk array controller in more detail.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 3</figref> is a schematic illustration of an exemplary fault tolerance system.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 4</figref> is a schematic illustration of a graph representing components of a data storage system.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIGS. 5A-5D</figref> are flowcharts illustrating operations in an exemplary process for configuring a fault tolerance system.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart illustrating operations in an exemplary process for deleting a node from a system model.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIGS. 7A-7C</figref> are flowcharts illustrating operations in an exemplary process for recalculating the state of one or more system nodes in a fault tolerance system.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart that illustrates operations in an exemplary process for generating a new event.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart illustrating operations of the fault tolerance logic engine in response to a fault event.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0017" num="0016">Described herein are exemplary architectures and techniques for managing a fault-tolerant system. The methods described herein may be embodied as logic instructions on a computer-readable medium, firmware, or as dedicated circuitry. When executed on a processor, the logic instructions (or firmware) cause a processor to be programmed as a special-purpose machine that implements the described methods. The processor, when configured by the logic instructions (or firmware) to execute the methods recited herein, constitutes structure for performing the described methods.</p>
<p id="h-0006" num="0000">Exemplary Architecture</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic illustration of an exemplary implementation of a data storage system <b>100</b>. The data storage system <b>100</b> has a disk array with multiple storage disks <b>130</b><i>a</i>-<b>130</b><i>f</i>, a disk array controller module <b>120</b>, and a storage management system <b>110</b>. The disk array controller module <b>120</b> is coupled to multiple storage disks <b>130</b><i>a</i>-<b>130</b><i>f </i>via one or more interface buses, such as a small computer system interface (SCSI) bus. The storage management system <b>110</b> is coupled to the disk array controller module <b>120</b> via one or more interface buses. It is noted that the storage management system <b>110</b> can be embodied as a separate component (as shown), or within the disk array controller module <b>120</b>, or within a host computer.</p>
<p id="p-0019" num="0018">In an exemplary implementation data storage system <b>100</b> may implement RAID (Redundant Array of Independent Disks) data storage techniques. RAID storage systems are disk array systems in which part of the physical storage capacity is used to store redundant data. RAID systems are typically characterized as one of six architectures, enumerated under the acronym RAID. A RAID <b>0</b> architecture is a disk array system that is configured without any redundancy. Since this architecture is really not a redundant architecture, RAID <b>0</b> is often omitted from a discussion of RAID systems.</p>
<p id="p-0020" num="0019">A RAID <b>1</b> architecture involves storage disks configured according to mirror redundancy. Original data is stored on one set of disks and a duplicate copy of the data is kept on separate disks. The RAID <b>2</b> through RAID <b>5</b> architectures involve parity-type redundant storage. Of particular interest, a RAID <b>5</b> system distributes data and parity information across a plurality of the disks <b>130</b><i>a</i>-<b>130</b><i>c</i>. Typically, the disks are divided into equally sized address areas referred to as “blocks”. A set of blocks from each disk that have the same unit address ranges are referred to as “stripes”. In RAID <b>5</b>, each stripe has N blocks of data and one parity block which contains redundant information for the data in the N blocks.</p>
<p id="p-0021" num="0020">In RAID <b>5</b>, the parity block is cycled across different disks from stripe-to-stripe. For example, in a RAID <b>5</b> system having five disks, the parity block for the first stripe might be on the fifth disk; the parity block for the second stripe might be on the fourth disk; the parity block for the third stripe might be on the third disk; and so on. The parity block for succeeding stripes typically rotates around the disk drives in a helical pattern (although other patterns are possible). RAID <b>2</b> through RAID <b>4</b> architectures differ from RAID <b>5</b> in how they compute and place the parity block on the disks. The particular RAID class implemented is not important.</p>
<p id="p-0022" num="0021">In a RAID implementation, the storage management system <b>110</b> optionally may be implemented as a RAID management software module that runs on a processing unit of the data storage device, or on the processor unit of a computer <b>130</b>.</p>
<p id="p-0023" num="0022">The disk array controller module <b>120</b> coordinates data transfer to and from the multiple storage disks <b>130</b><i>a</i>-<b>130</b><i>f</i>. In an exemplary implementation, the disk array module <b>120</b> has two identical controllers or controller boards: a first disk array controller <b>122</b><i>a </i>and a second disk array controller <b>122</b><i>b</i>. Parallel controllers enhance reliability by providing continuous backup and redundancy in the event that one controller becomes inoperable. Parallel controllers <b>122</b><i>a </i>and <b>122</b><i>b </i>have respective mirrored memories <b>124</b><i>a </i>and <b>124</b><i>b</i>. The mirrored memories <b>124</b><i>a </i>and <b>124</b><i>b </i>may be implemented as battery-backed, non-volatile RAMs (e.g., NVRAMs). Although only dual controllers <b>122</b><i>a </i>and <b>122</b><i>b </i>are shown and discussed generally herein, aspects of this invention can be extended to other multi-controller configurations where more than two controllers are employed.</p>
<p id="p-0024" num="0023">The mirrored memories <b>124</b><i>a </i>and <b>124</b><i>b </i>store several types of information. The mirrored memories <b>124</b><i>a </i>and <b>124</b><i>b </i>maintain duplicate copies of a cohesive memory map of the storage space in multiple storage disks <b>130</b><i>a</i>-<b>130</b><i>f </i>This memory map tracks where data and redundancy information are stored on the disks, and where available free space is located. The view of the mirrored memories is consistent across the hot-plug interface, appearing the same to external processes seeking to read or write data.</p>
<p id="p-0025" num="0024">The mirrored memories <b>124</b><i>a </i>and <b>124</b><i>b </i>also maintain a read cache that holds data being read from the multiple storage disks <b>130</b><i>a</i>-<b>130</b><i>f</i>. Every read request is shared between the controllers. The mirrored memories <b>124</b><i>a </i>and <b>124</b><i>b </i>further maintain two duplicate copies of a write cache. Each write cache temporarily stores data before it is written out to the multiple storage disks <b>130</b><i>a</i>-<b>130</b><i>f. </i></p>
<p id="p-0026" num="0025">The controller's mirrored memories <b>122</b><i>a </i>and <b>122</b><i>b </i>are physically coupled via a hot-plug interface <b>126</b>. Generally, the controllers <b>122</b><i>a </i>and <b>122</b><i>b </i>monitor data transfers between them to ensure that data is accurately transferred and that transaction ordering is preserved (e.g., read/write ordering).</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic illustration of an exemplary implementation of a dual disk array controller in greater detail. In addition to controller boards <b>210</b><i>a </i>and <b>210</b><i>b</i>, the disk array controller also has two I/O modules <b>240</b><i>a </i>and <b>240</b><i>b</i>, an optional display <b>244</b>, and two power supplies <b>242</b><i>a </i>and <b>242</b><i>b</i>. The I/O modules <b>240</b><i>a </i>and <b>240</b><i>b </i>facilitate data transfer between respective controllers <b>210</b><i>a </i>and <b>210</b><i>b </i>and a host computer. In one implementation, the I/O modules <b>240</b><i>a </i>and <b>240</b><i>b </i>employ fiber channel technology, although other bus technologies may be used. The power supplies <b>242</b><i>a </i>and <b>242</b><i>b </i>provide power to the other components in the respective disk array controllers <b>210</b><i>a</i>, <b>210</b><i>b</i>, the display <b>272</b>, and the I/O modules <b>240</b><i>a</i>, <b>240</b><i>b. </i></p>
<p id="p-0028" num="0027">Each controller <b>210</b><i>a</i>, <b>210</b><i>b </i>has a converter <b>230</b><i>a</i>, <b>230</b><i>b </i>connected to receive signals from the host via respective I/O modules <b>240</b><i>a</i>, <b>240</b><i>b</i>. Each converter <b>230</b><i>a </i>and <b>230</b><i>b </i>converts the signals from one bus format (e.g., Fibre Channel) to another bus format (e.g., peripheral component interconnect (PCI)). A first PCI bus <b>228</b><i>a</i>, <b>228</b><i>b </i>carries the signals to an array controller memory transaction manager <b>226</b><i>a</i>, <b>226</b><i>b</i>, which handles all mirrored memory transaction traffic to and from the NVRAM <b>222</b><i>a</i>, <b>222</b><i>b </i>in the mirrored controller. The array controller memory transaction manager maintains the memory map, computes parity, and facilitates cross-communication with the other controller. The array controller memory transaction manager <b>226</b><i>a</i>, <b>226</b><i>b </i>is preferably implemented as an integrated circuit (IC), such as an application-specific integrated circuit (ASIC).</p>
<p id="p-0029" num="0028">The array controller memory transaction manager <b>226</b><i>a</i>, <b>226</b><i>b </i>is coupled to the NVRAM <b>222</b><i>a</i>, <b>222</b><i>b </i>via a high-speed bus <b>222</b><i>a</i>, <b>222</b><i>b </i>and to other processing and memory components via a second PCI bus <b>220</b><i>a</i>, <b>220</b><i>b</i>. Controllers <b>210</b><i>a</i>, <b>210</b><i>b </i>may include several types of memory connected to the PCI bus <b>220</b><i>a </i>and <b>220</b><i>b</i>. The memory includes a dynamic RAM (DRAM) <b>214</b><i>a</i>, <b>214</b><i>b</i>, flash memory <b>218</b><i>a</i>, <b>218</b><i>b</i>, and cache <b>216</b><i>a</i>, <b>216</b><i>b. </i></p>
<p id="p-0030" num="0029">The array controller memory transaction managers <b>226</b><i>a </i>and <b>226</b><i>b </i>are coupled to one another via a communication interface <b>250</b>. The communication interface <b>250</b> supports bi-directional parallel communication between the two array controller memory transaction managers <b>226</b><i>a </i>and <b>226</b><i>b </i>at a data transfer rate commensurate with the NVRAM buses <b>224</b><i>a </i>and <b>224</b><i>b. </i></p>
<p id="p-0031" num="0030">The array controller memory transaction managers <b>226</b><i>a </i>and <b>226</b><i>b </i>employ a high-level packet protocol to exchange transactions in packets over hot-plug interface <b>250</b>. The array controller memory transaction managers <b>226</b><i>a </i>and <b>226</b><i>b </i>perform error correction on the packets to ensure that the data is correctly transferred between the controllers.</p>
<p id="p-0032" num="0031">The array controller memory transaction managers <b>226</b><i>a </i>and <b>226</b><i>b </i>provide a memory image that is coherent across the hot plug interface <b>250</b>. The managers <b>226</b><i>a </i>and <b>226</b><i>b </i>also provide an ordering mechanism to support an ordered interface that ensures proper sequencing of memory transactions.</p>
<p id="p-0033" num="0032">In an exemplary implementation each controller <b>210</b><i>a</i>, <b>210</b><i>b </i>includes multiple central processing units (CPUs) <b>212</b><i>a</i>, <b>213</b><i>a</i>, <b>212</b><i>b</i>, <b>213</b><i>b</i>, also referred to as processors. The processors on each controller may be assigned specific functionality to manage. For example, a first set of processing units <b>212</b><i>a</i>, <b>212</b><i>b </i>may manage storage operations for the plurality of disks <b>130</b><i>a</i>-<b>130</b><i>f</i>, while a second set of processing units <b>213</b><i>a</i>, <b>213</b><i>b </i>may manage networking operations with host computers or software modules that request storage services from data storage system <b>100</b>.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 3</figref> is a schematic illustration of an exemplary fault tolerance system <b>300</b>. In one exemplary implementation the fault tolerance system <b>300</b> depicted in <figref idref="DRAWINGS">FIG. 3</figref> may be implemented in a storage controller such as, e.g., the storage controller depicted in <figref idref="DRAWINGS">FIG. 2</figref>. Fault tolerance system <b>300</b> comprises a series of active components including a configuration manager <b>315</b>, a fault normalizer <b>335</b>, and a fault tolerance logic engine <b>340</b>. These active components may be implemented as logic instructions implemented in software executable on a processor, such as one of the CPUs <b>212</b><i>a</i>, <b>212</b><i>b </i>in the storage controller depicted in <figref idref="DRAWINGS">FIG. 2</figref>. Alternatively, the logic instructions may be implemented in firmware, or may be reduced to hardware in a controller. These active components create and/or interact with a series of storage tables including a component class table <b>310</b>, a fault symptom catalog table <b>320</b>, a system relationship and state table <b>325</b>, and an event generation registry table <b>330</b>. These tables may be implemented in one or more of the memory modules depicted in <figref idref="DRAWINGS">FIG. 2</figref>, or in an external memory location such as, e.g., a disk drive.</p>
<p id="p-0035" num="0034">When fault tolerance system <b>300</b> is implemented in a data storage system such as the system depicted in <figref idref="DRAWINGS">FIG. 1</figref>, components of the data storage system such as power supplies, controllers, disks and switches are represented as a set of object-oriented classes, which are stored in the component classes table <b>310</b>. In an exemplary implementation the component classes table <b>310</b> may be constructed by the manufacturer or administrator of the data storage system.</p>
<p id="p-0036" num="0035">The fault symptom catalog table <b>320</b> is a data table that provides a mapping between failure information for specific components and fault events in the context of a larger data storage system. In an exemplary implementation the fault symptom catalog table <b>320</b> may be constructed by the manufacturer or administrator of the data storage system.</p>
<p id="p-0037" num="0036">The event generation registry table <b>330</b> is a data table that maps reporting events for particular fault events or configuration change events to particular modules/devices in the data storage system. By way of example, a disk array in a storage system that utilizes the services of a power supply may register with the event generation registry table to receive notification of a failure event for the power supply.</p>
<p id="p-0038" num="0037">As the data storage system is constructed (or modified) the configuration manager <b>315</b> and the fault tolerance logic engine <b>340</b> cooperate to build a system relationship and state table <b>325</b> that describes relationships between components in the data storage system. In operation, fault events and configuration change events are delivered to the fault tolerance logic engine <b>340</b>, which uses the system relationship and state table <b>325</b> to generate fault reporting and recovery action events. The fault recovery logic engine <b>340</b> uses the mapping information in the event generation registry table <b>330</b> to propagate the reporting and recovery action events generated by the fault recovery logic engine <b>340</b> to other modules/devices in the storage system.</p>
<p id="p-0039" num="0038">Operation of the system <b>300</b> will be described with reference to the flowcharts of <figref idref="DRAWINGS">FIGS. 5A</figref> through <figref idref="DRAWINGS">FIG. 7</figref>, and the graph depicted in <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="h-0007" num="0000">Exemplary Operations</p>
<p id="p-0040" num="0039">In operation, fault tolerance system <b>300</b> constructs an abstract model representative of a real, physical fault tolerant system such as, e.g., a storage system. The abstract model is configured with relationships and properties representative of the real fault tolerant system. Then the fault tolerance system <b>300</b> monitors operation of real fault tolerant system for changes in the status of the real fault tolerant system. The abstract model is updated to reflect changes in the status of one or more components of the real fault tolerant system.</p>
<p id="p-0041" num="0040">More particularly, the configuration manager <b>315</b> receives configuration events (e.g., when the real system is powered on or when a new component is added to the system) and translates information about the construction of the real fault tolerant system and its components into a description usable by the fault tolerance logic engine <b>340</b>. In an exemplary implementation configuration events may be formatted in a manner specific to the component that generates the configuration event. Accordingly, the configuration manager <b>315</b> associates a hardware-specific event with a component class in the component classes table <b>310</b> to translate the configuration event from a hardware-specific code into a code that is compatible with the model developed by system <b>300</b>. The fault tolerance logic engine receives configuration information form the configuration manager <b>315</b> and constructs a model of the real physical system. In an exemplary implementation the real physical system may be implemented as a storage system and the model may depict the system as a graph.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 4</figref> is a graph illustrating a model of an exemplary storage system. Referring to <figref idref="DRAWINGS">FIG. 4</figref>, an exemplary storage system <b>400</b> may comprise a plurality of accessible disks units <b>412</b><i>a</i>-<b>412</b><i>d</i>, each of which is connected to a controller <b>410</b>. Each accessible disk unit <b>412</b><i>a</i>-<b>412</b><i>d </i>may include on or more physical disks <b>420</b><i>a</i>-<b>420</b><i>d</i>. Disk units <b>412</b><i>a</i>-<b>412</b><i>d </i>may be connected to a common backplane <b>414</b> and to a redundant I/O unit <b>416</b>, which may comprise redundant I/O cards <b>418</b><i>a</i>, <b>418</b><i>b</i>. The disks <b>420</b><i>a</i>-<b>420</b><i>d </i>and the redundant I/O cards <b>418</b><i>a</i>, <b>418</b><i>b </i>may be connected to a redundant power unit <b>422</b>, which comprises two field replaceable units (FRUs) <b>424</b><i>a</i>, <b>424</b><i>b</i>. Each FRU comprises a power supply <b>426</b><i>a</i>, <b>426</b><i>b </i>and a fan <b>428</b><i>a</i>, <b>428</b><i>b. </i></p>
<p id="p-0043" num="0042">By way of overview, in one exemplary implementation, the following configuration modification process is implemented using the configuration manager <b>315</b>. First, an object is created for each primitive physical component in the real physical system by informing the fault tolerance logic engine <b>340</b> of the existence of the component, its name, its state and other parametric information that may be interpretable either by the fault tolerance logic engine <b>340</b> or by recipients of outbound events. Each of these objects is likely to represent a field replaceable unit such as a power supply, fan, PC board, or storage device.</p>
<p id="p-0044" num="0043">Second, a dependency group is created for each set of primitive devices that depend on each other for continued operation. A dependency group is a logical association between a group (or groups) of components in which all of the components must be functioning correctly in order for the group to perform its collective function. For example, an array controller with its own non-redundant power supply and fan would represent a dependency group.</p>
<p id="p-0045" num="0044">Third, a redundancy group is created for each set of components or groups that exhibits some degree of fault tolerant behavior. Redundancy parameters of the group may be set to represent the group's behavior within the bounds of a common fault tolerance relationship.</p>
<p id="p-0046" num="0045">Fourth, additional layers of dependency and redundancy groups are created to represent the topology, construction and fault tolerance behavior of the entire system. This may be done by creating groups for whole rack mountable components that comprise a system, followed by additional layers indicating how those components are integrated into the particular system.</p>
<p id="p-0047" num="0046">Fifth track component additions, deletions and other system modifications by destroying groups and creating others. Each time a group is created or destroyed, the state of all other components whose membership has changed as a result of the new configuration is recomputed. This is implemented by querying the states of all of the constituent components in the group after the change and combining them according to the type (dependency vs. redundancy) and parameters of the group. Any internal state changes that result are propagated throughout the system model within the apparatus.</p>
<p id="p-0048" num="0047">These operations are described in greater detail in connection with the following text and the accompanying flowcharts.</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIGS. 5A-5D</figref> are flowcharts illustrating operations in an exemplary configuration process in a fault tolerance system. In an exemplary implementation the configuration process is invoked when a system is powered-up, so that the various components and groups in a system report their existence to the configuration manager <b>315</b>. In addition, the configuration process is invoked when components (or groups) are added to or deleted from the system. The configuration manager processes the configuration events and forwards the configuration information to the fault tolerance logic engine <b>340</b>, which invokes the operations of <figref idref="DRAWINGS">FIGS. 5A-5D</figref> to configure the model in the system relationship and state table <b>325</b> in accordance with the configuration events received by the configuration manager <b>315</b>.</p>
<p id="p-0050" num="0049">The operations of <figref idref="DRAWINGS">FIG. 5A</figref> are triggered when an add component event or a remove component event is received (operation <b>510</b>) by the fault tolerance logic engine <b>340</b>. For example, when a new component is added to the storage system the configuration manager <b>315</b> collects information about the new component and forwards an add component event to the fault tolerance logic engine <b>340</b>. Similarly, when a component is removed, the removal is detected by the configuration manager <b>315</b>, which forwards a remove component event to the fault tolerance logic engine <b>340</b>.</p>
<p id="p-0051" num="0050">Referring to <figref idref="DRAWINGS">FIG. 5A</figref>, at operation <b>512</b> if the event is an add component event, then control passes to operation <b>514</b> and the new component is located in the component classes table <b>310</b>. At operation <b>516</b> the component is added to the model constructed by the fault tolerance logic engine <b>340</b>. In an exemplary implementation the component is assigned a handle, i.e., an identifier by which the component may be referenced in the model. The component is then entered in the system relationship and state table <b>325</b>. At operation <b>518</b> the component class and handle are returned for future reference, and at operation <b>520</b> control returns to the calling routine.</p>
<p id="p-0052" num="0051">By contrast, if at operation <b>512</b> the event is not an add component event (i.e., if the event is a remove component event), then control passes to operation <b>522</b> and the remove node process is executed to remove a component node from the model constructed by the fault tolerance logic engine <b>340</b>. The remove node process is described in detail below with reference to <figref idref="DRAWINGS">FIG. 6</figref>. At operation <b>524</b>, control is returned to the calling routine.</p>
<p id="p-0053" num="0052">The operations of <figref idref="DRAWINGS">FIG. 5B</figref> are triggered when an add group event or a remove group event is received (operation <b>540</b>) by the fault tolerance logic engine <b>340</b>. For example, when a new group of components is added to the storage system the configuration manager <b>315</b> collects information about the new group of components and forwards an add group event to the fault tolerance logic engine <b>340</b>. Similarly, when a group of components is removed, the removal is detected by the configuration manager <b>315</b>, which forwards a remove group event to the fault tolerance logic engine <b>340</b>.</p>
<p id="p-0054" num="0053">Referring to <figref idref="DRAWINGS">FIG. 5B</figref>, at operation <b>542</b> if the event is an add group event, then control passes to operation <b>544</b> and the new group is created within the model constructed by the fault tolerance logic engine <b>340</b>. In an exemplary implementation the group is assigned a handle, i.e., an identifier by which the group may be referenced in the model, at operation <b>546</b>. At operation <b>5480</b> control returns to the calling routine.</p>
<p id="p-0055" num="0054">By contrast, if at operation <b>542</b> the event is not an add group event (i.e., if the event is a remove group event), then control passes to operation <b>552</b> and the remove node process is executed to remove the group from the model constructed by the fault tolerance logic engine <b>340</b>. The remove node process is described in detail below with reference to <figref idref="DRAWINGS">FIG. 6</figref>. At operation <b>554</b> control is returned to the calling routine.</p>
<p id="p-0056" num="0055">The operations of <figref idref="DRAWINGS">FIG. 5C</figref> are triggered when a group member change event is received, at operation <b>560</b>. For example, when a component is added to or deleted from a group of components the configuration manager <b>315</b> collects information about the newly added or removed component and forwards an add member event or a remove member event to the fault tolerance logic engine <b>340</b>. For the purpose of adding or deleting group members, a group of components may be treated as a component. In other words, group members may be single components or groups of components. At operation <b>562</b> the group is updated to reflect the addition or deletion of a member. At operation <b>564</b> a process is invoked to recalculate the state of any dependent nodes. This process is described in detail below with reference to <figref idref="DRAWINGS">FIGS. 7A-7C</figref>. Thus, the graph represented in <figref idref="DRAWINGS">FIG. 4</figref> may be constructed by a repetitive process of discovering components as illustrated in <figref idref="DRAWINGS">FIG. 5A</figref>, creating components as illustrated in <figref idref="DRAWINGS">FIG. 5B</figref>, and adding components as illustrated in <figref idref="DRAWINGS">FIGS. 5C</figref>.</p>
<p id="p-0057" num="0056">The operations of <figref idref="DRAWINGS">FIG. 5D</figref> are triggered when a component state change (e.g., a component failure) or a parameter change (e.g., a change in a failure threshold) event is received, at operation <b>570</b>. For example, if the state of a component changes from active to inactive the configuration manager <b>315</b> collects the state change information and forwards a state change event to the fault tolerance logic engine <b>340</b>. At operation <b>572</b> the state information (or parameter) is modified to reflect the reported change. At operation <b>574</b> a process is invoked to recalculate the state of any dependent nodes. This process is described in detail below with reference to <figref idref="DRAWINGS">FIGS. 7A-7C</figref>.</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart illustrating operations in an exemplary process for deleting a node from a system model. Referring to <figref idref="DRAWINGS">FIG. 6</figref>, at operation <b>610</b> a delete node event is received, e.g., as a result of being invoked by operation <b>522</b>. The process is invoked with a specific node. The delete node process implements a loop, represented by operations <b>612</b>-<b>616</b>, in which the logical association between all nodes dependent on the specific node is dissolved and the state of the dependent group is recalculated. Thus, if at operation <b>616</b> the specific node has one or more dependent nodes, the control passes to operation <b>614</b> and the link between the dependent group and the specific node is dissolved. At operation <b>616</b> the state of each dependent group is recalculated. This process is described in greater detail below with reference to <figref idref="DRAWINGS">FIGS. 7A-7C</figref>.</p>
<p id="p-0059" num="0058">Control then passes back to operation <b>612</b> and operations <b>612</b>-<b>616</b> are repeated until there are no more dependent nodes, whereupon control passes to operation <b>618</b>. If, at operation <b>618</b>, the specific node is a component, then control passes to operation <b>622</b> and the component node data structure is deleted. By contrast, if the specific node is not a component node (i.e., it is a group node) then control passes to operation <b>620</b> and the logical links between the group and its constituent members are dissolved. Control then passes to operation <b>622</b>, and the specific group node data structure is deleted. At operation <b>624</b> control returns to the calling routine.</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIGS. 7A-7C</figref> are flowcharts illustrating operations in an exemplary process for recalculating the state of one or more nodes in a fault tolerance system. The operations of <figref idref="DRAWINGS">FIGS. 7A-7C</figref> are invoked, e.g., at operations <b>564</b> and <b>574</b>. Referring to <figref idref="DRAWINGS">FIG. 7A</figref>, at operation <b>710</b> a node state change event is received. In an exemplary implementation the fault tolerance logic engine <b>340</b> generates a node state change event (e.g., at operations <b>564</b> and <b>574</b>) when the process for recalculating the state of one or more nodes in the fault tolerance system is invoked. The node state change event enumerates a specific node.</p>
<p id="p-0061" num="0060">If, at operation <b>712</b>, the specific node is a component node, then control passes to operation <b>714</b> and the fault tolerance logic engine <b>340</b> generates an event for the event generation registry <b>330</b>. This process is described in detail below, with reference to <figref idref="DRAWINGS">FIG. 8</figref>. Operations <b>716</b>-<b>718</b> represent a recursive invocation of the state change process. If, at operation <b>716</b> the specific nodes has one or more dependent nodes, then at operation <b>718</b> the state of the dependent nodes are recalculated. The operations <b>716</b>-<b>718</b> are repeated until all nodes dependent on the specific node are processed. This may involve processing multiple layers of nodes in a graph such as the graph illustrated in <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0062" num="0061">By contrast, if at operation <b>712</b> the specific node is not a component node (i.e., it is a redundancy node or a dependency node) then control passes to operation <b>722</b> and a node state accumulator is initialized. In an exemplary implementation a node state accumulator may be embodied as a numerical indicator of the number of bad node states in a redundancy node or a dependency node. In an alternate implementation a node state accumulator may be implemented as a Boolean state indicator.</p>
<p id="p-0063" num="0062">If, at operation <b>724</b>, the specific node is a redundancy node, then at operation <b>726</b> control passes to the operations of <figref idref="DRAWINGS">FIG. 7B</figref>. Referring to <figref idref="DRAWINGS">FIG. 7B</figref>, in a loop represented by operations <b>740</b>-<b>744</b> the bad node states in the redundancy group are counted and node state accumulator is updated to reflect the number of bad node states. Thus, if at operation <b>740</b> there are more nodes in the group to process then control passes to operation <b>742</b> and the number of bad node states is counted and at operation <b>744</b> the number of partial failure indications is accumulated in the node state accumulator.</p>
<p id="p-0064" num="0063">When all the members of the redundancy group have been processed, then control passes from operation <b>740</b> to operation <b>746</b> and the number of bad node states is compared to a redundancy level threshold. If the number of bad node states exceeds the redundancy level threshold, then the node state is changed to “failed” at operation <b>750</b>, and control returns to the calling routine at operation <b>754</b>. By contrast, if the number of bad node states remains below the redundancy level threshold, then control passes to operation <b>748</b>. If, at operation <b>748</b> the number of bad node states is zero, then control returns to the calling routine at operation <b>754</b>. By contrast, if the number of bad node states is not zero, then control passes to operation <b>752</b> and the node state is changed to reflect a partial failure.</p>
<p id="p-0065" num="0064">In an exemplary implementation the redundancy level may be implemented as a threshold that represents the maximum number of bad node states allowable in a redundancy node before the state of the redundancy node changes from active to inactive (or failed). The threshold may be set, e.g., by a manufacturer of a device or by a system administrator as part of configuring a system. By way of example, a redundancy group that represents a disk array having eight disks that is configured to implement RAID <b>5</b> storage may be further configured to change its state from active to failed if three or more disks become inactive.</p>
<p id="p-0066" num="0065">Referring back to <figref idref="DRAWINGS">FIG. 7A</figref>, if at operation <b>724</b> the node is not a redundancy node (i.e., if it is a dependency node) then control passes to the operations of <figref idref="DRAWINGS">FIG. 7C</figref>. Referring to <figref idref="DRAWINGS">FIG. 7C</figref>, in a loop represented by operations <b>762</b>-<b>770</b> the bad node states in member nodes of the dependency group are counted (operation <b>764</b>) and node state accumulator is updated (operation <b>766</b>) to reflect the number of bad member node states. If at operation <b>768</b> a member node indicates a failure level (either full or partial failure), then control passes to operation <b>770</b> and the dependency group state is reset to the worst failure state of its constituent members. By way of example, if a dependency group includes several members having a partial failure state and other members having a complete failure state, then the dependency group is assigned a complete failure state. At operation <b>772</b>, control is returned to the calling routine.</p>
<p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart that illustrates operations in an exemplary process for generating a new event. At operation <b>810</b> a generate event call is received, e.g., as a result of operation <b>714</b> when a new node state is being calculated. In response to the event call, the fault tolerance logic engine <b>340</b> invokes a query to the event generation registry table <b>330</b> to determine if one or more components in the event generation registry table <b>330</b> is registered to receive a notice of the event. If, at operation <b>812</b>, there are no more registrants for the node enumerated in the event, then the routine terminates at operation <b>814</b>. By contrast, if at operation <b>812</b> there are more registrants for the node, then control passes to operation <b>816</b>, where it is determined whether the new node state matches criteria specified in a the event generation registry table <b>330</b>. As described above, the event generation registry table <b>330</b> contains entries from devices associated with the system that indicate when the devices want to receive event notices. For example, a device associated with the system may wish to receive an event notice in the event that a disk array fails.</p>
<p id="p-0068" num="0067">If, at operation <b>816</b> the new node state matches criteria specified in the event generation registry table, then control passes to operation <b>818</b> and a new event is generated. At operation <b>820</b> the new node state is added to the new event, and at operation <b>822</b> the new event is reported to the device(s) that are registered to receive the event. In an exemplary implementation the event may be reported by transmitting an event message using conventional electronic message transmitting techniques.</p>
<p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart illustrating operations of the fault tolerance logic engine in response to a fault event. In operation, after the system has configured a model of the fault tolerant system the fault tolerance logic engine <b>340</b> monitors the fault tolerant system for fault events. In an exemplary implementation fault events from the fault tolerant system are received by the fault normalizer <b>335</b>, which consults the component classes table <b>310</b> and the fault symptom catalog table <b>320</b> to convert the fault events into a format acceptable for input to the fault tolerance logic engine.</p>
<p id="p-0070" num="0069">At operation <b>910</b> a fault event is received in the fault normalizer <b>335</b>. At operation <b>912</b> the fault normalizer <b>335</b> determines the system fault description, e.g., by looking up the system fault description in the fault symptom catalog table <b>320</b> based on the received hardware-specific event. At operation <b>914</b> the system fault description (e.g., a node handle for use in the fault tolerance logic engine <b>340</b> and a new node state) is associated with the hardware specific event. At operation <b>916</b> the event is logged, e.g., in a memory location associated with the system. And at operation <b>918</b> the event component state is delivered to the fault tolerance logic engine <b>340</b>, which processes the event.</p>
<p id="p-0071" num="0070">Although the described arrangements and procedures have been described in language specific to structural features and/or methodological operations, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or operations described. Rather, the specific features and operations are disclosed as preferred forms of implementing the claimed present subject matter.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of monitoring a fault tolerant system, comprising:
<claim-text>maintaining an abstract model of the fault tolerant system; monitoring operation of the fault tolerant system;</claim-text>
<claim-text>applying fault events received from the fault tolerant system to the abstract model; and</claim-text>
<claim-text>reporting one or more changes in the abstract model to a component in the fault tolerant system, wherein maintaining an abstract model of the fault tolerant system comprises:
<claim-text>receiving a configuration event indicating the removal of at least one component to the fault tolerant system; and</claim-text>
<claim-text>in response, removing at least one corresponding component from the abstract model; and</claim-text>
</claim-text>
<claim-text>wherein removing at least one corresponding component from the abstract model comprises:
<claim-text>dissolving the logical association between the at least one corresponding component and one or more components dependent on the at least one corresponding component; and</claim-text>
<claim-text>recalculating a state of the one or more components dependent on the at least one corresponding component.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein maintaining an abstract model of the fault tolerant system comprises: receiving a configuration event indicating the addition of at least one component to the fault tolerant system; and in response, adding at least one corresponding component to the abstract model.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising representing redundancy relationships between the at least one corresponding component and one or more other components in the abstract model.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, further comprising representing dependency relationships between the at least one corresponding component and one or more other components in the abstract model.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein removing at least one corresponding component from the abstract model comprises:
<claim-text>dissolving one or more logical associations between the at least one corresponding component and at least one additional component in the abstract model.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein maintaining an abstract model of the fault tolerant system comprises:
<claim-text>receiving a configuration event indicating an addition or a removal of at least one component to a logical group in the fault tolerant system; and</claim-text>
<claim-text>in response, updating the logical group to reflect the addition or removal of the at least one component; and</claim-text>
<claim-text>recalculating a state of a group of components dependent on the at least one component.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein recalculating a state of one or more components dependent on the at least one component comprises propagating a failure state associated with the at least one component to a group of components dependent on the at least one component.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, further comprising:
<claim-text>maintaining a failure indicator that represents one or more failure parameters in the group of components dependent on the at least one component; and</claim-text>
<claim-text>setting a group state parameter to indicate a group failure if the failure indicator exceeds a threshold.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, further comprising:
<claim-text>maintaining a failure indicator that represents one or more failure parameters in the group of components dependent on the at least one component; and</claim-text>
<claim-text>setting a group state parameter to indicate a group failure if any group state parameter indicates a failure.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein applying fault events received from the fault tolerant system to the abstract model comprises: receiving a state change event for one or more components in the fault tolerant system; updating the abstract model to propagate the state change event to a group of components dependent on the at least one component.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein updating the abstract model to propagate the state change event to a group of components dependent on the at least one component comprises:
<claim-text>maintaining a failure indicator that represents one or more failure parameters in the group of components dependent on the at least one component; and</claim-text>
<claim-text>setting a group state parameter to indicate a group failure if the failure indicator exceeds a threshold.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein updating the abstract model to propagate the state change event to a group of components dependent on the at least one component comprises:
<claim-text>maintaining a failure indicator that represents one or more failure parameters in the group of components dependent on the at least one component; and</claim-text>
<claim-text>setting a group state parameter to indicate a group failure if any group state parameter indicates a failure.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein reporting one or more changes in the abstract model to a component in the fault tolerant system comprises searching an event generation registry table for entries corresponding to a specific node in the abstract model.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the means for generating one or more reporting events in response to changes in the availability of a component in the abstract model comprises logic instructions executable on a processor that search an event generation registry table for entries corresponding to a specific node in the abstract model.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. A method of monitoring a fault tolerant system, comprising:
<claim-text>maintaining an abstract model of the fault tolerant system;</claim-text>
<claim-text>monitoring operation of the fault tolerant system; applying fault events received from the fault tolerant system to the abstract model; and</claim-text>
<claim-text>reporting one or more changes in the abstract model to a component in the fault tolerant system, wherein maintaining an abstract model of the fault tolerant system comprises:</claim-text>
<claim-text>receiving a configuration event indicating an addition or a removal of at least one component to a logical group in the fault tolerant system; and</claim-text>
<claim-text>in response, updating the logical group to reflect the addition or removal of the at least one component; and recalculating a state of a group of components dependent on the at least one component, and wherein recalculating a state of one or more components dependent on the at least one component comprises propagating a failure state associated with the at least one component to a group of components dependent on the at least one component;</claim-text>
<claim-text>maintaining a failure indicator that represents one or more failure parameters in the group of components dependent on the at least one component; and</claim-text>
<claim-text>setting a group state parameter to indicate a group failure if the failure indicator exceeds a threshold.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein maintaining an abstract model of the fault tolerant system comprises:
<claim-text>receiving a configuration event indicating the addition of at least one component to the fault tolerant system; and</claim-text>
<claim-text>in response, adding at least one corresponding component to the abstract model.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, further comprising representing redundancy relationships between the at least one corresponding component and one or more other components in the abstract model.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising representing dependency relationships between the at least one corresponding component and one or more other components in the abstract model.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein maintaining an abstract model of the fault tolerant system comprises: receiving a configuration event indicating the removal of at least one component to the fault tolerant system; and in response, removing at least one corresponding component from the abstract model.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein removing at least one corresponding component from the abstract model comprises:
<claim-text>dissolving the logical association between the at least one corresponding component and one or more components dependent on the at least one corresponding component; and</claim-text>
<claim-text>recalculating a state of the one or more components dependent on the at least one corresponding component.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein removing at least one corresponding component from the abstract model comprises:
<claim-text>dissolving one or more logical associations between the at least one corresponding component and at least one additional component in the abstract model.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising:
<claim-text>maintaining a failure indicator that represents one or more failure parameters in the group of components dependent on the at least one component; and</claim-text>
<claim-text>setting a group state parameter to indicate a group failure if any group state parameter indicates a failure.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein applying fault events received from the fault tolerant system to the abstract model comprises:
<claim-text>receiving a state change event for one or more components in the fault tolerant system;</claim-text>
<claim-text>updating the abstract model to propagate the state change event to a group of components dependent on the at least one component.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein updating the abstract model to propagate the state change event to a group of components dependent on the at least one component comprises:
<claim-text>maintaining a failure indicator that represents one or more failure parameters in the group of components dependent on the at least one component; and</claim-text>
<claim-text>setting a group state parameter to indicate a group failure if the failure indicator exceeds a threshold.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein updating the abstract model to propagate the state change event to a group of components dependent on the at least one component comprises:
<claim-text>maintaining a failure indicator that represents one or more failure parameters in the group of components dependent on the at least one component; and</claim-text>
<claim-text>setting a group state parameter to indicate a group failure if any group state parameter indicates a failure.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein reporting one or more changes in the abstract model to a component in the fault tolerant system comprises searching an event generation registry table for entries corresponding to a specific node in the abstract model.</claim-text>
</claim>
</claims>
</us-patent-grant>
