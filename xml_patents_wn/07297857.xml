<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07297857-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07297857</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10640590</doc-number>
<date>20030813</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>127</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>10</class>
<subclass>H</subclass>
<main-group>1</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification> 84600</main-classification>
<further-classification>3405731</further-classification>
</classification-national>
<invention-title id="d0e53">System of processing music performance for personalized management and evaluation of sampled data</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5177311</doc-number>
<kind>A</kind>
<name>Suzuki et al.</name>
<date>19930100</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification> 84600</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6132337</doc-number>
<kind>A</kind>
<name>Krupka et al.</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>482  8</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6662032</doc-number>
<kind>B1</kind>
<name>Gavish et al.</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600323</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6703549</doc-number>
<kind>B1</kind>
<name>Nishimoto et al.</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 84609</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6856249</doc-number>
<kind>B2</kind>
<name>Strubbe et al.</name>
<date>20050200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3405731</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2001/0015123</doc-number>
<kind>A1</kind>
<name>Nishitani et al.</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification> 84615</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2003/0070537</doc-number>
<kind>A1</kind>
<name>Nishitani et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification> 84633</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2004/0020348</doc-number>
<kind>A1</kind>
<name>Ishida et al.</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 84609</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2004/0171460</doc-number>
<kind>A1</kind>
<name>Park</name>
<date>20040900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>482  8</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>GB</country>
<doc-number>2377315</doc-number>
<kind>A</kind>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>JP</country>
<doc-number>09-237088</doc-number>
<date>19970900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>JP</country>
<doc-number>2001-067572</doc-number>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>JP</country>
<doc-number>2001-340319</doc-number>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>19</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification> 84600</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84601</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84609</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification> 84615</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>482  8</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3405731</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>11</number-of-drawing-sheets>
<number-of-figures>12</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20040055443</doc-number>
<kind>A1</kind>
<date>20040325</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Nishitani</last-name>
<first-name>Yoshiki</first-name>
<address>
<city>Hamakita</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Ishida</last-name>
<first-name>Kenji</first-name>
<address>
<city>Hamamatsu</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Kobayashi</last-name>
<first-name>Eiko</first-name>
<address>
<city>Hamakita</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Harness, Dickey &amp; Pierce, PLC</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Yamaha Corporation</orgname>
<role>03</role>
<address>
<city>Shizuoka-Ken</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Donovan</last-name>
<first-name>Lincoln</first-name>
<department>2837</department>
</primary-examiner>
<assistant-examiner>
<last-name>Qin</last-name>
<first-name>Jianchun</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A performance processing apparatus is operable by user with aide of control and sound devices for providing sample music data to data management apparatus. A storage section stores original music data representing a music piece composed of tones. An acquisition section acquires input information from control device which has a detector for detecting either physical action or physiological state of user and operated by user to provide input information indicating detection result by detector. A processing section controls a performance parameter according to input information for enabling sound device to generate tones of the music piece represented by original music data and altered by user. A transmitting section transmits sample music data representing music piece composed of tones controlled by the performance parameter to the data management apparatus which has a storage device for storing sample music data for use as a material of evaluating mental or physical function of user.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="114.30mm" wi="120.73mm" file="US07297857-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="196.51mm" wi="135.89mm" file="US07297857-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="95.76mm" wi="130.73mm" file="US07297857-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="165.86mm" wi="130.56mm" orientation="landscape" file="US07297857-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="137.75mm" wi="100.41mm" orientation="landscape" file="US07297857-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="133.18mm" wi="126.32mm" file="US07297857-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="140.04mm" wi="127.08mm" orientation="landscape" file="US07297857-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="169.42mm" wi="135.13mm" orientation="landscape" file="US07297857-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="193.55mm" wi="130.22mm" file="US07297857-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="199.39mm" wi="141.39mm" orientation="landscape" file="US07297857-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="164.68mm" wi="128.19mm" orientation="landscape" file="US07297857-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="93.47mm" wi="138.77mm" file="US07297857-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">1. Industrial Field of Utilization</p>
<p id="p-0003" num="0002">The present invention relates generally to a technology for controlling tones sounded from a sound output device such as a loudspeaker in accordance with operations by a user or physiological conditions of a user.</p>
<p id="p-0004" num="0003">2. Prior Art</p>
<p id="p-0005" num="0004">Music therapy has been attracting attention in wide-ranging medical care fields such as the rehabilitation for maintaining and recovering mental and physical functions, the treatment of diseases, the prevention of dementia, and the caring of handicapped children. In music therapy, methods are employed in which music is used to mitigate the anxiety and pain of patients and the behavior in music performance by patients is observed by experts called music therapists to evaluate (or diagnose) patient's mental and physical functions.</p>
<p id="p-0006" num="0005">However, in music therapy, the mental and physical functions of patients are evaluated in accordance with the results of observation of the patient's behavior in music performance. In contrast to the conventional medical approaches based on the evaluation of patient's mental and physical functions by use of quantitative data such as heart rate and blood pressure, the music therapy is difficult to objectively grasp patient's mental and physical functions.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0007" num="0006">It is therefore an object of the present invention to collect the quantitative data to be provided for the evaluation of user's mental and physical functions and TO use the collected data for the evaluation of user's mental and physical functions.</p>
<p id="p-0008" num="0007">In carrying out the invention and according to one aspect thereof, there is provided a performance processing apparatus operable by a user with an aide of a control device and a sound device for providing sample music data to a data management apparatus. The inventive performance processing apparatus comprises a first storage section that stores original music data representing a music piece composed of tones, an acquisition section that acquires input information from the control device which has a detector for detecting either of physical action or physiological state of the user and which is operated by the user to provide the input information indicating the detection result by the detector, a processing section that controls a performance parameter according to the input information for enabling the sound device to generate tones of the music piece which is represented by the original music data and which is altered by the user, and a transmitting section that transmits sample music data representing the music piece composed of the tones controlled by the performance parameter to the data management apparatus which has a second storage section for storing the sample music data for use as a material of evaluating mental or physical function of the user.</p>
<p id="p-0009" num="0008">According to this novel configuration, the sample music data with the performance parameters of the original music data controlled in accordance with user's action or physiological condition are generated, so that the sample music data may be used as the quantitative data for evaluating user's mental and physical functions.</p>
<p id="p-0010" num="0009">In another aspect of the invention, the above-mentioned data management apparatus is provided for managing data including original music data and sample music data in association with a performance processing apparatus having a sound device and being operated by a user. The inventive data management apparatus comprises a receiving section that receives the sample music data from the performance processing apparatus, which controls a performance parameter according to input information representing physical action or physiological state of the user for enabling the sound device to generate tones of a music piece which is represented by the original music data and which is altered by the user, and which transmits the sample music data representing the music piece composed of the tones controlled by the performance parameter, and a storage section that stores the received sample music data for use as a material of evaluating mental or physical function of the user.</p>
<p id="p-0011" num="0010">According to this data management apparatus, the sample music data with user's action or physiological condition reflected are held in its storage section, so that use of these sample music data may realize the objective evaluation of user's mental and physical functions.</p>
<p id="p-0012" num="0011">In the above-mentioned data management apparatus, the sample music data stored in the storage section may be transmitted to the evaluation apparatus which is separate from the data management apparatus. Otherwise, the data management apparatus may have a providing section for providing the sample music data to the evaluator who evaluates user's mental and physical functions on the basis of the performance parameters of the sample music data. Namely, the data management apparatus associated with the former has a sample music data transmitting section for transmitting the sample music data stored in the above-mentioned sample music data storage section to the evaluation apparatus for evaluating the mental and physical functions of the user of the above-mentioned performance processing apparatus on the basis of the performance parameters of the sample music data. On the other hand, the data management apparatus associated with the latter has a data providing section for providing the data to the evaluator who evaluates the mental and physical functions of the user of the above-mentioned performance processing apparatus on the basis of the performance parameters of the sample music data. In each configuration, in order to realize a more objective and reliable evaluation, it is desirable to arrange a configuration in which not only the sample music data but also the original music data common in music with the sample music data, thereby providing these two data for the evaluation of user's mental and physical functions on the basis of the comparison between the performance parameters of the sample music data and those of the original music data.</p>
<p id="p-0013" num="0012">In carrying out the invention and according to still another aspect thereof, there is provided an evaluation apparatus in association with the data management apparatus for evaluating sample music data from the performance processing apparatus having a sound device and being operated by a user. The inventive evaluation apparatus comprises a receiving section that receives the sample music data via the data management apparatus from the performance processing apparatus, which controls a performance parameter according to input information representing physical action or physiological state of the user for enabling the sound device to generate tones of a music piece which is represented by original music data and which is altered by the user, and which transmits the sample music data representing the music piece composed of the tones controlled by the performance parameter, a storage section that stores the sample music data received by the receiving section, and a providing section that provides the sample music data to an evaluator who evaluates a mental or physical function of the user according to the performance parameter contained in the provided sample music data.</p>
<p id="p-0014" num="0013">According to this evaluation apparatus, the evaluator may objectively evaluate user's mental and physical functions on the basis of the performance parameters of the sample music data supplied from the data providing section. It should be noted that, in order to realize a more objective and reliable evaluation, it is desirable to provide, in addition to the sample music data, the original music data to the evaluator who evaluate user's mental and physical functions on the basis of the comparison between the performance parameters of the sample music data and those of the original music data.</p>
<p id="p-0015" num="0014">It should be noted that the present invention may also be identified as a data management system comprising the above-mentioned performance processing apparatus, data management apparatus, and evaluation apparatus. In this data management system, the data management apparatus and the evaluation apparatus may be arranged in one unit or separate units. In addition, the present invention may be identified as a software program for making a computer function as the above-mentioned performance processing apparatus, data management apparatus, or evaluation apparatus. This software program may be installed in the computer via a network or from a computer-readable recording medium.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram illustrating a configuration of a communication system practiced as one embodiment of the invention.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 2</figref> is a perspective view illustrating the external view of a control.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram illustrating an internal configuration of the above-mentioned control.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram illustrating a configuration of a performance processing apparatus.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 5</figref> is a diagram illustrating a configuration of music data.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 6</figref> is a block diagram illustrating a configuration of a data management apparatus.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 7</figref> is a diagram illustrating the contents of a performance contents table.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 8</figref> is a block diagram illustrating a configuration of an evaluation apparatus.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 9</figref> is a sequence chart illustrating operations of the above-mentioned embodiment.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 10</figref> is a block diagram schematically illustrating the contents of performance processing.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 11</figref> is a diagram illustrating the contents of a mental and physical function evaluation screen.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 12</figref> is another diagram illustrating other contents of the mental and physical function evaluation screen.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0028" num="0027">This invention will be described in further detail by way of example with reference to the accompanying drawings.</p>
<p id="h-0005" num="0000">&lt;A: Configuration of Embodiment&gt;</p>
<p id="p-0029" num="0028">First, an entire configuration of a communication system practiced as one embodiment of the invention will be described with reference to <figref idref="DRAWINGS">FIG. 1</figref>. As shown in the figure, this communication system comprises a communication network <b>10</b> including the Internet, a public telephone network, and so on, a performance processing system <b>20</b>, a data management apparatus <b>30</b>, and an evaluation apparatus <b>40</b>. The data management apparatus <b>30</b>, the evaluation apparatus <b>40</b>, and a performance processing apparatus <b>23</b> of the performance processing system <b>20</b> are connected to the communication network <b>10</b>. It should be noted that <figref idref="DRAWINGS">FIG. 1</figref> illustrates a configuration in which the performance processing apparatus <b>23</b> (the performance processing system <b>20</b>), the data management apparatus <b>30</b>, and the evaluation apparatus <b>40</b> are arranged each in a single unit; it will be apparent that each of the these apparatuses may be arranged in two or more units.</p>
<p id="p-0030" num="0029">The performance processing system <b>20</b> is installed at facilities (for example, rehabilitation facilities and nursing homes) for those having mental or physical troubles and patients suffering from various diseases (these people will hereafter be referred to as “users”). This performance processing system <b>20</b>, while controlling the performance parameters (tempo, volume, and so on) of a tone sounded from a loudspeaker on the basis of music data in accordance with the action of the user, generates new music data (namely, the music data of tones actually sounded from the loudspeaker) with the performance parameters changed in accordance with this action of the user. In what follows, the music data on which the sound output by the performance processing system <b>20</b> is based may be referred to as “original tone data” to distinguish from the new music data to be referred to as “sample music data” generated on the basis of this sound output. Obviously, if these two kinds of tone data need not be distinguished from each other, they will be generically referred to as “tone data.” As described above, the sample music data are obtained by reflecting the action of the user. Therefore, in the present embodiment, the sample music data generated by the performance processing system <b>20</b> are put in use as the data for evaluating the mental and physical functions of the user.</p>
<p id="p-0031" num="0030">As shown in <figref idref="DRAWINGS">FIG. 1</figref>, the performance processing system <b>20</b> comprises a plurality of controls <b>21</b>, the performance processing apparatus <b>23</b>, a sound system <b>251</b>, and a loudspeaker <b>252</b>. The sound system <b>251</b> and the loudspeaker <b>252</b> output tones under the control of the performance processing apparatus <b>23</b>. To be more specific, the sound system <b>251</b> receives the digital data (hereafter referred to as tone waveform data) indicative of the waveform of tones from the performance processing apparatus <b>23</b>, converts the received tone waveform data into an analog signal, amplifies this analog signal, and outputs the amplified analog signal. The loudspeaker <b>252</b> outputs, as music tones, the analog signal received from the sound system <b>251</b>. Instead of the loudspeaker <b>252</b>, an earphone or a headphone may be used.</p>
<p id="p-0032" num="0031">Each of the plurality of controls <b>21</b> is carried or worn by the user to detect the action of the user and transmits the information indicative of the detection results (hereafter referred to as “action information”) to the performance processing apparatus <b>23</b>. As shown in <figref idref="DRAWINGS">FIG. 2</figref>, the control <b>21</b> associated with the invention is a long, generally cylindrical member which is gripped by the user. To be more specific, the control <b>21</b> is tapered from its each end toward a position in the proximity of the center along its length so that this position is smaller in diameter than each end. Gripping the control <b>21</b> on the position in the proximity of the center of the control <b>21</b>, the user swings or shakes the control <b>21</b> as desired. In what follows, with the user, standing perpendicular to the horizontal plane, gripping the control <b>21</b>, its length being toward the user, the horizontal direction relative to the user is expressed as “x-axis direction,” the vertical (up and down) direction relative the user is expressed as “y-axis direction,” and the forward and backward direction relative to the user is expressed as “z-axis direction.”</p>
<p id="p-0033" num="0032">Referring to <figref idref="DRAWINGS">FIG. 3</figref>, there is shown a block diagram illustrating an internal configuration of the control <b>21</b>. As shown, the control <b>21</b> comprises a CPU (Central Processing Unit) <b>211</b>, a ROM (Read Only Memory) <b>212</b>, a sensor <b>213</b>, and a transmitter <b>214</b>. The CPU <b>211</b> controls the entire operation of the control <b>21</b> by executing programs stored in the ROM <b>212</b>. The ROM <b>212</b> stores the programs to be executed by the CPU <b>211</b> and the identification information allocated uniquely to the control <b>21</b>.</p>
<p id="p-0034" num="0033">The sensor <b>213</b> outputs to the CPU <b>211</b> an electrical signal corresponding to an action of the user, in other words, an electrical signal corresponding to a motion of the control <b>21</b> accompanying an operation of the user. The sensor <b>213</b> may be any of detection devices such as two-dimensional velocity sensor, two-dimensional acceleration sensor, three-dimensional velocity sensor, three-dimensional acceleration sensor, and strain detector. In the present embodiment, a three-dimensional acceleration sensor for detecting the accelerations in the x-axis, y-axis, and z-axis directions is assumed as the sensor <b>213</b>. The CPU <b>211</b> generates action information on the basis of the electrical signals supplied from the sensor <b>213</b>. This action information includes acceleration αx in the x-axis direction, acceleration αy in the y-axis direction, and acceleration α z in the z-axis direction (refer to <figref idref="DRAWINGS">FIG. 10</figref>).</p>
<p id="p-0035" num="0034">On the other hand, the transmitter <b>214</b> executes communication with the performance processing apparatus <b>23</b>. To be more specific, the transmitter <b>214</b> transmits the action information generated by the CPU <b>211</b> to the performance processing apparatus <b>23</b> along with the identification information of the control <b>21</b>. For the communication between the transmitter <b>214</b> and the performance processing apparatus <b>23</b>, the infrared communication based on IrDA or the wireless communication based on Bluetooth (trademark) may be used. However, the communication between the transmitter <b>214</b> and the performance processing apparatus <b>23</b> is not limited to the above-mentioned communication schemes; for example, a communication cable may be connected between the transmitter <b>214</b> and the performance processing apparatus <b>23</b> for wired communication.</p>
<p id="p-0036" num="0035">The performance processing apparatus <b>23</b> shown in <figref idref="DRAWINGS">FIG. 1</figref> is a computer system which controls the performance parameters in accordance with an action of the user and outputs the resultant tones indicated by the original music data from the loudspeaker <b>252</b> while generating the sample music data indicative of the music based on the tones with the performance parameters controlled and altered. As shown in <figref idref="DRAWINGS">FIG. 4</figref>, the performance processing apparatus <b>23</b> comprises a CPU (Central Processing Unit) <b>231</b>, a RAM (Random Access Memory) <b>232</b>, a storage unit <b>233</b>, an input unit <b>234</b>, a communication unit <b>235</b>, a receiver <b>236</b>, a tone generator circuit <b>237</b>, and an effector circuit <b>238</b>. These components are interconnected via a bus <b>239</b>.</p>
<p id="p-0037" num="0036">The CPU <b>231</b> controls the entire operation of the performance processing apparatus <b>23</b> by executing the programs stored in the storage unit <b>233</b> and a ROM (Read Only Memory) not shown. The RAM <b>232</b> is used by the CPU <b>231</b> as its main storage. Namely, the RAM <b>232</b> temporarily stores the programs to be executed by the CPU <b>231</b> and the data for use in the execution of these programs. The storage unit <b>233</b> is a hard disk drive for example, which stores the programs to be executed by the CPU <b>231</b>, for example. These programs include a performance processing program for controlling the performance parameters of music in accordance with the action information inputted from the control <b>21</b>.</p>
<p id="p-0038" num="0037">The storage unit <b>233</b> also stores the original music data and the sample music data generated on the basis of the original music data. In the present embodiment, the original music data and the sample music data are both of SMF (Standard MINI File) format based on MIDI (Musical Instrument Digital Interface). Referring to <figref idref="DRAWINGS">FIG. 5</figref>, there is schematically shown a data structure of music data (the original music data and the sample music data). The music data of one piece of music include two or more pieces of data (hereafter referred to as part data) corresponding to different parts. Each piece of part data is a data sequence made up of many sequentially arranged pairs of delta time (Δ t) and events. The delta time is data indicative of a time interval between two events outputted contiguously in time to the tone generator circuit <b>237</b>.</p>
<p id="p-0039" num="0038">The events in the part data specify, for the tone generator circuit <b>237</b>, the tone of that part and the generation or mute of this tone and are largely divided into MIDI events for specifying the contents of performance such as note-on and note-off and the meta events for specifying tempo and so on. The MIDI events include a note-on event including the specifications of a note number to be sounded and velocity, a note-off event including the specification of a tone to be noted off, a program change event including the specification of timbre, a control change event including the specification of an effect to be imparted to a tone, and a pitch bend event including the specification of a pitch variable. The meta events include the specification of music tempo and so on.</p>
<p id="p-0040" num="0039">The input unit <b>234</b> shown in <figref idref="DRAWINGS">FIG. 4</figref> has a plurality of operator keys through which the user enters various operations and supplies the electrical signals representative of these operations to the CPU <b>231</b>. The communication unit <b>235</b> exchanges information with the data management apparatus <b>30</b> via the communication network <b>10</b>. To be more specific, the communication unit <b>235</b> receives the original music data from the data management apparatus <b>30</b> and outputs the received data to the CPU <b>231</b>, at the same time receiving from the CPU <b>231</b> the sample music data generated in accompaniment with the performance processing using the original music data to transmit the received sample music data to the data management apparatus <b>30</b>. The receiver <b>236</b> carries out communication with the controls <b>21</b>. Namely, the receiver <b>236</b> receives action information from one or more of the controls <b>21</b> and outputs the received information to the CPU <b>231</b>.</p>
<p id="p-0041" num="0040">The tone generator circuit <b>237</b> and the effector circuit <b>238</b> are means for generating tone waveform data under the control of the CPU <b>231</b>, each being constituted by a DSP (Digital Signal Processor). The tone generator circuit <b>237</b>, upon reception of an event from the CPU <b>231</b>, generates tone waveform data indicative of a tone waveform corresponding to the received event. The tone generator circuit <b>237</b> has a plurality of channels corresponding to different parts. In each of the channels, the event of part data corresponds to that channel. In this configuration, the tone waveform data of a plurality of parts are outputted in parallel from the tone generator circuit <b>237</b>.</p>
<p id="p-0042" num="0041">The effector circuit <b>238</b> imparts various musical effects to the tone waveform data of different parts outputted from the tone generator circuit <b>237</b>. The contents and degrees of the effects to be imparted by the effector circuit <b>238</b> are determined by the CPU <b>231</b> with reference to the action information received from the controls <b>21</b> corresponding to the parts. The effects to be imparted to tones include reverberation, echo, and others.</p>
<p id="p-0043" num="0042">The data management apparatus <b>30</b> shown in <figref idref="DRAWINGS">FIG. 1</figref> is a computer system for managing the original music data of the music to be performed in the performance processing system <b>20</b> and for managing the sample music data created by the performance processing apparatus <b>23</b>. As shown in <figref idref="DRAWINGS">FIG. 6</figref>, the data management apparatus <b>30</b> comprises a CPU (Central Processing Unit) <b>301</b>, a communication unit <b>302</b> connected to the CPU <b>301</b> via a bus <b>310</b>, and a storage unit <b>303</b>. The CPU <b>301</b> controls the components of the data management apparatus <b>30</b> by executing programs stored in the storage unit <b>303</b>. On the other hand, the communication unit <b>302</b> carries out communication with the performance processing apparatus <b>23</b> and the evaluation apparatus <b>40</b> via the communication network <b>10</b>.</p>
<p id="p-0044" num="0043">The storage unit <b>303</b> stores original music data, sample music data, and a performance contents table, in addition to the data management program to be executed by the CPU <b>301</b>. The sample music data stored in the storage unit <b>303</b> were created in the past by the performance processing apparatus <b>23</b> on the basis of the action of the user. Therefore, for each piece of music indicated by the original music data, two or more pieces of sample music data created in the past can be stored in the storage unit <b>303</b>. It should be noted that the configurations of the original music data and the sample music data are as described with reference to <figref idref="DRAWINGS">FIG. 5</figref>. The performance contents table is indicative of the contents of performance processing conducted in the performance processing system <b>20</b>. To be more specific, as shown in <figref idref="DRAWINGS">FIG. 7</figref>, the performance contents table has a plurality of records. Each of these records includes, as fields, the names of groups performed by use of the performance processing system <b>20</b>, one or more user names belonging to that group, and one or more part names allocated to the controls <b>21</b> owned by each user.</p>
<p id="p-0045" num="0044">The evaluation apparatus <b>40</b> shown in <figref idref="DRAWINGS">FIG. 1</figref>, is a computer system installed at facilities (such as medical facilities or a nursing home) in which such experts associated with the evaluation and analysis of mental and physical functions as music therapists reside. The evaluation apparatus <b>40</b> is used for evaluating the mental and physical functions of the user. In what follows, the person (for example, a music therapist) who evaluates the user's mental and physical functions by use of the evaluation apparatus <b>40</b> is referred to simply as “evaluator.”</p>
<p id="p-0046" num="0045">As shown in <figref idref="DRAWINGS">FIG. 8</figref>, the evaluation apparatus <b>40</b> comprises a CPU (Central Processing Unit) <b>401</b>, a RAM (Random Access Memory) <b>402</b>, a storage unit <b>403</b>, an input unit <b>404</b>, a communication unit <b>405</b>, a display unit <b>406</b>, a tone generator circuit <b>407</b>, an effector circuit <b>408</b>, a sound system <b>409</b>, and a loudspeaker <b>410</b>. It should be noted that the CPU <b>401</b>, the RAM <b>402</b>, the storage unit <b>403</b>, the communication unit <b>404</b>, the tone generator circuit <b>405</b>, the effector circuit <b>408</b>, the sound system <b>409</b>, and the loudspeaker <b>410</b> are the same in function as those shown in <figref idref="DRAWINGS">FIG. 4</figref>. Therefore, the descriptions of these components will be skipped herein. However, it should be noted that the storage unit <b>403</b> stores the evaluation program to be executed by the CPU <b>401</b>. This evaluation program provides the evaluator with the performance parameters of the sample music data and the parameters of the original music data as the data for evaluating user's mental and physical functions.</p>
<p id="p-0047" num="0046">The display unit <b>406</b> comprises a CRT (Cathode Ray Tube) and a liquid crystal display panel for example, and displays various images under the control of the CPU <b>401</b>. To be more specific, the display unit <b>406</b> displays in graph the change in performance parameters from the start of a music performance to its end based on the sample music data created for a particular piece of music and the original music data of that piece of music. Visually checking this change, the evaluator executes comparison between the change in the performance parameters of the sample music data and the change in performance parameters of the original music data, thereby evaluating user's mental and physical functions.</p>
<p id="h-0006" num="0000">&lt;B: Operation of Embodiment&gt;</p>
<p id="p-0048" num="0047">The following describes the operation of the present embodiment with reference to <figref idref="DRAWINGS">FIG. 9</figref>. In what follows, the operation will be described on focus of the transfer of data between the performance processing apparatus <b>23</b> and the data management apparatus <b>30</b> and the operation on focus of the transfer of data between the data management apparatus <b>30</b> and the evaluation apparatus <b>40</b>. It should be noted that, in a configuration with a plurality of the performance processing apparatuses <b>23</b> and a plurality of the evaluation apparatuses <b>40</b> arranged, the data management apparatus <b>30</b> executes the following operation between each performance processing apparatus <b>23</b> and each evaluation apparatus <b>40</b>.</p>
<p id="h-0007" num="0000">&lt;B-1: Operation Between the Performance Processing Apparatus <b>23</b> and the Data Management Apparatus <b>30</b>&gt;</p>
<p id="p-0049" num="0048">First, when the user executes a predetermined operation through the input unit <b>234</b>, the performance processing apparatus <b>23</b> is connected to the data management apparatus <b>30</b> via the communication network <b>10</b>. When the user executes a predetermined operation through the input unit <b>234</b> in this state to select a desired piece of music, the CPU <b>231</b> of the performance processing apparatus <b>23</b> transmits an original music data request to the data management apparatus <b>30</b> (step S<b>10</b>). This original music data request, a command for requesting the data management apparatus <b>30</b> for the original music data, includes the specification of the piece of music selected by the user.</p>
<p id="p-0050" num="0049">Receiving the original music data request, the CPU <b>301</b> of the data management apparatus <b>30</b> reads the original music data of the music specified in this request from the storage unit <b>303</b> and transmits the retrieved original music data to the performance processing apparatus <b>23</b> (step S<b>11</b>). The CPU <b>231</b> of the performance processing apparatus <b>23</b> stores the received original music data into the storage unit <b>233</b>.</p>
<p id="p-0051" num="0050">Then, when the user executes a predetermined operation through the input unit <b>234</b> to command the start of performing music, the CPU <b>231</b> loads the performance processing programs from the storage unit <b>233</b> into the RAM <b>232</b> and sequentially executes these programs (step S<b>12</b>). When the programs are executed, the performance processing based on the original music data specified by the user is executed. On the other hand, a plurality of users having their different controls <b>21</b> turn on the power to the controls <b>21</b> and then swing or shake the controls <b>21</b> as desired along with the performance presented by the performance processing apparatus <b>23</b>.</p>
<p id="p-0052" num="0051">Referring to <figref idref="DRAWINGS">FIG. 10</figref>, there is shown a schematic diagram illustrating the contents of the performance processing (step S<b>12</b>) by the CPU <b>231</b>. The CPU <b>231</b> executes each processing shown in the figure for one or more parts allocated to each control <b>21</b>. Namely, the CPU <b>231</b> identifies the control <b>21</b> from which the action information concerned has been received on the basis of the identification information received from the control <b>21</b> along with the action information, and executes the processing shown in the figure for the one or more parts allocated to that control <b>21</b>. In what follows, one or more part data, among all the part data constituting the original music data, are sometimes expressed especially as “target part data.”</p>
<p id="p-0053" num="0052">First, receiving the action information indicative of the accelerations (αx, αy, and αz) of a particular control <b>21</b>, the CPU <b>231</b> analyzes the contents of the action done by the user of this control <b>21</b> on the basis of the action information (S<b>121</b>). To be more specific, the CPU <b>231</b> first obtains the absolute value |α| of the accelerations applied to the control <b>21</b>. And, for example, if x-axis acceleration αx and y-axis acceleration αy are greater than z-axis acceleration αz and x-axis acceleration αx is greater than y-axis acceleration αy, then the CPU <b>231</b> determines that the user is executing “vertical cutting action” in which the user is shaking the control <b>21</b> in generally the perpendicular direction; if y-axis acceleration αy is greater than x-axis acceleration αx, then the CPU <b>231</b> determines that the user is executing “horizontal cutting action” in which the user shaking the control <b>21</b> in generally the horizontal direction; and if z-axis acceleration αz is greater than x-axis acceleration αx and y-axis acceleration αy, then the CPU <b>231</b> determines that the user is executing “pushing action” in which the user is pushing the control <b>21</b> forward and backward.</p>
<p id="p-0054" num="0053">Next, on the basis of the analysis result in step S<b>121</b>, the CPU <b>231</b> changes the performance parameters for the target part data read from the storage unit <b>233</b> (step S<b>122</b>). Further, the CPU <b>231</b> tells the tone with the performance parameter changed to the tone generator circuit <b>237</b> or the effector circuit <b>238</b> (step S<b>123</b>) and stores the part data indicative of the music after parameter change into the storage unit <b>233</b> as one portion of the sample music data (step S<b>124</b>). The following describes the performance parameter change processing in step S<b>122</b> by use of a specific example.</p>
<p id="p-0055" num="0054">First, in accordance with the absolute value |α| of the acceleration obtained in step S<b>121</b>, the CPU <b>231</b> changes the velocity (namely, the volume of this part) of the event included in the note-on event of the target part data. For example, as the absolute value |α| of the acceleration increases, the CPU <b>231</b> increases the velocity and, as the absolute value |α| of the acceleration decrease, the CPU <b>231</b> decreases the velocity. If the CPU <b>231</b> determines that the user is executing “horizontal cutting action” with the control <b>21</b>, the CPU <b>231</b> changes the delta time (namely, the tempo of this part) of the target part data in accordance with the period of this action. For example, as the period of “horizontal cutting action” increases, the CPU <b>231</b> increases the delta time in order to lower the tempo and, as the period decreases, the CPU <b>231</b> decreases the delta time in order to quicken the tempo. If the CPU <b>231</b> determines that the user is executing “vertical cutting action” with the control <b>21</b>, the CPU <b>231</b> changes the note number (namely, the pitch of the part) of the note-on event included in the target part data in accordance with the period of this action. For example, as the period of “vertical cutting action” increases, the CPU <b>231</b> changes the note number to a greater one (a higher pitch) and, as this period decreases, the CPU <b>231</b> changes the note number to a smaller one.</p>
<p id="p-0056" num="0055">As a result of the execution of the processing shown in <figref idref="DRAWINGS">FIG. 10</figref> for all parts constituting the music piece, a tone represented in accordance with the performance parameter of the original music data and changed in accordance with action of the user is outputted from the loudspeaker <b>252</b>. At the same time, the sample music data made up of the part data with the performance parameters of the original music data changed in accordance with the user's action are created and stored in the storage unit <b>233</b>. Subsequently, the user of the performance processing apparatus <b>23</b> operates the input unit <b>234</b> to enter the names of the users having these controls <b>21</b> and the name of the group to which these users belong. The data indicative of these items (hereafter referred to as “user data”) are stored in the storage unit <b>233</b> as related with the sample music data.</p>
<p id="p-0057" num="0056">On the other hand, triggered by the predetermined operation done by the user through the input unit <b>234</b>, the CPU <b>231</b> of the performance processing apparatus <b>23</b> transmits the sample music data and the user data related thereto from the storage unit <b>233</b> to the data management apparatus <b>30</b> (step S<b>13</b> in <figref idref="DRAWINGS">FIG. 9</figref>). Receiving these data, the CPU <b>301</b> of the data management apparatus <b>30</b> stores the sample music data into the storage unit <b>303</b> and updates or newly creates records of the performance contents table on the basis of the user data (step S<b>14</b>).</p>
<p id="h-0008" num="0000">&lt;B-2: Operation Between the Data Management Apparatus <b>30</b> and the Evaluation Apparatus <b>40</b>&gt;</p>
<p id="p-0058" num="0057">The following describes the operation with attention paid to the data transfer between the data management apparatus <b>30</b> and the evaluation apparatus <b>40</b>.</p>
<p id="p-0059" num="0058">First, when the user executes a predetermined operation through the input unit <b>404</b>, the evaluation apparatus <b>40</b> is connected to the data management apparatus <b>30</b>. When the user selects a target of evaluation in this state, the CPU <b>401</b> of the evaluation apparatus <b>40</b> transmits a sample music data request to the data management apparatus <b>30</b> (step S<b>20</b>). This sample music data request, a command for requesting the data management apparatus <b>30</b> for the sample music data, includes the user specification selected by the evaluator.</p>
<p id="p-0060" num="0059">Receiving the sample music data request, the CPU <b>301</b> of the data management apparatus <b>30</b> references the performance contents table stored in the storage unit <b>303</b> to identify one or more sample music data generated by the group to which the user specified in this request belongs. Then, the CPU <b>301</b> reads the identified sample music data along with the original music data common in music piece from the storage unit <b>303</b>, and transmits these data to the evaluation apparatus <b>40</b> (step S<b>21</b>). These sample music data and the original music data are received by the CPU <b>401</b> of the evaluation apparatus <b>40</b> and stored in the storage unit <b>403</b>.</p>
<p id="p-0061" num="0060">Then, on the basis of the sample music data and the original music data stored in the storage unit <b>403</b>, the CPU <b>401</b> of the evaluation apparatus <b>40</b> executes processing for providing the evaluator with the data for evaluating the action-associated functions of the user (step S<b>22</b>). To be more specific, the CPU <b>401</b> displays the change in the performance parameters from the start to the end of music performance based on the sample music data and the original music data onto the display unit <b>406</b> in a graphic manner or outputs the tones based on the sample music data from the loudspeaker <b>410</b>.</p>
<p id="h-0009" num="0000">(1) Graphic Representation of Performance Parameters</p>
<p id="p-0062" num="0061">When the evaluator executes a predetermined operation through the input unit <b>404</b> to command the graphic representation of the performance parameters, the CPU <b>401</b> displays a mental and physical function evaluation screen shown in <figref idref="DRAWINGS">FIG. 11</figref> onto the display unit <b>406</b>. This screen is provided for each of the users in a group who executed performance by use of the performance processing apparatus <b>23</b>. <figref idref="DRAWINGS">FIG. 11</figref> illustrates a mental and physical function evaluation screen prepared for “User Ua1” belonging to “Group Ga”. In this example, it is assumed that only one piece of sample music data is obtained for the user to be evaluated, namely the user's performance made by use of the performance processing apparatus <b>23</b> was executed only once in the past.</p>
<p id="p-0063" num="0062">This mental and physical function evaluation screen includes graphs indicative of the performance parameters (tempo, volume, and pitch in this example) associated with a part performed by the user, among the sample music data and the original music data. To be more specific, in the graphs indicative of tempo, volume, and pitch, the changes in the tempo, volume, and pitch of the original music data are represented each with a dashed line, while the changes in the tempo, volume, and pitch of the sample music data are represented each with a solid line.</p>
<p id="p-0064" num="0063">Referencing this graph representation, the evaluator evaluates the mental and physical functions of the user. For example, the tempo graph shown in <figref idref="DRAWINGS">FIG. 11</figref> shows that, while there is found an approximate match between the tempo of the original music data and the tempo of the sample music data immediately after the start of the performance of music, the difference therebetween increases as the performance of music progresses. As described above, the tempo of the sample music data is determined in accordance with the period of “horizontal cutting action,” so that the evaluator may evaluate that the user (User Ua1) in this graph representation is not enough in the recovery of the horizontal movement function and endurance. Conversely, if there is found an approximate match between the tempo of the original music data and the tempo of the sample music data all over a time from the start to the end of the performance of music, the evaluator may evaluate that the user is fully recovered in the horizontal movement function and endurance. As for the volume determined in accordance with the absolute value of acceleration |α| and the pitch determined in accordance with “vertical cutting action,” the evaluator may evaluate the user's mental and physical functions in the same manner as above.</p>
<p id="p-0065" num="0064">On the other hand, if a plurality of pieces of sample music data are received from the data management apparatus <b>30</b> for the user to be evaluated, namely, if this user executed several performance actions for the same piece of music by use of the performance processing apparatus <b>23</b>, a graph shown in <figref idref="DRAWINGS">FIG. 12</figref> is displayed. It should be noted that <figref idref="DRAWINGS">FIG. 12</figref> displays only the graph of the tempo; actually, the graphs for the plurality of performance parameters as shown in <figref idref="DRAWINGS">FIG. 11</figref> are displayed.</p>
<p id="p-0066" num="0065">The graph in <figref idref="DRAWINGS">FIG. 12</figref> shows the change in the tempo of the original music data and the tempo change for each of the plurality of sessions of the sample music data. By referencing this graph display, the evaluator may not only evaluate the mental and physical functions based on one performance session, but also evaluate the transition of the time-dependent mental and physical functions based on two or more performance sessions. To be more specific, as shown in <figref idref="DRAWINGS">FIG. 12</figref>, at the first performance session, the deviation in tempo increases in the early stage of music performance, but, as the music performance advances from the second session to the third session, the deviation in tempo decreases. By referencing this graph display, the evaluator may evaluate that the mental and physical functions for carrying out “horizontal cutting action” for the tempo are gradually recovering.</p>
<p id="h-0010" num="0000">(2) Outputting Tones</p>
<p id="p-0067" num="0066">When the evaluator executes a predetermined operation through the input unit to command the outputting of tones on the basis of the sample music data (if there are two or more pieces of the sample music data, any one of them), the CPU <b>401</b> sequentially outputs the events of the sample music data stored in the storage unit <b>403</b> to the tone generator circuit <b>407</b> or the effector circuit <b>408</b> in a specified timed relation. As a result, the tone indicated by the sample music data is outputted from the loudspeaker <b>410</b>. Listening to this tone, the evaluator determines whether the tempo, volume, and pitch of the tone sounds natural as compared with the music indicated by the original music data. If there is any unnatural performance parameter, the evaluator evaluates that the user is deficit of the function for performing the action corresponding to the unnatural performance parameter. For example, if the tempo of the music sounded from the loudspeaker <b>410</b> gradually delays as the music progresses, the evaluator evaluates that the user lacks the function for “horizontal cutting action” corresponding to the tempo.</p>
<p id="p-0068" num="0067">When the evaluator executes a predetermined operation through the input unit <b>404</b> after the evaluation as above, the CPU <b>401</b> of the evaluation apparatus <b>40</b> executes the processing for editing the original music data (step S<b>23</b> in <figref idref="DRAWINGS">FIG. 9</figref>). In this editing processing, the music data to be used by the user for performance actions are generated by changing any of the performance parameters of the original music data on the basis of the results of the evaluation of user's mental and physical functions. For example, for the user determined to be not enough in the function for carrying out “horizontal cutting action” corresponding to the tempo, the evaluator may newly generate the music data in which a tempo slower than that of the original music data is set. The new music data may be generated by displaying the performance parameters of the original music data onto he display unit <b>406</b> and editing the contents (or values) of each performance parameter in accordance with the operation done through the input unit <b>404</b>.</p>
<p id="p-0069" num="0068">After generating the new music data as described above, the evaluator executes a predetermined operation through the input unit <b>404</b> to command the evaluation apparatus <b>40</b> for transmitting the newly generated music data to the data management apparatus <b>30</b>. Detecting this operation, the CPU <b>401</b> transmits the newly generated music data to the data management apparatus <b>30</b> (step S<b>24</b>). The newly generated music data are received by the CPU <b>301</b> of the data management apparatus <b>30</b> and stored in the storage unit <b>303</b> as the new original music data (step S<b>25</b>). Then, when the original music data are requested by the already evaluated group, the original music data stored in step S<b>25</b>, namely the original music data edited by the evaluator, are transmitted to the performance processing apparatus <b>23</b> (step S<b>10</b>).</p>
<p id="p-0070" num="0069">As described, in the present embodiment, the sample music data with the performance parameters of the original music data altered in accordance with the action done by the user are generated, so that the sample music data thus generated may be used as the quantitative data for evaluating the mental and physical functions of the user. Therefore, the objectivity of the evaluation associated with the mental and physical functions of the user may be enhanced.</p>
<p id="p-0071" num="0070">If a facility dedicated to the gathering of physiological data such as muscle strength, respiratory rate, and electroencephalography, the user becomes aware of being diagnosed or rehabilitated for mental and physical functions, thereby sometimes increasing his mental bourdon for the worse. However, according to the present embodiment, the sample music data are generated by user's enjoyment of performance actions, so that the data for evaluating user's mental and physical functions may be obtained in an objective manner without making the user aware of being diagnosed or rehabilitated for his mental and physical functions.</p>
<p id="p-0072" num="0071">Moreover, in the present embodiment, the sample music data having the contents reflecting the user's actions are transmitted to the evaluation apparatus <b>40</b>, so that there is no need for both the evaluator and the user to have a face-to-face interaction in carrying out the evaluation of mental and physical functions. Namely, the evaluator need not actually visit the user or vice versa. Consequently, the present embodiment mitigates the work loads of both the evaluator and the user and therefore increases the opportunity for the user to be evaluated for his mental and physical functions. For example, the user geographically remote from the evaluator may get the evaluation of mental and physical functions.</p>
<p id="h-0011" num="0000">&lt;C: Variations&gt;</p>
<p id="p-0073" num="0072">While the preferred embodiment of the present invention has been described using specific terms, such description is for illustrative purposes only, and it is to be understood that changes and variations may be made without departing from the spirit or scope of the appended claims. For example, the following variations are possible.</p>
<p id="h-0012" num="0000">&lt;C-1: Variation 1&gt;</p>
<p id="p-0074" num="0073">In the above-mentioned embodiment, in order for the evaluator to evaluate the mental and physical functions of the user, the change in performance parameters is displayed in graphs on the basis of the original music data and the sample music data and tones are generated on the basis of the sample music data. The method of providing the sample music data and the original music data for the evaluation by the evaluator is not restricted to the above-mentioned embodiment. For example, the integrated values of the differences between the performance parameters of the sample music data and the performance parameters of the original music data or the deviations therebetween may be displayed as numeric values. Namely, “provision of the sample music data (or the sample music data and the original music data) for the evaluation of the mental and physical functions of the user” denotes “outputting of the sample music data to the evaluator such that the evaluator referencing the performance parameters of the sample music data may evaluate the mental and physical functions of the user.”</p>
<p id="p-0075" num="0074">In the above-mentioned embodiment, both the sample music data and the original music data are provided for the evaluation of mental and physical functions. Alternatively, only the sample music data alone may be provided for the evaluation of mental and physical functions. Namely, the original music data common in music with the sample music data are not always required for the evaluation of user's mental and physical functions. For example, if displaying the change in performance parameters of the sample music data or outputting a tone from the loudspeaker <b>410</b> on the basis of the sample music data result in a slower tempo halfway in the music, it may indicate that the user's function corresponding to the tempo is not fully operating without requiring to draw a comparison with the performance parameters of the original music data.</p>
<p id="p-0076" num="0075">However, in order to obtain a more objective and reliable evaluation of user's mental and physical functions, it is preferable to draw a comparison between the performance parameters of the original music data and those of the sample music data. From this point of view, not only the sample music data but also the original music data that are common in music with the sample music data are preferably transmitted to the evaluation apparatus <b>40</b> to be provided for the evaluation of mental and physical functions based on the comparison between the performance parameters of both the music data.</p>
<p id="h-0013" num="0000">&lt;C-2: Variation 2&gt;</p>
<p id="p-0077" num="0076">In the above-mentioned embodiment and the variation thereto, the sample music data are generated by reflecting the action of the user onto the tempo, volume, and pitch of music. The performance parameters (namely, the elements on which the evaluation of user's mental and physical functions is based) to which the action of the user is to be reflected are not always these three at a time. For example, the action of the user may be reflected to at least one of tempo, volume, and pitch. Alternatively, the action of the user may be reflected to the degree of an effect to be imparted to a tone (for example, the depth of reverberation), a timbre, or other performance parameters. Namely, the performance parameters to be reflected to the contents of the sample music data herein may be any that is quantitatively indicative of user's mental and physical functions.</p>
<p id="h-0014" num="0000">&lt;C-3: Variation 3&gt;</p>
<p id="p-0078" num="0077">In the above-mentioned embodiment and the variations thereto, the control <b>21</b> which is manually held by the user is used. The form of the control <b>21</b> is not necessarily restricted to this type. For example, a control in which the sensor <b>213</b> is installed at the heel of a shoe worn by the user may be used as the control <b>21</b>. In this configuration, the performance parameters are controlled in accordance with the action information obtained when the user treads or tap-dances.</p>
<p id="p-0079" num="0078">In the above-mentioned embodiment and the variations thereto, the performance parameters are controlled in accordance with the contents of user's action. Instead of this or with the contents of user's action, the performance parameters may be controlled in accordance with the physiological conditions of the user. For example, a pulsation (or pulse wave) detector may be arranged on the control <b>21</b> which is wearable on the user to control the performance parameters on the basis of the action information representative of the detection result of pulsation. For the physiological conditions of the user available for performance parameter control, such indexes as body temperature, blood pressure, electroencephalography, respiratory rate, and ocular movement may be mentioned, in addition to pulsation.</p>
<p id="p-0080" num="0079">As described, the element for determining the performance parameters of the sample music data may be at least one of (or both of) the user's action and the user's physiological condition. The “mental and physical functions” to be evaluated on the basis of the sample music data are a concept which includes such action-associated functions of the autonomic nerve system as the adjustment of body temperature and blood pressure, in addition to the physical action-associated functions for moving arms, legs and other body parts and the mental action-associated functions.</p>
<p id="h-0015" num="0000">&lt;C-4: Variation 4&gt;</p>
<p id="p-0081" num="0080">In the above-mentioned embodiment and the variations thereto, the performance processing apparatus <b>23</b> carries out the performance processing by use of the original music data supplied by the data management apparatus <b>30</b>. Alternatively, the original music data for use in the performance processing may be one stored in the storage unit <b>233</b> of the performance processing apparatus <b>23</b> in advance. For example, the original music data retrieved from portable recording media such as a flexible disk and a CD-ROM (Compact Disk Read Only Memory) may be used for the performance processing by the performance processing apparatus <b>23</b>.</p>
<p id="h-0016" num="0000">&lt;C-5: Variation 5&gt;</p>
<p id="p-0082" num="0081">In the above-mentioned embodiment and the variations thereto, the performance processing system <b>20</b> has a plurality of controls <b>21</b>. Alternatively, the performance processing system <b>20</b> may have only one control <b>21</b> in which the action of only one user is reflected onto the sample music data. However, if a plurality of controls <b>21</b> are used as with the above-mentioned embodiment, the data for evaluating the mental and physical functions of a plurality of users may be obtained by a single performance processing operation, thereby making the above-mentioned embodiment advantageous in the accumulation of the data with higher efficiency.</p>
<p id="h-0017" num="0000">&lt;C-6: Variation 6&gt;</p>
<p id="p-0083" num="0082">In the above-mentioned embodiment and the variations thereto, the data management apparatus <b>30</b> and the evaluation apparatus <b>40</b> are arranged in a separate manner. It will be apparent that the evaluation apparatus <b>40</b> may be functionally arranged in the data management apparatus <b>30</b> (or vice versa). Namely, the data management apparatus <b>30</b> may have both the function (1) for storing the sample music data supplied from the performance processing system <b>20</b> as the data to be provided for the evaluation of user's mental and physical functions and the function (2) for providing the sample music data for the evaluation of user's mental and physical functions on the basis of the performance parameters of the sample music data. This configuration requires the arrangement of a display unit or a tone output unit (namely, a loudspeaker) for providing the sample music data for the evaluation of user's mental and physical functions on the data management apparatus <b>30</b>. It will also be apparent that the data management apparatus <b>30</b> may also carry out the processing of generating the original music data by the evaluator.</p>
<p id="h-0018" num="0000">&lt;C-7: Variation 7&gt;</p>
<p id="p-0084" num="0083">A display unit for displaying particular images when the user executes a performance action may be arranged on the performance processing apparatus shown in the above-mentioned embodiment and the variations thereto. The images to be displayed on this display unit may include prepared images and the image of the user himself who is carrying out a performance action, for example. The images to be displayed on this display unit may be appropriately changed in accordance with the actions and physiological conditions of the user. The configuration allows the user to further enjoy his performance actions, thereby making him less aware of being diagnosed or rehabilitated for the more objective evaluation of his mental and physical functions.</p>
<p id="h-0019" num="0000">&lt;C-8: Variation 8&gt;</p>
<p id="p-0085" num="0084">In the above-mentioned embodiment and the variations thereto, the data are transferred between the performance processing apparatus <b>23</b>, the data management apparatus <b>30</b>, and the evaluation apparatus <b>40</b> via the communication network <b>10</b>. The method the data transfer between these apparatuses is not restricted to the above-mentioned configuration. For example, the data management apparatus <b>30</b> may receive the sample music data directly from performance processing apparatus <b>23</b> (namely, without using any intervening relay apparatus). This holds true with the data transfer between the data management apparatus <b>30</b> and the evaluation apparatus <b>40</b>. The communication between these apparatuses may be carried out in not only a wired manner, but also in a wireless manner.</p>
<p id="p-0086" num="0085">As described and according to the invention, the quantitative data for evaluating user's mental and physical functions may be gathered and provided for this evaluation.</p>
<p id="p-0087" num="0086">The entire content of Priority Document No. 2002-250727 is incorporated herein by reference.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A performance processing apparatus operable by a user with the aid of a control device and a sound device for providing sample music data to a data management apparatus, the performance processing apparatus comprising:
<claim-text>a first storage section that stores original music data representing a music piece composed of tones;</claim-text>
<claim-text>an acquisition section and acquires input information from the control device which has a detector for detecting either of physical action or physiological state of the user and which is operated by the user to provide the input information indicating the detection result by the detector;</claim-text>
<claim-text>a processing section that controls a performance parameter of the original music data according to the input information, and that generates the sample music data for enabling the sound device to generate tones of the music piece which is represented by the original music data and which is altered by the user; and</claim-text>
<claim-text>a transmitting section that transmits the sample music data representing the music piece composed of the tones controlled by the performance parameter and generated by the processing section to the data management apparatus which has a second storage section for storing the sample music data for use as a material of in evaluating the physiological or physical condition of the user by comparing the sample music data with the original music data;</claim-text>
<claim-text>wherein the first storage section stores the original music data divided into part data corresponding to a plurality of parts of the music piece, the acquisition section acquires the input information from a plurality of the control devices which are allotted to one or more of the parts and which are operated by users to jointly perform the allotted parts, the processing section controls the respective performance parameters of the respective parts according to the input information for enabling the sound device to generate tones of the respective parts, and the transmitting section transmits the sample music data to the data management apparatus, the music data containing the part data representing the performance parameters of the respective parts controlled according to the input information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The performance processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the data management apparatus initially stores the original music data in the second storage section, the performance processing apparatus further comprising a receiving section that receives the original music data from the data management apparatus.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The performance processing apparatus according the <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing section controls the performance parameter selected from a volume, tempo, timbre, effect and pitch of the tones.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A data management apparatus provided for managing data including original music data and sample music data in association with a performance processing apparatus having a sound device and being operated by a user, the data management apparatus comprising:
<claim-text>a receiving section that receives the sample music data from the performance processing apparatus, which controls a performance parameter of the original music data according to input information representing physical action or physiological state of the user for enabling the sound device to generate tones of a music piece which is represented by the original music data and which is altered by the user, and which generates and transmits the sample music data representing the music piece composed of the tones controlled by the performance parameter;</claim-text>
<claim-text>a storage section that stores the received sample music data generated by the performance processing apparatus for use as in evaluating the physiological or physical function of the user by comparing the sample music data with the original music data; and</claim-text>
<claim-text>a transmitting section that transmits the sample music data to an evaluation apparatus which evaluates the physical function of the user according to the performance parameter contained in the transmitted sample music data;</claim-text>
<claim-text>wherein the receiving section receives from the evaluation apparatus music data which contains a performance parameter determined by the evaluation apparatus based on results of evaluating the physiological or physical functions of the user, the storage section stores the music data received from the evaluation apparatus as original music data, and the transmitting section transmits the original music data stored in the storage section to the performance processing apparatus.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A data management apparatus provided for managing data including original music data and sample music data in association with a performance processing apparatus having a sound device and being operated by a user, the data management apparatus comprising:
<claim-text>a receiving section that receives the sample music data from the performance processing apparatus, which controls a performance parameter of the original music data according to input information representing physical action or physiological state of the user for enabling the sound device to generate tones of a music piece which is represented by the original music data and which is altered by the user, and which generates and transmits the sample music data representing the music piece composed of the tones controlled by the performance parameter; and</claim-text>
<claim-text>a storage section that stores the received sample music data generated by the performance processing apparatus for use as in evaluating the physiological or physical function of the user by comparing the sample music data with the original music data;</claim-text>
<claim-text>further comprising a creating section that creates music data containing a performance parameter determined according to results of evaluating the physiological or physical function of the user, such that the created music data is stored in the storage section as original music data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The data management apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref> or <claim-ref idref="CLM-00005">5</claim-ref>, further comprising another storage section that stores the original music data, and a transmitting section that transmits the stored original music data to the performance processing apparatus.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The data management apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref> or <claim-ref idref="CLM-00005">5</claim-ref>, wherein the transmitting section further transmits the original music data representing the same music piece as represented by the sample music data to the evaluation apparatus which evaluates the physiological or physical function of the user by comparing the altered performance parameter contained in the sample music data with an original performance parameter contained in the original music data.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The data management apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref> or <claim-ref idref="CLM-00005">5</claim-ref>, further comprising a providing section that provides the sample music data to an evaluator who evaluates the physiological or physical function of the user according to the performance parameter contained in the provided sample music data.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The data management apparatus according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the providing section provides the original music data representing the same music piece as represented by the sample music data to the evaluator so that the evaluator evaluates the physiological or physical function of the user by comparing the altered performance parameter contained in the sample music data with an original performance parameter contained in the original music data.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The data management apparatus according the <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the providing section displays a variation of the performance parameter contained in the sample music data on a display device.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The data management apparatus according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the providing section generates the tones of the music piece through a sound device according to the sample music data.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. An evaluation apparatus provided in association with a data management apparatus for evaluating sample music data from a performance processing apparatus having a sound device and being operated by a user, the evaluation apparatus comprising:
<claim-text>a receiving section that receives the sample music data via the data management apparatus from the performance processing apparatus, which controls a music performance parameter of the original music data according to input information representing physical action or physiological state of the user for enabling the sound device to generate tones of a music piece which is represented by original music data and which is altered by the user, and which generates and transmits the sample music data representing the music piece composed of the tones controlled by the performance parameter;</claim-text>
<claim-text>a storage section that stores the sample music data generated by the performance processing apparatus and received by the receiving section; and</claim-text>
<claim-text>a providing section that provides the sample music data to an evaluator who evaluates the physiological or physical condition of the user by comparing the sample music data with the original music data according to the music performance parameter contained in the provided sample music data;</claim-text>
<claim-text>further comprising a creating section that creates music data containing a performance parameter determined according to results of evaluating the physiological or physical function of the user, and a transmitting section that transmits the created music data to the data management apparatus which stores the created music data in a storage section as original music data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The evaluation apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the receiving section receives from the data management apparatus the original music data representing the same music piece as represented by the sample music data, and the providing section provides the original music data to the evaluator together with the sample music data so that the evaluator evaluates the physiological or physical function of the user by comparing the altered performance parameter contained in the sample music data with an original performance parameter contained in the original music data).</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The evaluation apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the providing section displays a variation of the performance parameter contained in the sample music data on a display device.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The evaluation apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising a creating section that creates music data containing a performance parameter determined according to results of evaluating the physiological or physical function of the user, and a transmitting section that transmits the created music data to the data management apparatus which stores the created music data in a storage section as original music data.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. A computer-readable medium encoded with a computer program for use in a performance processing apparatus operable by a user with the aid of a control device and a sound device for providing sample music data to a data management apparatus, the computer program being executable for causing the performance processing apparatus to carry out a method comprising the steps of:
<claim-text>storing in a first storage section original music data representing a music piece composed of tones;</claim-text>
<claim-text>acquiring by an acquisition section input information from the control device which has a detector for detecting either of physical action or physiological state of the user and which is operated by the user to provide the input information indicating the detection result by the detector;</claim-text>
<claim-text>controlling by a processing section a performance parameter of the original music data according to the input information, and generating the sample music data for enabling the sound device to generate tones of the music piece which is represented by the original music data and which is altered by the user; and</claim-text>
<claim-text>transmitting by a transmitting section the sample music data representing the music piece composed of the tones controlled by the performance parameter and generated by the processing section to the data management apparatus which has a second storage section for storing the sample music data for use as a material of in evaluating the physiological or physical condition of the user by comparing the sample music data with the original music data;</claim-text>
<claim-text>wherein the first storage section stores the original music data divided into part data corresponding to a plurality of parts of the music piece, the acquisition section acquires the input information from a plurality of the control devices which are allotted to one or more of the parts and which are operated by users to jointly perform the allotted parts, the processing section controls the respective performance parameters of the respective parts according to the input information for enabling the sound device to generate tones of the respective parts, and the transmitting section transmits the sample music data to the data management apparatus, the music data containing the part data representing the performance parameters of the respective parts controlled according to the input information.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. A computer-readable medium encoded with a computer program for use in a data management apparatus for managing data including original music data and sample music data in association with a performance processing apparatus having a sound device and being operated by a user, the computer program being executable for causing the data management apparatus to carry out a method comprising the steps of:
<claim-text>receiving by a receiving section that receives the sample music data from the performance processing apparatus, which controls a performance parameter of the original music data according to input information representing physical action or physiological state of the user for enabling the sound device to generate tones of a music piece which is represented by the original music data and which is altered by the user, and which generates and transmits the sample music data representing the music piece composed of the tones controlled by the performance parameter;</claim-text>
<claim-text>storing in a storage section that stores the received sample music data generated by the performance processing apparatus for use as in evaluating the physiological or physical function of the user by comparing the sample music data with the original music data; and</claim-text>
<claim-text>transmitting by a transmitting section that transmits the sample music data to an evaluation apparatus which evaluates the physical function of the user according to the performance parameter contained in the transmitted sample music data;</claim-text>
<claim-text>wherein the receiving section receives from the evaluation apparatus music data which contains a performance parameter determined by the evaluation apparatus based on results of evaluating the physiological or physical functions of the user, the storage section stores the music data received from the evaluation apparatus as original music data, and the transmitting section transmits the original music data stored in the storage section to the performance processing apparatus.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. A computer-readable medium encoded with a computer program for use in a data management apparatus for managing data including original music data and sample music data in association with a performance processing apparatus having a sound device and being operated by a user, the computer program being executable for causing the data management apparatus to carry out a method comprising the steps of:
<claim-text>receiving by a receiving section that receives the sample music data from the performance processing apparatus, which controls a performance parameter of the original music data according to input information representing physical action or physiological state of the user for enabling the sound device to generate tones of a music piece which is represented by the original music data and which is altered by the user, and which generates and transmits the sample music data representing the music piece composed of the tones controlled by the performance parameter; and</claim-text>
<claim-text>storing in a storage section that stores the received sample music data generated by the performance processing apparatus for use as in evaluating the physiological or physical function of the user by comparing the sample music data with the original music data;</claim-text>
<claim-text>creating by a creating section that creates music data containing a performance parameter determined according to results of evaluating the physiological or physical function of the user, such that the created music data is stored in the storage section as original music data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. A computer-readable medium encoded with a computer program for use with an evaluation apparatus provided in association with a data management apparatus for evaluating sample music data from a performance processing apparatus having a sound device and being operated by a user, the computer program being executable for causing an evaluation apparatus to carry out a method comprising the steps of:
<claim-text>receiving by a receiving section that receives the sample music data via the data management apparatus from the performance processing apparatus, which controls a music performance parameter of the original music data according to input information representing physical action or physiological state of the user for enabling the sound device to generate tones of a music piece which is represented by original music data and which is altered by the user, and which generates and transmits the sample music data representing the music piece composed of the tones controlled by the performance parameter;</claim-text>
<claim-text>storing in a storage section that stores the sample music data generated by the performance processing apparatus and received by the receiving section; and</claim-text>
<claim-text>providing by a providing section that provides the sample music data to an evaluator who evaluates the physiological or physical condition of the user by comparing the sample music data with the original music data according to the music performance parameter contained in the provided sample music data</claim-text>
<claim-text>creating by a creating section that creates music data containing a performance parameter determined according to results of evaluating the physiological or physical function of the user, and a transmitting section that transmits the created music data to the data management apparatus which stores the created music data in a storage section as original music data.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
