<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298918-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298918</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10601965</doc-number>
<date>20030623</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2003-080314</doc-number>
<date>20030324</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>865</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>40</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382266</main-classification>
<further-classification>382167</further-classification>
<further-classification>382260</further-classification>
<further-classification>382269</further-classification>
<further-classification>358  326</further-classification>
<further-classification>358  327</further-classification>
<further-classification>358518</further-classification>
</classification-national>
<invention-title id="d0e71">Image processing apparatus capable of highly precise edge extraction</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5291300</doc-number>
<kind>A</kind>
<name>Ueda</name>
<date>19940300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>386117</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5315413</doc-number>
<kind>A</kind>
<name>Yamamoto et al.</name>
<date>19940500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358512</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5712474</doc-number>
<kind>A</kind>
<name>Naneda</name>
<date>19980100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>2502081</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5825938</doc-number>
<kind>A</kind>
<name>De Lange</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382263</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6141446</doc-number>
<kind>A</kind>
<name>Boliek et al.</name>
<date>20001000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382233</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6173084</doc-number>
<kind>B1</kind>
<name>Aach et al.</name>
<date>20010100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382260</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6356300</doc-number>
<kind>B1</kind>
<name>Shiba</name>
<date>20020300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348130</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6665439</doc-number>
<kind>B1</kind>
<name>Takahashi</name>
<date>20031200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382199</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6674880</doc-number>
<kind>B1</kind>
<name>Stork et al.</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382128</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6819790</doc-number>
<kind>B2</kind>
<name>Suzuki et al.</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382156</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6842538</doc-number>
<kind>B2</kind>
<name>Lee et al.</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382224</main-classification></classification-national>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>JP</country>
<doc-number>2000-013607</doc-number>
<kind>A</kind>
<date>20000100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>JP</country>
<doc-number>2002-175534</doc-number>
<kind>A</kind>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>16</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382260</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382266</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382269</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382274</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382275</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382167</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382  327</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382518</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358  326</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358  327</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358463</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358518</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>6</number-of-drawing-sheets>
<number-of-figures>11</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20040190778</doc-number>
<kind>A1</kind>
<date>20040930</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Sumitomo</last-name>
<first-name>Hironori</first-name>
<address>
<city>Nishinomiya</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Kawakami</last-name>
<first-name>Yuichi</first-name>
<address>
<city>Nishinomiya</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Sidley Austin LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Minolta Co., Ltd.</orgname>
<role>03</role>
<address>
<city>Osaka</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Kassa</last-name>
<first-name>Yosef</first-name>
<department>2624</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An image processing apparatus first forms an edge image of an input image using, for example, SOBEL operator, and performs a smoothing process on the formed edge image by using an average filter. Thereafter, the image processing apparatus calculates a difference between the edge image and the edge smoothed image, and binarizes the edge image based on the difference.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="179.58mm" wi="97.62mm" file="US07298918-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="192.45mm" wi="138.51mm" file="US07298918-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="205.82mm" wi="106.85mm" file="US07298918-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="195.07mm" wi="125.90mm" file="US07298918-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="160.10mm" wi="148.93mm" file="US07298918-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="98.30mm" wi="155.96mm" file="US07298918-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="194.73mm" wi="137.75mm" file="US07298918-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<p id="p-0002" num="0001">This application is based on Japanese Patent Application No. 2003-80314 filed with Japan Patent Office on Mar. 24, 2003, the entire content of which is hereby incorporated by reference.</p>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to an image processing apparatus, an image processing program product and an image pick-up apparatus. More specifically, the present invention relates to an image processing apparatus, an image processing program product and an image pick-up apparatus that are capable of extracting edge portions with high precision.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">Conventionally, a technique has been proposed in which each pixel of an image prepared by extracting edge components from an image input through a camera or the like (hereinafter referred to as an edge image) is compared in magnitude with a threshold value set in advance, to form an image having edge portions and non-edge portions distinguished from each other (hereinafter referred to as an edge binarized image). When the threshold value is set large in such a technique, it becomes difficult to extract a portion that is desirable to be extracted as the edge portion, if that portion is a thin line with small gradation difference. On the contrary, when the threshold value is set small, it becomes possible to extract that portion of the input image which has small gradation difference. However, it becomes more likely that edge components that exist around the original edge component that has been successfully extracted are undesirably extracted as edge portions as well, resulting in an edge portion that is too thick. Further, there is a higher possibility that not only a thin line but also noise components would undesirably be extracted. Thus, it has been very difficult to determine a right threshold value that can simultaneously solve both of the above described problems.</p>
<p id="p-0007" num="0006">Japanese Laid-Open Patent Publication No. 2000-13607 discloses an image processing method in which an image prepared by smoothing an input image (hereinafter referred to as a smoothed image) is subtracted from the input image, an edge component is extracted based on the result of subtraction, and the edge component is binarized by using a prescribed threshold value, whereby an edge portion and a non-edge portion are distinguished from each other.</p>
<p id="p-0008" num="0007">The image processing method disclosed in Japanese Laid-Open Patent Publication No. 2000-13607 will be specifically described.</p>
<p id="p-0009" num="0008">FIG. 9 represents an image A-1 having large gradation difference, an image B-1 having a small gradation difference, and an image C-1 having moderate gradation with the gradation difference changing like a wave. According to the image processing method disclosed in Japanese Laid-Open Patent Publication No. 2000-13607, first, the input images are smoothed using an average filter. Edge smoothed images A-2, B-2 and C-2 obtained by averaging the input images of FIG. 9 by taking 7 pixels by 7 pixels are shown in FIG. 10.</p>
<p id="p-0010" num="0009">Thereafter, according to the image processing method disclosed in Japanese Laid-Open Patent Publication No. 2000-13607, difference between the input image (or the image for outline extraction) and the smoothed image is calculated. Results of subtraction A-3, B-3 and C-3 of smoothed images A-2, B-2 and C-2 shown in FIG. 10 from the input images A-1, B-1 and C-1 shown in FIG. 9 are shown in FIG. 11.</p>
<p id="p-0011" num="0010">Japanese Laid-Open Patent Publication No. 2002-175534 discloses a method in which an edge image is formed from, an input image, and using an average value and standard deviation of the edge component of the edge image, an edge binarized image is formed.</p>
<p id="p-0012" num="0011">The method disclosed in Japanese Laid-Open Patent Publication No. 2000-13607 has a problem that when there is a portion having wave-like gradation difference where the gradation changes moderately, the peak portion of the wave that should not be extracted as an edge is undesirably extracted as an edge portion. More specifically, in the method disclosed in Japanese Laid-Open Patent Publication No. 2000-13607, the portion {circle around (7)} is extracted as the edge portion based on the result of subtraction B-3 shown in FIG. 11, and therefore, when the threshold value is set to 8 as an example, portions {circle around (7)} and {circle around (8)} of input image A-1 would be extracted as the edge portion based on the result of subtraction A-3. Thus, the extracted edge portion becomes rather thick. When the edge portion is detected thick, it becomes sometimes difficult to detect accurate position of an object. Further, in the result of subtraction C-3, values of portions {circle around (5)} to {circle around (7)} are higher than the threshold value 8, and therefore, these portions in input image C-1 are undesirably extracted as the edge portion, though these portions actually have the wave-like gradation difference with moderately changing gradation.</p>
<p id="p-0013" num="0012">The method disclosed in Japanese Laid-Open Patent Publication No. 2002-175534 also has a problem that it is difficult to extract, as an edge portion, a portion having small gradation difference such as a thin line existing in an input image of which portions mostly have large gradation difference.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0014" num="0013">Therefore, an object of the present invention is to provide an image processing apparatus, an image processing program and an image pick-up apparatus that are capable of extracting edge portions with high precision.</p>
<p id="p-0015" num="0014">The above described object of the present invention is attained by an image processing apparatus including the following elements. Specifically, the image processing apparatus includes an edge image forming unit extracting an edge from an input image and forming an edge image, an edge smoothed image forming unit smoothing the edge image to from an edge smoothed image, a difference calculating unit calculating difference between the edge image and the edge smoothed image, and a binarizing unit binarizing the edge image based on the difference.</p>
<p id="p-0016" num="0015">According to another aspect, the present invention provides an image processing program product that makes a computer execute an image processing, including an edge smoothed image forming step of smoothing an edge image formed based on an input image and forming an edge smoothed image, a difference calculating step of calculating difference between the edge image and the edge smoothed image, and a binarizing step of binarizing the edge image based on the difference.</p>
<p id="p-0017" num="0016">According to a still further aspect, the present invention provides an image pick-up apparatus including an image pick-up unit picking-up an object and capturing an object image, an edge image forming unit forming an edge image by extracting an edge from the picked-up image, an edge smoothed image forming unit forming an edge smoothed image by smoothing the edge image, a difference calculating unit calculating difference between the edge image and the edge smoothed image, and a binarizing unit binarizing the edge image based on the difference.</p>
<p id="p-0018" num="0017">The foregoing and other objects, features, aspects and advantages of the present invention will become more apparent from the following detailed description of the present invention when taken in conjunction with the accompanying drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 1</figref> shows a specific exemplary configuration of an image processing system in accordance with an embodiment.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 2</figref> is a flow chart representing the process executed by the image processing system in accordance with the embodiment.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 3</figref> represents specific examples of edge images.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 4</figref> represents specific examples of edge smoothed images averaged by taking 7 pixels by 7 pixels of the input image.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 5</figref> represents specific examples of results of subtraction of the edge smoothed images from the edge images.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIGS. 6 and 7</figref> illustrate the principle of edge portion extraction.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 8</figref> shows a specific exemplary configuration of a camera <b>2</b>, when image processing is done by the camera <b>2</b>.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 9</figref> represents specific examples of input images.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 10</figref> represents specific examples of edge smoothed images averaged by taking 7 pixels by 7 pixels of the input image.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 11</figref> represents specific examples of results of subtraction of the edge smoothed images from the input images.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0029" num="0028">Embodiments of the present invention will be described with reference to the figures. In the following description, same or corresponding elements are denoted by the same reference characters. Names and functions of these portions are also the same. Therefore, detailed description thereof will not be repeated.</p>
<p id="p-0030" num="0029">Referring to <figref idref="DRAWINGS">FIG. 1</figref>, the image processing system in accordance with the present invention includes a camera <b>2</b> inputting images to an image processing apparatus such as a personal computer (hereinafter referred to as a PC), and PC <b>1</b> processing the images obtained from camera <b>2</b>. The image processing apparatus of the present invention is not limited to the personal computer as specifically represented in the present embodiment, and the apparatus may be implemented as a semiconductor chip, or as an image processing board.</p>
<p id="p-0031" num="0030">Further referring to <figref idref="DRAWINGS">FIG. 1</figref>, PC <b>1</b> as the image processing apparatus is controlled by a CPU (Central Processing Unit) <b>101</b>, and processes an image input from camera <b>2</b> through a camera I/F (interface) <b>107</b> (which is also referred to as an image capturing unit). The program executed by CPU <b>101</b> is stored in a HDD (Hard Disk Drive) <b>102</b> or a ROM (Read Only Memory) <b>103</b> as a storing unit. Alternatively, the program executed by CPU <b>101</b> is read by a reading unit <b>108</b> from a storage medium <b>109</b> such as a CD-ROM (Compact Disc-ROM). A RAM (Random Access Memory) <b>104</b> serves as a temporary work space when the program is executed by CPU <b>101</b>. Further, RAM <b>104</b> also serves as a buffer, that is, a temporary storage area, for the following processes. A user inputs information and instructions through an input unit <b>105</b> including a keyboard and a mouse. Images received from camera <b>2</b> and results of processing thereof are displayed on a display unit <b>106</b>. The configuration shown in <figref idref="DRAWINGS">FIG. 1</figref> is a general configuration of a personal computer, and the configuration of PC <b>1</b> is not limited to that shown in <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0032" num="0031">Camera <b>2</b> may be any general apparatus, such as a video recorder, which has means for capturing an image and for inputting the same to PC <b>1</b>.</p>
<p id="p-0033" num="0032">In such an image processing system, the following image processing is executed, an edge image is formed from the image captured by camera <b>2</b>, and the edge image is binarized. <figref idref="DRAWINGS">FIG. 2</figref> is a flow chart representing the process executed by the image processing system in accordance with the present embodiment, realized by the program read by CPU <b>101</b> of PC <b>1</b> from HDD <b>102</b> or ROM <b>103</b> or the program obtained by reading unit <b>108</b> from storage medium <b>109</b>, and executed by RAM <b>104</b>.</p>
<p id="p-0034" num="0033">Referring to <figref idref="DRAWINGS">FIG. 2</figref>, first, CPU <b>101</b> of PC <b>1</b> receives an input of an object image OI (x, y) from camera <b>2</b> through camera I/F <b>107</b> (S<b>1</b>). Here, the input object image OI (x, y) input from camera <b>2</b> is either a color image or a gray scale image.</p>
<p id="p-0035" num="0034">Thereafter, CPU <b>101</b> executes the program to transform the input object image OI (x, y) to a gray scale image GI (x, y) (S<b>2</b>). In step S<b>2</b>, when the input object image OI (x, y) is a color image, the calculation represented by Equation (1) below is performed on each pixel of the input object image OI (x, y), to transform the input object image OI (x, y) to the gray scale image GI (x, y):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>GI</i>(<i>x,y</i>)=0.299<i>×ROI</i>(<i>x,y</i>) +0.587<i>×GOI</i>(<i>x,y</i>) +0.114<i>×BOI</i>(<i>x,y</i>)  (1)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where (x, y) represents coordinates indicating the pixel position in the image, ROI (x, y) represents an R plane of the input object image OI (x, y) that is a color image, BOI (x, y) represents a B plane of the input object image OI (x, y) that is a color image, and GOI (x, y) represents a G plane of the input object image OI (x, y) that is a color image.
</p>
<p id="p-0036" num="0035">When the input object image OI (x, y) input in step S<b>1</b> is already a gray scale image GI (x, y), the process of step S<b>2</b> is omitted, and the process proceeds to the next step.</p>
<p id="p-0037" num="0036">Next, CPU <b>101</b> extracts an edge component from the gray scale image GI (x, y) transformed in step S<b>2</b>, and forms an edge image El (x, y) (S<b>3</b>). As to the method of forming an edge image EI (x, y) in step S<b>3</b>, various conventional methods may by utilized, and not specifically limited in the present invention. By way of example, a method may be used in which the calculation represented by Equation (2) below is performed on each pixel of the gray scale image GI (x, y):</p>
<p id="p-0038" num="0037">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>EI</mi>
          <mo>⁡</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mi>x</mi>
              <mo>,</mo>
              <mi>y</mi>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <msqrt>
          <mrow>
            <msup>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mrow>
                    <mi>GI</mi>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>x</mi>
                        <mo>,</mo>
                        <mi>y</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>-</mo>
                  <mrow>
                    <mi>GI</mi>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>x</mi>
                        <mo>,</mo>
                        <mrow>
                          <mi>y</mi>
                          <mo>-</mo>
                          <mn>1</mn>
                        </mrow>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                </mrow>
                <mo>)</mo>
              </mrow>
              <mn>2</mn>
            </msup>
            <mo>+</mo>
            <msup>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mrow>
                    <mi>GI</mi>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>x</mi>
                        <mo>,</mo>
                        <mi>y</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>-</mo>
                  <mrow>
                    <mi>GI</mi>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mrow>
                          <mi>x</mi>
                          <mo>-</mo>
                          <mn>1</mn>
                        </mrow>
                        <mo>,</mo>
                        <mi>y</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                </mrow>
                <mo>)</mo>
              </mrow>
              <mn>2</mn>
            </msup>
          </mrow>
        </msqrt>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>2</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0039" num="0038">The forming method mentioned above is generally well-known, by which the difference value between adjacent pixels is extracted as an edge component.</p>
<p id="p-0040" num="0039">Alternatively, a method using SOBEL operator represented by Equation (3) or a method using PREWITT operator represented by Equation (4) may also be utilized, to similarly form the edge image EI (x, y). Further, similar effects can be attained by forming the edge image EI (x, y) using a method of extracting edge components other than the methods described below.</p>
<p id="p-0041" num="0040">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mrow>
  <mo> </mo>
  <mtable>
    <mtr>
      <mtd>
        <mrow>
          <mtable>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <msub>
                      <mi>EI</mi>
                      <mi>x</mi>
                    </msub>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>x</mi>
                        <mo>,</mo>
                        <mi>y</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>=</mo>
                  <mrow>
                    <mrow>
                      <mo>(</mo>
                      <mtable>
                        <mtr>
                          <mtd>
                            <mrow>
                              <mo>-</mo>
                              <mn>1</mn>
                            </mrow>
                          </mtd>
                          <mtd>
                            <mrow>
                              <mo>-</mo>
                              <mn>2</mn>
                            </mrow>
                          </mtd>
                          <mtd>
                            <mrow>
                              <mo>-</mo>
                              <mn>1</mn>
                            </mrow>
                          </mtd>
                        </mtr>
                        <mtr>
                          <mtd>
                            <mn>0</mn>
                          </mtd>
                          <mtd>
                            <mn>0</mn>
                          </mtd>
                          <mtd>
                            <mn>0</mn>
                          </mtd>
                        </mtr>
                        <mtr>
                          <mtd>
                            <mn>1</mn>
                          </mtd>
                          <mtd>
                            <mn>2</mn>
                          </mtd>
                          <mtd>
                            <mn>1</mn>
                          </mtd>
                        </mtr>
                      </mtable>
                      <mo>)</mo>
                    </mrow>
                    <mo>×</mo>
                    <mrow>
                      <mi>GI</mi>
                      <mo>⁡</mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <mi>x</mi>
                          <mo>,</mo>
                          <mi>y</mi>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <msub>
                      <mi>EI</mi>
                      <mi>y</mi>
                    </msub>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>x</mi>
                        <mo>,</mo>
                        <mi>y</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>=</mo>
                  <mrow>
                    <mrow>
                      <mo>(</mo>
                      <mtable>
                        <mtr>
                          <mtd>
                            <mrow>
                              <mo>-</mo>
                              <mn>1</mn>
                            </mrow>
                          </mtd>
                          <mtd>
                            <mrow>
                              <mo>-</mo>
                              <mn>2</mn>
                            </mrow>
                          </mtd>
                          <mtd>
                            <mn>1</mn>
                          </mtd>
                        </mtr>
                        <mtr>
                          <mtd>
                            <mrow>
                              <mo>-</mo>
                              <mn>2</mn>
                            </mrow>
                          </mtd>
                          <mtd>
                            <mn>0</mn>
                          </mtd>
                          <mtd>
                            <mn>2</mn>
                          </mtd>
                        </mtr>
                        <mtr>
                          <mtd>
                            <mrow>
                              <mo>-</mo>
                              <mn>1</mn>
                            </mrow>
                          </mtd>
                          <mtd>
                            <mn>0</mn>
                          </mtd>
                          <mtd>
                            <mn>1</mn>
                          </mtd>
                        </mtr>
                      </mtable>
                      <mo>)</mo>
                    </mrow>
                    <mo>×</mo>
                    <mrow>
                      <mi>GI</mi>
                      <mo>⁡</mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <mi>x</mi>
                          <mo>,</mo>
                          <mi>y</mi>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <mi>EI</mi>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>x</mi>
                        <mo>,</mo>
                        <mi>y</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>=</mo>
                  <msqrt>
                    <mrow>
                      <msup>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <msub>
                              <mi>EI</mi>
                              <mi>x</mi>
                            </msub>
                            <mo>⁡</mo>
                            <mrow>
                              <mo>(</mo>
                              <mrow>
                                <mi>x</mi>
                                <mo>,</mo>
                                <mi>y</mi>
                              </mrow>
                              <mo>)</mo>
                            </mrow>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                        <mn>2</mn>
                      </msup>
                      <mo>+</mo>
                      <msup>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <msub>
                              <mi>EI</mi>
                              <mi>y</mi>
                            </msub>
                            <mo>⁡</mo>
                            <mrow>
                              <mo>(</mo>
                              <mrow>
                                <mi>x</mi>
                                <mo>,</mo>
                                <mi>y</mi>
                              </mrow>
                              <mo>)</mo>
                            </mrow>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                        <mn>2</mn>
                      </msup>
                    </mrow>
                  </msqrt>
                </mrow>
              </mtd>
            </mtr>
          </mtable>
          <mo>}</mo>
        </mrow>
      </mtd>
      <mtd>
        <mrow>
          <mo>(</mo>
          <mn>3</mn>
          <mo>)</mo>
        </mrow>
      </mtd>
    </mtr>
    <mtr>
      <mtd>
        <mrow>
          <mtable>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <msub>
                      <mi>EI</mi>
                      <mi>x</mi>
                    </msub>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>x</mi>
                        <mo>,</mo>
                        <mi>y</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>=</mo>
                  <mrow>
                    <mrow>
                      <mo>(</mo>
                      <mtable>
                        <mtr>
                          <mtd>
                            <mrow>
                              <mo>-</mo>
                              <mn>1</mn>
                            </mrow>
                          </mtd>
                          <mtd>
                            <mrow>
                              <mo>-</mo>
                              <mn>1</mn>
                            </mrow>
                          </mtd>
                          <mtd>
                            <mrow>
                              <mo>-</mo>
                              <mn>1</mn>
                            </mrow>
                          </mtd>
                        </mtr>
                        <mtr>
                          <mtd>
                            <mn>0</mn>
                          </mtd>
                          <mtd>
                            <mn>0</mn>
                          </mtd>
                          <mtd>
                            <mn>0</mn>
                          </mtd>
                        </mtr>
                        <mtr>
                          <mtd>
                            <mn>1</mn>
                          </mtd>
                          <mtd>
                            <mn>1</mn>
                          </mtd>
                          <mtd>
                            <mn>1</mn>
                          </mtd>
                        </mtr>
                      </mtable>
                      <mo>)</mo>
                    </mrow>
                    <mo>×</mo>
                    <mrow>
                      <mi>GI</mi>
                      <mo>⁡</mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <mi>x</mi>
                          <mo>,</mo>
                          <mi>y</mi>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <msub>
                      <mi>EI</mi>
                      <mi>y</mi>
                    </msub>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>x</mi>
                        <mo>,</mo>
                        <mi>y</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>=</mo>
                  <mrow>
                    <mrow>
                      <mo>(</mo>
                      <mtable>
                        <mtr>
                          <mtd>
                            <mrow>
                              <mo>-</mo>
                              <mn>1</mn>
                            </mrow>
                          </mtd>
                          <mtd>
                            <mn>0</mn>
                          </mtd>
                          <mtd>
                            <mn>1</mn>
                          </mtd>
                        </mtr>
                        <mtr>
                          <mtd>
                            <mrow>
                              <mo>-</mo>
                              <mn>1</mn>
                            </mrow>
                          </mtd>
                          <mtd>
                            <mn>0</mn>
                          </mtd>
                          <mtd>
                            <mn>1</mn>
                          </mtd>
                        </mtr>
                        <mtr>
                          <mtd>
                            <mrow>
                              <mo>-</mo>
                              <mn>1</mn>
                            </mrow>
                          </mtd>
                          <mtd>
                            <mn>0</mn>
                          </mtd>
                          <mtd>
                            <mn>1</mn>
                          </mtd>
                        </mtr>
                      </mtable>
                      <mo>)</mo>
                    </mrow>
                    <mo>×</mo>
                    <mrow>
                      <mi>GI</mi>
                      <mo>⁡</mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <mi>x</mi>
                          <mo>,</mo>
                          <mi>y</mi>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <mi>EI</mi>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>x</mi>
                        <mo>,</mo>
                        <mi>y</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>=</mo>
                  <msqrt>
                    <mrow>
                      <msup>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <msub>
                              <mi>EI</mi>
                              <mi>x</mi>
                            </msub>
                            <mo>⁡</mo>
                            <mrow>
                              <mo>(</mo>
                              <mrow>
                                <mi>x</mi>
                                <mo>,</mo>
                                <mi>y</mi>
                              </mrow>
                              <mo>)</mo>
                            </mrow>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                        <mn>2</mn>
                      </msup>
                      <mo>+</mo>
                      <msup>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <msub>
                              <mi>EI</mi>
                              <mi>y</mi>
                            </msub>
                            <mo>⁡</mo>
                            <mrow>
                              <mo>(</mo>
                              <mrow>
                                <mi>x</mi>
                                <mo>,</mo>
                                <mi>y</mi>
                              </mrow>
                              <mo>)</mo>
                            </mrow>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                        <mn>2</mn>
                      </msup>
                    </mrow>
                  </msqrt>
                </mrow>
              </mtd>
            </mtr>
          </mtable>
          <mo>}</mo>
        </mrow>
      </mtd>
      <mtd>
        <mrow>
          <mo>(</mo>
          <mn>4</mn>
          <mo>)</mo>
        </mrow>
      </mtd>
    </mtr>
  </mtable>
</mrow>
</math>
</maths>
</p>
<p id="p-0042" num="0041">Here, EIx (x, y) and EIy (x, y) represent an edge image with edge component along the X direction extracted and an edge image with edge component along the Y direction extracted, respectively.</p>
<p id="p-0043" num="0042">Thereafter, CPU <b>101</b> performs a smoothing process on the edge image El (x, y) formed in step S<b>3</b>, to form an edge smoothed image EHI (x, y) (S<b>4</b>). In step S<b>4</b>, the edge smoothed image EHI (x, y) is formed by using an average filter. Specifically, a method represented by Equation (5) below using an average filter of 7 pixels×7 pixels is used.</p>
<p id="p-0044" num="0043">
<maths id="MATH-US-00003" num="00003">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>EHI</mi>
          <mo>⁡</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mi>x</mi>
              <mo>,</mo>
              <mi>y</mi>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <mfrac>
            <mn>1</mn>
            <mn>49</mn>
          </mfrac>
          <mo>⁢</mo>
          <mrow>
            <mo>(</mo>
            <mtable>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mn>1</mn>
                </mtd>
              </mtr>
            </mtable>
            <mo>)</mo>
          </mrow>
          <mo>×</mo>
          <mrow>
            <mi>EI</mi>
            <mo>⁡</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>x</mi>
                <mo>,</mo>
                <mi>y</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>5</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0045" num="0044">The method of forming the edge smoothed image EHI (x, y) in step S<b>4</b> is not limited to the method represented by Equation (5) above, and similar processing is possible using an average filter of different size. A larger filter size is advantageous in that the edge image EI (x, y) can be made smoother, while it is disadvantageous in that amount of calculation increases. Through trials, the inventors have found that the filter size of 5 pixels×5 pixels to 11 pixels×11 pixels is preferable, and 7 pixels×7 pixels given in Equation (5) is most preferable.</p>
<p id="p-0046" num="0045">Thereafter, CPU <b>101</b> calculates the difference Diff between edge image EI (x, y) formed in step S<b>3</b> and edge smoothed image EHI (x, y) formed in step S<b>4</b>, in accordance with Equation (6) below.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Diff=EI (x,y)−EHI (x,y)  (6)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0047" num="0046">Then, CPU <b>101</b> binarizes edge image EI (x, y) in accordance with the value of difference Diff calculated in step S<b>5</b>, to form an edge binarized image EB (x, y) (S<b>6</b>). Here, a pixel of which value of difference Diff is larger than a preset threshold value TH is regarded as an edge portion, to form the edge binarized image EB (x, y).</p>
<p id="p-0048" num="0047">In the manner described above, image processing by PC <b>1</b> is completed, and an edge binarized image can be obtained from the image captured by camera <b>2</b>.</p>
<p id="p-0049" num="0048">The value of difference Diff calculated in step S<b>5</b> tends to be relatively large at a portion having a small gradation difference but to be extracted as an edge portion, and the value tends to be very small where the gradation difference changes moderately like a wave. Such tendency will be described with reference to specific examples of image processing above. Though the input image is considered as one-dimensional for convenience of description in the following, it would be readily understood that the same applies similarly to two-dimensional images.</p>
<p id="p-0050" num="0049">Assume that PC <b>1</b> receives the images shown in <figref idref="DRAWINGS">FIG. 9</figref> described above, i.e. the image A-<b>1</b> having large gradation difference, the image B-<b>1</b> having small gradation difference, and the image C-<b>1</b> having gradation difference moderately changing like a wave, as inputs from camera <b>2</b>. CPU <b>101</b> of PC <b>1</b> calculates the difference between adjacent pixels of respective input images A-<b>1</b>, B-<b>1</b> and C-<b>1</b> in step S<b>3</b> described above to extract edge components, and forms the edge images A-<b>4</b>, B-<b>4</b> and C-<b>4</b> shown in <figref idref="DRAWINGS">FIG. 3</figref>, respectively.</p>
<p id="p-0051" num="0050">Thereafter, CPU <b>101</b> of PC <b>1</b> subtracts respective edge smoothed images A-<b>5</b>, B-<b>5</b> and C-<b>5</b> from edge images A-<b>4</b>, B-<b>4</b> and C-<b>4</b>, to obtain results of subtraction A-<b>6</b>, B-<b>6</b> and C-<b>6</b>, as shown in <figref idref="DRAWINGS">FIG. 5</figref>. Specifically, the following calculations are executed to obtain the results A-<b>6</b>, B-<b>6</b> and C-<b>6</b>:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(<i>A</i>-6)=(<i>A</i>-4)−(<i>A</i>-5)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(<i>B</i>-6)=(<i>B</i>-4)−(<i>B</i>-5)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(<i>C</i>-6)=(<i>C</i>-4)−(<i>C</i>-5).<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0052" num="0051">Here, if the threshold value is set to <b>18</b>, for example, to extract the portion {circle around (<b>7</b>)} of edge image B-<b>4</b> as an edge portion, portions {circle around (<b>5</b>)} to {circle around (<b>7</b>)} would be extracted in edge image A-<b>4</b>, resulting in a thick edge portion.</p>
<p id="p-0053" num="0052">When the threshold value is set to 15, for example, to extract the portion {circle around (<b>7</b>)} of input image B-<b>1</b> as an edge portion based on the result of subtraction B-<b>6</b>, only the portion {circle around (<b>7</b>)} in input image A-<b>1</b> is extracted as an edge portion based on the result of subtraction A-<b>6</b>. Namely, edge portions can be extracted successfully from both the portion having large gradation difference and the portion having small gradation difference. Further, it is noted that every pixel value is much lower than the threshold value TH=15 in the result of subtraction C-<b>6</b>, and therefore, an edge portion is not extracted from the portion having the gradation difference changed moderately like a wave.</p>
<p id="p-0054" num="0053">This can be explained with reference to <figref idref="DRAWINGS">FIGS. 6 and 7</figref>. Specifically, when the input image has gradation difference, the pixel values of the edge image change considerably as shown in <figref idref="DRAWINGS">FIG. 6</figref>. Therefore, the portion of the edge image having high pixel values, that is, the edge portion, comes to have large difference from the edge smoothed image. Accordingly, by setting a prescribed threshold value in consideration of the difference between the edge image and the edge smoothed image, the edge portion can be extracted.</p>
<p id="p-0055" num="0054">When the gradation of the input image changes moderately, the change in pixel values of the edge image is small, as can be seen from <figref idref="DRAWINGS">FIG. 7</figref>. Therefore, the difference between the edge image and the edge smoothed image comes to be very small. Accordingly, by setting a prescribed threshold value in consideration of the difference between the edge image and the edge smoothed image, it becomes possible not to extract the peak portion of the wave of the moderately changing gradation as the edge portion.</p>
<p id="p-0056" num="0055">As described above, when the method in which the edge is binarized based on the difference between the edge image and the edge smoothed image is used, it becomes possible to extract the portion having a large gradation difference without making the edge portion thick. Further, the peak portion of the wave of moderately changing gradation is not extracted as an edge portion, and hence, edge detection with higher precision becomes possible.</p>
<p id="p-0057" num="0056">In the embodiment above, it is described that a color image is transformed to a gray scale image and thereafter edge component is extracted, in steps S<b>2</b> and S<b>3</b>. Similar effects can be attained when the process of step S<b>3</b> is performed to extract the edge component in each of the RGB planes of the color image. Further, where it is possible to obtain information close to that of a gray scale image by using only one of the RGB planes of the color image, the process of step S<b>3</b> may be performed only for one color plane.</p>
<p id="p-0058" num="0057">Though it is described in the embodiment above that image processing is performed by PC <b>1</b> on the image captured by camera <b>2</b>, image processing may be performed by camera <b>2</b>, if camera <b>2</b> has such a configuration as shown in <figref idref="DRAWINGS">FIG. 8</figref>. Referring to <figref idref="DRAWINGS">FIG. 8</figref>, when camera <b>2</b> is controlled by a CPU <b>201</b> and performs processing of the image picked-up by image pick-up unit <b>204</b>, the above described image processing may be performed by control unit <b>201</b> executing the program. In this case, the program to be executed by CPU <b>201</b> of camera <b>2</b> is stored in a ROM <b>202</b> as a storage unit. RAM <b>203</b> serves as a temporary storage area when the program is executed by CPU <b>201</b>. The user inputs information and instructions through an operating unit <b>205</b> including buttons or the like. The image picked-up by image pick-up unit <b>204</b>, result of processing thereof and so on are output from an output unit <b>206</b>. Output unit <b>206</b> may be a display unit implemented by a liquid crystal panel, or it may be an I/F for transmitting data to other apparatuses. The configuration shown in <figref idref="DRAWINGS">FIG. 8</figref> represents a general configuration of a digital camera and the like, and the configuration of camera <b>2</b> here is not limited to the one shown in <figref idref="DRAWINGS">FIG. 8</figref>.</p>
<p id="p-0059" num="0058">Further, the method of image processing performed by PC <b>1</b> or camera <b>2</b> as the image processing apparatus described above may be provided as a program. Such a program may be recorded on a computer readable recording medium such as a flexible disk, CD-ROM, ROM or memory card to be used with a computer, and provided as a program product. Alternatively, the program may be provided recorded on a recording medium such as a hard disk mounted inside the computer. Further, the program may be downloaded though a network.</p>
<p id="p-0060" num="0059">The provided program product is installed in a program storing unit such as a hard disk and executed. The program product encompasses the program itself and the recording medium on which the program is recorded.</p>
<p id="p-0061" num="0060">Although the present invention has been described and illustrated in detail, it is clearly understood that the same is by way of illustration and example only and is not to be taken by way of limitation, the spirit and scope of the present invention being limited only by the terms of the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US07298918-20071120-M00001.NB">
<img id="EMI-M00001" he="5.33mm" wi="76.20mm" file="US07298918-20071120-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US07298918-20071120-M00002.NB">
<img id="EMI-M00002" he="58.59mm" wi="76.20mm" file="US07298918-20071120-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00003" nb-file="US07298918-20071120-M00003.NB">
<img id="EMI-M00003" he="26.84mm" wi="76.20mm" file="US07298918-20071120-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image processing apparatus, comprising:
<claim-text>an edge image forming unit extracting an edge from an input image to form an edge image;</claim-text>
<claim-text>an edge smoothed image forming unit smoothing said edge image to form an edge smoothed image;</claim-text>
<claim-text>a difference calculating unit calculating a difference between said edge image and said edge smoothed image; and</claim-text>
<claim-text>a binarizing unit binarizing said edge image based on said difference.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>said edge smoothed image forming unit smoothes said edge image using an average filter of 5 pixels×5 pixels to 11 pixels×11 pixels.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>said input image is a gray scale image; and</claim-text>
<claim-text>said edge image forming unit extracts an edge from said gray scale image to form said edge image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>said input image is an image obtained by transforming a color image to a gray scale image; and</claim-text>
<claim-text>said edge image forming unit extracts an edge from said image obtained by transforming said color image to said gray scale image to form said edge image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The image processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein
<claim-text>said input image is a color image; and</claim-text>
<claim-text>said edge image forming unit extracts an edge from at least one plane of said color image to form said edge image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A computer readable medium containing a computer executable program, said program comprising computer executable code to cause a computer to perform:
<claim-text>an edge smoothed image forming step of forming an edge smoothed image by smoothing an edge image formed based on an input image;</claim-text>
<claim-text>a difference calculating step of calculating a difference between said edge image and said edge smoothed image; and</claim-text>
<claim-text>a binarizing step of binarizing said edge image based on said difference.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The computer readable medium according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the computer executable code is configured to cause a computer to perform the steps such that:
<claim-text>in said edge smoothed image forming step, said edge image is smoothed by using an average filter of 5 pixels×5 pixels to 11 pixels×11 pixels.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The computer readable medium according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the computer executable code is configured to cause a computer to perform the steps such that:
<claim-text>said input image is a gray scale image; and</claim-text>
<claim-text>in said edge smoothed image forming step, said edge smoothed image is formed by smoothing an edge image formed based on said gray scale image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The computer readable medium according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the computer executable code is configured to cause a computer to perform the steps such that:
<claim-text>said input image is an image obtained by transforming a color image to a gray scale image; and</claim-text>
<claim-text>in said edge smoothed image forming step, said edge smoothed image is formed by smoothing an edge image formed based on said image obtained by transforming said color image to said gray scale image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The computer readable medium according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the computer executable code is configured to cause a computer to perform the steps such that:
<claim-text>said image is a color image; and</claim-text>
<claim-text>in said edge smoothed image forming step, said edge smoothed image is formed by smoothing an edge image formed by extracting an edge in at least one plane of said color image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. An image pick-up apparatus, comprising:
<claim-text>an image pick-up unit picking-up an image of an object and capturing an object image;</claim-text>
<claim-text>an edge image forming unit forming an edge image by extracting an edge from said object image;</claim-text>
<claim-text>an edge smoothed image forming unit smoothing said edge image to form an edge smoothed image;</claim-text>
<claim-text>a difference calculating unit calculating a difference between said edge image and said edge smoothed image; and</claim-text>
<claim-text>a binarizing unit binarizing said edge image based on said difference.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The image pick-up apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein
<claim-text>said edge smoothed image forming unit smoothes said edge image using an average filter of 5 pixels×5 pixels to 11 pixels×11 pixels.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The image pick-up apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein said image pick-up unit captures said object image that is a gray scale image.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The image pick-up apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein
<claim-text>said image pick-up unit captures said object image that is a color image; and</claim-text>
<claim-text>said edge image forming unit extracts an edge from an image obtained by transforming said object image that is a color image to a gray scale image, to form said edge image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The image pick-up apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein
<claim-text>said image pick-up unit captures said object image that is a color image; and</claim-text>
<claim-text>said edge image forming unit extracts an edge from at least one plane of said object image that is a color image, to form said edge image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The image pick-up apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein
<claim-text>said image pick-up unit, said edge image forming unit, said edge smoothed image forming unit, said difference calculating unit and said binarizing unit are integrated.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
