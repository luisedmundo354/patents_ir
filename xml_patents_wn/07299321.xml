<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07299321-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07299321</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10713595</doc-number>
<date>20031114</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>616</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>12</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>09</class>
<subclass>G</subclass>
<main-group>5</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>N</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>711154</main-classification>
<further-classification>711100</further-classification>
<further-classification>345701</further-classification>
</classification-national>
<invention-title id="d0e53">Memory and force output management for a force feedback system</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>3157853</doc-number>
<kind>A</kind>
<name>Hirsch</name>
<date>19641100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>3220121</doc-number>
<kind>A</kind>
<name>Cutler</name>
<date>19651100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>3497668</doc-number>
<kind>A</kind>
<name>Hirsch</name>
<date>19700200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>3517446</doc-number>
<kind>A</kind>
<name>Cortyon et al.</name>
<date>19700600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>3902687</doc-number>
<kind>A</kind>
<name>Hightower</name>
<date>19750900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>3903614</doc-number>
<kind>A</kind>
<name>Diamond et al.</name>
<date>19750900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>4160508</doc-number>
<kind>A</kind>
<name>Salsbury</name>
<date>19790700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>4236325</doc-number>
<kind>A</kind>
<name>Hall et al.</name>
<date>19801200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>4513235</doc-number>
<kind>A</kind>
<name>Acklam et al.</name>
<date>19850400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>4581491</doc-number>
<kind>A</kind>
<name>Boothroyd</name>
<date>19860400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>4599070</doc-number>
<kind>A</kind>
<name>Hladky et al.</name>
<date>19860700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>4699043</doc-number>
<kind>A</kind>
<name>Violante De Dionigi</name>
<date>19871000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification> 91182</main-classification></classification-national>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>4708656</doc-number>
<kind>A</kind>
<name>De Vries et al.</name>
<date>19871100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>4713007</doc-number>
<kind>A</kind>
<name>Alban</name>
<date>19871200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>4891764</doc-number>
<kind>A</kind>
<name>McIntosh</name>
<date>19900100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>4930770</doc-number>
<kind>A</kind>
<name>Baker</name>
<date>19900600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>4934694</doc-number>
<kind>A</kind>
<name>McIntosh</name>
<date>19900600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>5019761</doc-number>
<kind>A</kind>
<name>Kraft</name>
<date>19910500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>5022407</doc-number>
<kind>A</kind>
<name>Horch et al.</name>
<date>19910600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>5035242</doc-number>
<kind>A</kind>
<name>Franklin</name>
<date>19910700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>5038089</doc-number>
<kind>A</kind>
<name>Szakaly</name>
<date>19910800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>5078152</doc-number>
<kind>A</kind>
<name>Bond</name>
<date>19920100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>5132927</doc-number>
<kind>A</kind>
<name>Lenoski et al.</name>
<date>19920700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>365 49</main-classification></classification-national>
</citation>
<citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>5186695</doc-number>
<kind>A</kind>
<name>Mangseth et al.</name>
<date>19930200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>5212473</doc-number>
<kind>A</kind>
<name>Louis</name>
<date>19930500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>5240417</doc-number>
<kind>A</kind>
<name>Smithson et al.</name>
<date>19930800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>5247648</doc-number>
<kind>A</kind>
<name>Watkins et al.</name>
<date>19930900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711143</main-classification></classification-national>
</citation>
<citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>5271290</doc-number>
<kind>A</kind>
<name>Fischer</name>
<date>19931200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>5275174</doc-number>
<kind>A</kind>
<name>Cook</name>
<date>19940100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>5299810</doc-number>
<kind>A</kind>
<name>Pierce</name>
<date>19940400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>5309140</doc-number>
<kind>A</kind>
<name>Everett</name>
<date>19940500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>5334027</doc-number>
<kind>A</kind>
<name>Wherlock</name>
<date>19940800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>5457793</doc-number>
<kind>A</kind>
<name>Elko et al.</name>
<date>19951000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707205</main-classification></classification-national>
</citation>
<citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>5466213</doc-number>
<kind>A</kind>
<name>Hogan</name>
<date>19951100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>5547382</doc-number>
<kind>A</kind>
<name>Yamasaki</name>
<date>19960800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>5766016</doc-number>
<kind>A</kind>
<name>Sinclair</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00037">
<document-id>
<country>US</country>
<doc-number>5785630</doc-number>
<kind>A</kind>
<name>Bobick et al.</name>
<date>19980700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00038">
<document-id>
<country>US</country>
<doc-number>6047356</doc-number>
<kind>A</kind>
<name>Anderson et al.</name>
<date>20000400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711129</main-classification></classification-national>
</citation>
<citation>
<patcit num="00039">
<document-id>
<country>US</country>
<doc-number>6111577</doc-number>
<kind>A</kind>
<name>Zilles et al.</name>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00040">
<document-id>
<country>US</country>
<doc-number>6192432</doc-number>
<kind>B1</kind>
<name>Slivka et al.</name>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710 68</main-classification></classification-national>
</citation>
<citation>
<patcit num="00041">
<document-id>
<country>US</country>
<doc-number>6219034</doc-number>
<kind>B1</kind>
<name>Elbing et al.</name>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00042">
<document-id>
<country>US</country>
<doc-number>6295608</doc-number>
<kind>B1</kind>
<name>Parkes et al.</name>
<date>20010900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714  1</main-classification></classification-national>
</citation>
<citation>
<patcit num="00043">
<document-id>
<country>US</country>
<doc-number>6422941</doc-number>
<kind>B1</kind>
<name>Thorner et al.</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00044">
<document-id>
<country>EP</country>
<doc-number>0349086</doc-number>
<date>19900100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00045">
<document-id>
<country>JP</country>
<doc-number>H1-3664</doc-number>
<date>19900700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00046">
<document-id>
<country>JP</country>
<doc-number>H2-109714</doc-number>
<date>19920100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00047">
<document-id>
<country>JP</country>
<doc-number>H4-007371</doc-number>
<date>19930800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00048">
<document-id>
<country>JP</country>
<doc-number>H5-193862</doc-number>
<date>19950100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00049">
<othercit>Scannell, “Taking a Joystick Ride,” Computer Currents, Boston Edition, vol. 9, No. 11, Nov. 1994.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00050">
<othercit>Kontarinis et al., “Display of High-Frequency Tactile Information to Teleoperators,” Telemanipulator Technology and Space Telerobotics, Won S. Kim, Editor, Proc. SPIE vol. 2057, pp. 40-50, Sep. 7-9, 1993.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00051">
<othercit>Patrick et al., “Design and Testing of A Non-reactive, Fingertip, Tactile Display for Interaction with Remote Environments,” Cooperative Intelligent Robotics in Space, Rui J. deFigueiredo et al., Editor, Proc. SPIE vol. 1387, pp. 215-222, 1990.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00052">
<othercit>Adelstein, “A Virtual Environment System For The Study of Human Arm Tremor,” Ph.D. Dissertation, Dept. of Mechanical Engineering, MIT, Jun. 1989.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00053">
<othercit>Bejczy, “Sensors, Controls, and Man-Machine Interface for Advanced Teleoperation,” Science, vol. 208, No. 4450, pp. 1327-1335, 1980.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00054">
<othercit>Bejczy, “Generalization of Bilateral Force-Reflecting Control of Manipulators,” Proceedings Of Fourth CISM-IFToMM, Sep. 8-12, 1981.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00055">
<othercit>McAffee, “Teleoperator Subsystem/Telerobot Demonsdtrator: Force Reflecting Hand Controller Equipment Manual,” JPL D-5172, pp. 1-50, A1-A36, B1-B5, C1-C36, Jan. 1988.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00056">
<othercit>Minsky, “Computational Haptics: The Sandpaper System for Synthesizing Textue for a Force-Feedback Display,” Ph.D. Dissertation, MIT, Jun. 1995.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00057">
<othercit>Jacobsen et al., “High Performance, Dextrous Telerobotic Manipulator With Force Reflection,” Intervention/ROV '91 Conference &amp; Exposition, Hollywood, Florida, May 21-23, 1991.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00058">
<othercit>Shimoga, “Finger Force and Touch Feedback Issues in Dexterous Telemanipulation,” Proceedings of Fourth Annual Conference on Intelligent Robotic Systems for Space Exploration, Rensselaer Polytechnic Institute, Sep. 30-Oct. 1, 1992.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00059">
<othercit>IBM Technical Disclosure Bullein, “Mouse Ball-Actuating Device With Force and Tactile Feedback,” vol. 32, No. 9B, Feb. 1990.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00060">
<othercit>Terry et al., “Tactile Feedback In A Computer Mouse,” Proceedings of Fourteenth Annual Northeast Bioengineering Conference, University of New Hampshire, Mar. 10-11, 1988.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00061">
<othercit>Howe, “A Force-Reflecting Teleoperated Hand System for the Study of Tactile Sensing in Precision Manipulation,” Proceedings of the 1992 IEEE International Conference on Robotics and Automation, Nice, France, May 1992.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00062">
<othercit>Eberhardt et al., “OMAR—A Haptic display for speech perception by deaf and def-blind individuals,” IEEE Virtual Reality Annual International Symposium, Seattle, WA, Sep. 18-22, 1993.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00063">
<othercit>Rabinowitz et al., “Multidimensional tactile displays: Identification of vibratory intensity, frequency, and contractor area,” Journal of The Accoustical Society of America, vol. 82, No. 4, Oct. 1987.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00064">
<othercit>Bejczy et al., “Kinesthetic Coupling Between Operator and Remote Manipulator,” International Computer Technology Conference, The American Society of Mechanical Engineers, San Francisco, CA, Aug. 12-15, 1980.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00065">
<othercit>Bejczy et al., “A Laboratory Breadboard System For Dual-Arm Teleoperation,” SOAR '89 Workshop, JSC, Houston, TX, Jul. 25-27, 1989.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00066">
<othercit>Ouh-Young, “A Low-Cost Force Feedback Joystick and Its Use in PC Video Games,” IEEE Transactions on Consumer Electronics, vol. 41, No. 3, Aug. 1995.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00067">
<othercit>Marcus, “Touch Feedback in Surgery,” Proceedings of Virtual Reality and Medicine The Cutting Edge, Sep. 8-11, 1994.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00068">
<othercit>Bejczy, et al., “Universal Computer Control System (UCCS) For Space Telerobots,” CH2413-3/87/0000/0318501.00 1987 IEEE, 1987.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00069">
<othercit>Aukstakalnis et al., “Silicon Mirage: The Art and Science of Virtual Reality,” ISBN 0-938151-82-7, pp. 129-180, 1992.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00070">
<othercit>Eberhardt et al., “Including Dynamic Haptic Perception by The Hand: System Description and Some Results,” DSC-vol. 55-1, Dynamic Systems and Control: vol. 1, ASME 1994.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00071">
<othercit>Gobel et al., “Tactile Feedback Applied to Computer Mice,” International Journal of Human-Computer Interaction, vol. 7, No. 1, pp. 1-24, 1995.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00072">
<othercit>Pimentel et al., “Virtual Reality: through the new looking glass,” 2<sup>nd </sup>Edition; McGraw-Hill, ISBN 0-07-050167-X, pp. 41-202, 1994.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00073">
<othercit>“Cyberman Technical Specification,” Logitech Cyberman SWIFT Supplement, Apr. 5, 1994.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00074">
<othercit>Ouhyoung et al., “The Development of A Low-Cost Force Feedback Joystick and Its Use in the Virtual Reality Environment,” Proceedings of the Third Pacific Conference on Computer Graphics and Applications, Pacific Graphics '95, Seoul, Korea, Aug. 21-24, 1995.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00075">
<othercit>Kaczmarek et al., “Tactile Displays,” Virtual Environment Technologies.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00076">
<othercit>Baigrie, “Electric Control Loading—A Low Cost, High Performance Alternative,” Proceedings, pp. 247-254, Nov. 6-8, 1990.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00077">
<othercit>Iwata, “Pen-based Haptic Virtual Environment,” 0-7803-1383-1/93 IEEE, pp. 287-292, 1993.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00078">
<othercit>Russo, “The Design and Implementation of a Three Degree of Freedom Force Output Joystick,” MIT Libraries Archives Aug. 14, 1990, pp. 1-131, May 1990.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00079">
<othercit>Brooks et al., “Hand Controllers for Teleoperation—A State-of-the-Art Technology Survey and Evaluation,” JPL Publication 85-11; NASA-CR-175890; N85-28559, pp. 1-84, Mar. 1, 1985.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00080">
<othercit>Jones et al., “A perceptual analysis of stiffness,” ISSN 0014-4819 Springer International (Springer-Verlag); Experimental Brain Research, vol. 79, No. 1, pp. 150-156, 1990.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00081">
<othercit>Burdea et al., “Distributed Virtual Force Feedback, Lecture Notes for Workshop on Force Display in Virtual Environments and its Application to Robotic Teleoperation,” 1993 IEEE International Conference on Robotics and Automation, pp. 25-44, May 2, 1993.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00082">
<othercit>Snow et al., “Model-X Force-Reflecting-Hand-Controller,” NT Control No. MPO-17851; JPL Case No. 5348, pp. 1-4, Jun. 15, 1989.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00083">
<othercit>Ouh-Young, “Force Display in Molecular Docking,” Order No. 9034744, p. 1-389, 1990.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00084">
<othercit>Tadros, Control System Design for a Three Degree of Freedom Virtual Environment Simulator Using Motor/Brake Pair Actuators, MIT Archive© Massachusetts Institute of Technology, pp. 1-88, Feb. 1990.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00085">
<othercit>Caldwell et al., “Enhanced Tactile Feedback (Tele-Traction) Using a Multi-Functional Sensory System,” 1050-4729/93, pp. 955-960, 1993.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00086">
<othercit>Adelstein, “Design and Implementation of a Force Reflecting Manipulandum for Manual Control research,” DSC-vol. 42, Advances in Robotics, Edited by H. Kazerooni, pp. 1-12, 1992.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00087">
<othercit>Gotow et al, “Controlled Impedance Test Apparatus for Studying Human Interpretation of Kinesthetic Feedback,” WA11-11:00, pp. 332-337; Jun. 21, 1989.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00088">
<othercit>Stanley et al., “Computer Simulation of Interacting Dynamic Mechanical Systems Using Distributed Memory Parallel Processors,” DSV-vol. 42, Advances in Robotics, pp. 55-61, ASME 1992.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00089">
<othercit>Russo, “Controlling Dissipative Magnetic Particle Brakes in Force Reflective Devices,” DSC-vol. 42, Advances in Robotics, pp. 63-70, ASME 1992.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00090">
<othercit>Kaczmarek et al., “Tactile Displays,” Virtual Environment Technologies, 1995.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>6</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>711100</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711118</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711133</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711134</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711135</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711136</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711167</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711154</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>711159</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>710 57</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>341 20</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>341 27</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345701</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345702</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>9</number-of-drawing-sheets>
<number-of-figures>11</number-of-figures>
</figures>
<us-related-documents>
<division>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>10060472</doc-number>
<kind>00</kind>
<date>20020129</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>6715045</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>10713595</doc-number>
</document-id>
</child-doc>
</relation>
</division>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>09401564</doc-number>
<kind>00</kind>
<date>19990922</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>6343349</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>10060472</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>09305872</doc-number>
<kind>00</kind>
<date>19990505</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>6252583</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>09401564</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<continuation-in-part>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>08970953</doc-number>
<kind>00</kind>
<date>19971114</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>6300936</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>09305872</doc-number>
</document-id>
</child-doc>
</relation>
</continuation-in-part>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20040104924</doc-number>
<kind>A1</kind>
<date>20040603</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Braun</last-name>
<first-name>Adam C.</first-name>
<address>
<street>1316 Oxbow Ct.</street>
<city>Sunnyvale</city>
<state>CA</state>
<postcode>94087</postcode>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Beamer</last-name>
<first-name>Jonathan L.</first-name>
<address>
<street>1202 Cloud Ave.</street>
<city>Menlo Park</city>
<state>CA</state>
<postcode>94025</postcode>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Chang</last-name>
<first-name>Dean C.</first-name>
<address>
<street>2885 Stevenson St.</street>
<city>Santa Clara</city>
<state>CA</state>
<postcode>95051</postcode>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Kilpatrick Stockton LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<examiners>
<primary-examiner>
<last-name>Thai</last-name>
<first-name>Tuan V.</first-name>
<department>2186</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Methods and apparatus for efficient management of memory and force output in a force feedback system including a host computer and a force feedback device. A representation of device memory is maintained on the host computer to allow the host computer knowledge and control over storage and force effects in the device memory. A host cache for force effects is provided to allow almost unlimited numbers of force effects to be created for the device, where any force effects not able to fit in device memory are stored in the host cache. Other aspects of the invention include a playlist stored on the device of force effects being played by the device, and management of force output using relatively small, discrete time intervals.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="238.76mm" wi="181.36mm" file="US07299321-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="239.52mm" wi="181.86mm" file="US07299321-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="224.79mm" wi="155.62mm" file="US07299321-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="204.64mm" wi="140.72mm" file="US07299321-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="246.89mm" wi="189.82mm" file="US07299321-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="248.92mm" wi="185.42mm" file="US07299321-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="247.65mm" wi="177.29mm" file="US07299321-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="240.79mm" wi="190.25mm" file="US07299321-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="144.61mm" wi="157.90mm" file="US07299321-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="136.91mm" wi="151.47mm" file="US07299321-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application claims the benefit of and is a divisional of U.S. application Ser. No. 10/060,472, filed Jan. 29, 2002, now U.S. Pat. No. 6,715,045, which is a continuation of U.S. application Ser. No. 09/401,564, filed on Sep. 22, 1999, now U.S. Pat. No. 6,343,349, which is a continuation of U.S. application Ser. No. 09/305,872, filed on May 5, 1999, now U.S. Pat. No. 6,252,583, which is a continuation-in-part of U.S. application Ser. No. 08/970,953, filed Nov. 4, 1997, now U.S. Pat. No. 6,300,936, each of which is assigned to the assignee of the present application, and each of which is incorporated in its entirety herein by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention relates generally to interface devices for allowing humans to interface with computer systems, and more particularly to computer interface devices that allow the user to provide input to computer systems and provide force feedback to the user.</p>
<p id="p-0004" num="0003">Computer systems are used extensively to implement many applications, such as word processing, data management, simulations, games, and other tasks. A computer system typically displays a visual environment to a user on a display screen or other visual output device. Users can interact with the displayed environment to perform functions on the computer, play a game, experience a simulated environment, use a computer aided design (CAD) system, etc. One visual environment that is particularly common is a graphical user interface (GUI), and include such systems as the Windows™ operating system from Microsoft Corporation, the MacOS operating system from Apple Computer, Inc., and X-Windows for the Unix operating system. Most GUI's are currently 2-dimensional as displayed on a computer screen; however, three dimensional (3-D) GUI's with 3-D environments can also be provided. Other graphical environments include games, simulations, CAD environments, World Wide Web/Internet interfaces, etc. which present 2-D or 3-D interactive environments manipulatable by the user.</p>
<p id="p-0005" num="0004">The user interaction with and manipulation of the computer environment is achieved using any of a variety of types of human-computer interface devices that are connected to the computer system controlling the displayed environment. In most systems, an application program running on the host computer updates the environment in response to the user's manipulation of a user manipulandum that is included in the interface device, such as a mouse, joystick handle, track ball, steering wheel, etc. The computer provides feedback to the user utilizing the display screen.</p>
<p id="p-0006" num="0005">Force feedback interface devices allow a user to experience forces on the manipulandum based on interactions and events within the displayed graphical environment. Force feedback devices can be implemented in many forms, such as a joystick, mouse, steering wheel, etc. Typically, computer-controlled actuators are used to output forces on the user object in provided degrees of freedom to simulate various sensations, such as an obstruction force when moving a cursor into a wall, a vibration force when a virtual race car drives off a race track, or a spring force to bias a cursor to move back toward a starting position of the spring.</p>
<p id="p-0007" num="0006">Force sensations are usually commanded to be output on the device by the application program running on the host computer. Most consumer-market force feedback devices include a microprocessor and memory to parse host commands and store and manage various force feedback effects local to the device. The device microprocessor can check user input and other conditions based on commands from the host, and can output force sensations using the force sensation data stored in local memory. The local management of force sensations on the device greatly increases the realism of generated force sensations due to the responsiveness of the device processing; if the host had to process all input and generate all forces, the transmission of data between host and device would cause delays in responsiveness that would seriously degrade the quality of force sensations. Thus, the ability of the device to store force sensation data and independently command those force sensations when conditions warrant is critical to realistic force feedback.</p>
<p id="p-0008" num="0007">When providing force feedback sensations on a force feedback device, several issues arise as to the management of force feedback sensations. One problem is that the memory on the force feedback device is limited due to cost concerns. A device may only be able to store a certain limited number of force sensation data (“force effects”) before the local memory is filled. An application program, however, may require a large number of different force effects to be output during different conditions and events in the program. For example, a racing game program may wish to output 20 different force effects for various racing conditions during a game; however, the device may only be able to store data for 10 force effects at a time.</p>
<p id="p-0009" num="0008">Since data for a force effect should be stored local to the device before the force is output, the application program must first attempt to store effect data to the device. One existing way to store force effects on a device is for the host application to send a request to the device to store a specified force effect in device memory. The device determines if sufficient memory is available and responds to the host that either the requested force effect has been stored in device memory, or that the requested force effect could not be stored due to lack of sufficient space. If the effect could not be stored, the host application can send a “destroy” command to the device to remove a currently-unused force effect from device memory to free up sufficient room for the requested force effect, and then send the request again to store the new force effect. However, this method can cause some degradation in force quality on the device since the device and host must transmit data several times back and forth to free up device memory and store a new force effect.</p>
<p id="p-0010" num="0009">In addition, since the device memory usually cannot store all the force effects which a host application wishes to use, the host application must spend processing time for memory management tasks. For example, the host application must determine whether to swap out an old force effect in device memory with a new force effect and then command that such a swap take place. The application must keep track of how much space is available in device memory and which force effects are currently being output. Such extra processing by the host application can degrade the overall performance of the application and compels the designer of the application to focus on low-level processing, thereby detracting from the higher-level force design process.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0011" num="0010">The present invention is directed to memory management of force effects and other management of force sensations for a force feedback system. Embodiments are disclosed which provide for efficient management of device memory and force effect output.</p>
<p id="p-0012" num="0011">More specifically, the present invention provides force effects with a force feedback device having local control of the output of force sensations. A representation of device memory is created, where the device memory is provided on the force feedback device, and the representation is allocated in memory of the host computer. A force effect load command is received from an application program running on the host, where the force effect load command instructs that data for a force effect be stored in the device memory. It is then determined whether the device memory can store the force effect by examining the representation of device memory. If the device memory can store the force effect, the data for the force effect is send to the force feedback device to be stored in the device memory. The force feedback device uses the data to control a force output to a user of the force feedback device. If the device memory can store the force effect, the data for said force effect can be stored in a location of the representation of device memory, or an indication of the memory space taken by the force effect can be stored. The application program can later send a play command or a stop command, which is sent to the force feedback device to output or stop the output of force based on the loaded force effect. The total number of playing force effects loaded to the device are summed to provide the total output force on the user.</p>
<p id="p-0013" num="0012">In a different aspect of the present invention, the management of storage of force effects in a force feedback system includes receiving a force effect create command by a driver running on the host computer. The command is sent from an application program running on the host computer and instructs that particular force effect data for a particular force effect be stored in memory local to the force feedback device. It is then determined whether the local memory has sufficient space to store the particular force effect data. If there is sufficient space, the particular force effect data is sent to the force feedback device to be stored in the local memory. If there is not sufficient space, the particular force effect data is stored in a cache implemented in host computer memory instead of the local memory. When a command is later received by the driver to output the cached force effect to a user of the force feedback device, the driver swaps the particular force effect data with loaded force effect data in the local memory and instructs the force feedback device to output the particular force effect.</p>
<p id="p-0014" num="0013">Preferably, the driver creates a representation of the local memory in the host computer memory, and the representation can be examined for sufficient space for the force effect. Alternatively, the force feedback device can be queried and a response can be received indicating whether sufficient space is available. In addition, it can be determined whether a force effect can be loaded by comparing a priority of the particular force effect with a priority of one or more loaded force effects, where the greater priority effect can be loaded to the device memory. Priority of the loaded force effect(s) can be determined based at least partially on whether the loaded force effect is currently being output by the device, on the time period since the loaded force effect was last output by said device, and/or on whether said loaded force effect is likely to be output based on a direction of movement of a manipulandum of the force feedback device in a workspace of the manipulandum of the device. The priority can also be predefined, e.g. by the application program. Furthermore, force effects can be grouped in categories to help determine which loaded force effects can be swapped with cached force effects. An apparatus for managing storage of effect using a host cache operates as described above.</p>
<p id="p-0015" num="0014">In a different aspect of the present invention, forces are output from a force feedback device coupled to a host computer. A force effect play command is received from the host computer which instructs that a particular force effect be output by the force feedback device. The data for the particular force effect and data for at least one other force effect is stored in a memory local to the force feedback device. An identification of the particular force effect is designated in a playlist in local memory. When a force is to be output, the playlist is examined to determine which of the stored force effects are to be output. A force is then determined based on the force effects designated in the playlist and the force is output to a user of the force feedback device. Preferably, the output force is based on a sum of contributions from the force effects designated in the playlist. A number can be stored in local memory indicating how many the force effects stored in local memory are currently designated to be output. This allows efficient access to only the playing force effects on the device.</p>
<p id="p-0016" num="0015">In yet another aspect of the present invention, force output is provided to a user of a force feedback device only at predetermined time intervals. A first force to be output by actuators of the force feedback device is determined and then output at a first point in time occurring when a predetermined time interval has passed. A second force to be output is then determined. If the predetermined time interval has not passed when the second force has been determined, then the device waits for a second time interval and outputs the second force at a second point in time. If the predetermined time interval has passed when the second force has been determined, indicating the processing of the force has taken longer than one time interval, then the device waits for a successive time interval after an integer number of the predetermined time intervals has passed, and outputs a third force at the successive point in time. The third force is appropriate to the successive point in time. For example, the first force and the second force can be at least partially based on a periodic function that varies with time, so that the third force is based on an appropriate later point of the periodic function. This allows a small time interval to be used and thus faster updating of output forces; during infrequent intervals where force processing takes longer than one time interval, the force can be output at later intervals.</p>
<p id="p-0017" num="0016">The present invention provides several embodiments for managing force effect and force output in a force feedback system. A representation of the device memory is preferably maintained in host computer memory to allow the host computer to efficiently determine when effects can be loaded in device memory. Host caching of force effects allows the application program to function as if the device can store an almost unlimited number of effects, thereby freeing the application from managing low-level processing and swapping of force effects. The playlist and discrete interval force output on the force feedback device allows efficient and high fidelity output of force sensations.</p>
<p id="p-0018" num="0017">These and other advantages of the different embodiments of the present invention will become apparent to those skilled in the art upon a reading of the following specification of the invention and a study of the several figures of the drawing.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram illustrating a force feedback system suitable for use with the present invention;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram illustrating a hierarchy of programs running on the host computer in the force feedback system of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 3</figref> is a diagrammatic illustration of an example force effect structure which can be used in the present invention;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 4</figref> is a diagrammatic illustration of an organization of device memory in the force feedback device of the system of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 5</figref> is a flow diagram illustrating a method of the present invention for host management of force effects using a host representation of device memory;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 6</figref> is a flow diagram illustrating a process for outputting forces running on the force feedback device;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 7</figref> is a flow diagram illustrating a method of the present invention for host management of force effects using a device memory representation and host caching of force effects;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 8</figref> is a diagrammtic illustration of a graphical user interface and cursor for illustrating the spatial caching of the present invention;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIGS. 9</figref><i>a </i>and <b>9</b><i>b </i>are diagrammatic illustrations of device memory, the host representation thereof, and force effects stored in each; and</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 10</figref> is a diagrammatic illustration of device memory and a playlist of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS</heading>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram illustrating a force feedback system <b>10</b> suitable for use with the present invention. System <b>10</b> includes a host computer <b>18</b> and a force feedback interface device <b>11</b>. A similar system is described in detail in patent application Ser. No. 08/970,953 and U.S. Pat. No. 5,734,373, which are incorporated herein by reference.</p>
<p id="p-0030" num="0029">Host computer <b>18</b> is preferably a personal computer or workstation, such as a PC compatible computer or Macintosh personal computer, or a SUN or Silicon Graphics workstation. Alternatively, host computer system <b>18</b> can be one of a variety of home video game systems commonly connected to a television set, such as console systems available from Nintendo, Sega, or Sony. In other embodiments, host computer system <b>18</b> can be a “set top box” which can be used, for example, to provide interactive television functions to users, or a “network-” or “internet-computer” which allows users to interact with a local or global network using standard connections and protocols such as used for the Internet and World Wide Web.</p>
<p id="p-0031" num="0030">Host computer <b>18</b> commonly includes a host microprocessor <b>108</b>, random access memory (RAM) <b>110</b>, read-only memory (ROM) <b>112</b>, input/output (I/O) electronics <b>114</b>, a clock <b>116</b>, a display device <b>20</b>, and an audio output device <b>118</b>. Host microprocessor <b>108</b> can include a variety of available microprocessors from Intel, AMD, Motorola, or other manufacturers. Microprocessor <b>108</b> preferably retrieves and stores instructions and other necessary data from RAM <b>110</b> and ROM <b>112</b> as is well known to those skilled in the art. In the described embodiment, host computer <b>18</b> can receive sensor data or a sensor signal via a bus <b>120</b> from sensors of device <b>11</b> and other information. Microprocessor <b>108</b> can receive data from bus <b>120</b> using I/O electronics <b>114</b>, and can use the I/O electronics, bus <b>120</b>, and/or other buses to control other peripheral devices, such as disk drives, hard drives, CDROM, DVDROM, non-volatile memory etc. Host computer <b>18</b> can also output commands to interface device <b>11</b> via bus <b>120</b> to cause force feedback for the system <b>10</b>.</p>
<p id="p-0032" num="0031">Computer <b>18</b> can operate under the Window™, MacOS, Unix, or other operating systems, or other software. Host computer <b>18</b> preferably implements one or more application programs (“applications”) with which a user is interacting via mouse <b>12</b> and other peripherals, if appropriate, and which can include force feedback functionality. For example, the host applications can include a simulation, video game, Web page or browser that implements HTML or VRML instructions, word processor, drawing program, spreadsheet, scientific analysis program, or other application program that utilizes user input from device <b>11</b> and outputs force feedback commands to the device <b>11</b>. In the preferred embodiment, multiple applications can run simultaneously in a multitasking environment of the host computer. Herein, computer <b>18</b> may be referred as displaying “graphical objects” or “computer objects.” These objects are not physical objects, but are logical software unit collections of data and/or procedures that may be displayed as images by computer <b>18</b> on display screen <b>20</b>, as is well known to those skilled in the art. A displayed cursor or a simulated cockpit of an aircraft might be considered a graphical object. Suitable software drivers which interface such applications with computer input/output (I/O) devices are available from Immersion Corporation of San Jose, Calif.</p>
<p id="p-0033" num="0032">Display device <b>20</b> can be included in host computer <b>18</b> and can be a standard display screen (LCD, CRT, etc.), 3-D goggles, or any other visual output device. Typically, the host application provides images to be displayed on display device <b>20</b>. For example, display screen <b>20</b> can display images from a GUI, from a moving, first person point of view in a virtual reality game, a third-person perspective of objects, backgrounds, a simulation (such as a medical simulation), etc.</p>
<p id="p-0034" num="0033">Clock <b>116</b> is a standard clock crystal or equivalent component used by host computer <b>18</b> to provide timing to electrical signals used by host microprocessor <b>108</b> and other components of the computer <b>18</b>. Audio output device <b>118</b>, such as speakers, can be coupled to host microprocessor <b>108</b> via amplifiers, filters, and other circuitry well known to those skilled in the art. Host processor <b>108</b> outputs signals to speakers <b>118</b> to provide sound output to the user when an “audio event” occurs during the implementation of the host application program. Other types of peripherals can also be coupled to host processor <b>108</b>, such as storage devices (hard disk drive, CD ROM drive, floppy disk drive, etc.), printers, and other input and output devices.</p>
<p id="p-0035" num="0034">Force feedback device <b>11</b> is coupled to host computer system <b>18</b> by a bi-directional bus <b>120</b>. The bi-directional bus sends data in either direction between host computer system <b>18</b> and the interface device <b>11</b>. Bus <b>120</b> can be a serial interface bus providing data according to a serial communication protocol, a parallel bus using a parallel protocol, or other types of buses. An interface port of host computer system <b>18</b>, such as a USB or RS232 serial interface port, connects bus <b>120</b> to host computer system <b>18</b>. Alternatively, Firewire (also called IEEE 1394) can be used as bus <b>120</b>; or, the bus can be between an interface card in the host computer <b>18</b>, where the interface card holds components of device <b>11</b> such as microprocessor <b>130</b>. In other embodiments, signals can be sent between interface <b>14</b> and computer <b>18</b> by wireless transmission/reception.</p>
<p id="p-0036" num="0035">Force feedback device <b>11</b> includes an electronic interface <b>26</b>, a mechanical portion <b>24</b>, and a manipulandum or “user object” <b>12</b>. Electronic interface <b>26</b>, mechanical portion <b>24</b>, and user object <b>12</b> can also collectively be considered the force feedback device <b>11</b>.</p>
<p id="p-0037" num="0036">The electronic portion <b>26</b> of interface <b>14</b> may couple the mechanical portion <b>24</b> of the interface to the host computer <b>18</b>. The electronic portion <b>26</b> is preferably included within a housing of the device <b>11</b> or, alternatively, the electronic portion may be included in host computer <b>18</b> or as a separate unit with its own housing. Electronic interface <b>26</b> includes a local microprocessor <b>130</b>, local clock <b>132</b>, local memory <b>134</b>, sensor interface <b>136</b>, and actuator interface <b>138</b>. Interface <b>26</b> may also include additional electronic components for communicating via standard protocols on bus <b>120</b>. In various embodiments, electronic interface <b>26</b> or components thereof can be included in mechanical portion <b>24</b>, in host computer <b>18</b>, or in its own separate housing.</p>
<p id="p-0038" num="0037">Local microprocessor <b>130</b> preferably coupled to bus <b>120</b> and may be closely linked to mechanical portion <b>24</b> to allow fast communication with other components of the interface device. Processor <b>130</b> is considered “local” to interface device <b>11</b>, where “local” herein refers to processor <b>130</b> being a separate microprocessor from any processors <b>108</b> in host computer <b>18</b>. “Local” also preferably refers to processor <b>130</b> being dedicated to force feedback and sensor I/O of the system <b>10</b>, and being closely coupled to sensors and actuators of the mechanical portion <b>24</b>, such as within the housing of or in a housing coupled closely to portion <b>24</b>. Microprocessor <b>130</b> can be provided with software instructions to wait for commands or requests from computer host <b>18</b>, parse/decode the command or request, and handle/control input and output signals according to the command or request. In addition, processor <b>130</b> preferably operates independently of host computer <b>18</b> by reading sensor signals and calculating appropriate forces from those sensor signals, time signals, and force processes selected in accordance with a host command, and output appropriate control signals to the actuators. A suitable microprocessor for use as local microprocessor <b>130</b> includes the 8X930AX by Intel; or alternatively the MC68HC711E9 by Motorola or the PIC16C74 by Microchip, for example. Microprocessor <b>130</b> can include one microprocessor chip, or multiple processors and/or co-processor chips. In other embodiments, microprocessor <b>130</b> can include digital signal processor (DSP) functionality or be implemented as state logic or circuitry.</p>
<p id="p-0039" num="0038">In a local control embodiment that utilizes microprocessor <b>130</b>, host computer <b>18</b> provides high level supervisory commands to microprocessor <b>130</b> over bus <b>120</b>, and microprocessor <b>130</b> manages low level force control loops to sensors and actuators in accordance with the high level commands and independently of the host computer <b>18</b>. The microprocessor <b>130</b> can process inputted sensor signals to determine appropriate output actuator signals by following the instructions of a “force process” that may be stored in local memory and includes calculation instructions, formulas, force magnitudes, or other data. The force process can command distinct force sensations, such as vibrations, textures, jolts, or even simulated interactions between displayed objects. The microprocessor can be provided with the necessary instructions or data to check sensor readings, determine graphical object positions, and determine output forces independently of host computer <b>18</b>. The host can implement program functions (such as displaying images) when appropriate, and synchronization commands can be communicated between the microprocessor and host <b>18</b> to correlate the microprocessor and host processes. Sensor signals (and/or processed sensor signals) received and used by microprocessor <b>130</b> are also reported to host computer system <b>18</b>, which updates the host application program. Such commands and related functionality is discussed in greater detail in U.S. Pat. No. 5,734,373. The host can send the local processor a spatial layout of objects in the graphical environment to store in local memory <b>134</b> so that the microprocessor has a mapping of locations of graphical objects like enclosures and can determine interactions with the cursor locally. Alternatively, the computer <b>18</b> can directly send force feedback signals to the microprocessor <b>130</b> to be directly output to actuators and provide forces on user object <b>12</b>. Force feedback used in graphical environments is described in greater detail in co-pending patent application Ser. Nos. 08/571,606, and 08/924,462, and U.S. Pat. No. 5,825,308, all of which are incorporated by reference herein. In a different embodiment, host computer <b>18</b> can provide low-level force commands over bus <b>120</b>, which microprocessor <b>130</b> directly transmits to the actuators.</p>
<p id="p-0040" num="0039">A local clock <b>132</b> can be coupled to the microprocessor <b>130</b> to provide timing data, similar to system clock <b>116</b> of host computer <b>18</b>; the timing data might be required, for example, to compute forces output by actuators <b>64</b> (e.g., forces dependent on calculated velocities, accelerations, or other time dependent factors). In alternate embodiments using the USB communication interface or other bus having a synchronization signal, timing data for microprocessor <b>130</b> can be retrieved from the USB interface.</p>
<p id="p-0041" num="0040">Local memory <b>134</b>, such as RAM and/or ROM, is preferably coupled to microprocessor <b>130</b> in interface <b>26</b> to store force sensations (“force effects”), other instructions for microprocessor <b>130</b>, and store temporary and other data. Microprocessor <b>130</b> may also store calibration parameters in a local memory <b>134</b>. Memory <b>134</b> may also be used to store the state of the force feedback device, including a reference position, current control mode or configuration, etc. Memory management techniques of the present invention for local memory <b>34</b> are described in greater detail below.</p>
<p id="p-0042" num="0041">Sensor interface <b>136</b> may optionally be included in electronic interface <b>26</b> to convert sensor signals to signals that can be interpreted by the microprocessor <b>130</b> and/or host computer system <b>18</b>. Such circuits, or equivalent circuits, are well known to those skilled in the art. Alternately, microprocessor <b>130</b> or host <b>18</b> can perform these interface functions. Actuator interface <b>138</b> can be optionally connected between the actuators <b>64</b> and microprocessor <b>130</b> to convert signals from microprocessor <b>130</b> into signals appropriate to drive the actuators. Interface <b>138</b> can include power amplifiers, switches, digital to analog controllers (DACs), and other components as well known to those skilled in the art. In alternate embodiments, interface <b>138</b> circuitry can be provided within microprocessor <b>130</b> or in the actuators. Power supply <b>140</b> can be used to supply power to the actuators <b>64</b> and other components. Power can also be supplied by the host computer over USB <b>120</b>.</p>
<p id="p-0043" num="0042">Mechanical portion <b>24</b> is coupled to electronic portion <b>26</b> and preferably includes sensors <b>62</b>, actuators <b>64</b>, and mechanism <b>40</b>. Sensors <b>62</b> sense the position, motion, and/or other characteristics of manipulandum <b>12</b> along one or more degrees of freedom and provide signals to microprocessor <b>130</b> including information representative of those characteristics. A sensor <b>62</b> is provided for each degree of freedom of the manipulandum <b>12</b>, or, a single compound sensor can be used for multiple degrees of freedom. Example of sensors suitable for embodiments described herein are rotary optical encoders, as described above, linear optical encoders, analog sensors such as potentiometers, or non-contact sensors, such as Hall effect magnetic sensors or an optical sensor such as a lateral effect photo diode having an emitter/detector pair. In addition, velocity sensors (e.g., tachometers) and/or acceleration sensors (e.g., accelerometers) for measuring acceleration can be used. Furthermore, either relative or absolute sensors can be employed.</p>
<p id="p-0044" num="0043">Actuators <b>64</b> transmit forces to user object <b>12</b> in one or more directions along one or more degrees of freedom in response to signals output by microprocessor <b>130</b> and/or host computer <b>18</b>, i.e., they are “computer controlled.” Typically, an actuator <b>64</b> is provided for each degree of freedom along which forces are desired to be transmitted. Actuators <b>64</b> can be electromagnetic actuators such as DC motors, or can be other active actuators, such as linear current control motors, stepper motors, pneumatic/hydraulic active actuators, a torquer (motor with limited angular range), voice coil motors; or passive actuators such as magnetic particle brakes, friction brakes, or pneumatic/hydraulic passive actuators, passive damper elements, an electrorheological fluid actuator, a magnetorheological fluid actuator. In some embodiments, all or some of sensors <b>62</b> and actuators <b>64</b> can be included together as a sensor/actuator pair transducer.</p>
<p id="p-0045" num="0044">Mechanism <b>40</b> can any of several types of mechanisms. For example, mechanisms disclosed in co-pending patent applications Ser. Nos., 08/664,086, 08/709,012, and 08/736,161, or U.S. Pat. Nos. 5,623,582, 5,731,804, 5,767,839, 5,721,566, 5,805,140, and 5,691,898, all incorporated herein by reference, can be included.</p>
<p id="p-0046" num="0045">User object <b>12</b> is a physical object that is preferably grasped or gripped and manipulated by a user. By “grasp,” it is meant that users may physically engage a portion of the object in some fashion, such as by hand, with their fingertips, etc. A great number of types of user manipulable objects can be used with the method and apparatus of the present invention. For example, such objects may include a mouse, sphere, a puck, a joystick, cubical- or other-shaped hand grips, a fingertip receptacle for receiving a finger or a stylus, a flat planar surface like a plastic card having a rubberized, contoured, and/or bumpy surface, a gamepad, a steering wheel, a pool cue, a handheld remote control used for controlling web pages or other devices, or other objects.</p>
<p id="p-0047" num="0046">Other input devices <b>141</b> can optionally be included in system <b>10</b> and send input signals to microprocessor <b>130</b> and/or host computer <b>18</b>. Such input devices can include buttons, switches, dials, knobs, or other controls used to supplement the input from the user to an application program. Also, voice recognition hardware (with software implemented by host <b>18</b>), or other input mechanisms can be used. Safety or “deadman” switch <b>150</b> is preferably included in interface device to provide a mechanism to allow a user to deactivate actuators <b>64</b> for safety reasons. The user must continually close safety switch <b>150</b> during manipulation of user object to enable the actuators <b>64</b>. A capacitive contact sensor, mechanical switch, electrostatic contact switch, or optical switch, z-axis force sensor, piezo electric sensor, force sensitive resistor, a strain gauge, or a hand weight safety switch can be used to sense the presence of the user's contact with the user object.</p>
<heading id="h-0006" level="1">Host Computer Force Feedback Architecture</heading>
<p id="p-0048" num="0047">The host computer <b>18</b> interacts with interface device <b>11</b>, in the present invention, using a number of different levels of controllers. These controllers are preferably implemented in software, e.g. program instructions or code, and such is the embodiment described herein; however, all or part of the controllers may also be implemented in hardware, where the conversion of functionality of the software to hardware is well known to those skilled in the art. The architecture described herein is oriented towards providing force feedback functionality for a system including a host computer connected to a force feedback interface device, where the interface device stores force information from the host and receives commands from the host to implement forces based on the stored information. The described architecture is most applicable to a computer such as a PC, Macintosh, workstation, etc., and is not as applicable to other host computers such as console game systems. However, such other systems often include the equivalent to many of the described control levels. For example, a game program on a console can be considered an application and a library on the console that is accessed by function calls from the game program can be the equivalent of the API and/or translation layers.</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of a preferred architecture for the host computer to communicate with and control a force feedback interface device <b>11</b>. One or more application programs <b>202</b> and <b>204</b> can be running on the host computer <b>18</b> (concurrently, if more than one application is running). If more than one application is running, one of the application programs is actively running in an operating system as the “active” application program (also known as the application program that is “in focus” or which has “keyboard focus”). In a GUI, the active window is typically the topmost displayed window in which input is provided by the user using the mouse-controlled cursor, a keyboard, or other peripheral. The other applications are “inactive” in that they are not receiving input from the user (although they may have a window displayed in the GUI which can be updated on the screen). The inactive applications may also receive input or send output from other sources, such as peripherals. For example, the Window™ operating system from Microsoft Corp. provides a multitasking or pseudo-multitasking environment in which programs run simultaneously; other operating systems such as Unix also offer multitasking. For example, a word processor may be the active application to receive input from the keyboard and display input characters in a displayed active window on display screen <b>20</b>, while a inactive communication program may be receiving data over a network and saving the data on a storage device, or sending data out to be printed. When the user moves the cursor over an inactive window and provides a command gesture such as clicking a button on a mouse, the inactive window becomes the active window and the former active window becomes inactive. Alternatively, the active application program may take control of the entire screen; for example, an active game program may display its environment exclusively on a full screen rather than in a window of the GUI. The active and inactive applications are also known as “foreground” applications, as opposed to the background application described below.</p>
<p id="p-0050" num="0049">A master application <b>206</b> may also be running on host computer <b>18</b> and is referred to as the “background” force feedback application. This application is preferably a general purpose program that always runs inactively in the operating system and whose set of commanded forces are always available to be output and controlled on the interface device <b>11</b> and/or other devices. An example interface window for master application is a “desktop” control panel for force feedback, described in greater detail in the parent application Ser. No. 08/970,953. The types of forces possible to be output by the device are described in greater detail in co-pending patent applications Ser. Nos. 08/839,249 and 08/877,114 and U.S. Pat. No. 5,734,373, all incorporated by reference herein.</p>
<p id="p-0051" num="0050">The force sensations specified by the background application will be output by the force feedback device by default, unless a different foreground application program deactivates the force sensations or replaces a force sensation with its own. For example, a background-specified snap force is preferably applied to all menus of all running application programs in the GUI, since it is a background force effect. If the foreground active application program has its own force sensations which define that application's menus to have a jolt instead of a snap, then the jolt will be superimposed on the snap unless the active application program deactivates the background force(s). In general, a particular active application program can only command forces to objects of its own, e.g., that application's own menus, windows, scrollbars, icons, window borders, etc.</p>
<p id="p-0052" num="0051">A user can specify multiple background force sensations for each graphical object. This allows the multiple force sensations to be superimposed on each other, unless the application program overrides one or more of the superimposed forces. Thus, a user can assign a damper force sensation and a “ticks” force sensation to scrollbars, and all scrollbars will have these forces associated with them unless overridden by the foreground application program. Other controls in the background application can include a device gain to set the percentage of maximum magnitude for all the forces of the background application.</p>
<p id="p-0053" num="0052">Application programs <b>202</b>, <b>204</b>, and <b>206</b> communicate with a force feedback Application Programming Interface (“API”) <b>208</b> which is resident in the host computer's memory and which allows a given application program to communicate with lower level drivers and other force feedback functions. For example, in the Windows operating system, API's are commonly used to allow a developer of an application program to call functions at a high level for use with the application program, and not worry about the low level details of actually implementing the function.</p>
<p id="p-0054" num="0053">The API of the present invention includes a set of software “objects” that can be called to command a force feedback interface device <b>11</b>. Objects are a set of instructions and/or data which can be called by a pointer and/or an identifier and parameters to implement a specified function. For example, three types of objects are provided in one preferred API implementation: interface objects, device objects, and effect objects. Each of these objects makes use of one or more force feedback device drivers which are implemented as objects in the API <b>208</b>.</p>
<p id="p-0055" num="0054">Interface objects represent the API at the highest level. An application program (which is referred to as a “client” of the API) can create an interface object to access lower level objects and code that implement force feedback device functionality. For example, the interface object allows an application program to enumerate and receive information about individual devices and create lower level objects for each device used by the application program.</p>
<p id="p-0056" num="0055">Device objects each represent a physical force feedback device (or other compatible device or peripheral) in communication with the host computer <b>18</b>. For example, the force feedback device <b>11</b> would be represented as a single device object. The device objects access the set of force feedback routines to receive information about an associated physical device, set the properties of the physical device, register event handlers (if events are implemented on the host), and to create effect objects.</p>
<p id="p-0057" num="0056">Effect objects each represent a force feedback effect defined by the application program to be output one or more times to the user using a force feedback device. The effect objects access the set of force feedback routines to download force effects to the force feedback device, start and stop the output of force effects by the force feedback device, and modify the parameters of the effects.</p>
<p id="p-0058" num="0057">A “force effect,” as referred to herein, is a definition for a force or series of forces that may be commanded within the API. The force effect typically has a name (identifier) to identify it and one or more parameters to characterize the force effect as desired. For example, several types of force effects have been defined, including vibrations, enclosures, grids, textures, walls, dampers, snap sensations, vibrations, circles, ellipses, etc. For example, a vibration force effect may have parameters of duration, frequency, magnitude, and direction. The force sensations output to the user can be derived from one or more force effects (e.g., force effects can be superimposed on each other). Force effects, in turn, are made up of one or more basic force prototypes, such as springs, dampers, and vector forces.</p>
<p id="p-0059" num="0058">In some embodiments, an application program client interacts with the API <b>206</b> by first receiving a pointer to a resident force feedback interface; for example, a preferred interface includes procedures specified by the Component Object Model (COM) of Microsoft Windows, an object oriented model for constructing interfaces (embodiments in which host computer <b>18</b> is a console game system, for example, may use other software architectures). Using the force feedback interface, the application program enumerates the force feedback devices on the computer system <b>18</b>. The application program selects a desired one of the force feedback devices and creates a device object associated with that device. Using the force feedback interface, the application then acquires the device, sets the device up with setup and default parameters, and creates effect objects and event objects during the execution of the application program at times designated by the developer of the application. At appropriate times, the application program will command the creation/destruction of force effects and the start, stop, or, pause of the playback of force effects by accessing the appropriate interface instructions associated with the desired effect. If appropriate (see below), the API can indicate to a context driver <b>210</b> to create a “context” (i.e. “effect set”) for an application program, and sends effects and events to be associated with that context. A “context” is a group or set of effects and events that are associated with a particular application program.</p>
<p id="p-0060" num="0059">In embodiments allowing multiple application programs to be simultaneously running on the host, each application program may have its own set of force sensations to output to the force feedback device. Since the device cannot implement all force sensations at any one time due to cost and hardware constraints, the forces commanded by each application must be organized by the architecture to take these limitations into account.</p>
<p id="p-0061" num="0060">Context driver <b>210</b> is used to implement force effects for multiple application programs. Context driver <b>210</b> receives contexts <b>222</b> and device manipulation data <b>223</b> from the API <b>208</b>. The context driver is provided at a level below the API to organize contexts for applications <b>202</b> and <b>204</b> running on the host computer. In the preferred embodiment, the effects and events in a context are not known to the application program itself, rather, the context driver <b>210</b> creates a context internally for an application. Thus, an application commands that a particular force sensation be output in response to different interactions or occurrences, e.g., an interaction of a cursor with an object or region, or the output of a force based on other criteria (time, received data, random event, etc.). The API sends the commanded effect(s) to the context driver <b>210</b>, and the context driver stores the effects in the context created for that application program.</p>
<p id="p-0062" num="0061">Since each application may have a completely different set of force effects to output, each context must be associated with its particular application program. In the preferred embodiment, there are two types of contexts: foreground contexts and background contexts. One foreground context is associated with the application program <b>202</b> or <b>204</b> that is currently active in the operating system. Different foreground contexts can include the effects and events for inactive application programs. A background (primary) context includes effects for the master application program <b>206</b>. In addition, a “global context” can be provided, which includes common effects almost always used by application programs (e.g. a pop force) and which can automatically be downloaded to the force feedback device. Effects in the global context need not be stored in individual contexts for particular application programs.</p>
<p id="p-0063" num="0062">When an application program is first executed by the host computer and loaded into memory, if the application is able to command a force feedback device, the application will query for the API <b>208</b>. Once communication is established, the API will contact the context driver <b>210</b> to create an entry location for a context set for the initiated application program.</p>
<p id="p-0064" num="0063">The context driver <b>210</b> receives individual effects and events as they are created by the application program using API <b>208</b> and stores the effects and events in a context list <b>212</b>, storing each context in a different storage location in the host's memory or on some other type of storage device. An active or inactive application program can create a context and have it stored, but only the active application's context will be sent to the force feedback device. The context driver <b>210</b> can examine an identifier in a created effect or event to determine which application program is associated with it and thus store the effect or event in the proper memory location. The context driver sets pointers to the contexts and to the effects and events in the contexts to access them. An effect can be created initially when the application program is first executed, before any forces are commanded, or the effect can be later created during application execution and then immediately commanded to be played by the force feedback device. Each context also preferably includes an entry into a device state structure. This entry governs the “gain” or force level for all effects in the context. For example, all the forces in the context can be cut to 50% of full magnitude by storing a value of 50 in the device state structure. One of the contexts stored in list <b>214</b> is a primary context <b>216</b>, which is the list of effects and events used by the master application <b>206</b> or “background” application.</p>
<p id="p-0065" num="0064">At a later time, after the context driver has stored the contexts in list <b>212</b>, an application program may send a command to the API to output or “play” a particular force sensation. The API checks whether the application program is active or in the background (primary); if not, the API does not send any data to the device and/or to the lower drivers. Alternatively, the commands from an inactive foreground application can be stored and then sent to the device when the application becomes active. If the application is active or background, the API sends the start information to the context driver <b>210</b> indicating the application program that commanded the force and the particular force effects to be commanded. The context driver <b>210</b> then associates the commanding application program with a context <b>214</b> in list <b>212</b> and sends the effects from the context to the force feedback device (if not previously sent). For example, if a context for a particular application program includes a spring effect, a damper effect, and a vibration effect, and the application program commands the vibration to be output, then the context driver selects the vibration effects to be output to the device. The data describing this effect is then output by the context driver <b>210</b>. Similarly, the application program can send a command to stop particular force effects, to pause the effects, to get the status information of an effect, or to destroy an effect. Some of these commands are described in greater detail below. Thus, the application program believes it is the only one using the force feedback device when in actuality the context driver uses one particular set of multiple sets of force effects based on the active application. In effect, there is a virtual force feedback device dedicated to each running application program.</p>
<p id="p-0066" num="0065">A context is therefore only allowed to exert forces with the force feedback device when that context is active, i.e., is associated with an active application program or the background application. In the described embodiment, only one foreground context can be active at any given time. Any number of background contexts may be simultaneously active; however, there may be a device limit on the number of background contexts that may be created. For example, the device <b>11</b> may only allow one background context to be created at any one time, which is the preferred embodiment. Thus, if an inactive (not in focus) foreground application program commands a force to be output, the API will ignore the command after determining that the commanding application is not active (or, the command will only be sent to the device when that application becomes active).</p>
<p id="p-0067" num="0066">If the active application program becomes inactive (or is removed from the host's memory) and a different application becomes active, then the API indicates this to the context driver <b>210</b>, which then deactivates the context associated with that application program and loads the effects from the new active context to the force feedback device <b>11</b>. Likewise, when the original application program again becomes active, the API tells the context driver to activate the associated context and load the appropriate effects to the force feedback device.</p>
<p id="p-0068" num="0067">Device manipulation data <b>223</b> is also received by context driver <b>210</b>. Data <b>223</b> is used to set a global device state on the force feedback device, as described below, and this information is passed unmodified to the translation layer.</p>
<p id="p-0069" num="0068">Some embodiments may not allow multiple simultaneous application programs to each command forces; there is only one active application that uses the device <b>11</b>. For example, in such an implementation, a force feedback game might be running on the host, and no other application programs can be allowed to command forces to the device <b>11</b>. Such an implementation does not require the context driver <b>210</b> to operate; commands from the API can be passed directly to the translation layer <b>218</b>, described below. The translation layer would access a single context list <b>220</b> in such a case, i.e., there would be no need to provide multiple contexts <b>214</b>.</p>
<p id="p-0070" num="0069">Translation layer <b>218</b> manages the sending of effects to the device <b>11</b>, receives information from the device to the host (in some embodiments), and maintains a representation or model of the memory of device <b>11</b>. Translation layer <b>218</b> receives an individual effect <b>219</b> for the active (or background) application program and device manipulation data <b>223</b> sent by the context driver <b>210</b> (or from the API <b>208</b> if no context driver <b>210</b> is used). The translation layer provides the effect from a context list <b>220</b> of individual effects <b>222</b> (list <b>220</b> represents a context <b>214</b>). A different context list <b>220</b> is provided in each context <b>214</b> of list <b>212</b>. Each effect <b>222</b> in list <b>220</b> defines a force or series of forces that is to be output on the user object <b>12</b> by the force feedback device <b>11</b>. When the effects are to be loaded on the device <b>11</b> (“created”) by the application, they are selected and copies are output to the device by the translation layer. Preferably, each effect is output by the translation layer as soon as it is received by the layer <b>218</b>. Each effect stored in list <b>220</b> as examined by the translation layer is available on force feedback device <b>11</b>, i.e., the local microprocessor <b>130</b> should recognize the effect and be able to output the effect immediately or when conditions dictate.</p>
<p id="p-0071" num="0070">In a multiple-application system, when an active application becomes inactive, the translation layer is instructed by the context driver <b>210</b> to “unload” the effects of the context of the previous active application from the force feedback device (e.g., designate the memory space for those effects as free), receives the effects from the now active application and loads those effects to the force feedback device <b>11</b> (the effects for the background (primary) application are preferably never unloaded).</p>
<p id="p-0072" num="0071">The translation layer also preferably handles events. For example, when a screen position is received from the device <b>11</b>, the translation layer can check whether any of the conditions/triggers of the active events are met. If so, a message is sent which eventually reaches the associated active or background application program. In alternate embodiments, the microprocessor <b>130</b> on device <b>11</b> can check for events and send event notifications through translation layer <b>218</b> up to the application program.</p>
<p id="p-0073" num="0072">The translation layer also can store a device state <b>224</b> in memory. Device manipulation data <b>223</b> from the active application and the background application determines the device state. This is the state that the active application program wishes to impose on the device, if any. For example, an overall condition can be stored, such as an enable or disable for all forces, so that if all forces are disabled, no forces will be output by the device. An overall gain can also be set to limit all output force magnitudes to a desired level or percentage of maximum output.</p>
<p id="p-0074" num="0073">The translation layer outputs device messages <b>225</b> (commands) to the device <b>11</b> by way of the next layer. Messages may include force effects to be output and/or any other information such as device identification numbers or instructions from the context driver for an effect (start, stop, pause, reset, etc.) The translation layer outputs messages <b>225</b> to the device driver <b>226</b>.</p>
<p id="p-0075" num="0074">Device communication driver <b>226</b> communicates directly with the force feedback device. Driver <b>226</b> receives the device messages <b>225</b> from translation layer <b>218</b> and directly transmits the messages to the force feedback device over bus <b>120</b>, e.g. a USB, in a form the device <b>11</b> can understand. The driver <b>226</b> is implemented, in the preferred embodiment, as a standard device driver to communicate over such a serial port of host computer <b>18</b>. Other types of drivers and communication interfaces can be used in other embodiments.</p>
<heading id="h-0007" level="1">Memory Management of Force Effects</heading>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. 3</figref> illustrates an example data structure for a force effect. An important aspect of the present invention is that a model or representation of the memory <b>134</b> on device <b>11</b> is maintained by the translation layer (or API or other driver) on the host computer <b>18</b>. Thus, the translation layer knows exactly when an effect can be downloaded to and stored by the device <b>11</b> and when there is not sufficient memory on the device to store a particular effect. The size of the effect list <b>220</b> on the host computer should be the same as (or smaller than) the available memory for such a list in the force feedback device so that the translation layer knows when the memory of the force feedback device is full. If the memory <b>134</b> is full, the translation layer can delay the output of additional effects until enough memory space is available (e.g. see effect caching with regard to <figref idref="DRAWINGS">FIG. 7</figref>), or can simply discard the effect.</p>
<p id="p-0077" num="0076">Example data structure <b>240</b> may include several fields, such as duration <b>242</b> indicating the amount of time the force effect is to be played, direction <b>244</b> indicating the direction in one or more degrees of freedom the force is applied, an envelope pointer <b>246</b> pointing to an envelope data structure <b>248</b>, and a type pointer <b>250</b> pointing to a type data structure. The duration <b>242</b> and direction <b>244</b> fields can simply store one or more values associated with those characteristics. The envelope data structure <b>248</b> can either be null if the force effect does not use an envelope (e.g. a condition force), or the data structure <b>248</b> can hold several values that define an “envelope” for a periodic wave, such as impulse time <b>252</b>, impulse level <b>254</b>, fade time <b>256</b>, and fade level <b>258</b>. Shaping of waves using such parameters is described in greater detail in co-pending patent application Ser. No. 08/747,841, incorporated by reference herein. Type pointer <b>250</b> can point to one of multiple possible different data structures, depending on the type of force effect. For example, if it is a constant force effect, data structure <b>260</b> is pointed to, having a magnitude parameter <b>262</b> (which can be signed). If it is a periodic effect, data structure <b>264</b> is referenced, having values of magnitude <b>266</b>, offset <b>268</b>, phase <b>270</b>, and period <b>272</b> that define the periodic effect. If it is a condition effect, such as a spring or damper, then data structure <b>274</b> is referenced, having offset <b>276</b>, deadband <b>278</b>, constant <b>280</b> (e.g., spring constant or damping constant), and saturation <b>282</b> values.</p>
<p id="p-0078" num="0077">As exemplified by <figref idref="DRAWINGS">FIG. 3</figref>, different force effects have different storage requirements. Some force effects may not need to store envelope data from structure <b>248</b>, while some periodic and constant effects may require additional space to store the envelope information. Condition force effects require a different amount of memory space for data in structure <b>274</b> than do constant force effects for data in structure <b>260</b>. Since a model of the device memory is maintained on the host computer, the host knows how much memory is available on the device, i.e., when a particular effect can be stored by the device and when an effect cannot be stored.</p>
<p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. 4</figref> illustrates another example of a layout of device memory <b>134</b> provided in device <b>11</b> which is modeled on the host computer. An effect memory block <b>300</b> can be allocated in memory (both host and device memory) for storing data relating to the identification of distinct force effects. Each force effect stored in effect block <b>300</b> has the same size. For example, in <figref idref="DRAWINGS">FIG. 4</figref> the device <b>11</b> can store six force effects in block <b>300</b>, one effect in each effect space <b>302</b> of an array. Each effect space <b>302</b> holds a pointer to the particular parameters defining that force effect. The parameters can be stored in a parameter block <b>304</b> of the memory <b>134</b>. Since the parameters can differ in amount and in size for different force effects, there is no constant amount of memory space in the parameter block allocated for each force effect. Rather, the amount of space (e.g. the offsets into the memory) that each set of parameters occupies must be tracked so that additional parameters can be stored around existing parameters, and so that it is known when the memory is full. Furthermore, the parameter block <b>304</b> is used to store working values used during playback of a force effect; thus, additional space is often needed beyond what is required simply to store the parameters. In other embodiments, the effect block and parameter block may be combined as a single block of memory, similar to the embodiment for a single context <b>220</b> shown in <figref idref="DRAWINGS">FIG. 2</figref>. For example, parameters for an effect can be stored directly after the identifying information.</p>
<p id="p-0080" num="0079">As explained above, the translation layer on the host computer preferably maintains a model of the device memory <b>134</b> to determine where to store parameters and to determine when the memory is full. Initially, such as at power up of the device <b>11</b>, the host preferably asks the device for any relevant information to model the memory, such as the size of the available effect and parameters blocks, as well as the number of effects that can be stored in effect block <b>300</b> (which can vary depending on the device <b>11</b>). Some devices <b>11</b> may be able to inform the host how much space must be allocated for each effect slot <b>302</b>, parameters for an effect, and/or how to specify the usage of parameter pointers.</p>
<p id="p-0081" num="0080"><figref idref="DRAWINGS">FIG. 5</figref> is a flow diagram illustrating a basic memory management process <b>310</b> for use with a single application program and a force feedback device. This process is described from the point of view of a lower-level program on the host (generically called a “driver” herein), such as the translation layer, the API, a library (e.g., library functions and procedures), or another driver, but may be implemented at other levels of the host architecture in other embodiments. Process <b>310</b> may be used whether the application program is the only application program, or if the program is one of multiple programs concurrently running on the host. It should be noted that the order of steps described below is only provided for explanatory purposes, and that the various steps, checks and events can occur in different sequences or in parallel (multitasking) in various embodiments. For example, many of the checks can be implemented as function calls or interrupts, where associated steps can simply be processed when called regardless of any current stages of other processes.</p>
<p id="p-0082" num="0081">The process <b>310</b> begins at <b>311</b>. In step <b>312</b>, the host <b>18</b> creates a memory model using information from the device <b>11</b>. For example, a context <b>220</b> can be created as explained above with reference to <figref idref="DRAWINGS">FIG. 2</figref>. The model used in <figref idref="DRAWINGS">FIG. 4</figref> can be used; this model is referred to in the following discussion. As explained above, the device can send the host <b>18</b> information such as the size of memory and number of effects that can be stored.</p>
<p id="p-0083" num="0082">In step <b>314</b>, the process determines whether the application program (e.g. by a function call to the API or library) is commanding to create or destroy any force effects on the device <b>11</b>. Creation of effects typically occurs when the application program is first executed on the host computer, but also may occur at other times during application execution. For example, when a game program is first executed, the program has a set of force effects which are intended to be used by and with the game. The game typically creates the force effects on the device <b>11</b> at startup of the game so the effects will be available immediately for output. Different effects can also be later created during the game if needed. If a GUI is executed on the host, the GUI can immediately create background (primary) force effects on the device <b>11</b> so that such effects are immediately available.</p>
<p id="p-0084" num="0083">If the application has not commanded to create or destroy any effects on the device in step <b>314</b>, the process continues to step <b>324</b>, explained below. If the application wishes to create an effect on the device, then in step <b>316</b> the host determines if there is any device memory available to store the effect. The host driver (e.g. translation layer or, alternatively, the API) checks the host model of device memory to determine if there is sufficient space. Preferably, the host driver checks for sufficient space both in the effect block <b>300</b> and in the parameter block <b>304</b>; there should be sufficient space in both blocks. If there is not, in step <b>318</b> the force effect is discarded, never to be used; preferably, the application program is informed that the effect could not be created, i.e. that the create command failed (in an alternate embodiment of the present invention described below, the effect can be cached by the host). The process then continues to step <b>334</b>, described below. If there is sufficient memory for the created effect in step <b>316</b>, then in step <b>320</b> the host stores the effect in its memory model and also sends one or more create commands are sent to the device to load the effect in the actual device memory. It should be noted that, in embodiments providing multiple concurrently-running application programs, the device <b>11</b> can includes a number of effects standardized in its memory which it can implement if the effects are within the active or background context. Such effects do not need to be downloaded from the host and stored in an effect slot.</p>
<p id="p-0085" num="0084">As an example, a set of commands and appropriate parameters are shown below to create a periodic effect on the device:</p>
<p id="p-0086" num="0085">SET_ENVELOPE (offset1, values)</p>
<p id="p-0087" num="0086">SET_PERIODIC (offset2, values)</p>
<p id="p-0088" num="0087">SET_EFFECT (effect_index, values, flags, offset1, offset2)</p>
<p id="p-0089" num="0088">The SET_ENVELOPE command provides a “msg_id” value indicating its command type (identifier). The offset value “offset 1” indicates the offset into the parameter block <b>304</b> at which to store the accompanying values. The values can be, in this example, the envelope parameters in the data structure <b>248</b> shown in <figref idref="DRAWINGS">FIG. 3</figref>, such as impulse time, impulse level, fade time, and fade level. Alternatively, for other types of force effects (e.g. conditions), the envelope parameters can be null, or the envelope command need not even be sent. The SET_PERIODIC command similarly provides an identifier and a second offset value “offset2” (different from offset1) at which to store the values in the periodic command. The host <b>18</b> knows how much memory space is taken by each effect and parameters and thus can determine the appropriate offsets at which to store the effect data in the device memory without writing over other values. For example, the host knows how much space the envelope parameters of the SET_ENVELOPE command take, and can calculate offset2 to be appropriately located in the parameter block. The values for a periodic command can be those shown in data structure <b>264</b> of <figref idref="DRAWINGS">FIG. 3</figref>, for example.</p>
<p id="p-0090" num="0089">The SET_EFFECT command provides the data to be stored in the effect block <b>300</b> of the device memory. After an identifier value, the “effect_index” value indicates which effect slot <b>302</b> in which the effect is to be stored. Since the host is modelling the device memory, the host knows which effect slots are available, e.g. open or no longer used. The values can be those shown in structure <b>240</b> of <figref idref="DRAWINGS">FIG. 3</figref>, for example. Offset1 and offset2 indicate where the envelope parameters and the periodic parameters, respectively, are stored in the parameter block (if these parameters are not used then the offset values can be null).</p>
<p id="p-0091" num="0090">It should be noted that the host can store in its memory model either the actual data for the effect, or only the location and size of the portion of memory space that the effect occupies. This is because, at a basic level, the host is only keeping track of available device memory and does not need the actual effect data. However, in a preferred embodiment, the host does store the actual effect data in the memory model. In some embodiments, this allows the host driver to examine effect data and to perform some decisions about whether to send a command to the device. For example, the application may command that a new effect be created which is a periodic wave having a frequency of 20 Hz. The host driver might examine the data for currently-loaded effects in its memory model and find that there is already a periodic wave loaded on the device having a frequency of 25 Hz. The host driver could then decide that the new, 20 Hz periodic is redundant in view of the 25 Hz periodic, and thus ignore the create command (and use the 25 Hz effect whenever the 20 Hz effect is commanded to be played). This type of host driver ability can be performed only if actual effect data is stored in the host memory model. Furthermore, this type of “smart” effect management must be balanced in view of extra processing time and the intentions of the application developer. For example, if the application believes that multiple (redundant) effects are stored in the device and will provide an additive force output, the host driver will not want to simply modify an existing effect but should create a new effect. Also, the efficiency in effect storage gained may not in some cases be worth the extra processing time in managing the effects intelligently. After step <b>320</b>, the process continues to step <b>334</b>, described below.</p>
<p id="p-0092" num="0091">If in step <b>314</b> the application has commanded to destroy an effect, then in step <b>323</b> an effect slot is freed up in the host memory model. In the preferred embodiment, the device <b>11</b> need not be instructed to destroy an effect in the device memory in most cases; rather, old effect data can be simply written over with new effect data in the device memory when the new data is ready to be loaded. The host, however, must free up memory space in its own memory model to allow other effects to be stored and thus the driver should be instructed to destroy an effect to clear the effect data in the memory model. After a destroy command has been received, the host driver knows that the slot of the destroyed effect is available to store a different force effect that may be created in the future by the application program.</p>
<p id="p-0093" num="0092">In some cases, the device needs to be informed that an effect has been destroyed. For example, a trigger effect can be loaded into device memory and outputs a force if a particular trigger condition occurs, such as a button being pressed on the user manipulatable object. If a trigger effect is being stored in the device memory and is destroyed by the application, that trigger effect cannot be simply left in device memory until it is written over, since a trigger condition may occur before the trigger is overwritten; instead, the device must be immediately informed that the trigger effect should be destroyed or flagged appropriately. Likewise, if an effect is playing when it is destroyed, the device should be immediately informed so that it can turn off the effect. After step <b>323</b>, the process continues to step <b>334</b>, described below.</p>
<p id="p-0094" num="0093">If no create or destroy command is received in step <b>314</b>, the process checks in step <b>324</b> whether the application program on the host is commanding to change an effect state. Herein, an effect state is the current status of the effect, e.g. “playing,” “stopped,” “paused,” etc. If no effect state is being commanded, the process continues to step <b>334</b>, described below. In a preferred embodiment, steps <b>314</b> and <b>324</b> are actually function calls made to and implemented by the API which can be made at any time, such that steps <b>314</b> and <b>324</b> need not be implemented in the sequence shown.</p>
<p id="p-0095" num="0094">If in step <b>324</b> the effect state being commanded is to “play” or “start” (output) a particular force effect to the user, then in step <b>326</b> an appropriate “play” command is sent from the host driver to the device. For example, the command can be SET_EFFECT_STATE (effect_index, state, loop_count). The effect_index value indicates the slot in the effect block in device memory and thus the particular force effect which is to be played. The state value indicates to “play” the designated effect. The loop_count value can optionally be used to designate a number of times for the device to repeat playing the entire force effect. In step <b>328</b>, the host (e.g. translation layer) “tags” the effect (i.e. sets a flag) in its memory model so that the host knows which effects are currently playing on the device (the device also tags the effect, as described in greater detail with respect to <figref idref="DRAWINGS">FIG. 6</figref>). The process then returns to step <b>314</b>.</p>
<p id="p-0096" num="0095">If in step <b>324</b> an effect state is being commanded to stop playing a particular force effect, then in step <b>330</b> an appropriate command is sent from the host to the device. Such a command can be similar to the play command described above except that the state indicates to stop playing the designated effect. In step <b>332</b>, the host “untags” the designated effect in its model of device memory, i.e. removes the tag for the designated effect. The process then returns to step <b>314</b>. In other embodiments, additional changes in effect states can also be commanded, such as to pause and resume a force effect, etc.</p>
<p id="p-0097" num="0096">In step <b>334</b>, the host can check whether any playing effect has expired or finished, e.g. whether an effect has played to its full duration. The device preferably keeps track of effect duration since it is actually implementing the output of the forces. To inform the host of the expiration of an effect, the device preferably sends a status report to the host, which is checked in step <b>334</b>. In some embodiments, the host can also independently keep track of the duration of a force effect for memory management purposes, i.e. it can be useful for the host to independently determine when a force effect is finished playing to help determine which cached effects can be loaded. Furthermore, the host can resynchronize its tracked durations if the host and device durations are learned to be out of synchronization. If no effects have expired, the process returns to step <b>314</b>. If at least one effect has expired, then the process continues to step <b>336</b> to untag the expired effect in the host memory model. The process then returns to step <b>314</b>.</p>
<p id="p-0098" num="0097">The host can also receive status reports from the device <b>11</b> at periodic intervals and/or when the status of force effects and other conditions change, such as an effect starting to play or finishing playing, a deadman switch being activated, power supply interrupted, etc.</p>
<p id="p-0099" num="0098"><figref idref="DRAWINGS">FIG. 6</figref> illustrates a process <b>350</b> running on the device <b>11</b> which creates and plays designated force effects for the device. The process begins at <b>351</b>, and at <b>352</b>, the process checks whether it has received a command from the host computer <b>18</b>. In the preferred embodiment, the device process is in actuality “event” or interrupt driven such that when a host command is received, an event has occurred, and the device will immediately process it rather than having to check for received commands. Note that this type of event is provided from the host to the device, not from the device to the host. (The device can also send events to the host, such as the movement of the user object into an area corresponding to a graphical object, and status reports to the host at periodic intervals or when events occur; such events are described in co-pending patent application Ser. No. 08/970,953.) If a command has not been received by the host in step <b>352</b> (e.g., no command event has occurred), then the process continues to step <b>362</b>, described below.</p>
<p id="p-0100" num="0099">If a host command has been received by the device and that command creates a force effect on the device, then in step <b>354</b> the process writes the effect data in the device memory in the effect slot designated by the command, i.e. the identifier and the parameters are stored in device memory <b>134</b>. For example, the local microprocessor <b>130</b> can parse the msg_id value (identifier) of each command to determine the type of command. Once the device knows the type of command, it also knows how to store and process each of the succeeding parameters in the command. Thus, the device knows that the second value in the SET_EFFECT command indicates the effect slot in the effect block <b>302</b> at which to store the succeeding values. The device also knows to store values at the appropriate offsets provided in the periodic and envelope commands. The process then continues to step <b>362</b>, described below.</p>
<p id="p-0101" num="0100">If a command has been received to change the state of an effect already created on the device, then in step <b>356</b> the process parses the command to check whether the command is a “play” command. If so, then in step <b>358</b> the device “tags” the effect designated in the command. The tag is an indication (such as a flag) that the effect is to be played, to be later examined by the process as detailed below. The process then continues to step <b>362</b>.</p>
<p id="p-0102" num="0101">If the command received in step <b>356</b> is not a “play” command, then it is a “stop” command to cause the designated force effect to stop playing. Additional commands can also be implemented in other embodiments, such as “pause”, which can stop the playing of a force effect in its current state; after a “resume” or “unpause” command is received, the effect would continue playing from the point at which it was paused rather than restarting; or a “stop_all” command which stops the playing of all effects; or a “modify” command, which modifies only the parameters of a previously-loaded effect. In step <b>360</b>, the process “untags” the effect designated in the command, i.e. indicates the designated effect should not be played The process then continues to step <b>362</b>.</p>
<p id="p-0103" num="0102">In step <b>362</b>, the process checks whether the time interval has lapsed, i.e. whether a time event has occurred. In the described embodiment of the present invention, the device operates according to a time interval as measured by a clock. At each time interval, the device <b>11</b> should output a force for that interval as contributed to by any playing force effects. For example, the time interval can be 1 millisecond, where the device is expected to process any required information and output a force on the user object <b>12</b> every millisecond. When the millisecond time interval passes, it is considered an event which causes the microprocessor to output a force. Thus, if no time interval has elapsed in step <b>362</b>, the process returns to step <b>352</b>, e.g. the microprocessor continues to wait for an event such as a command or time interval. Before the next event occurs, the device can perform other tasks such as suspending operation until the next event, processing input sensor values, calculating the next forces, building and sending messages to the host computer, and/or updating force output from the actuators.</p>
<p id="p-0104" num="0103">If a time interval has elapsed, then a force should be output, and the process continues to step <b>363</b> to start the implementation of force output. In step <b>363</b>, a variable N is set to 1. N indicates the index or slot of an effect in the effect block of device memory. In step <b>364</b>, the process examines the effect(N), i.e. the effect stored at slot(N). If the examined effect is determined in step <b>366</b> to be untagged, then in step <b>368</b> N is incremented. In step <b>370</b> the process checks whether N&gt;M, where M is the number of effects that the device <b>11</b> can store. If N&gt;M, then all the effects have been checked, and the process continues to step <b>372</b>, explained below. If N is not greater than M, then the process examines the next effect in the device memory in step <b>364</b>. For an alternate method of examining effects in memory, see the “playlist” embodiment of <figref idref="DRAWINGS">FIG. 10</figref>.</p>
<p id="p-0105" num="0104">If the effect(N) is determined in step <b>366</b> to be tagged, then in step <b>374</b> a force is calculated by the device microprocessor <b>130</b> based on the data for effect(N), e.g. the parameters such as magnitude, direction, and the like. The microprocessor <b>130</b> can use locally-stored force processes, force algorithms, stored force magnitudes, functions of space and/or time, a history of stored motion values of the user object, and/or other instructions to calculate the force as explained above with reference to <figref idref="DRAWINGS">FIG. 1</figref>. For example, the microprocessor can calculate the raw contribution to the output force from the effect and apply an envelope scaling (detailed in copending application Ser. No. 08/747,841, incorporated by reference herein). In step <b>376</b>, the calculated force is added to a sum of forces calculated for the other playing effects. In determining the total sum, the device preferably combines all constant forces (e.g., conditions and time-based forces) and limits the constant force sum to a predetermined magnitude, then combines all dynamic forces and limits the dynamic force sum to a predetermined magnitude. Dynamic forces are detailed in application Ser. No. 08/846,011, incorporated herein by reference. The two sums are then added together and the total force sum is output by the actuators of the device <b>11</b>. Alternatively, all forces can be treated the same and summed together. Furthermore, steps <b>374</b> and <b>376</b> can be processed together or intermixed when determining the effect force and the total force.</p>
<p id="p-0106" num="0105">In step <b>378</b>, any working values in parameter block <b>304</b> are updated. For example, such values can include a time value that indicates the amount of time that has expired for the current force effect. If the microprocessor <b>130</b> has determined that the time value for the effect has reached the duration limit for the effect, the microprocessor <b>130</b> preferably untags the effect so that it will no longer be played. Parameters for the effect can also be updated if a command has required such. After step <b>378</b>, the process continues to step <b>368</b>, where N is incremented, and then to step <b>370</b>, where N is compared to M as described above to determine whether all the effects in the device memory have been checked. If N&gt;M, step <b>372</b> is implemented, where the total force is output by the device to the user. The total force is the sum of each force contributed by each playing force effect. The process outputs force signals to one or more actuators to apply a force in the appropriate direction with the appropriate magnitude. The process then returns to step <b>352</b> to wait for the next command event or in step <b>353</b>, the next time interval. The device also preferably sends status reports to the host concerning the status of effects, and these status reports can be sent periodically and/or when the status of an effect changes. Of course, other data and conditions of the device are also reported to the host (sensor data, button data, whether power is being received, deadman switch state, etc.) which are not detailed in process <b>350</b>.</p>
<p id="p-0107" num="0106">The processes described with reference to <figref idref="DRAWINGS">FIGS. 5 and 6</figref> are very efficient. Since the host knows the layout of memory and what is currently stored there, the host need only send one command to load new effects; the host already knows when effects can or cannot be created. In previous embodiments, the host would have to query the device and wait for an answer from the device as whether an effect could be created, thus slowing down communication and response of the device and creating potential confusion when multiple application programs are running and commanding forces.</p>
<p id="p-0108" num="0107">One aspect of the present invention concerns the time interval event and its implementation as described above for step <b>353</b>. One way to implement the time interval is to choose a long enough period of time that allows the microprocessor to perform any potential required calculation and still output a force at each time interval. A different implementation of the present invention can provide a smaller time interval which usually is sufficiently long to allow a force to be output at each interval, but which may be insufficient in length in particular circumstances. If the time interval is too short in a particular circumstance, the microprocessor <b>130</b> preferably then waits the next discrete time interval to output the force instead of outputting force as soon as it has been determined. This allows a consistent period of force output to be maintained. Preferably, the force output at the second interval point is appropriate to that interval and is not necessarily the force which should have been output at the skipped interval point. For example, if the time interval is specified as 1 ms, the device is usually able to make calculations and output a force every millisecond. However, in some cases such as when a complex command is received, when calculations for several and/or complex force effects are made, or other condition requiring more processing occurs, the extra processing might cause a delay in the output of the force past the 1 ms interval point. Instead of outputting the force when the calculation is complete, the process delays the output of the force until the next discrete interval point, i.e. after an integer number of time intervals have passed. Furthermore, the process also computes the force which should be output at the second interval rather than the first. For example, if the force is based on a periodic function, then the force that should be output at the second interval can be determined using the periodic function. This maintains the fidelity of the force sensation to the user and is important for time-based effects. This method allows a faster update interval with only occasional delays in force output, thus providing better overall force output quality than if a longer time interval is used.</p>
<heading id="h-0008" level="1">Effect Caching on the Host Computer</heading>
<p id="p-0109" num="0108">One limitation of force feedback devices is the relatively small amount of memory included on the devices. To create a realistic, immersive environment, many different force effects should be output by an application program. However, only a small number of effects can usually be stored on a force feedback device, often less than the application program wishes to use. In current implementations, if an application program commands the creation of more force effects than can be stored by the device, the effects that cannot be stored are simply discarded and not output, and the application program is informed of the failure (the application program can react to the failure in any way the developer desires). One way around the limitation is to provide a “smart” application program that only outputs a small number of force effects at once which can all be stored on the device; when the application wishes to create and output a new, different force effect, it destroys a previously-used effect and commands a new force effect. However, ideally the application program should be able to output as many force effects as it wishes without having to consider the memory limitations of the force feedback device and without having to spend extra processing time swapping force effects.</p>
<p id="p-0110" num="0109">Effect caching by the host is a way to use to the host's memory in addition to limited device memory to store as many force effects as an application program needs to use. Host memory is used as an overflow cache for the device to store any effects not able to be stored on the device. In the view of the application program, all commanded effects have been stored on the device, so that the application program need never receive a failure message for running out of device memory. A driver program on the host (such as the translation layer, API or other library, or a lower-level driver) handles all the effect caching at a lower level than the application program.</p>
<p id="p-0111" num="0110"><figref idref="DRAWINGS">FIG. 7</figref> is a flow diagram illustrating a memory management process <b>400</b> from the point of view of the host (e.g. the translation layer or other levels of the host architecture in other embodiments) using a host cache to store effects. The term “cached effect” herein refers to an effect whose data is stored in the host memory but is not stored in the device memory due to the device memory being full. The force effect is cached by the host when the application program (via the API) requests to create a force effect on the device and the device has no effect slots available to store the effect. Instead of returning a “failure” message to the application program, the host caches the force effect in the host's memory. Preferably, this is done by a driver on the host so that the application program believes that the device has loaded all effects. It should be noted that the order of steps described below is only an example, and that the various checks and events can occur in at any time or in different sequences as function calls, interrupts, and/or in parallel (multitasking) in various embodiments.</p>
<p id="p-0112" num="0111"><figref idref="DRAWINGS">FIG. 7</figref> illustrates a process <b>400</b> running on host <b>18</b>. The process <b>400</b> is similar to process <b>310</b> of <figref idref="DRAWINGS">FIG. 5</figref> at many steps. Process <b>400</b> begins at <b>402</b>, and in step <b>404</b>, the host <b>18</b> creates a memory model similarly to step <b>312</b> of <figref idref="DRAWINGS">FIG. 5</figref>. In step <b>406</b>, the process determines whether the application program (e.g. through the API) is commanding to create or destroy any force effects on the device <b>11</b>. If the application does not currently wish to create or destroy any effects on the device, then step <b>418</b> is initiated, explained below. If the application wishes to modify a force effect by creating an effect on the device, then in step <b>408</b> the host checks the host model of device memory to determine if there is any device memory available to store the effect. If there is not, in step <b>412</b> the force effect is cached in the host memory but is not loaded into the device memory. Since host memory is for many practical purposes unlimited when compared to device memory, the host cache should be able to store all force effects created by the application program. The cached force effects are preferably included in the same device memory model as the actual loaded effects (see <figref idref="DRAWINGS">FIGS. 9</figref><i>a </i>and <b>9</b><i>b</i>). The process then continues to step <b>438</b>, described below. If there is sufficient memory for the created effect in step <b>408</b>, then in step <b>410</b> one or more create commands are sent to the device to load the effect on the device and the effect is also stored in the host memory model. The process then continues to step <b>438</b>, described below.</p>
<p id="p-0113" num="0112">If in step <b>406</b> the application has commanded to destroy an effect, then in step <b>414</b> an effect slot is freed up on the host, creating an open slot in the device memory model. In next optional step <b>416</b>, the host can send a create command to the device to load a cached effect into the empty slot in device memory. Since there is an empty slot in device memory, and since the host cache may include effects that the application program assumes are loaded on the device, it can be efficient to have all the slots in the device memory filled. The host can load a cached effect based on the order in which it was cached, e.g. the effect that was cached first has the highest priority to be loaded. Alternatively, the host can prioritize the cached effects in some way and load the effect having the highest priority. For example, trigger effects may be considered higher priority than other effects. Effects can also be assigned priority based on several factors including the effect's magnitude, type, duration, or age, and/or a weighted combination of several of these factors. In other embodiments, step <b>416</b> is not implemented and the host can load cached effect data to the device at the time the effect is commanded to be played, as in step <b>432</b> below. The process then continues to step <b>438</b>, described below.</p>
<p id="p-0114" num="0113">If no create or destroy command is made in step <b>406</b>, the process checks in step <b>418</b> whether the application program on the host is commanding an effect state. If in step <b>418</b> a “stop” command has been made, then in step <b>420</b> the host sends a stop command to the device similarly to step <b>330</b> of <figref idref="DRAWINGS">FIG. 5</figref>. In step <b>422</b> the host untags the effect in the host memory model similarly to step <b>332</b> of <figref idref="DRAWINGS">FIG. 5</figref>. Next step <b>423</b> is similar to step <b>416</b>, described above, where the host can send a create command to the device to load a cached effect into the memory space occupied by the effect that was commanded to stop. As explained above, the host can determine which of the cached effects has the highest priority to be loaded. However, step <b>423</b> has the additional step of checking whether any cached effect, such as the highest-priority cached effect, has a greater priority than the stopped effect. In some cases, the stopped effect may have a higher priority than any cached effects and thus should remain in device memory, e.g. in an implementation placing high priority on trigger effects, the stopped effect may be a trigger and the cached effects may be periodics with lesser priority. Priority of effects is described below with respect to step <b>434</b>. The process then continues to step <b>438</b>, described below.</p>
<p id="p-0115" num="0114">If in step <b>418</b> a “play” command was made, then in step <b>424</b> the process checks whether the commanded effect is already loaded on the device. The host can maintain a list indicating which of the effects have been loaded to the device and which have been cached on the host, as shown in <figref idref="DRAWINGS">FIGS. 9</figref><i>a </i>and <b>9</b><i>b</i>. If the commanded effect has previously been loaded on the device, then the play command is sent to the device in step <b>426</b> similarly to step <b>326</b> of <figref idref="DRAWINGS">FIG. 5</figref>, and the effect is tagged in step <b>428</b> in the host memory model similarly to step <b>328</b> of <figref idref="DRAWINGS">FIG. 5</figref> (the device also tags the effect, as described in greater detail with respect to <figref idref="DRAWINGS">FIG. 6</figref>). The process then continues to step <b>438</b>.</p>
<p id="p-0116" num="0115">If the commanded effect(s) has not been loaded on the device, i.e., has been cached on the host, then in step <b>430</b> the process checks whether there is an open slot in the device memory in which to store the cached effect. An open slot does not have any effect data stored therein. If there is an open slot, then the process continues to step <b>432</b></p>
<p id="p-0117" num="0116">If it is determined that the commanded effect (or a waiting effect; in step <b>414</b> any waiting effect that is to loaded can be considered a “commanded effect”) can be loaded on the device, then in step <b>432</b> the host sends a create command to the device to create the commanded effect in the available effect slot of the device memory in step <b>416</b>, e.g. the effect is stored in the effect block and parameter block (if such a memory structure is being used), as explained with reference to step <b>320</b> of <figref idref="DRAWINGS">FIG. 5</figref>. The process then continues to step <b>426</b> to send the “play” command for the created effect as explained above. After the effect is tagged in step <b>428</b> on the device and the host, the process continues to step <b>438</b>, described below.</p>
<p id="p-0118" num="0117">If there is no open slot on the device in step <b>430</b>, then in step <b>434</b> the process checks whether any of the loaded effects can be “swapped” with the commanded effect, e.g. whether the loaded effect can be unloaded (written over) in its device memory slot and the commanded effect stored in its place.</p>
<p id="p-0119" num="0118">The process can use many different criteria to determine if any slots are available in the device memory. In one embodiment, the process checks whether all the loaded effects are currently playing; the slots of all of the loaded effects that are not currently playing might be considered available slots. The host can simply write the commanded effect in the first available slot of memory.</p>
<p id="p-0120" num="0119">In some embodiments, time-based (temporal) criteria can be used. For example, a long period of time may have passed since a loaded effect was last played, such that this effect can be considered to be expendable and the slot it occupies can be available for the newly-commanded effect. Such an expendable effect may perhaps no longer be in immediate use by the application program and thus is most eligible to be unloaded. The loaded effect having the longest time since last played can be considered the most eligible to be unloaded.</p>
<p id="p-0121" num="0120">In other embodiments, instead of or in addition to using such time-based criteria, spatially-based criteria can be used to determine slot availability. This method predicts movement of the user object <b>12</b> by the user to help determine which effects should be loaded on the device. <figref idref="DRAWINGS">FIG. 8</figref> illustrates one use of spatial caching. In a GUI <b>450</b> displayed on screen <b>20</b>, the user of device <b>11</b> can move a cursor <b>452</b> to different areas of the GUI. Many force effects are output based on the cursor's location in the GUI. For example, an attractive gravity field can be output to bias the cursor/user object to an icon <b>454</b> when the cursor is moved within an external range <b>455</b> around the icon. Or, a snap force can be output when the cursor moves over a window border <b>464</b> of window <b>462</b>.</p>
<p id="p-0122" num="0121">Using spatial criteria, those force effects that are associated with graphical objects in the current path of movement of the cursor can be considered more essential since they are more likely to have to be output in the immediate future when the cursor moves to the associated graphical objects. Those effects associated with graphical objects away from the current path of the cursor are more expendable since they are less likely to require immediate output. Thus, the host can determine the current direction (and velocity, if desired) of the cursor <b>452</b> to determine which graphical objects and effects are in the current path of movement of the cursor and which graphical objects and effects are far away from the current path of movement. The effect associated with the graphical object furthest away from the cursor path can be considered the most expendable effect and can be unloaded and replaced by an effect closer to the cursor path of movement.</p>
<p id="p-0123" num="0122">For example, in <figref idref="DRAWINGS">FIG. 8</figref>, it has been determined by the host, e.g. by examining a history of two or more cursor positions, that the cursor <b>452</b> is currently moving in the direction <b>466</b>. The cursor is likely to continue moving in the direction <b>468</b> (the velocity of the cursor can optionally influence this determination; if the cursor is moving fast, it is much more likely to continue in the same direction <b>466</b> than if it is moving slower or is currently stopped). Therefore, the icons <b>454</b> and <b>456</b> and the window <b>458</b> are away from the likely path of the cursor and any force effects associated with these objects may not be required to be output in the immediate future. However, the cursor may be heading directly to icon <b>460</b>; since the attractive field associated with the icon range <b>461</b> may have to be output very soon, the attractive field effect has a much higher spatial priority than the effects associated with objects <b>454</b>, <b>456</b>, <b>458</b>. Window <b>462</b> is not in a direct a path of the cursor as is icon <b>460</b>, but since it is near the path <b>468</b>, the effects associated with window <b>462</b> should have a higher spatial priority than the effects of objects <b>454</b>, <b>456</b>, and <b>458</b> and should be loaded in place of one of the lower-priority effects.</p>
<p id="p-0124" num="0123">In a more general sense, the host can monitor the motion of the user object <b>12</b> and swap multiple effects on the device with cached effects that are more likely to be output in the immediate future. Spatially-based criteria also can be used in conjunction with time-based criteria for determining memory slot availability.</p>
<p id="p-0125" num="0124">Referring back to <figref idref="DRAWINGS">FIG. 7</figref>, a priority system can also be used to determine which effect is most eligible to be unloaded or swapped out and replaced with a cached effect. For example, each type of force effect can be assigned a priority in an absolute priority system, where each effect can be given a rank in a priority list according to the type of effect. For example, a damping effect may be considered lower priority than a vibration periodic effect that may be more noticeable to the user. A “trigger” effect preferably has a higher priority than non-trigger effects. A trigger effect is an effect that is not always playing, but which must be immediately output if a predefined event or condition occurs. For example, a gun recoil trigger effect can be played each time a button on the device <b>11</b> is pushed by the user. Since trigger effects need to be played quickly, they should remain loaded in device memory as much as possible. Furthermore, an effect that is currently playing can have a higher priority than non-playing effects (including trigger effects not currently being played), since it can be disruptive to a user to suddenly stop playing an effect before it has finished. However, this may not be the case when using spatial caching since an effect currently playing can be immediately turned off if the user moves the user object <b>12</b> to a different location.</p>
<p id="p-0126" num="0125">The priority of the commanded effect is compared to the priorities of the loaded effects; the first effect having a lower priority is eligible to be swapped with the commanded effect. Alternatively, all the loaded effects can be examined, and the effect having the lowest priority can be eligible to be replaced with the commanded effect if the commanded effect has a higher priority than that effect. In some embodiments, only effects not currently playing are examined for availability; alternatively, all the loaded effects, whether currently playing or not, can be examined and the lowest priority effect unloaded.</p>
<p id="p-0127" num="0126">Furthermore, in some embodiments the priorities of effects for caching purposes can be changed by an operating system, application, or other program or user. For example, a developer of a force feedback application program can in some embodiments assign priorities to particular effects so that the developer has the flexibility to designate the importance of various effects to his or her particular application program. A priority system for a particular application could be provided to the host driver upon start-up of the application program. Such a priority system could be stored in a context for that application program, as described for <figref idref="DRAWINGS">FIG. 2</figref>, for example. In such a system, the developer should be able to assign the highest possible priority to any effect desired, which will cause a commanded effect having such a priority to be always loaded on the device regardless of which effects are already loaded. This allows the application to directly command force feedback on the device with no concerns about receiving failure messages.</p>
<p id="p-0128" num="0127">In addition, effects can be organized into various categories or “suites”, where the effects in a category are assigned priorities and/or where only particular categories need be in use at a particular time. This allows effects from other “inactive” categories to be unloaded from the device and effects included in the “active” category to be loaded. The priorities in some cases can be assigned by the developer of an application program. For example, a developer of a game application can make a category “On Land” which includes a collision effect and a weapon fire effect as priority <b>1</b>, an engine rumble effect as priority <b>2</b>, and a “slight breeze” effect as priority <b>3</b>. The developer also can make a category of “In Water” including a water resistance (damping) effect and explosion effect as priority <b>1</b>, a “strong current” effect as priority <b>2</b>, and “hitting sea kelp” as priority <b>4</b>. The application program calls the API to inform the host driver which category is currently in use, and when to switch categories. When, in the game, the user controls a vehicle to move from land into water, the application program indicates that the “On Land” category of effects should be switched to the “hi Water” category of effects. The host driver then knows that all “On Land” effects are free to be unloaded from the device memory and that the “In Water” effects should be loaded. Furthermore, since each effect has been assigned a priority, the host driver knows that if there is not enough slots to store all of the “On Water” effects, the water resistance and explosion effects should be loaded before the lower priority effects. Other uses of categories and priorities is described in co-pending patent application Ser. No. 09/306,002 entitled “Command of Force Sensations in a Force Feedback System using Force Effect Suites,” filed concurrently herewith, and incorporated herein by reference.</p>
<p id="p-0129" num="0128">The priority system described above can also be combined with other criteria, such as time-based and/or spatially-based criteria described above. For example, a priority can be assigned to a loaded effect based on multiple factors such as its effect type, its application-assigned priority, its time-based criteria, and/or its spatially-based criteria. For example, some force effects may be “one-shot” effects which are played once and then not used. These effects could have an initially high priority; once they are played, their priority can go to zero. In some embodiments, a total weighted priority can be assigned to the effect based on these factors and any weights assigned to the factors. The weighted priority of the loaded effect can then be compared to the (weighted) priority of the commanded effect to determine if the loaded effect can be swapped with the commanded effect.</p>
<p id="p-0130" num="0129">Furthermore, other criteria may also determine whether the commanded effect can be loaded. When implementing more sophisticated comparisons, weights, etc. the tradeoffs between available host processing power and gains in caching efficiency should be considered.</p>
<p id="p-0131" num="0130">A further consideration is whether the commanded effect can actually fit into the memory space occupied by a particular loaded effect. All effects occupy the same amount of space in the effect block <b>300</b>, but different effects occupy different amounts of space in the parameter block <b>304</b> based on how many parameters are used and workspace required for an effect. If the commanded effect will not fit into the space occupied by the loaded effect with the lowest priority, then that loaded effect should be excluded from comparison and other loaded effects are examined for eligibility. Alternatively, if the examined loaded effect does not occupy sufficient space for the commanded effect, the loaded effect can still be unloaded or destroyed. The process then examines another low-priority loaded effect and unloads that effect as well; this process may continue until sufficient space is freed for the commanded effect.</p>
<p id="p-0132" num="0131">If it is determined that the commanded effect can be loaded over a loaded effect in step <b>434</b>, then in step <b>432</b> a create command(s) is sent to the device to load the data for the commanded effect in the space of the expendable effect. It should be noted that the expendable effect is still available to be commanded by the application since it still resides in the host cache and memory model. The process then continues to step <b>426</b> to send a play command to the device and play the commanded effect as described above.</p>
<p id="p-0133" num="0132">If it is determined that the commanded effect cannot be loaded in step <b>434</b>, then in step <b>436</b> the command is given a failure status, and the commanded effect is not loaded to the device. Of course, only the “play” command itself has failed; the effect data still resides in the host cache and memory model. In some embodiments, the application program can remain ignorant of the failure; this allows the application program to believe that the force effect is playing properly and to issue another play command for that effect at a later time without disruption or additional processing (and the later command may succeed); in addition, this prevents the application from overreacting to the failure. In other embodiments, it may be desirable to inform the application program of any failure to play an effect so that the application program can compensate for the failure in other ways. The application program can be provided with varying degrees of information; for example, that the effect has been cached but did not play, or that the effect simply did not play. The process continues to step <b>438</b>, described below.</p>
<p id="p-0134" num="0133">In an alternate embodiment, the process can mark a failed cached commanded effect as “waiting.” Effects which have a status of “waiting” can be given a high priority to be loaded if any of the effect slots on the device should open up in future iterations. The host can maintain the effect's duration while it has a waiting status so that if an effect slot opens up, the host will know whether the waiting effect should still be output and if so, at which point in its duration. Thus, only effects which have a relatively long duration need be given a waiting status. For example, if a periodic effect having a duration of 4 seconds is waiting to be loaded on the device, the host keeps track of the duration; if 2 seconds have elapsed before an effect slot is available, the host commands the periodic effect starting at the third second. If four seconds have elapsed before an effect slot becomes available, then the host should cancel the effect since its duration has expired. In such a waiting embodiment, the process can check whether any waiting effects can be loaded to the device after an effect is untagged in step <b>422</b> or destroyed in step <b>414</b>; if so, the create command of step <b>416</b> or step <b>423</b> can be sent for the waiting effect (if the waiting effect has a high enough priority), and a play command can be sent, if appropriate, to play the formerly-waiting effect. Also, in steps <b>430</b> and <b>434</b>, a waiting effect can be assigned a priority or its existing priority can be increased due to the waiting status, and the waiting effect may be loaded before a currently-commanded effect if its priority is higher. It should be noted that in many implementations, such a waiting status is unnecessary, since many force effects are too short in duration to justify the extra processing required. In addition, devices having several effect slots can usually maintain realistic forces even if some force effects are discarded.</p>
<p id="p-0135" num="0134">In step <b>438</b>, the host can check whether any playing effect has expired, similarly to step <b>334</b> of <figref idref="DRAWINGS">FIG. 5</figref>. If no effects have expired, the process returns to step <b>406</b>. If at least one effect has expired, then the process continues to step <b>440</b> to untag the expired effect in the host memory model. In other embodiments, steps <b>438</b> and <b>440</b> can be omitted. The process then returns to step <b>406</b>.</p>
<p id="p-0136" num="0135">Force effect caching on the host can also be useful in other memory management paradigms in addition to the implementation described above where the host maintains a device memory model. For example, if only the device knows whether a commanded force effect can be stored in device memory, the device is queried by the host. If the device says that it cannot store any more effects, a driver on the host can create and cache the effect and inform the application program that its effect has been created, rather than indicating that the create command has failed.</p>
<p id="p-0137" num="0136">It is important to note that the process described above preferably is implemented at a level on the host computer lower than the application program controlling the forces. The application program thus is unaware of all the effect processing that may be going on. This relieves the application program from having to determine which effects should be destroyed and which should be created at different times, and allows the developer of the application to focus on other important aspects of application and force design.</p>
<p id="p-0138" num="0137"><figref idref="DRAWINGS">FIGS. 9</figref><i>a </i>and <b>9</b><i>b </i>are diagrammatic illustrations of the memory of the host and device when caching a force effect as explained in <figref idref="DRAWINGS">FIG. 7</figref>. In the example of <figref idref="DRAWINGS">FIG. 9</figref><i>a</i>, a device has five effect slots <b>480</b>, and all five slots have been filled with a force effect as shown. Two of the effects are currently playing (tagged) as shown in column <b>482</b>. The host, meanwhile, is storing a memory model <b>484</b> that includes seven force effects <b>485</b>. This is because the application program has created seven force effects and believes that all seven effects have been created on the device. Therefore, two of the created force effects have been cached by the host since the device can only store five effects.</p>
<p id="p-0139" num="0138">As shown in column <b>486</b>, the host driver keeps track of which force effects have actually been created (loaded) on the device. The host driver also keeps track in column <b>488</b> of which force effects are currently playing, i.e. output to the user. Thus, in the example shown, the host knows that the effects in slots <b>1</b>, <b>3</b>, <b>4</b>, <b>5</b>, and <b>6</b> of the host are loaded in the available slots of the device. The slots of the host and the device need not correspond since the host loads and unloads different effects from the device during application execution; however, the host driver does need to know which slots of the device the effects are stored so that the proper index into the effect block may be sent to the device. The host also knows that the effects in slots <b>3</b> and <b>4</b> of the host are currently playing on the device. If a cached effect is commanded to be played by the application, such as the Spring effect in slot <b>7</b> of the host, then the host can examine the loaded effect slots <b>480</b> to determine which slot the Spring effect can be loaded to. For example, the Periodic<b>1</b>, TriggerForce, and Periodic<b>2</b> effects on the device are not currently playing; since Trigger effects have a high priority, the Periodic<b>1</b> or Periodic<b>2</b> effect could likely be unloaded and the Spring<b>2</b> effect loaded in the available slot, depending on the conditions of availability and priorities used. In addition, in some embodiments the host can also maintain a “priority” field for each effect in the model <b>485</b> to allow the comparison of priorities for loading purposes.</p>
<p id="p-0140" num="0139"><figref idref="DRAWINGS">FIG. 9</figref><i>b </i>illustrates an embodiment <b>490</b> providing the waiting feature described above as an alternative to step <b>436</b> in <figref idref="DRAWINGS">FIG. 7</figref>. The host keeps track of which force effects are “waiting” as shown in column <b>492</b>. Thus, in the example shown, the effects in slots <b>1</b>, <b>3</b>, <b>4</b>, <b>5</b>, and <b>6</b> of the device have been loaded to the device and are all tagged, meaning they are all being currently output. The ConstantForce<b>1</b> effect in slot <b>2</b> of the host has been commanded by the application program to be played, but there is no available effect slot to store the commanded effect. The host therefore marks the commanded effect as “waiting” and monitors the device memory to determine if the commanded effect can be later loaded to the device and played. The host internally maintains the duration of the ConstantForce<b>1</b> effect so as to output the correct force magnitude, direction, etc. at the point in time when the waiting effect can be actually loaded to the device.</p>
<p id="p-0141" num="0140"><figref idref="DRAWINGS">FIG. 10</figref> is a diagrammatic illustration of an alternate “playlist” embodiment of the device memory of device <b>11</b>. In the above embodiments as shown in steps 362-378 of <figref idref="DRAWINGS">FIG. 6</figref>, the device <b>11</b> examined each effect slot in order and checked whether each effect was tagged (playing); if the effect were tagged, a force based on that effect was added to a total force that was output on the user manipulatable object <b>12</b>. <figref idref="DRAWINGS">FIG. 10</figref> illustrates an alternate method in which a playlist <b>500</b> is stored in device memory. An effect block <b>502</b> is stored on the device and host as explained above (a parameter block (not shown) may also be stored). When an effect is tagged by process <b>310</b> (e.g. in step <b>328</b> of <figref idref="DRAWINGS">FIG. 5</figref>), a pointer to that effect or index into the effect block is stored in the next available slot in the playlist <b>500</b>. Thus, only the topmost slots of the playlist are preferably filled, with any open slots at the bottom of the list. The total number of tagged effects is stored as a number in a memory location <b>504</b>, and is updated whenever an effect is tagged or untagged. In most implementations, the number of slots in the playlist <b>500</b> can be less than the number of effect slots implemented in the effect block <b>502</b>, since the number of playing effects is likely to be smaller than the total number of effects stored on the device. For example, the device may be able to store 30 effects, but the playlist might only require 10 slots.</p>
<p id="p-0142" num="0141">When an effect finishes or is stopped by a command, the effect is removed from the playlist. If there are other effects still playing which are located further down in the list past the removed effect, then one or more of these later effects can be moved to maintain a continuous playlist without gaps. For example, the last effect in the playlist can be moved to the location at which the removed effect used to be stored. In addition, after the effect is removed from the playlist, the total number of effects in location <b>504</b> is decremented.</p>
<p id="p-0143" num="0142">The efficiency of the playlist <b>500</b> is demonstrated when the playing process <b>350</b> of <figref idref="DRAWINGS">FIG. 6</figref> examines the device memory to determine which effects are to be output as forces. Instead of sequentially examining each slot in the effect block <b>502</b> as described in <figref idref="DRAWINGS">FIG. 6</figref>, the process instead simply examines the memory location <b>504</b> for the number of effects currently tagged (playing). Once this number T is known, the process then looks at the top T entries in the playlist <b>500</b> to determine which particular effects are playing, and calculates forces for those effects. This is much more efficient than examining the tag field for each entry in the effect block <b>502</b>, especially when there are many effects in the effect block <b>502</b>. Furthermore, if no effects or only a small number of effects are playing, no processing time is wasted checking each slot in the effects table.</p>
<p id="p-0144" num="0143">While this invention has been described in terms of several preferred embodiments, it is contemplated that alterations, permutations and equivalents thereof will become apparent to those skilled in the art upon a reading of the specification and study of the drawings. Also, the various features of the embodiments herein can be combined in various ways to provide additional embodiments of the present invention. Furthermore, certain terminology has been used for the purposes of descriptive clarity, and not to limit the present invention. It is therefore intended that the following appended claims include all such alterations, permutations, and equivalents as fall within the true spirit and scope of the present invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A computer-readable medium on which is encoded a computer program, comprising:
<claim-text>code for creating a representation of a haptic feedback device memory in a computer memory;</claim-text>
<claim-text>code for storing a haptic effect in a cache allocated in said computer memory;</claim-text>
<claim-text>code for determining whether said haptic feedback device memory can store said haptic effect by examining said representation of said haptic feedback device memory; and</claim-text>
<claim-text>code for sending said haptic effect to said haptic feedback device memory.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. A computer-readable medium as recited in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said haptic effect is sent to said haptic feedback device memory only if said haptic feedback device memory can store said haptic effect.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. A computer-readable medium as recited in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein determining whether said haptic feedback device memory can store said haptic effect comprises:
<claim-text>code for comparing a priority of said haptic effect with a priority of a loaded haptic effect already stored in said haptic feedback device memory; and</claim-text>
<claim-text>code for sending said haptic effect if said priority of said haptic effect is greater than said priority of said loaded haptic effect.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A computer-readable medium as recited in <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising code for storing a plurality of haptic effects in said cache in said computer memory regardless of whether said haptic feedback device memory comprises sufficient space to store said plurality of haptic effects.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A computer-readable medium as recited in <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising code for delaying the sending of said haptic effect to said haptic feedback device memory if said haptic feedback device memory is full.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A computer-readable medium as recited in <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>code for storing a plurality of haptic effects in said computer memory;</claim-text>
<claim-text>code for sending one of said plurality of haptic effects to said haptic feedback device memory when said one of said plurality of haptic effects is to be played; and</claim-text>
<claim-text>code for replacing a haptic effect stored in said haptic feedback device memory with said one of said plurality of haptic effects.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
