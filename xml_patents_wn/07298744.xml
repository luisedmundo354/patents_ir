<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298744-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298744</doc-number>
<kind>B1</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10749542</doc-number>
<date>20031230</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>803</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>12</main-group>
<subgroup>28</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>12</main-group>
<subgroup>56</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>370393</main-classification>
<further-classification>37039551</further-classification>
<further-classification>370466</further-classification>
<further-classification>370539</further-classification>
<further-classification>370907</further-classification>
<further-classification>709201</further-classification>
<further-classification>709202</further-classification>
<further-classification>709203</further-classification>
<further-classification>709213</further-classification>
<further-classification>709214</further-classification>
</classification-national>
<invention-title id="d0e53">Method and apparatus for centralized processing of contiguously and virtually concatenated payloads</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6842455</doc-number>
<kind>B1</kind>
<name>Heuer</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370393</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>2003/0007519</doc-number>
<kind>A1</kind>
<name>Murton et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370539</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2003/0043851</doc-number>
<kind>A1</kind>
<name>Wu et al.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370476</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2003/0074449</doc-number>
<kind>A1</kind>
<name>Smith et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709226</main-classification></classification-national>
</citation>
</references-cited>
<number-of-claims>17</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>14</number-of-drawing-sheets>
<number-of-figures>24</number-of-figures>
</figures>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Suh</last-name>
<first-name>Soowan</first-name>
<address>
<city>San Ramon</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Ling</last-name>
<first-name>Jing</first-name>
<address>
<city>Fremont</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Calderon</last-name>
<first-name>Juan-Carlos</first-name>
<address>
<city>Fremont</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="004" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Caia</last-name>
<first-name>Jean-Michel</first-name>
<address>
<city>San Francisco</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Blakley, Sokoloff, Taylor &amp; Zafman LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Intel Corporation</orgname>
<role>02</role>
<address>
<city>Santa Clara</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Jain</last-name>
<first-name>Raj K.</first-name>
<department>2616</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method and apparatus for processing at least two types of payloads received at varying intervals in a communications network using a single processing path is provided. The two types of payloads may include virtually and contiguously concatenated payloads according to SONET/SHD architecture. The method comprises assigning pseudo indices to payloads having no indices associated therewith and providing both sets of payloads, including indices and pseudo indices, to the single processing path.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="118.70mm" wi="234.87mm" file="US07298744-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="241.72mm" wi="155.62mm" orientation="landscape" file="US07298744-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="219.29mm" wi="152.40mm" orientation="landscape" file="US07298744-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="235.63mm" wi="154.52mm" orientation="landscape" file="US07298744-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="241.98mm" wi="158.58mm" orientation="landscape" file="US07298744-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="247.31mm" wi="177.80mm" orientation="landscape" file="US07298744-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="221.32mm" wi="172.21mm" orientation="landscape" file="US07298744-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="223.69mm" wi="157.65mm" orientation="landscape" file="US07298744-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="250.19mm" wi="167.05mm" orientation="landscape" file="US07298744-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="248.16mm" wi="176.36mm" orientation="landscape" file="US07298744-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="228.94mm" wi="188.89mm" orientation="landscape" file="US07298744-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="229.79mm" wi="188.89mm" orientation="landscape" file="US07298744-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="245.19mm" wi="176.95mm" orientation="landscape" file="US07298744-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="126.07mm" wi="189.74mm" orientation="landscape" file="US07298744-20071120-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="114.47mm" wi="127.93mm" orientation="landscape" file="US07298744-20071120-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">1. Field of the Invention</p>
<p id="p-0003" num="0002">The present invention relates generally to the field of high speed data transfer, and more specifically to managing contiguously and virtually concatenated payloads in specific data transfer architectures, such as SONET/SDH.</p>
<p id="p-0004" num="0003">2. Description of the Related Art</p>
<p id="p-0005" num="0004">Data communication networks receive and transmit ever increasing amounts of data. Data is transmitted from an originator or requester through a network to a destination, such as a router, switching platform, other network, or application. Along this path may be multiple transfer points, such as hardware routers, that receive data typically in the form of packets or data frames. At each transfer point data must be routed to the next point in the network in a rapid and efficient manner.</p>
<p id="p-0006" num="0005">Data transmission over fiber optics networks may conform to the SONET and/or SDH standards. SONET and SDH are a set of related standards for synchronous data transmission over fiber optic networks. SONET is short for Synchronous Optical NETwork and SDH is an acronym for Synchronous Digital Hierarchy. SONET is the United States version of the standard published by the American National Standards Institute (ANSI). SDH is the international version of the standard published by the International Telecommunications Union (ITU). As used herein, the SONET/SDH concepts are more fully detailed in various ANSI and ITU standards, including but not limited to the discussion of concatenated payloads, ITU-T G.707 2000, T1.105-2001 (draft), and T1.105.02-1995.</p>
<p id="p-0007" num="0006">SONET/SDH may employ at least two different types of payloads called contiguously concatenated payloads and virtually concatenated payloads. The difficulty with employing both contiguously concatenated and virtually concatenated payloads is that multiple paths may be required to process data received in both formats. Two paths and/or two processors may typically be employed to address both types of payloads. Contiguously concatenated payloads may, for example, be provided on one path and processed with knowledge that only contiguously concatenated data is received, while virtually concatenated payloads may be processed on another path with similar knowledge about the payloads received. While separate pipelines and/or separate processors may enable systematic and straightforward processing, such a multiple path implementation tends to decreased throughput and is generally inefficient.</p>
<p id="p-0008" num="0007">A design that enables both contiguously concatenated payloads and virtually concatenated payloads to be processed irrespective of the type of payload received may provide increased throughput and other advantageous qualities over previously known designs, including designs employing the SONET/SDH architecture.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0002" level="1">DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0009" num="0008">The present invention is illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings in which:</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 1</figref> is a conceptual illustration of a SONET/SDH communications switching system;</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 2A</figref> shows an empty STM-8 signal having eight time slots;</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 2B</figref> shows the STM-8 signal having one VC-4-4c virtual container and four VC-4 virtual containers included in the eight time slots;</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 3</figref> is one implementation of the present design;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 4A</figref> shows a data ordering pattern as may be encountered in a SONET/SDH environment;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 4B</figref> is a reoriented or reindexed data ordering pattern of the pattern of <figref idref="DRAWINGS">FIG. 4A</figref>;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 5</figref> illustrates the order for arrival of words from certain time slots as may be encountered in a SONET/SDH environment;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 6</figref> is an algorithm for generating pseudo multi frame indications, or MFIs;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 7</figref> illustrates an example of a traffic pattern that may be received by the eight preprocessors of the design in <figref idref="DRAWINGS">FIG. 3</figref>;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 8</figref> illustrates the traffic pattern from <figref idref="DRAWINGS">FIG. 7</figref> after reformatting;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 9</figref> shows eight physical FIFOs each containing 24 logical FIFOs;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 10</figref> is an example of an implementation of an interleaved data read-write reformatting method according to the present design;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIGS. 11A-11F</figref> present operation of the design of <figref idref="DRAWINGS">FIG. 10</figref>;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 12</figref> illustrates an alternate reformatting implementation according to the present design that uses a limited number of flip flops; and</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIGS. 13A-E</figref> show operation of the reformatting design of <figref idref="DRAWINGS">FIG. 12</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0003" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0025" num="0024">The present design provides for simultaneously addressing payloads or packets of data having different sizes or parameters. While the description provided herein is applicable to the SONET/SDH architecture, it is to be understood that the invention is not so limited, and may be employed in other transmission architectures.</p>
<p id="p-0026" num="0025">SONET/SDH defines optical carrier levels and electrically equivalent synchronous transport signals (STSs) for the fiber-optic based hierarchy. In SONET, any type of service, ranging from voice to high speed data and video, can be accepted by various types of service adapters. A service adapter maps the signal into the payload envelope of the STS-1 or virtual tributary. All inputs received are eventually converted to a base format of a synchronous STS-1 signal at 51.84 Mbps or higher. Several synchronous STS-1s may then be multiplexed together in either a single or two stage process to form an electrical STS-n signal, where n is one or more.</p>
<p id="p-0027" num="0026">SONET uses a basic transmission rate of STS-1, equivalent to 51.84 Mbps. Higher level signals are integer multiples of the base rate. For example, STS-3 is three times the rate of STS-1, i.e. three times 51.84 or 155.52 Mbps, while an STS-12 rate would be twelve times 51.84 or 622.08 Mbps. The SONET architecture employs frames, where the frame is generally divided into two main areas: transport overhead and the synchronous payload envelope, or SPE. The SPE comprises two components, namely STS path overhead and payload. The payload is the traffic being transported and routed over the SONET network. Once the payload is multiplexed into the SPE, the payload can be transported and switched through SONET without having the need to be examined and possibly demultiplexed at intermediate nodes.</p>
<p id="p-0028" num="0027">The SONET/SDH architecture supports contiguous concatenation, wherein a few standardized “concatenated” signals are defined, and each concatenated signal is transported as a single entity across the network. The concatenated signals are obtained by assembling, end to end, the payloads of the constituent signals, to form the contiguously concatenated payload. The payloads of the constituent signals arrive in fixed sizes, namely sizes specified for the SPE and STS arrangements described above. In creating, assembling or processing the contiguously concatenated payloads, the SONET/SDH standards establish certain rules for the arrangement or placement of standard concatenated signals. These rules were intended to ease the development burden for SONET/SDH designers, but the rules can significantly affect the bandwidth efficiency of SONET/SDH links.</p>
<p id="p-0029" num="0028">In order to address certain shortcomings of the contiguously concatenated payloads, the SONET/SDH architecture also supports the concept of Virtually Concatenated Payloads. Virtual concatenation enables dividing payloads to improve partitioning of SONET/SDH bandwidth and more efficiently carry traffic. Virtual concatenation employs the base SONET/SDH payloads and groups these payloads together to create a larger, size appropriate aggregate payload based on the STS and SPE employed. Virtual concatenation thus enables variation of the payload capacity and allows payload sizes matching client service data rate. This sizing enhancement allows a larger number of channels to be mapped into the SONET/SDH signal.</p>
<p id="p-0030" num="0029">A typical SONET/SDH switching system <b>100</b> is shown in <figref idref="DRAWINGS">FIG. 1</figref>. In the SONET/SDH switching system <b>100</b>, a transmitter <b>110</b> is connected through a communication pathway <b>115</b> to a switching network <b>120</b>. Switching network <b>120</b> is connected through a communication pathway <b>125</b> to a destination <b>130</b>. The transmitter <b>110</b> sends a frame as a series of payloads to the destination <b>130</b> through the switching network <b>120</b>. In the switching network <b>120</b>, packets typically pass through a series of hardware and/or software components, such as servers. As each payload arrives at a hardware and/or software component, the component may store the payload briefly before transmitting the payload to the next component. The packets proceed individually through the network until they arrive at the destination <b>130</b>. The destination <b>130</b> may contain one or more processing chips <b>135</b> and/or one or more memory chips <b>140</b>.</p>
<p id="p-0031" num="0030">In the SONET/SDH architecture, payloads may be transmitted in contiguously concatenated payloads and virtually concatenated payloads. The contiguous concatenation payload scheme uses a concatenation indicator in the pointer associated with each concatenated frame. The concatenation indicator indicates that the SPEs associated with the pointers are concatenated. Generally, every intermediate node or intermediate hardware/software component through which the concatenated string passes is configured to support contiguous concatenation. Payloads are generally of fixed sizes in contiguous concatenation.</p>
<p id="p-0032" num="0031">Contiguously concatenated payloads addressed may include those having payloads and data transfer rates designated in SONET/SDH as VC-4-Xc, where x is 1, 4, 16, or 64 for standard rate and other values between 1 and 64 for non-standard rate. Generally, these represent virtual containers of data, where, for example, VC-4-4c is a virtual container with four columns of fixed data, namely one column of path overhead and three columns of fixed data, and 1040 columns of payload data. VC-4-Xc virtual containers are loaded into an STM-X signal, where X may be any number of time slots, but typically 4, 16, etc. <figref idref="DRAWINGS">FIG. 2A</figref> shows an empty STM-8 signal <b>200</b> having eight time slots <b>201</b>-<b>208</b>. <figref idref="DRAWINGS">FIG. 2B</figref> shows a non-standard STM-8 signal having one VC-4-4c virtual container <b>209</b> in time slots <b>1</b>-<b>4</b> and four VC-4 virtual containers <b>210</b>-<b>213</b> included in time slots <b>5</b>-<b>8</b>. Other contiguously concatenated payload arrangements may be employed. Data transfer rates for these designations have the following values: VC-4-4c is 599.040 Mbit/s, VC-4-16c is 2,396.160 Mbit/s, and VC-4-64c is 9,584.640 Mbit/s.</p>
<p id="p-0033" num="0032">Virtual concatenation is available as an alternative to contiguous concatenation in transmitting payloads across the network. In virtual concatenation, each SPE within a concatenated group representing the data frame for transmission contains an identifier, called a Multi-Frame Identifier, or MFI. The MFI forms part of the SONET/SDH path overhead information in the SPE and indicates the SPE's sequence and position within the group. As may be appreciated, the ability to identify the individual payloads by the MFI provides the ability for the system to split the payloads into various sizes or configurations, as long as the MFI is provided with each payload.</p>
<p id="p-0034" num="0033">Virtual concatenation does not require intermediate node support, so the destination <b>130</b> for the network is the only specialized hardware required. The destination <b>130</b> reassembles the SPEs in the correct order to recover the data. To compensate for different arrival times of the received data, a phenomenon known as differential delay, the receiving circuits has typically contained some buffer memory so that the data can be properly realigned.</p>
<p id="p-0035" num="0034">The transmission rates and capacities of virtually concatenated payloads may vary, and may include, for example, SONET/SDH designations VC-3 and VC-4, which have payload capacities of 48.960 Mbit/s and 149.760 Mbit/s, respectively. Again, the VC-3 and VC-4 designations represent the virtual containers where, for example, VC-4 includes 9 rows of 261 columns transmitted in a 125 microsecond interval, and VC-3 is 9 rows of 85 columns transmitted in the 125 microsecond interval.</p>
<p id="p-0036" num="0035">The common challenge faced occurs upon reception of both contiguously concatenated payloads and virtually concatenated payloads. When both types of payloads are received, they are typically stored in storage buffers and reassembled either by separate processors or by a single processor that must await receipt of all payloads, contiguously or virtually concatenated. Due to the differential delay, data or payloads in the same group may arrive at the destination <b>130</b> at different times. In a dual processor or dual channel configuration, the system can be slow to act on the payloads received.</p>
<p id="p-0037" num="0036">In the present design, the destination <b>130</b> uses the MFI value to realign the VC-3 or VC-4 payloads belonging to the same group. The MFI value and the position in the virtual container determine whether two bytes from two different payloads were generated at the same time on the source side. To compensate for the differential delay, the destination <b>130</b> uses alignment buffers to store incoming data for each payload. The destination <b>130</b> reads data from the different payloads from the various alignment buffers having the same MFI and byte position at the same time. By associating the MFI and byte position in the virtual container with the corresponding byte at the input to the alignment buffer, the destination <b>130</b> can realign the data at the output of the buffer.</p>
<p id="p-0038" num="0037">Incoming SONET/SDH traffic may be byte interleaved among different time slots at a given rate. In one aspect of the present design, multi-rate ports may be provided, such as STM-1, STM-4, STM-16, and STM-64, having a data path width of 8 bytes and each byte in the format of a non-standard frame before conversion of the associated data.</p>
<p id="p-0039" num="0038">One implementation of the present design is presented in <figref idref="DRAWINGS">FIG. 3</figref>. From <figref idref="DRAWINGS">FIG. 3</figref>, eight byte STM-8 (non-standard frame) preprocessors may be employed, numbered <b>301</b>-<b>308</b>. Each incoming word belongs to a different time slot, one column out of every 192 columns at the STS-1 rate. The eight preprocessors <b>301</b>-<b>308</b> receive the SONET/SDH payload data in bytes which may be in any SONET/SDH compliant format, such as contiguously concatenated and virtually concatenated payload formats. As 192 STS-1 time slots exist in STM-64, after 24 clock cycles, the eight preprocessors <b>301</b>-<b>308</b> receive 192 slots of incoming data. Byte-to-word converter <b>309</b> then converts each of the 8 bytes from the 24 clock cycles, or interleaves one word of one time slot from each STM-8. Once the data is converted to words, the words then pass to processing block <b>310</b>. Data may be either virtually concatenated or contiguously concatenated when received by processing block <b>310</b>.</p>
<p id="p-0040" num="0039">In one aspect of the design, using AU-3 numbering as found in the ITU standard, in STM-64, at 10 Gbps, the ordering pattern <b>401</b> shown in <figref idref="DRAWINGS">FIG. 4A</figref> results. Each clock cycle in ordering pattern <b>401</b> represents one word. The index of a slot may be represented by:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Index=(<i>D−</i>1)*48+(<i>C−</i>1)*12+(<i>B−</i>1)*3+(<i>A−</i>1)  (1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 4A</figref> may then be reconfigured or re-indexed to the pattern <b>402</b> as shown in <figref idref="DRAWINGS">FIG. 4B</figref>. In this arrangement, after differential delay compensation and removal of SONET/SDH overhead, virtually no difference exists between processing contiguously concatenated payloads and virtually concatenated payloads.</p>
<p id="p-0042" num="0041">Data Reformatting</p>
<p id="p-0043" num="0042">The eight preprocessors <b>301</b>-<b>308</b> operate as follows. For a 10 Gbps signal (STM-64), with an internal processing frequency of 155.52 Mhz and a data path eight bits wide, employing STS-1, the traffic pattern illustrated in <figref idref="DRAWINGS">FIG. 7</figref> may be received by the eight preprocessors. Time zero is at the right side of <figref idref="DRAWINGS">FIG. 7</figref>, and each rectangle represents one byte from an STS-1 time slot. The slot number in <figref idref="DRAWINGS">FIG. 7</figref> is used to identify a slot, and is not related to the SONET/SDH interleaving sequence. The top line, representing data received at the first preprocessor <b>301</b>, includes STS-1 bit numbers <b>0</b> through <b>23</b> for all eight bytes received, while the second line represents STS-1 bit numbers <b>24</b> through <b>47</b> for all eight bytes received.</p>
<p id="p-0044" num="0043">In order to provide data for subsequent processing in a standardized and ordered manner, the present design reformats the incoming data by accumulating all eight bytes for each STS-1 time slot. This reformatting enables ordered reading and writing of data in compliance with SONET/SDH standards and enabling use of shared processing hardware. Once reformatted, the data is made available in the format shown in <figref idref="DRAWINGS">FIG. 8</figref>. The reformatting of <figref idref="DRAWINGS">FIG. 8</figref> provides data from one time slot for every clock cycle. Data on each line, again representing data at first preprocessor <b>301</b>, provides data at STS-1 slot numbers <b>0</b>, <b>24</b>, <b>48</b>, <b>72</b>, up to <b>168</b>, followed by data at STS-1 slot numbers <b>1</b>, <b>25</b>, <b>49</b>, <b>73</b>, up to <b>169</b>, and so forth, up to data at STS-1 slot numbers <b>23</b>, <b>47</b>, <b>71</b>, <b>95</b>, up to <b>191</b>.</p>
<p id="p-0045" num="0044">This reformatting enables reading 8 bytes of data from the same slot in a single clock cycle. Typical hardware and FIFO design has prohibited reading data in this manner, as data bytes from the same slot are all in the same RAM areas and the RAM width is only 8 bits. At most, in this hardware arrangement, one byte may be read from each slot during one clock cycle, not 8 bytes. In previous hardware arrangements, if one byte is removed for a certain STS-1 time slot, the time slot will not have 8 bytes available for reading. When output has a strict interleaving pattern, such as is required by SONET/SDH, the next time data bytes from the aforementioned time slot may be read is 192 cycles later. During the 192 clock cycles, more data bytes will arrive and additional storage space may be necessary. The reformatting detailed herein enables reading eight bytes from each slot during one clock cycle.</p>
<p id="p-0046" num="0045">The present reformatting uses 512 or 1024 flip flops, but other data arrangements employing different architectures and/or parameters may employ a larger or smaller number of flip flops. Use of 512 or 1024 flip flops in the present example can enable writing of data bytes from the same set of slots during every eight clock cycles.</p>
<p id="p-0047" num="0046">Data is first written into a 1 byte wide FIFO associated with the given slot. One byte-FIFO is required for each byte in the data path to accommodate the different read time at the output. Each byte-FIFO is time sliced into 24 logical FIFOs for each of the 24 STS-1 time slots. The size of each FIFO may be determined for the implementation as follows: as 8 bytes are read while accumulating another 8 bytes, 16 bytes may be available. To account for addition and removal of bytes, another 8 bytes of data may be required. Reading of the FIFOs may start at different times for each FIFO, requiring an additional 8 bytes of data, totaling 32 as the total number of bytes available per logical FIFO. <figref idref="DRAWINGS">FIG. 9</figref> shows 8 physical FIFOs each containing 24 logical FIFOs.</p>
<p id="p-0048" num="0047">One processor reads 8 bytes from eight different STS-1 time slots from FIFOs during each clock cycle. This processor then writes data into the reformatting flip flops. At the output of the reformatting flip flops, 8 bytes from the same STS-1 time slot may be read at one time. Reading 8 bytes from the same STS-1 time slot during 8 consecutive clock cycles and outputting data from the reformatting flip flops will be available in 8 clock cycles instead of 192, using the 1-byte wide FIFO memories before the reformatting flip flops.</p>
<p id="p-0049" num="0048">Alternately, the system may employ two sets of flip flops for reformatting data into the desired format. While writing in one set, the other set is read. Operation in such a design entails first writing to a first set of data, then writing to a second set of data while reading from the first, and finally reading from the second and writing to the first, and so on. Operation of such an interleaved read-write method and implementation thereof is illustrated in <figref idref="DRAWINGS">FIG. 10</figref>. From <figref idref="DRAWINGS">FIG. 10</figref>, the eight sets of physical FIFOs <b>1001</b> through <b>1008</b> write data to multiple sets of 2 by 8 flip flops, including 2 by 8 flip flops <b>1011</b>-<b>1018</b> and <b>1021</b>-<b>1028</b>. Data is then provided to a series of multiplexors, such as multiplexors <b>1031</b>, <b>1032</b>, and <b>1038</b>, which combine the data from the first set of flip flops (<b>1011</b> and <b>1021</b>, for example) into an 8 byte word, and data from the second set of flip flops (<b>1012</b> and <b>1022</b>, for example) into another 8 byte word, and so forth.</p>
<p id="p-0050" num="0049">The implementation of <figref idref="DRAWINGS">FIG. 10</figref> operates to transfer data as shown in <figref idref="DRAWINGS">FIGS. 11A-11F</figref>. Each square in <figref idref="DRAWINGS">FIGS. 11A-11G</figref> represent 8 flip flops or one byte of data. The number in each square represents the slot to which the data byte belongs. After the first clock cycle, data appears as shown in <figref idref="DRAWINGS">FIG. 11A</figref>. After 2 clock cycles, the data received appears as shown in <figref idref="DRAWINGS">FIG. 11B</figref>. After eight clock cycles, the data received appears as shown in <figref idref="DRAWINGS">FIG. 11C</figref>. The processor then can read eight bytes from a lot, and the eight bytes may be read from any of slots <b>0</b>, <b>24</b>, <b>48</b>, . . . , <b>168</b>. For example, the network may read slot <b>0</b> in the next clock cycle, and can write one data byte each from slots <b>1</b>, <b>25</b>, <b>49</b>, . . . , <b>169</b> in the next clock cycle. After 9 clock cycles, the data appears as shown in <figref idref="DRAWINGS">FIG. 11D</figref>, where slot <b>0</b> data has been removed and new data added in the rightmost column. Eight bytes may read and 8 written for each of the next several cycles. After 15 cycles, the data appears as shown in <figref idref="DRAWINGS">FIG. 11E</figref>. The final eight bytes may be read in the 16<sup>th </sup>clock cycle, and the result after the 16<sup>th </sup>clock cycle is as shown in <figref idref="DRAWINGS">FIG. 11F</figref>. At this point, the process may be repeated to read and write concurrently and fill and empty the flip flops.</p>
<p id="p-0051" num="0050">Another implementation of reformatting is illustrated in <figref idref="DRAWINGS">FIG. 12</figref>. From <figref idref="DRAWINGS">FIG. 12</figref>, the eight sets of physical FIFOs <b>1201</b> through <b>1208</b> write data to multiple sets of 8 flip flops, including 8 flip flops <b>1211</b>-<b>1218</b> and <b>1221</b>-<b>1228</b>. Data is then provided to a series of multiplexors, such as multiplexors <b>1231</b>, <b>1232</b>, and <b>1238</b>, which combine the data from the first set of flip flops (<b>1211</b> and <b>1221</b>, for example) into an 8 byte word, and data from the second set of flip flops (<b>1212</b> and <b>1222</b>, for example) into another 8 byte word, and so forth. This design uses only half the flip flops, namely 512 flip flops instead of 1024, and may employ a specific reading and writing arrangement.</p>
<p id="p-0052" num="0051">Reading and writing this data is illustrated in <figref idref="DRAWINGS">FIGS. 13A-E</figref>. Data written after one clock cycle appears as shown in <figref idref="DRAWINGS">FIG. 13A</figref>. After two clock cycles, data appears as in <figref idref="DRAWINGS">FIG. 13B</figref>, and after eight cycles as in <figref idref="DRAWINGS">FIG. 13C</figref>. After the eighth clock cycle, the network can read 8 bytes of data from slot <b>0</b> and will simultaneously write one byte of data from blocks <b>1</b> to <b>8</b>. After nine clock cycles, the data appears as shown in <figref idref="DRAWINGS">FIG. 13D</figref>, and after 10 clock cycles as in <figref idref="DRAWINGS">FIG. 13E</figref>. This diagonal reading and writing arrangement may proceed indefinitely, and enables use of fewer flip flops.</p>
<p id="p-0053" num="0052">Processing Payloads</p>
<p id="p-0054" num="0053">The complete reconstructed word, contiguous or virtual, is provided to the processing block <b>310</b>. Processing block <b>310</b> associates each virtually concatenated word with a number based on its MFI and position in the container, where the container may be a buffer or other data maintenance device, real or virtual. The number determines the time when processing block <b>310</b> reads the corresponding word at the output of alignment buffer <b>311</b> relative to all other time slot components in the same group. In certain configurations, such as the VC-4 configuration, the first time slot contains the MFI information and aligning and reading the MFI information in the first time slot enables processing of the virtually concatenated payload.</p>
<p id="p-0055" num="0054">Contiguously concatenated payloads contain no MFI information. In order to share the same path, including the same alignment buffer <b>311</b>, with a virtually concatenated payload, the same data read/write algorithm can be employed in this aspect of the design. The processor, and specifically the processing block <b>310</b>, may therefore establish a pseudo MFI for all contiguously concatenated time slots. In the SONET configuration, all VC-4s in the same VC-4-Xc data rate configurations may have the same MFI values for the virtual container generated by the processing block <b>310</b>. The master slot of a VC-4-Xc payload may generate an independent MFI value and all slave slots will use the same MFI value as the master slot.</p>
<p id="p-0056" num="0055">For nonstandard VC-4-Xc payloads, namely where X is not equal to 1, 4, 16, or 64, VC-4s contained in the same VC-4-Xc may spread over different STM-8 signals (or STM-16 or other signals). In such a nonstandard configuration, the master slot may be received at the destination <b>130</b> at a time later than slots in the same VC-4-Xc. For example, VC-4-9c virtual containers reside in slots having indices <b>21</b> through <b>47</b>, where the words from the corresponding time slots arrive in the order illustrated in <figref idref="DRAWINGS">FIG. 5</figref>. Master slots are shown in dark grey while slave slots are cross hatched.</p>
<p id="p-0057" num="0056">The pseudo MFI for a contiguously concatenated payload may be generated by the processing block <b>310</b> in varying ways. One way to form the pseudo MFI involves increasing the MFI value for the master slot by one at the beginning of each frame. The word number is 0 at the beginning of each frame. Subsequent slots in each VC-4 may copy the pseudo MFI from the previous slot. Slots in the same VC-4 typically arrive in order and thus copying later slots based on the first (master) slot MFI value will enable uniform pseudo MFI assignment. For the first time slot in each VC-4 other than the master slot, the processing block <b>310</b> copies the first slot from the previous VC-4. An algorithm for generating pseudo MFIs is illustrated in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0058" num="0057">From <figref idref="DRAWINGS">FIG. 6</figref>, the processing block <b>310</b> determines whether the current slot indices are divisible by three. As more words may be available in each frame than the number of time slots divided by three, the algorithm seeks to ensure that all time slots in the same VC-4-Xc virtual container have the same MFI value. If the current slot index is not divisible by three, and the current word number is zero, the MFI of the current slot index is equal to the MFI of the current slot index minus one. For example, if the slot index is <b>25</b> and the current word number is zero, the MFI of slot index <b>25</b> is equal to the MFI of slot index <b>24</b>. If the current slot is a master slot, and the current word number is one, the temporary MFI of the current slot index is equal to the temporary MFI of the current slot index plus one. For example, if the slot is a master slot and the word number is one, and the slot index is, for example, <b>21</b>, the temporary MFI of slot <b>21</b> is equal to the temporary MFI for slot <b>21</b> plus one. If the temporary MFI for slot <b>21</b> was <b>1203</b>, the temporary MFI for slot <b>21</b> becomes <b>1204</b>. If the current word number is zero, the MFI for the current slot index equals the temporary MFI for the current slot index. If the temporary MFI for slot <b>21</b> of word <b>0</b> is <b>1204</b>, the MFI for slot <b>21</b> becomes <b>1204</b>.</p>
<p id="p-0059" num="0058">If the current slot is not a master slot and the current slot index is divisible by three, the final processing of the <figref idref="DRAWINGS">FIG. 6</figref> algorithm occurs. If the current word number is equal to the current slot index divided by three plus one, then the temporary MFI for the current slot index is equal to the temporary MFI for the current slot index minus three. For example, if the current word number is <b>7</b>, and the current slot index is <b>18</b>, the word number (seven) is equal to the slot index (<b>18</b>) divided by three, or six, plus one, or seven. The temporary MFI for current slot index <b>18</b> is set equal to the temporary MFI for the current slot index (<b>18</b>) minus three, or 15. The temporary MFI for current slot <b>18</b> is set equal to the temporary MFI for slot <b>15</b>. Otherwise, if the current word number is zero, the MFI for the current slot index is set equal to the temporary MFI for the current slot index. If current word number is zero and the current slot index is <b>12</b>, the temporary MFI for slot <b>12</b> is provided as the MFI for slot <b>12</b>.</p>
<p id="p-0060" num="0059">From the foregoing, it may be appreciated that the current design entails receiving portions of a complete transmission, evaluating the portions of the transmission for indices and if indices are absent from the portions of the transmission, assigning an index to the portion and all portions of the complete transmission and passing the portions to a processor for processing irrespective of the presence or absence of indices. In the SONET/SDH environment, this entails receiving concatenated payloads, both virtual and contiguous, determining whether the payload is virtual or contiguous by evaluating the payload for the presence of an MFI, and if absent, providing an MFI, or pseudo MFI, to all payloads for the word transmitted. The payload may then be processed irrespective of whether it was virtually or contiguously concatenated using the SONET virtual concatenation ability at the receiving destination. The pseudo MFI is added to the contiguously concatenated payloads to enable processing by a single processor in a single path.</p>
<p id="p-0061" num="0060">Returning to <figref idref="DRAWINGS">FIG. 3</figref>, read/write addresses are provided by the processing block <b>310</b> to the alignment buffer <b>311</b>, which receives the data and aligns the data according to the read-write addresses provided. The aligned data is then provided to mappers <b>312</b> which map data for purposes of further processing.</p>
<p id="p-0062" num="0061">It will be appreciated to those of skill in the art that the present design may be applied to other systems that perform data processing, and is not restricted to the communications structures and processes described herein. Further, while specific hardware elements and related structures have been discussed herein, it is to be understood that more or less of each may be employed while still within the scope of the present invention. Accordingly, any and all modifications, variations, or equivalent arrangements which may occur to those skilled in the art, should be considered to be within the scope of the present invention as defined in the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for processing at least two types of payloads received at varying intervals in a communications network using a single processing path, said types of payloads including a first set of payloads having indices associated therewith, and a second set of payloads having no indices associated therewith, the method comprising:
<claim-text>assigning pseudo indices to the second set of payloads having no indices associated therewith; and</claim-text>
<claim-text>providing the first set of payloads having indices associated therewith and the second set of payloads having pseudo indices assigned to the single processing path, wherein the first set of payloads comprises virtually concatenated payloads according to SONET/SDH architecture, and the second set of payloads comprises contiguously concatenated payloads according to SONET/SDH architecture.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the providing comprises aligning the first set of payloads having indices associated therewith and the second set of payloads having pseudo indices assigned in an alignment buffer to form aligned data.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein said providing further comprises sending the aligned data to a data mapping element.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the aligning employs the indices for the first set of payloads to align the first set of payloads and the pseudo indices assigned to the second set of payloads to align the second set of payloads.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the indices for the first set of payloads comprise multi frame indication indices and the pseudo indices assigned to the second set of payloads comprise pseudo multi frame indication indices.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the indices for the first set of payloads comprise multi frame indication (MFI) indices and the pseudo indices assigned to the second set of payloads comprise pseudo MFI indices.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. An apparatus for processing at least two types of payloads received at varying intervals in a communications network using a single processing path, said types of payloads including a first set of payloads having indices associated therewith, and a second set of payloads having no indices associated therewith, the apparatus comprising:
<claim-text>a receiving preprocessing arrangement for receiving the first set of payloads and the second set of payloads, wherein the first set of payloads comprises virtually concatenated payloads according to SONET/SDH architecture, and the second set of Payloads comprises contiguously concatenated payloads according to SONET/SDH architecture;</claim-text>
<claim-text>a processor configured to receive the second set of payloads and assigning pseudo indices to the second set of payloads having no indices associated therewith; and</claim-text>
<claim-text>an alignment buffer configured to receive the first set of payloads, the second set of payloads, the indices for the first set of payloads, and the pseudo indices for the second set of payloads and provide aligned blocks of data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The apparatus of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the receiving preprocessing arrangement comprises a plurality of preprocessors configured to realign data.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the realignment of data comprises rearranging data into a predetermined format by simultaneously reading and writing data using a plurality of flip flops.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The apparatus of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the alignment buffer provides the aligned blocks of data to a data mapping element.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The apparatus of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the alignment buffer employs the indices for the first set of payloads to align the first set of payloads and the pseudo indices assigned to the second set of payloads to align the second set of payloads.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the indices for the first set of payloads comprise multi frame indication (MFI) indices and the pseudo indices assigned to the second set of payloads comprise pseudo MFI indices.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The apparatus of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the processor assigns pseudo indices for the second set of payloads based at least in part on word number and slot index for each payload of the second set of payloads.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A method for processing at least two types of payloads using a single processing path, said types of payloads including a first set of payloads having indices associated therewith and a second set of payloads having no indices associated therewith the method comprising:
<claim-text>assigning pseudo multi frame indications to all contiguously concatenated payloads; and</claim-text>
<claim-text>providing the virtually concatenated payloads and contiguously concatenated payloads having pseudo multi frame indications assigned thereto to the single processing path, wherein the first set of payloads includes virtually concatenated payloads and the second set of payloads includes contiguously concatenated payloads conforming to SONET/SDH requirements.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the providing comprises aligning the virtually concatenated payloads and contiguously concatenated payloads having pseudo multi frame indices assigned in an alignment buffer to form aligned data.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the aligning employs the multi frame indications for the virtually concatenated payloads to align the virtually concatenated payloads and the pseudo multi frame indications for the contiguously concatenated payloads to align the contiguously concatenated payloads.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein assigning pseudo multi frame indications is based at least in part on word number and slot index for each payload of the contiguously concatenated payloads.</claim-text>
</claim>
</claims>
</us-patent-grant>
