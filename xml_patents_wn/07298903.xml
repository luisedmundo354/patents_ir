<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298903-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298903</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>09895429</doc-number>
<date>20010628</date>
</document-id>
</application-reference>
<us-application-series-code>09</us-application-series-code>
<us-term-of-grant>
<us-term-extension>237</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>18</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382186</main-classification>
<further-classification>382187</further-classification>
</classification-national>
<invention-title id="d0e53">Method and system for separating text and drawings in digital ink</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4916608</doc-number>
<kind>A</kind>
<name>Shultz</name>
<date>19900400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5517578</doc-number>
<kind>A</kind>
<name>Altman et al.</name>
<date>19960500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382181</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5687254</doc-number>
<kind>A</kind>
<name>Poon et al.</name>
<date>19971100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382229</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5757962</doc-number>
<kind>A</kind>
<name>Gallo et al.</name>
<date>19980500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382204</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5889523</doc-number>
<kind>A</kind>
<name>Wilcox et al.</name>
<date>19990300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345854</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6084985</doc-number>
<kind>A</kind>
<name>Dolfing et al.</name>
<date>20000700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382187</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6161130</doc-number>
<kind>A</kind>
<name>Horvitz et al.</name>
<date>20001200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6192360</doc-number>
<kind>B1</kind>
<name>Dumais et al.</name>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6253169</doc-number>
<kind>B1</kind>
<name>Apte et al.</name>
<date>20010600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6304674</doc-number>
<kind>B1</kind>
<name>Cass et al.</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382224</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6565611</doc-number>
<kind>B1</kind>
<name>Wilcox et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715541</main-classification></classification-national>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2002/0064308</doc-number>
<kind>A1</kind>
<name>Altman et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382187</main-classification></classification-national>
</citation>
<citation>
<nplcit num="00013">
<othercit>Burges, C. “A Tutorial on Support Vector Machines for Pattern Recognition” ® 1998 Kluwer Academic Publishers, Boston. Data Mining and Knowledge Discovery, 2, 121-167.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00014">
<othercit>Poon, et al. “Scribbler: A Tool for Searching Digital Ink” [online] ® 1995 ACM [retrieved Jul. 16, 2004]. Retrieved from &lt;http://www.acm.org/sigchi/chi95/Electronic/documnts/shortppr/adp<sub>—</sub>bdy.htm&gt;.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00015">
<othercit>Joachims, T. “Text Categorization with Support Vector Machines: Learning wtih Many Relevant Features”. 1998, Proceedings the European Conference on Machine Learning, pp. 137-142.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00016">
<othercit>Lopresti, et al. “On the Searchability of Electronic Ink”, Proceedings of the Fourth International Workshop on Frontiers of Handwriting Recognition, Dec. 1994, Taipei, Taiwan, pp. 156-165.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00017">
<othercit>Lopresti, et al. “Algorithms for Matching Hand-Drawn Sketches”. Proceedings of the Fifth International Workshop on Frontiers Handwriting Recognition, Sep. 1996, Colchester, England, pp. 233-238.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00018">
<othercit>Lopresti, Daniel. “Ink As Multimedia Data”. Proceedings of the Fourth International Conference on Information, Systems, Analysis and Synthesis, Jul. 1998, Orlando, FL, pp. 122-128.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00019">
<othercit>Aref, et al. “On the Handling of Electronic Ink”. ACM Computing Surveys, vol. 27, No. 4, Dec. 1995, pp. 564-567.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
</references-cited>
<number-of-claims>14</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382159</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382179</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382182-183</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382185-186</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382198</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382200</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382202</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382225</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382229</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382187</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345858</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715514</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>14</number-of-drawing-sheets>
<number-of-figures>16</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20030007683</doc-number>
<kind>A1</kind>
<date>20030109</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Wang</last-name>
<first-name>Jian</first-name>
<address>
<city>Bejing</city>
<country>CN</country>
</address>
</addressbook>
<nationality>
<country>CN</country>
</nationality>
<residence>
<country>CN</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Ling</last-name>
<first-name>Haibin</first-name>
<address>
<city>Beijing</city>
<country>CN</country>
</address>
</addressbook>
<nationality>
<country>CN</country>
</nationality>
<residence>
<country>CN</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Lyu</last-name>
<first-name>Siwei</first-name>
<address>
<city>Beijing</city>
<country>CN</country>
</address>
</addressbook>
<nationality>
<country>CN</country>
</nationality>
<residence>
<country>CN</country>
</residence>
</applicant>
<applicant sequence="004" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Zou</last-name>
<first-name>Yu</first-name>
<address>
<city>Beijing</city>
<country>CN</country>
</address>
</addressbook>
<nationality>
<country>CN</country>
</nationality>
<residence>
<country>CN</country>
</residence>
</applicant>
</applicants>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Microsoft Corporation</orgname>
<role>02</role>
<address>
<city>Redmond</city>
<state>WA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>LaRose</last-name>
<first-name>Colin</first-name>
<department>2624</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A system for separating text and drawings in a digital ink file (e.g., a handwritten digital ink file). A stroke analyzer classifies single strokes that have been input by a user as “text” or “unknown.” The stroke analyzer utilizes a trainable classifier, such as a support vector machine. A grouping component is provided that groups text strokes in an attempt to form text objects (e.g., words, characters, or letters). The grouping component also groups unknown strokes in an attempt to form objects (e.g., shapes, drawings, or even text). A trainable classifier, such as a support vector machine, evaluates the grouped strokes to determine if they are objects.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="246.21mm" wi="165.35mm" file="US07298903-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="237.15mm" wi="186.27mm" orientation="landscape" file="US07298903-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="213.11mm" wi="135.97mm" orientation="landscape" file="US07298903-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="225.13mm" wi="172.89mm" file="US07298903-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="250.02mm" wi="179.75mm" file="US07298903-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="219.71mm" wi="146.39mm" file="US07298903-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="246.21mm" wi="165.61mm" file="US07298903-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="195.58mm" wi="168.49mm" file="US07298903-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="250.95mm" wi="179.83mm" file="US07298903-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="204.72mm" wi="177.88mm" file="US07298903-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="206.76mm" wi="132.08mm" file="US07298903-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="192.96mm" wi="141.82mm" file="US07298903-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="170.01mm" wi="183.64mm" file="US07298903-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="232.16mm" wi="167.47mm" file="US07298903-20071120-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="210.06mm" wi="154.18mm" file="US07298903-20071120-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">The invention relates generally to computers, and more particularly to digital ink files.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">Digital ink technology enables a user to write and draw on the touch-sensitive screen of a handheld PC or other writing tablet with a stylus or other pointing device, providing a convenient means for applications to accept input from a user without using a keyboard. For a user, taking notes or drawing sketches with using digital ink technology is very much like writing or drawing on paper.</p>
<p id="p-0004" num="0003">Often, a single handwriting sample that is input via digital ink technology includes both text and drawings. The drawings may be intermixed among the text, and may even encircle the text. Although displaying a text/drawing digital ink file is not that difficult, often a user desires to have the text recognized by the computer receiving the digital ink file. Recognizing the text may be difficult, however, because the digital ink technology may not be able to distinguish the drawings from the text.</p>
<p id="p-0005" num="0004">To address this problem, many handwriting recognition technologies assume that handwriting input by a user is text. Although this solution works well when the handwriting input actually is text, if a digital ink file does include both text and drawings, the assumption is not correct, and the accuracy and rate of the recognition decreases.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0006" num="0005">The present invention provides a method and system for separating text and drawings in a digital ink file (e.g., a handwritten digital ink file). To this end, the present invention provides a stroke analyzer that classifies single strokes that have been input by a user as “text” or “unknown.” In accordance with another aspect of the present invention, a grouping component is provided that attempts to group strokes so as to form text objects (e.g., words, characters, or letters). The text objects may then be recognized or otherwise processed with more efficiency.</p>
<p id="p-0007" num="0006">To perform the stroke analysis, in accordance with one aspect of the present invention, a model for curvature features for single strokes is trained using a trainable classifier, such as a support vector machine (SVM). The curvature features are represented by a curvature vector. The curvature vector may include information obtained, for example, by a tangent histogram or discrete curvature calculation of a stroke. Using the trainable classifier, a single stroke may be classified in accordance with the stroke's curvature vector as either “text” or “unknown.”</p>
<p id="p-0008" num="0007">In accordance with another aspect of the present invention, after the strokes have been classified as text or unknown, strokes are grouped on a spatial basis. The spatial grouping may be based upon how close single strokes were made relative to one another, a time stamp basis (e.g., the proximity of time of creation of the stroke to the time of creation of other strokes), a combination of these, or based on other criteria.</p>
<p id="p-0009" num="0008">After strokes are grouped, a determination is made whether the grouped text strokes are a text object (e.g., a word or letter). In accordance with one aspect of the present this determination may be made, for example, by evaluating the context each of the strokes in the group relative to other strokes in the group (i.e., locally). The local evaluation of the strokes may result in elimination of some of the strokes in a stroke group that have features that suggest the strokes are not text strokes.</p>
<p id="p-0010" num="0009">The grouped strokes may also be analyzed contextually on a global basis. The global contextual analysis involves evaluating the strokes in the group against the strokes in the digital ink file, including those outside the stroke group. This evaluation aids in determining if one or more strokes are to be eliminated from and/or added to the text group.</p>
<p id="p-0011" num="0010">Grouped unknown strokes are evaluated via a grouped stroke classification component. In one embodiment, the grouped stroke classification component is a trainable classifier, such as a neural network, a Bayesian network, or a support vector machine that is trained to classify grouped strokes as text or unknown based upon features of the grouped strokes. The grouped stroke classification component may utilize an energy spectrum vector generated for the grouped unknown strokes by a Harr wavelet transform to classify grouped unknown strokes.</p>
<p id="p-0012" num="0011">The ink separation and grouping methods of the present invention result efficient separation of text and drawings in a digital ink file. Separation permits increased recognition of text, permitting more efficient processing of a digital ink file.</p>
<p id="p-0013" num="0012">Other advantages will become apparent from the following detailed description when taken in conjunction with the drawings, in which:</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram representing a computer system into which the present invention may be incorporated;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 2</figref> shows generally an architecture for a system for separating text and drawings of a digital ink file in accordance with one aspect of the invention;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 3</figref> shows a block diagram representing an architecture of a stroke classification module in accordance with an aspect of the invention;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 4</figref> shows a general overview of a process for training a trainable classifier to recognize curvature features of strokes in accordance with one aspect of the present invention;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 5</figref> is a representation of an ink trace showing how discrete curvature may be calculated in accordance with one aspect of the present invention;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 6</figref> shows a general overview of a process for calculating a tangent histogram of an ink trace in accordance with an aspect of the present invention;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 7</figref> shows a general overview of a process for classifying strokes of a digital ink file as “text” or “unknown” in accordance with one aspect of the present invention;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 8</figref> is a representation of a digital ink document;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 9</figref> shows a block diagram representing an architecture of a grouping module in accordance with an aspect of the present invention;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 10</figref> shows a general overview of a process of grouping strokes and classifying the grouped strokes as text or drawing objects in accordance with one aspect of the present invention;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 11</figref> is a general overview of a process for grouping strokes spatially with a stroke known to be a text stroke in accordance with one aspect of the present invention;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 12</figref> shows a general overview of a process that may be used to evaluate grouped strokes locally in accordance with an aspect of the present invention;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 13</figref> shows a general overview of a process that may be used to evaluate grouped strokes globally in accordance with an aspect of the present invention;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 14</figref> shows a general overview of a process for evaluating whether a stroke should be added to a stroke group in accordance with one aspect of the present invention;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 15</figref> is a general overview of a process for training a trainable classifier to recognize density features of stroke groups in accordance with one aspect of the present invention; and</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 16</figref> shows a general overview of a process for classifying a stroke group as a text object or an unknown stroke group in accordance with one aspect of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0030" num="0029">In the following description, various aspects of the present invention will be described. For purposes of explanation, specific configurations and details are set forth in order to provide a thorough understanding of the present invention. However, it will also be apparent to one skilled in the art that the present invention may be practiced without the specific details. Furthermore, well known features may be omitted or simplified in order not to obscure the present invention.</p>
<p id="h-0006" num="0000">Exemlary Operating Environment</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an example of a suitable computing system environment <b>100</b> on which the invention may be implemented. The computing system environment <b>100</b> is only one example of a suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of the invention. Neither should the computing environment <b>100</b> be interpreted as having any dependency or requirement relating to any one or combination of components illustrated in the exemplary operating environment <b>100</b>.</p>
<p id="p-0032" num="0031">The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems, environments, and/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers, server computers, hand-held or laptop devices, multiprocessor systems, microcontroller-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and the like.</p>
<p id="p-0033" num="0032">The invention may be described in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, and so forth, which perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote computer storage media including memory storage devices.</p>
<p id="p-0034" num="0033">With reference to <figref idref="DRAWINGS">FIG. 1</figref>, an exemplary system for implementing the invention includes a general-purpose computing device in the form of a computer <b>110</b>. Components of the computer <b>110</b> may include, but are not limited to, a processing unit <b>120</b>, a system memory <b>130</b>, and a system bus <b>121</b> that couples various system components including the system memory to the processing unit <b>120</b>. The system bus <b>121</b> may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus also known as Mezzanine bus.</p>
<p id="p-0035" num="0034">Computer <b>110</b> typically includes a variety of computer-readable media. Computer-readable media can be any available media that can be accessed by the computer <b>110</b> and includes both volatile and nonvolatile media, and removable and non-removable media. By way of example, and not limitation, computer-readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules, or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can accessed by the computer <b>110</b>. Communication media typically embodies computer-readable instructions, data structures, program modules, or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term “modulated data signal” means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer-readable media.</p>
<p id="p-0036" num="0035">The system memory <b>130</b> includes computer storage media in the form of volatile and/or nonvolatile memory such as read only memory (ROM) <b>131</b> and random access memory (RAM) <b>132</b>. A basic input/output system <b>133</b> (BIOS), containing the basic routines that help to transfer information between elements within computer <b>110</b>, such as during start-up, is typically stored in ROM <b>131</b>. RAM <b>132</b> typically contains data and/or program modules that are immediately accessible to and/or presently being operated on by processing unit <b>120</b>. By way of example, and not limitation, <figref idref="DRAWINGS">FIG. 1</figref> illustrates operating system <b>134</b>, application programs <b>135</b>, other program modules <b>136</b>, and program data <b>137</b>.</p>
<p id="p-0037" num="0036">The computer <b>110</b> may also include other removable/non-removable, volatile/nonvolatile computer storage media. By way of example only, <figref idref="DRAWINGS">FIG. 1</figref> illustrates a hard disk drive <b>140</b> that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive <b>151</b> that reads from or writes to a removable, nonvolatile magnetic disk <b>152</b>, and an optical disk drive <b>155</b> that reads from or writes to a removable, nonvolatile optical disk <b>156</b> such as a CD ROM or other optical media. Other removable/non-removable, volatile/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive <b>141</b> is typically connected to the system bus <b>121</b> through a non-removable memory interface such as interface <b>140</b>, and magnetic disk drive <b>151</b> and optical disk drive <b>155</b> are typically connected to the system bus <b>121</b> by a removable memory interface, such as interface <b>150</b>.</p>
<p id="p-0038" num="0037">The drives and their associated computer storage media, discussed above and illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, provide storage of computer-readable instructions, data structures, program modules, and other data for the computer <b>110</b>. In <figref idref="DRAWINGS">FIG. 1</figref>, for example, hard disk drive <b>141</b> is illustrated as storing operating system <b>144</b>, application programs <b>145</b>, other program modules <b>146</b>, and program data <b>147</b>. Note that these components can either be the same as or different from operating system <b>134</b>, application programs <b>135</b>, other program modules <b>136</b>, and program data <b>137</b>. Operating system <b>144</b>, application programs <b>145</b>, other program modules <b>146</b>, and program data <b>147</b> are given different numbers herein to illustrate that at a minimum, they are different copies. A user may enter commands and information into the computer <b>20</b> through input devices such as a keyboard <b>162</b> and pointing device <b>161</b>, commonly referred to as a mouse, trackball or touch pad. Other input devices (not shown) may include a microphone, joystick, game pad, satellite dish, scanner, a touch-sensitive screen of an handheld PC or other writing tablet, or the like. These and other input devices are often connected to the processing unit <b>120</b> through a user input interface <b>160</b> that is coupled to the system bus, but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). A monitor <b>191</b> or other type of display device is also connected to the system bus <b>121</b> via an interface, such as a video interface <b>190</b>. In addition to the monitor, computers may also include other peripheral output devices such as speakers <b>197</b> and printer <b>196</b>, which may be connected through an output peripheral interface <b>190</b>.</p>
<p id="p-0039" num="0038">The computer <b>110</b> may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer <b>180</b>. The remote computer <b>180</b> may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer <b>110</b>, although only a memory storage device <b>181</b> has been illustrated in <figref idref="DRAWINGS">FIG. 1</figref>. The logical connections depicted in <figref idref="DRAWINGS">FIG. 1</figref> include a local area network (LAN) <b>171</b> and a wide area network (WAN) <b>173</b>, but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet.</p>
<p id="p-0040" num="0039">When used in a LAN networking environment, the computer <b>110</b> is connected to the LAN <b>171</b> through a network interface or adapter <b>170</b>. When used in a WAN networking environment, the computer <b>110</b> typically includes a modem <b>172</b> or other means for establishing communications over the WAN <b>173</b>, such as the Internet. The modem <b>172</b>, which may be internal or external, may be connected to the system bus <b>121</b> via the user input interface <b>160</b> or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer <b>110</b>, or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation, <figref idref="DRAWINGS">FIG. 1</figref> illustrates remote application programs <b>185</b> as residing on memory device <b>181</b>. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.</p>
<p id="h-0007" num="0000">System for Separating Text and Drawings in Digital Ink</p>
<p id="p-0041" num="0040">Typically, a user generates digital ink information by writing on a touch-sensitive screen or tablet with a stylus or other writing instrument. Other methods may be used to generate digital ink information, such as mouse or other pointer movements, or ink traces of existing documents. The digital ink file generated by a digital ink generator may include information about the user's writing movements, along with enhanced information such as calculated vector information, pressure, timing, strokes, angle of stylus, italic and bold states, and the like. There are a variety of different digital ink formats, and the additional information that the format can store or process with the ink trace varies for the different applications.</p>
<p id="p-0042" num="0041">In general, the most basic element of digital ink is a stroke. Each drawing, character, word, letter, or shape is typically input as a stroke, a series of strokes, or a portion of a stroke. When a touch sensitive screen is utilized, the stroke is the information generated between a pen down event and a pen up event. If a mouse or other pointer object is used, then the stroke is information that is generated without separation, such a continuous line, a swipe, or a mark. In either event, the stroke may be as short as a dot for an “I,” or may be as long as a flowing line with several curves, such as made when writing cursive English. One or more strokes may be used to form a letter or a character, or a single stroke may be used to form several letters or characters. As an example of the latter, a single English cursive stroke may represent several letters.</p>
<p id="p-0043" num="0042">The present invention is directed to a system and method for separating text and drawings in a digital ink file. Briefly described, the present invention classifies single strokes that have been input by a user as “text” or “unknown.” In accordance with one aspect of the present invention, a grouping component is provided that attempts to group text strokes so as to form text objects (e.g., words, characters, or letters). The grouping component also attempts to group unknown strokes to form objects (e.g., shapes, drawings, or even text).</p>
<p id="p-0044" num="0043">Turning now to the drawings, <figref idref="DRAWINGS">FIG. 2</figref> shows generally an architecture for a system <b>200</b> for separating text and drawings of a digital ink file in accordance with one aspect of the invention. The system <b>200</b> includes a computer <b>202</b> (e.g., the computer <b>110</b>) having a digital ink receiver <b>204</b>. The digital ink receiver <b>204</b> receives raw data generated by a user's writing movements, processes that data if necessary, and forwards corresponding digital ink data to appropriate software, such as an operating system or an application. In this manner, the digital ink receiver <b>204</b> enables a user to input information into a computer utilizing a digital ink generator such as a writing tablet, and without having to use a keyboard.</p>
<p id="p-0045" num="0044">In accordance with one aspect of the present invention, the digital ink receiver <b>204</b> includes, or alternatively is associated with, a stroke classification module <b>206</b>, which is configured to separate known text strokes from other strokes of a digital ink file, as is further described below. The digital ink receiver <b>204</b> and the stroke classification module <b>206</b> may be provided on a single PC (e.g., the personal computer <b>202</b>), or the stroke classification module <b>206</b> may be provided on a separate machine from the digital ink receiver <b>204</b>. In addition, their various functions may be performed by a single device or by several devices.</p>
<p id="p-0046" num="0045">In accordance with one aspect of the present invention, and as further described below, a grouping module <b>210</b> may be provided for grouping text strokes or unknown strokes, and for determining whether the grouped strokes are objects, such as words, characters, letters, shapes, or drawings. The grouping module <b>210</b> is included in, or otherwise is associated with, the stroke classification module <b>206</b>. The grouping and stroke classification modules <b>210</b>, <b>206</b> may be provided on a single PC (e.g., the personal computer <b>202</b>), or the stroke classification module <b>206</b> may be provided on a separate machine from the grouping module <b>210</b>. In addition, their various functions may be performed by a single device or by several devices located on the same machine or distributed over various machines.</p>
<p id="p-0047" num="0046">The grouping module <b>210</b> may be connected to a recognizer <b>208</b> and/or a display generation mechanism <b>209</b>, each of which may be integrated with, or separate from, the computer <b>202</b>. One or both of these components, or other software including the operating system for the computer <b>202</b>, may utilize the output of the grouping module <b>210</b>.</p>
<p id="p-0048" num="0047">The computer <b>202</b> is connected via a connection <b>212</b> to a digital ink generator <b>220</b>, which is a mechanism that generates digital ink, e.g., as a result of writing movements by a user. The digital ink generator <b>220</b> may be, for example, a writing tablet that receives writing input via a stylus, or a pen that incorporates components (e.g., an accelerometer) that generate digital ink information as a result of writing movements by a user. As another example, digital ink may be generated as a result of curve tracing of a digital image. However, the present invention has particular relevance to digital ink files in which the digital ink file generated by the digital ink generator <b>220</b> includes information about the strokes that were input to create the file.</p>
<p id="p-0049" num="0048">The digital ink data is transmitted to the computer <b>202</b> via the connection <b>212</b>. The connection <b>212</b> may be hardwired or wireless (wherein if wireless, the connection is conceptual, e.g., line-of-sight for infrared, or within range for FM transmissions, and so forth). As some examples, the computer <b>202</b> may be located remotely from the digital ink generator <b>220</b>, and transmission of digital ink from the digital ink generator <b>220</b> to the computer may occur via a wireless transmission, a local area network (e.g., the LAN <b>171</b>), a wide area network (e.g., the WAN <b>173</b>), the Internet, or through another network or similar connection. Alternatively, digital ink information may be stored in memory in the digital ink generator <b>220</b>, and may be later downloaded to the computer <b>202</b>. In addition, some or all of the functions of the digital ink receiver <b>204</b>, the stroke classification module <b>206</b>, and the grouping module <b>210</b> may be integrated with the digital ink generator <b>220</b>, although in practice, such a design may result in a mechanism that may be too cumbersome for comfortable digital ink input.</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 3</figref> shows a block diagram representing an architecture of the stroke classification module <b>206</b> in accordance with an aspect of the invention. The stroke classification module <b>206</b> includes a separation component <b>302</b>, a curvature calculator <b>304</b>, and a single stroke classification component <b>308</b>. The stroke classification module <b>206</b> includes, or otherwise is associated with, one or more databases <b>308</b> (only one is shown in the figures). The function and operation of each of these components is described below.</p>
<p id="h-0008" num="0000">Building the Single Stroke Classification Component</p>
<p id="p-0051" num="0050">In accordance with one aspect of the present invention, the single stroke classification component <b>308</b> is a trainable classifier that is configured to learn information about stroke curvature based upon a large data set of strokes. The trainable classifier may be, for example, a neural network, a Bayesian network, or a support vector machine, but is preferably a support vector machine. Although each of these trainable classifiers is known in the art, the theory and operation of a support vector machine is described for the reader's convenience.</p>
<p id="p-0052" num="0051">An object to be classified may be represented by a number of features, referred to as a “feature vector.” If, for example, the object to be classified is represented by two (2) features, it may be represented by a point in two (2) dimensional space. Similarly, if an object to be classified is represented by n features, it may be represented by a point in n-dimensional space. The simplest form of an support vector machine defines a plane in the n-dimensional space (also referred to as a “hyperplane”) that separates feature vector points associated with objects “in a class” and feature vector points associated with objects “not in the class.” A number of classes may be defined by defining a number of hyperplanes. The hyperplane defined by a trained support vector machine maximizes a distance (also referred to as an Euclidean distance) from it to the closest points (also referred to as “support vectors”) “in the class” and “not in the class.” A hyperplane is sought which maximizes the distances between the support vectors and the hyperplane, so that the support vector machine defined by the hyperplane is robust to input noise. The hyperplane (or hypersurface) is defined by a training process.</p>
<p id="p-0053" num="0052">In accordance with one aspect of the present invention, a trainable classifier is trained to define hyperplanes for curvature features of known stroke values. To this end, <figref idref="DRAWINGS">FIG. 4</figref> shows a general overview of a process for training the trainable classifier to recognize the curvature features of strokes in accordance with one aspect of the present invention. For ease of reference, the trainable classifier is referred to hereinafter as a support vector machine, although other trainable classifiers may be used. In this example, the objects that are to be in a class are strokes that fall within a margin of error of meeting the curvature features of a trained stroke, The different curvature features are defined by a “curvature vector,” which may include such information as a tangent histogram of a stroke, or information regarding the discrete curvature of a stroke, as further described below.</p>
<p id="p-0054" num="0053">Beginning at step <b>400</b>, the support vector machine retrieves a known stroke sample for a given class. The sample may be, for example, a known stroke element for a letter, or a stroke that represents an English cursive word. The stroke sample may be one of hundreds that have been generated by separate individuals.</p>
<p id="p-0055" num="0054">Information about the curvature of the stroke is then generated. The information represents the curvature vector that is supplied to the support vector machine, as further described below. In this example, discrete curvature of a number of points along the curve is calculated, and the combined curvature is used as the curvature vector. Other methods may be used, as is described below.</p>
<p id="p-0056" num="0055">In any event, in this example, at step <b>402</b>, the stroke is divided into a plurality of segments. The number of segments may be set as desired, but in one implementation of the invention is <b>64</b> segments. The segments are preferably of equal length.</p>
<p id="p-0057" num="0056">Using the stroke's segments, the discrete curvature of the points between segments is calculated at step <b>404</b> (e.g., by the curvature calculator <b>304</b>). An example of how the discrete curvature may be calculated is shown in <figref idref="DRAWINGS">FIG. 5</figref>. The original ink curve <b>500</b> in the example has been separated into a number of segments <b>502</b><sub>1</sub>, <b>502</b><sub>2 </sub>(only two of the segments are shown in <figref idref="DRAWINGS">FIG. 5</figref> for ease of example, but the number is preferably <b>64</b>, as described above). Points <b>504</b><sub>1</sub>, <b>504</b><sub>2</sub>, and <b>504</b><sub>3 </sub>are defined at the junctures of the segments.</p>
<p id="p-0058" num="0057">Having the points <b>504</b><sub>1</sub>, <b>504</b><sub>2</sub>, <b>504</b><sub>3</sub>, angles α<sub>1</sub>, α<sub>2 </sub>are defined between lines <b>506</b><sub>1</sub>, <b>506</b><sub>2 </sub>extending between the points and a reference line, in this case horizontal reference lines <b>508</b><sub>1</sub>, <b>508</b><sub>2</sub>. The discrete curvature of a point <b>504</b><sub>N </sub>along the line is then defined by the difference between the angle α<sub>N−1 </sub>at the previous point <b>504</b><sub>N−1 </sub>and the angle α<sub>N </sub>at the point <b>504</b><sub>N</sub>:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Curvature (Point <i>N</i>)=α<sub>N−1</sub>−α<sub>N</sub><?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0059" num="0058">The angle α<sub>N </sub>may be calculated using geometry:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>α<sub>N</sub>=arctan ((<i>X</i><sub>N+1</sub><i>−X</i><sub>N</sub>)/(<i>Y</i><sub>N+1</sub><i>−Y</i><sub>N</sub>))<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where X<sub>N+1 </sub>is the X coordinate for the point <b>504</b><sub>N+1</sub>, X<sub>N </sub>is the X coordinate for the point <b>504</b><sub>N</sub>, Y<sub>N+1 </sub>is the Y coordinate for the point <b>504</b><sub>N+1</sub>, and Y<sub>N </sub>is the Y coordinate for the point <b>504</b><sub>N</sub>.
</p>
<p id="p-0060" num="0059">Having the curvature for all points <b>504</b> along the line, the curvature vector for the series of curvatures is set as the curvature vector for the stroke at step <b>406</b>.</p>
<p id="p-0061" num="0060">The curvature vector may be calculated in other ways. As an example, as generally shown in <figref idref="DRAWINGS">FIG. 6</figref>, a tangent histogram for a stroke may be generated. The tangent histogram represents a series of the second derivatives of the tangents of the curve. To generate the tangent histogram, beginning at step <b>600</b>, a defined number of tangents are calculated at spaced distances along the curve. The number of tangents may be limited to tangents drawn at a number of equally spaced points along the curve, e.g., 64, or tangents may be drawn at any interval along the curve. Setting a limited number of tangents to be calculated limits the processing that must be conducted by the computer <b>202</b>.</p>
<p id="p-0062" num="0061">At step <b>602</b>, the derivatives (e.g., slopes) of the tangents are plotted, to form a representation of the angles of the curve relative to a reference line (e.g., horizontal). At step <b>604</b>, the derivative of the angle curve is calculated, which represents the curvature of the curve. It can be understood that the second derivative of the tangent information may be calculated directly from the tangent information, avoiding the intermediate step of generating the angle curve. The second derivative information along the stroke, representing the tangent of the stroke, may then be used as the curvature vector for the stroke at step <b>606</b>.</p>
<p id="p-0063" num="0062">The tangent histogram may be used to generate a more accurate representation of the curvature of the stroke. The discrete curvature calculations above, on the other hand, are roughly equivalent to the curvature of the stroke, but not quite as accurate. However, the discrete curvatures are more easily calculated, saving processing time and speeding the support vector machine learning process.</p>
<p id="p-0064" num="0063">In any event, returning to <figref idref="DRAWINGS">FIG. 4</figref>, at step <b>408</b>, the features of the curvature vector are compared by the support vector machine against possible curvature features for strokes. This information is used to train the support vector machine to generate a trained curvature vector for the present class of strokes.</p>
<p id="p-0065" num="0064">The process for training support vector machines in known, but a brief description is given here to aid the reader. First, the support vector machine is initialized and trained on known inputs (in this example, strokes) having known output values, or classifications. For example, a given text stroke value, if English, may be a letter, a series of letters, or a portion of a letter. A number of features are defined for a given curvature vector which may or may not be present within a particular class. The support vector machine may be initialized by setting the weights and biases of the processing features (e.g., values for the series of discrete curvatures) to random values, typically generated from a Gaussian distribution. The support vector machine is then trained using a succession of inputs (in this example, the curvature vectors of strokes) having known outputs or classes. As the training inputs are fed to the support vector machine, the values of the weights and biases for particular features are adjusted (e.g., in accordance with a known back-propagation technique) such that the output of the support vector machine of each individual training pattern approaches or matches the known output (step <b>410</b>). Basically, a gradient descent in weight space is used to minimize the output error. In this manner, learning using successive training inputs converges towards a locally optimal solution for the weights and biases. That is, the weights and biases are adjusted to minimize an error.</p>
<p id="p-0066" num="0065">In practice, the system is not trained to the point where it converges to an optimal solution. Otherwise, the system would be “over trained” such that it would be too specialized to the training data and might not be good at classifying inputs which differ, in some way, from those in the training set. Thus, at various times during its training, the system is tested on a set of validation data. Training is halted when the system's performance on the validation set no longer improves.</p>
<p id="p-0067" num="0066">At step <b>412</b>, a determination is made if the system's performance on the validation set no longer improves. If not, the process loops back to step <b>400</b>, where the next stroke for the class is obtained. If so, the process for that stroke ends, and a determination is made at step <b>414</b> whether all classes have been trained. If not, the next class of stroke begins training at step <b>416</b>. If so, the process ends.</p>
<p id="p-0068" num="0067">After all stroke classes have been trained, the support vector machine is ready for use with the invention. It can be understood that the number of classes may be large, and thus training the support vector machine may be a time-consuming and expensive process, requiring thousands of stroke samples from hundreds of individuals. However, once trained, the support vector machine of the present invention may be duplicated and used in the single stroke classification component <b>308</b> for multiple applications.</p>
<p id="h-0009" num="0000">Classifying Strokes</p>
<p id="p-0069" num="0068">In accordance with one aspect of the present invention, after trained, the stroke classification module <b>206</b> may be used to separate known text strokes from other strokes. <figref idref="DRAWINGS">FIG. 7</figref> shows a general overview of a process for classifying strokes of a digital ink file as “text” or “unknown” (e.g., via the stroke classification module <b>206</b>) in accordance with one aspect of the present invention. Beginning at step <b>700</b>, a user generates digital ink using the digital ink generator <b>220</b>. In general, as can be seen in <figref idref="DRAWINGS">FIG. 8</figref>, the original digital ink data may include a series of strokes <b>802</b> made by a user that represent a document <b>804</b> drawn by the user. <figref idref="DRAWINGS">FIG. 8</figref> is a simplistic example, but gives some examples of some types of strokes that may be included in a document or digital ink file. For example, some of the strokes may, by themselves, represent text (e.g., the single stroke <b>802</b><sub>1 </sub>is a continual stroke that represents the word “me”). Some strokes may be combined with other strokes to create text (e.g., the strokes <b>802</b><sub>2</sub>-<b>802</b><sub>7 </sub>represent the word “the”). Still other strokes may represent shapes or drawings (e.g., strokes <b>802</b><sub>8</sub>-<b>620</b><sub>12</sub>). Some of the drawing strokes may represent a shape by themselves (e.g., stroke <b>802</b><sub>8 </sub>is a square drawn by a single stroke). Other drawings strokes may combine with other strokes to form a shape (e.g., strokes <b>802</b><sub>9</sub>-<b>602</b><sub>10 </sub>are two line segments that generally represent a circle). If a touch-sensitive screen is utilized, additional digital ink information, such as calculated vector information, pressure, timing, strokes, angle of stylus, and the like, may be generated by the touch-sensitive screen or tablet, and may be included in the digital ink file. At step <b>702</b>, the strokes <b>802</b> and additional digital ink information (if available) are transferred to the computer <b>202</b> via the connection <b>212</b> and are received by the digital ink receiver <b>204</b>.</p>
<p id="p-0070" num="0069">At step <b>704</b>, the separation component <b>302</b> retrieves one of the strokes of the digital ink file, and at step <b>706</b> the separation component divides the stroke into a plurality of segments. The number of segments may be set as desired, but should be equal to the value used in the training process.</p>
<p id="p-0071" num="0070">At step <b>708</b>, the discrete curvature for the stroke's segments is calculated (e.g., by the curvature calculator <b>304</b> in the manner described above). Using the series of discrete curvatures, the curvature vector for the stroke is set at step <b>710</b>.</p>
<p id="p-0072" num="0071">The contents of the curvature vector are applied as input to the support vector machine (SVM) classifier of the single stroke classification component <b>308</b> (step <b>712</b>). Based on the features that are present in the curvature vector, the support vector machine generates a probabilistic measure as to whether the stroke is one of the trained strokes in the support vector machine or not (step <b>714</b>). This measure is then compared against a preset threshold value (step <b>716</b>).</p>
<p id="p-0073" num="0072">If probabilistic measure for the stroke equals or exceeds the threshold, then step <b>716</b> branches to step <b>718</b>, where the stroke is classified as “unknown.” Alternatively, if the probabilistic measure for the stroke is less than the threshold, then step <b>716</b> branches to step <b>720</b>, where the stroke is classified as text, and is assigned the value of the corresponding text stroke in the support vector machine (step <b>722</b>).</p>
<p id="p-0074" num="0073">The single stroke classification process described herein results in a number of strokes being classified as text and/or unknown. The classified strokes may then be further analyzed, as described below, or may be maintained in the database <b>308</b> for later analysis or use.</p>
<p id="h-0010" num="0000">Grouping Strokes and Classifying as Objects</p>
<p id="p-0075" num="0074">In accordance with one aspect of the invention, after strokes have been classified as “text” or “unknown,” strokes are grouped, and an analysis is made as to whether to classify the grouped strokes as a text object. The system uses components to analyze the groups, and through analysis, provides stroke groups that are likely text objects. By grouping the strokes into a text object, more efficient recognition, display, or other uses of the handwritten document are available.</p>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. 9</figref> shows a block diagram representing an architecture of the grouping module <b>210</b> in accordance with an aspect of the present invention. The grouping module <b>210</b> includes a text spatial grouping component <b>902</b>, a drawing spatial grouping component <b>904</b>, a local contextual analyzer <b>906</b>, a global contextual analyzer <b>908</b>, and a grouped stroke classification component <b>910</b>. The function and operation of each of these components is described below.</p>
<p id="p-0077" num="0076">A general overview of a process of grouping strokes and classifying the grouped strokes as text or drawing objects is shown in <figref idref="DRAWINGS">FIG. 10</figref>. Beginning at step <b>1000</b>, an evaluation is made whether all text strokes have been analyzed. That is, a determination is made if grouping and grouped classification has been attempted for all text strokes. If not, then step <b>1000</b> branches to step <b>1002</b>, where a text stroke is retrieved. At step <b>1004</b>, the text stroke is grouped with strokes that are adjacent in sequence and/or distance (e.g., by the text spatial grouping component <b>902</b>). The strokes that are grouped with the selected text stroke may have been previously classified as “text” or “unknown.” In general, in accordance with one aspect of the present invention, adjacent strokes are grouped with a text stroke because there is a probability that the strokes are also text because the strokes are close in sequence and location relative to the text stroke. A process for grouping the strokes spatially is described in connection with <figref idref="DRAWINGS">FIG. 11</figref>, below.</p>
<p id="p-0078" num="0077">At step <b>1006</b>, the grouped result is then evaluated contextually on a local basis (e.g., via the local contextual analyzer <b>906</b>). In general, evaluating the grouped strokes contextually involves eliminating some of the strokes in the stroke groups that have features that suggest the strokes are not text strokes. The strokes are evaluated against adjacent strokes, thus the term “local” is used to describe the evaluation. The process may result in a text group no longer being considered a text group, and changing the status of the text group to “unknown.” This process further assures that the strokes in the group represent text. A process for analyzing the context of the strokes locally is generally described in connection with <figref idref="DRAWINGS">FIG. 12</figref>, below.</p>
<p id="p-0079" num="0078">After being evaluated locally, the grouped strokes, whether classified as text or not, are analyzed contextually on a global basis at step <b>1008</b> (e.g., by the global contextual analyzer <b>908</b>). This process involves evaluating the strokes in the group against the strokes in the digital ink file, including those outside the stroke group. This evaluation aids in determining if one or more strokes are to be eliminated from and/or added to the text group. The process increases the likelihood that each of the strokes is a text stroke in a text group, and to further assures that all relevant strokes are included in the text group. In addition, a group that is not known to be a text group may be grouped with a text group on a global basis, and may thereby be classified as a text object. A process for analyzing the context of the strokes globally is described in connection with <figref idref="DRAWINGS">FIG. 13</figref>, below.</p>
<p id="p-0080" num="0079">If the grouped strokes are classified as a text object by the global contextual analyzer <b>908</b>, step <b>1010</b> branches to step <b>1012</b>, where the grouped strokes are labeled as a text object, and the process of grouping and classifying of that set of strokes is complete. The process then loops back to step <b>1000</b>, where a determination is made whether all text strokes have been analyzed.</p>
<p id="p-0081" num="0080">If the global contextual analysis does not classify the grouped strokes as text, then step <b>1010</b> branches to step <b>1014</b>, where the grouped strokes are designated as a grouped unknown strokes, which are analyzed later, described below. In either event, the process loops back to step <b>1000</b>, where a determination is made whether all text strokes have been analyzed.</p>
<p id="p-0082" num="0081">The process continues until all text strokes have been analyzed. It is possible that the process may be complete after analyzing of all text strokes. For example, the single stroke classification component <b>308</b> may have classified all strokes as text. In addition, all unknown strokes may have been grouped with text strokes during one or more operations of the grouping steps <b>1004</b>, <b>1006</b>, and/or <b>1008</b>, and may have been labeled as text objects. However, if unknown strokes and/or groups remain after all the text strokes have been analyzed, step <b>1000</b> branches to step <b>1016</b>, where a determination is made as to whether all unknown strokes or groups have been analyzed. If so, the process ends, as described below. If not, step <b>1016</b> branches to step <b>1018</b>, where an unknown stroke or group is retrieved. At step <b>1020</b>, the unknown strokes or groups are grouped spatially, if possible, e.g., by the drawing spatial grouping component <b>904</b>. The process for grouping the unknown strokes spatially is similar to the process for grouping the text strokes spatially, and is described in connection with the description of the grouping of text strokes spatially, generally with <figref idref="DRAWINGS">FIG. 11</figref>, below.</p>
<p id="p-0083" num="0082">After grouping the unknown strokes or groups spatially, at step <b>1022</b>, the grouped unknown strokes are evaluated via the grouped stroke classification component <b>910</b>. The processes of building the grouped stroke classification component <b>910</b>, and evaluating the grouped strokes via the grouped stroke classification component <b>910</b>, are described below. In summary, however, the grouped stroke classification component <b>910</b> is a trainable classifier, such as a neural network, a Bayesian network, or a support vector machine that is trained to classify grouped strokes as text or unknown based upon features of the grouped strokes. In one example described below, the grouped stroke classification component <b>910</b> utilizes an energy spectrum vector generated for the grouped unknown strokes by a Harr wavelet transform to classify grouped unknown strokes.</p>
<p id="p-0084" num="0083">After being classified by the grouped stroke classification component <b>910</b>, the grouped strokes are analyzed contextually on a global basis at step <b>1008</b> (e.g., by the global contextual analyzer <b>908</b>) to further classify the grouped strokes so that they might be labeled as a text object. The grouped stroke classification component <b>910</b> then may group some strokes with the group, as described below, and determines whether the group of strokes is a text object at step <b>1010</b>. The process then loops back to step <b>1016</b>, where a determination is made as to whether all unknown strokes and/or groups have been analyzed.</p>
<p id="p-0085" num="0084">After all unknown strokes and/or groups have been analyzed, step <b>1016</b> branches to step <b>1024</b>, where the unknown groups that were not classified as text objects are designated as drawing objects. The process is then complete, typically resulting in a number of text objects and a number of drawing objects.</p>
<p id="p-0086" num="0085">The grouping process described results in a number of grouped text or drawing objects. One or more of the objects may be a single stroke, because the grouping process may not result in grouping of a text or unknown stroke with other strokes. The text or drawing objects may then be processed as desired. For example, text recognition may be performed on the text objects, and the recognized text and drawing objects may be displayed. If desired, the text and drawing objects may be maintained in the database <b>308</b>, where they may be retrieved and processed later.</p>
<p id="h-0011" num="0000">Grouping the Strokes Spatially</p>
<p id="p-0087" num="0086">At step <b>1004</b>, described above, the text spatial grouping component <b>902</b> groups a text stroke with strokes that are spatially related to the text stroke. That is, sequential strokes that are in close proximity to a text stroke may be grouped with the text stroke. In general, in accordance with one aspect of the present invention, adjacent strokes are grouped with a text stroke because there is a probability that the strokes are also text because the strokes are close in sequence and position relative to the text stroke.</p>
<p id="p-0088" num="0087">The strokes are grouped based upon local characteristics. Thresholds may be set for determining whether a stroke is to be combined with a text stroke spatially. For example, if a stroke is the sequential stroke immediately before or after a text stroke, and is a defined distance from the text stroke, the text spatial grouping component may group the two strokes together. A similar process may be used for grouping unknown strokes, e.g., using the drawing spatial grouping component <b>904</b>.</p>
<p id="p-0089" num="0088">Numerous possibilities are available for combining strokes spatially, however, for ease of explanation, an example of a general overview of a process for grouping strokes spatially with a stroke known to be a text stroke is generally shown in <figref idref="DRAWINGS">FIG. 11</figref>. Beginning at step <b>1100</b>, a text stroke is retrieved. At step <b>1102</b>, the next sequential (i.e., after in time) stroke is retrieved. The next sequential stroke may be a text stroke or an unknown stroke. For ease of illustration, this particular stroke is referred to as “stroke <b>2</b>.”</p>
<p id="p-0090" num="0089">At step <b>1104</b>, a determination is made whether stroke <b>2</b> is within a defined distance, or within a distance threshold, from the text stroke. If so, then step <b>1104</b> branches to step <b>1106</b>, where stroke <b>2</b> is combined with the text stroke. The process then loops back to step <b>1102</b>, where the next sequential stroke is retrieved (for ease of illustration, referred to as “stroke <b>3</b>”). The process then proceeds through step <b>1104</b>, where a determination is made whether stroke <b>3</b> is within the defined distance from stroke <b>2</b>, and so forth.</p>
<p id="p-0091" num="0090">When a sequential stroke is outside the defined distance from the present stroke, then step <b>1104</b> branches to step <b>1108</b>, where the stroke that is immediately previous in sequence to the text stroke is retrieved. For ease of description, this stroke is referred to herein as “stroke (−1).” At step <b>1110</b>, a determination is made whether stroke (−1) is within the defined distance from the text stroke. If so, then step <b>1110</b> branches to step <b>1112</b>, where stroke (−1) is combined with the text stroke. The process then loops back to step <b>1108</b>, where the next previous sequential stroke is retrieved (for ease of illustration, referred to as “stroke (−2)”). The process then proceeds through step <b>1110</b>, where a determination is made whether the stroke (−2) is within the defined distance from the stroke (−1), and so forth. When a previous sequential stroke is outside the defined distance from the present stroke, the grouping process for the text stroke ends.</p>
<p id="p-0092" num="0091">The distance used as a threshold by the text spatial grouping component <b>902</b> may be fixed, such a distance obtained by a statistical analysis of several user's handwriting. Alternatively, the distance may be calculated from the strokes in the particular document, e.g., a maximum distance between known text strokes, or that maximum distance plus an error amount. In one embodiment, average stroke height h<b>0</b> and standard variance of height of known text strokes d<b>0</b> are calculated. Strokes that have a height that falls within the range of (h<b>0</b>+d<b>0</b>) and (h<b>0</b>−d<b>0</b>) are averaged to determine an average height h<b>1</b>. The distance threshold is then set at (h<b>1</b>)/2. Other methods of normalization may be used to determine the distance.</p>
<p id="p-0093" num="0092">The number of grouped strokes in a text group may vary depending upon the layout of the digital ink file. In some digital files, there may be multiple groups of multiple strokes. Using <figref idref="DRAWINGS">FIG. 8</figref> as an example, if at least one of the strokes <b>802</b><sub>2</sub>-<b>802</b><sub>7 </sub>was previously classified as a text stroke, and the strokes are within the defined distance from one another, the text spatial grouping component <b>902</b> would group these six strokes together. Similarly, multiple unknown strokes may be grouped by the drawing spatial grouping component <b>904</b>. Again using <figref idref="DRAWINGS">FIG. 8</figref> as an example, if none of the strokes <b>802</b><sub>9</sub>-<b>802</b><sub>13 </sub>was previously classified as a text stroke, and the strokes are within the defined distance from one another, the text spatial grouping component <b>902</b> would group these five strokes together.</p>
<p id="p-0094" num="0093">There may be times when a single text or unknown stroke, because of the defined threshold, may not be grouped with any other strokes. Using the document <b>804</b> in <figref idref="DRAWINGS">FIG. 8</figref> again as an example, the strokes <b>802</b><sub>1 </sub>and <b>802</b><sub>8</sub>, because of their distance to other strokes, may not be grouped with other strokes. Whether the single strokes would be considered a text or unknown group would depend upon the classification of the individual stroke. That is, if the stroke were classified by the single stroke classification component as being text, then the stroke would be classified as a text group.</p>
<p id="h-0012" num="0000">Analyzing Context Locally</p>
<p id="p-0095" num="0094">As described above, the local contextual analyzer <b>906</b> may evaluate local characteristics of the strokes that are grouped with one or more text strokes to further determine if each of the strokes should remain in the group before the group is classified as a text object. Although there is a good probability that strokes grouped by the text spatial grouping component <b>902</b> are text strokes, there are exceptions, and some of these exceptions may occur regularly so that the exceptions may be eliminated using statistical rules. To this end, the local context analyzer <b>906</b> utilizes one or more features of strokes and defines a threshold for each of the features, or a combination of the features. Rules are established using the thresholds wherein a stroke that exceeds (or falls under, depending upon the threshold limit) the threshold is not considered to be text. The strokes are evaluated against adjacent strokes, thus the term “local” is used to describe the evaluation. In this manner, the local context analyzer <b>906</b> may eliminate one or more strokes in a stroke group that was combined by the text spatial grouping component <b>902</b>, and the probability that all strokes in the text group are text increases.</p>
<p id="p-0096" num="0095">The process may result in a text group no longer being considered “text,” thus changing the category for the group to “unknown.” This feature eliminates some false positives that may have been grouped by the text spatial grouping component <b>902</b>, such as, for example, where a stroke was initially designated as text, grouped with other, unknown strokes, and then it is determined by the local context analyzer <b>906</b> that the stroke initially classified as text is likely not text.</p>
<p id="p-0097" num="0096">A number of different features may be used to help classify the strokes locally. As one example, some strokes may be eliminated for grouping because of relative height compared to the other strokes in the group. This approach may be used because, for the most part, the range of heights for adjacent characters typically does not alter that much in a user's writing. A rule such as the following may be established to eliminate strokes that are outside a normal variance in height relative to an adjacent stroke:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Threshold<sub>1</sub>&gt;(<i>h</i><sub>1</sub><i>/h</i><sub>2</sub>)&gt;(1/Threshold<sub>1</sub>)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where Threshold<sub>1 </sub>is a number that reflects an allowable variance in height between strokes that are adjacent in sequence, h<sub>1 </sub>is the height of a stroke that in a text group, and h<sub>2 </sub>is the height of the next adjacent stroke. Threshold<sub>1 </sub>may be a defined number for all writers, such as the number 2, or may be derived from the user's known text strokes. As an example of how to derive the number from a particular user's text stokes, a given user's known text strokes may vary no more than a ratio of 2 from the tallest to shortest strokes, and using that number, a variance, which may be 2, or 2 with an error factor (e.g., 2*1.1=2.2) may be used.
</p>
<p id="p-0098" num="0097">An unknown stroke that violates the above height rule against a known text stroke may be eliminated from a text group, and is designated as an unknown stroke. Similarly, a stroke that violates this rule against text strokes that are both before and after the stroke in a text group may be eliminated. This may result in separating the text group into two texts groups, the two text groups consisting of the strokes on opposite sides of the rule-violating stroke. Often, the rule-violating stroke is located at an end of a text group, and may be eliminated using the rule. Using the height rule above, a stoke that appears to be much taller or shorter than the normal range of a user's writing may be eliminated.</p>
<p id="p-0099" num="0098">As another example of a feature that may be used, some strokes may be eliminated because the aspect ratio of the stroke falls outside a defined range of aspect ratios for strokes. A formula may be defined for the range such as follows:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>(<i>W</i><sub>1</sub><i>/h</i><sub>1</sub>)&gt;(<i>w/h</i>)&gt;(<i>w</i><sub>2</sub><i>/h</i><sub>2</sub>)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where W<sub>1</sub>/h<sub>1 </sub>is a high threshold for an aspect ratio, W<sub>2</sub>/h<sub>2 </sub>is a low threshold for an aspect ratio, and W/h is the actual aspect ratio for a stroke. The stroke may be eliminated from a stroke group if it does not fall in this range. W<sub>1</sub>/h<sub>1 </sub>and W<sub>2</sub>/h<sub>2 </sub>may be determined based on the particular user's strokes, or may be determined statistically. As an example, a range for aspect ratios of strokes may be defined by extracting aspect ratios for text strokes formed from several people's handwriting. A margin of error for detecting the text strokes may be defined, and aspect ratios that result in an error percentage exceeding the margin may be considered to be too high. The ratio for a single stroke is very large so that only a very long and thin stroke will reasonably fall outside the range. In this manner, long cursive strokes are not eliminated.
</p>
<p id="p-0100" num="0099">An example of a general overview of a process that may be used by the local contextual analyzer <b>906</b> is shown in <figref idref="DRAWINGS">FIG. 12</figref>. Beginning at step <b>1200</b>, the thresholds for the aspect ratios of strokes in a text group is determined. At step <b>1202</b>, a stroke from a text group is retrieved, and at step <b>1204</b> the aspect ratio of the stroke is calculated. At step <b>1206</b>, a determination is made as to whether the aspect ratio of the stroke falls outside the defined thresholds. If so, then the stroke is discarded from the stroke group in step <b>1208</b>. A determination is then made at step <b>1210</b> whether all strokes have been evaluated. If so, the process ends. If not, then the process loops back to step <b>1202</b>, where the next stroke in the text group is retrieved.</p>
<p id="p-0101" num="0100">If the aspect ratio of the stroke does not exceed the defined thresholds, step <b>1206</b> branches directly to step <b>1210</b>, where a determination is made whether all strokes have been evaluated.</p>
<p id="p-0102" num="0101">The process used by the local contextual analyzer <b>906</b> improves the probability that all strokes within a given text group are text. This feature improves recognition or other processing after a text group has been classified as a text object.</p>
<p id="p-0103" num="0102">It is possible that, after the local contextual analyzer <b>906</b> has performed its analysis, the strokes that were initially designated as text by the single stroke classification component <b>306</b> may be eliminated. In some circumstances, this may result in strokes that were grouped by the text spatial grouping component that do not have any text strokes remaining. If this situation occurs, the group of strokes is evaluated by the global contextual analyzer <b>908</b>. This process may add strokes to the group, and may result in a designation as a text object.</p>
<p id="p-0104" num="0103">A general overview of a process for this aspect of the present invention is shown in <figref idref="DRAWINGS">FIG. 13</figref>. Beginning at step <b>1300</b>, a text stroke is retrieved (e.g., step <b>1100</b> described above). The text stroke is then grouped spatially at step <b>1302</b> (e.g., as described in connection with <figref idref="DRAWINGS">FIG. 11</figref>, above). A local contextual analysis is conducted at step <b>1304</b> (e.g., the local contextual analysis described in <figref idref="DRAWINGS">FIG. 12</figref>, above).</p>
<p id="p-0105" num="0104">At step <b>1306</b>, a determination is made whether any text strokes remain after the local contextual analysis. If so, step <b>1306</b> branches to step <b>1308</b>, where the group of strokes is designated as text group. If not, then the group proceeds to step <b>1310</b>, where it is designated as an unknown group. Whether the group is designated as text or unknown, the process then proceeds to global contextual analysis at step <b>1312</b>, described below.</p>
<p id="p-0106" num="0105">The process in <figref idref="DRAWINGS">FIG. 13</figref> occurs because, after the text strokes are removed from the group, the assumption that the grouped strokes are text no longer exists. Thus, the process proceeds as if the group were unknown. This feature of the present invention assures that false positives (i.e., groups marked text that are not) are minimized.</p>
<p id="h-0013" num="0000">Analyzing Context Globally</p>
<p id="p-0107" num="0106">As described above, the global contextual analyzer <b>908</b> may globally evaluate the strokes in a stroke group to add strokes to the stroke group, or remove strokes from the stroke group. The process may result in an unknown group being designated as a text group. In addition, the process may result in strokes being added to a text group, so as to further assure that all relevant strokes are included in the text group. To this end, the global context analyzer <b>908</b> utilizes one or more features of strokes and defines a threshold for each of the features, or a combination of the features. The thresholds are established based upon features of the strokes in the digital ink file, including the strokes that are not in the text group being evaluated. Rules are established for some of the thresholds wherein a stroke that exceeds (or falls under, depending upon the threshold limit) the threshold is not considered to be text. In this manner, the global context analyzer <b>908</b> may eliminate one or more strokes in a stroke group that was combined by the text spatial grouping component <b>902</b>. In addition, thresholds may be established whereby strokes not in a stroke group but falling within a threshold may be added to the stroke group by the global context analyzer <b>908</b>. In this manner, the global context analyzer <b>908</b> may add some strokes to a stroke group, assuring that as many relevant strokes are included in a text group as possible, or causing an unknown group to be classified as text.</p>
<p id="p-0108" num="0107">A number of different features may be used to help classify the strokes globally. As one example, a stroke may be eliminated for grouping because of the height of a stroke exceeds a threshold established for text strokes in the document. As one example, the average height of all known text strokes in the group (i.e., strokes designated as text by the single stroke classification component <b>306</b>) may be calculated, and a threshold relative to that average may be set. For example, the following threshold may be set for a stroke to be considered as a text stroke:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>h(ave)+threshold&gt;h&gt;h(ave)−threshold<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where h is the height of a stroke, h(ave) is the average height of a text stroke in the document, and “threshold” is an allowed variance for the height of a text stroke. Other methods of normalization of the strokes may be used.
</p>
<p id="p-0109" num="0108">Thresholds may also be defined for adding a stroke to a group. For example, a distance may be defined in which a stroke is grouped with a stroke group if the stroke is within the defined distance from the stroke group, regardless of where the stroke falls in the sequence of strokes. This feature may be used, for example, to add the dot of an “i” to a text object, even though the dot does not fall within the threshold of the distance used by the text spatial grouping component <b>902</b>. If desired, a stroke may only be added to the group if its length is below another threshold, preventing the addition of large strokes to an existing group, but allowing strokes that represent additions to text (e.g., the dot of an “i” or the cross of a “t”) to be added. Adding a stroke to an unknown group may result in the group being classified as text, for example, if the added stroke is a known text stroke.</p>
<p id="p-0110" num="0109">A general overview of a process for evaluating whether a stroke should be added to a stroke group in accordance with one aspect of the present invention is shown in <figref idref="DRAWINGS">FIG. 14</figref>. Beginning at step <b>1400</b>, a stroke that is outside the group is retrieved. At step <b>1402</b>, a determination is made whether the stroke is within a defined distance “D” from the stroke group. If not, the step <b>1402</b> branches to step <b>1404</b>, where a determination is made whether all strokes have been evaluated. If so, the process ends. If not, the process loops back to step <b>1400</b>, where the next stroke is retrieved.</p>
<p id="p-0111" num="0110">If the stroke is within the defined distance from the stroke group, step <b>1402</b> branches to step <b>1406</b>, where a determination is made whether the stroke is less than a defined length, “L.” If not, step <b>1406</b> branches to step <b>1404</b>, where a determination is made whether all strokes have been evaluated. If so, then step <b>1406</b> branches to step <b>1408</b>, where the stroke is added to the stroke group. The process then proceeds to step <b>1404</b>, where a determination is made whether all strokes have been evaluated.</p>
<p id="p-0112" num="0111">The process used by the global contextual analyzer <b>908</b> improves the probability that all strokes within a given text group are text, and provides a manner in which strokes may be added to the text group after being formed by the local contextual analyzer <b>906</b>. This feature improves recognition or other processing after a text group has been classified as a text object.</p>
<p id="p-0113" num="0112">In addition, the process used by the global textual analyzer may result in an unknown group having strokes added, which may result in classification by the global textual analyzer of the new group as text (e.g., where the added strokes are known text strokes). Even if the additional strokes do not result in the group being classified as text, adding a stroke or strokes to the unknown group may result in improved classification by the grouped stroke classification component <b>910</b>, described below.</p>
<p id="h-0014" num="0000">Building the Grouped Stroke Classification Component</p>
<p id="p-0114" num="0113">In accordance with one aspect of the present invention, the grouped stroke classification component <b>910</b> is configured to analyze a stroke group to determine whether it is a text object or an unknown stroke group. This process may be performed, for example, by choosing a feature of stroke groups, defining a threshold for the feature using statistics, and classifying using the threshold. As nonlimiting examples of features that may be used, a stroke group may be classified by its density, frequency, curvature, distribution, shape, image, texture, or aspect ratio.</p>
<p id="p-0115" num="0114">In accordance with one aspect of the present invention, the grouped stroke classification component <b>910</b> is a trainable classifier, such as a neural network, a Bayesian network, or a support vector machine that is trained to classify grouped strokes as text or unknown based upon features of the grouped strokes. In one implementation of the present invention, the grouped stroke classification component <b>910</b> is a support vector machine that utilizes the feature of texture, in the form of an energy spectrum, to classify the grouped strokes.</p>
<p id="p-0116" num="0115">In accordance with one aspect of the present invention, a trainable classifier is trained to define hyperplanes for the density of known stroke group values. To this end, <figref idref="DRAWINGS">FIG. 15</figref> is a general overview of a process for training the trainable classifier to recognize the density features of stroke groups in accordance with one aspect of the present invention. For ease of reference, the trainable classifier is referred to hereinafter as a support vector machine, although other trainable classifiers may be used. In this example, the objects that are to be in a class are stroke groups that fall within a margin of error of meeting the energy spectrum features of a trained stroke group class. The different energy spectrum features are defined by an energy spectrum vector, which may be created using a wavelet transform, as described further below.</p>
<p id="p-0117" num="0116">Beginning at step <b>1500</b>, the support vector machine retrieves a known stroke group sample for a given class. The class may be, for example, a known stroke or stroke group for a letter, a group of letters, or a character. The stroke group sample may be one of hundreds for the particular class that have been generated by separate individuals.</p>
<p id="p-0118" num="0117">Information about the energy spectrum of the stroke group is then generated. To evaluate the energy spectrum of the stoke groups, in accordance with one aspect of the present invention, the grouped stroke classification component <b>910</b> utilizes an energy spectrum vector generated for the grouped strokes by a Harr wavelet transform. A wavelet transform is a method of converting a signal into a series of wavelets, for example for efficient storage. One of its computing applications is in lossy compression for color graphics. An example of a Harr wavelet transform that may be used by the present invention is disclosed in Sun et al., “Fast Wavelet Transform for Color Image Compression,” Image Processing, 1996. Proceedings, International Conference Volume 1, pages 541-544.</p>
<p id="p-0119" num="0118">To prepare a stroke group for the Harr wavelet transform, the stroke group is digitized into a 16×16N cell at step <b>1502</b>, where “N” is the aspect ratio of the group. The Harr wavelet transform is then performed on the digitized cell to create an energy spectrum vector at step <b>1504</b>, which represents the density of the stroke group.</p>
<p id="p-0120" num="0119">At step <b>1506</b>, the features of the energy spectrum vector are compared by the support vector machine against possible energy spectrum features for stroke groups. This information is used to train the support vector machine to generate a trained energy spectrum vector for the present stroke group class.</p>
<p id="p-0121" num="0120">As the training inputs are fed to the support vector machine, the values of the weights and biases for particular features are adjusted (e.g., in accordance with a known back-propagation technique) such that the output of the support vector machine of each individual training pattern approaches or matches the known output (step <b>1508</b>). At step <b>1510</b>, a determination is made if the system's performance on the validation set no longer improves. If not, the process loops back to step <b>1500</b>, where the next stroke group for the class is obtained. If so, the process for that stroke group ends, and a determination is made at step <b>1512</b> whether all classes (e.g., words, letters, characters, strings of words, or the like) have been trained. If not, the next stroke group class begins training at step <b>1514</b>. If so, the process ends.</p>
<p id="p-0122" num="0121">After all stroke group classes have been trained, the support vector machine is ready for use with the invention. It can be understood that the number of class samples may be large, and thus training the support vector machine may be a time-consuming and expensive process, requiring thousands of stroke samples from hundreds of individuals. However, once trained, the support vector machine of the present invention may be duplicated and used in the grouped stroke classification component <b>910</b> for multiple applications.</p>
<p id="h-0015" num="0000">Classifying Strokes</p>
<p id="p-0123" num="0122">In accordance with one aspect of the present invention, after trained, the grouped stroke classification component <b>910</b> may be used to classify some a stroke group as a text object or an unknown stroke group. This process is very similar to the process used to classify single strokes, described above, in that a trained support vector machine is used. However, for grouped stroke classification, the features that are input are an energy spectrum of a group, as opposed to the curvature features entered for the single stroke classification.</p>
<p id="p-0124" num="0123"><figref idref="DRAWINGS">FIG. 16</figref> shows a general overview of a process for classifying a stroke group as a text object or an unknown stroke group in accordance with one aspect of the present invention. Beginning at step <b>1600</b>, an unknown stroke group is retrieved. At step <b>1602</b>, the stroke group is digitized into a 16×16N cell.</p>
<p id="p-0125" num="0124">At step <b>1604</b>, a wavelet transform is performed on the 16×16N digitized cell, forming an energy spectrum vector. The energy spectrum vector is applied as input to the support vector machine (SVM) classifier of the grouped stroke classification component <b>910</b> in step <b>1606</b>. Based on the features that are present in the energy spectrum vector, the support vector machine generates a probabilistic measure as to whether the stroke group is one of the trained stroke groups in the support vector machine or not (step <b>1608</b>). This measure is then compared against a preset threshold value (step <b>1610</b>).</p>
<p id="p-0126" num="0125">If the probabilistic measure for the stroke is greater than the threshold, then step <b>1610</b> branches to step <b>1612</b>, where the stroke group is classified as a text group. Otherwise, step <b>1610</b> branches to step <b>1614</b>, where the stroke group is classified as an unknown stroke group.</p>
<p id="p-0127" num="0126">The grouped stroke classification process described herein results in a stroke group being classified as a text group or an unknown group. The classified stroke groups may then be further analyzed by the global contextual analyzer <b>908</b>, as described above, or may be processed or maintained in the database <b>308</b> for later analysis or use.</p>
<p id="p-0128" num="0127">The present invention utilizes several different methods of classifying strokes or groups of strokes as text groups. After performing one or more of the processes of the present invention, a digital file may be processed more efficiently.</p>
<p id="p-0129" num="0128">While the invention is susceptible to various modifications and alternative constructions, a certain illustrated embodiment thereof is shown in the drawings and has been described above in detail. It should be understood, however, that there is no intention to limit the invention to the specific form or forms disclosed, but on the contrary, the intention is to cover all modifications, alternative constructions, and equivalents falling within the spirit and scope of the invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A computer readable medium having computer-executable instructions, comprising,
<claim-text>accessing a plurality of stroke samples, the stroke samples representing more than one class, wherein at least on class represented is a text class and at least one class represented is a drawing class;</claim-text>
<claim-text>extracting curvature features of each of the strokes for each class; and</claim-text>
<claim-text>using the curvature features, training a support vector machine to classify strokes for each class, wherein the curvature features of a stroke comprise a discrete curvature stroke, the discrete curvature being defined using a difference between angles determined in accordance with points along the stroke.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The computer readable medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the curvature features of a stroke comprise a tangent histogram of the stroke.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The computer readable medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising grouping some of the strokes of the plurality of strokes based upon a relative height threshold of the plurality of strokes.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The computer readable medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising grouping some of the strokes of the plurality of strokes based upon a relative aspect ratio of the plurality of strokes.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A computer readable medium having computer-executable instructions, comprising:
<claim-text>accessing a digital ink file having at least one stroke therein;</claim-text>
<claim-text>extracting curvature features of the at least one stroke;</claim-text>
<claim-text>based upon an analysis of the curvature features, determining whether the at least one stroke is text by evaluating the stroke with a support vector machine; and</claim-text>
<claim-text>based upon the curvature features, determining whether the at least one stroke is classified as an unknown stroke.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The computer readable medium of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the curvature features comprise the discrete curvature of the stroke.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The computer readable medium of <claim-ref idref="CLM-00005">claim 5</claim-ref>, further comprising:
<claim-text>accessing a plurality of strokes in the digital ink file, and</claim-text>
<claim-text>grouping some of the strokes of the plurality of strokes based upon local characteristics of the plurality of strokes to form grouped strokes.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The computer readable medium of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the grouped strokes are grouped based upon spatial information regarding the plurality of strokes.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The computer readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the spatial information comprises a distance threshold between strokes in the subset of the plurality of strokes.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The computer readable medium of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the grouped strokes are grouped based upon a relative height threshold of the strokes.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The computer readable medium of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the grouped strokes are grouped based upon a relative aspect ratio of the strokes.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The computer readable medium of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the grouped strokes are grouped based upon a normalized height of at least some of the plurality of strokes.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The computer readable medium of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the grouped strokes are grouped based upon a threshold distance between the strokes.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A computer readable medium having computer-executable instructions, comprising:
<claim-text>accessing a digital ink file having at least one stroke therein;</claim-text>
<claim-text>extracting the tangent histogram of the at least one stroke;</claim-text>
<claim-text>based upon an analysis of the the tangent histogram, determining whether the at least one stroke is text; and</claim-text>
<claim-text>based upon the the tangent histogram, determining whether the at least one stroke is classified as an unknown stroke.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
