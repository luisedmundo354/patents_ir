<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07299281-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07299281</doc-number>
<kind>B1</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10731277</doc-number>
<date>20031208</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>356</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>15</main-group>
<subgroup>173</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>Q</subclass>
<main-group>40</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>N</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>K</subclass>
<main-group>1</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>N</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>709224</main-classification>
<further-classification>235379</further-classification>
<further-classification>705 26</further-classification>
<further-classification>705 75</further-classification>
</classification-national>
<invention-title id="d0e53">Method and system for activating and capturing screen displays associated with predetermined user interface events</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5195133</doc-number>
<kind>A</kind>
<name>Kapp et al.</name>
<date>19930300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>705 75</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5388252</doc-number>
<kind>A</kind>
<name>Dreste et al.</name>
<date>19950200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714 46</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5732212</doc-number>
<kind>A</kind>
<name>Perholtz et al.</name>
<date>19980300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6091835</doc-number>
<kind>A</kind>
<name>Smithies et al.</name>
<date>20000700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382115</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6381344</doc-number>
<kind>B1</kind>
<name>Smithies et al.</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382115</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6446119</doc-number>
<kind>B1</kind>
<name>Olah et al.</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709224</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7229012</doc-number>
<kind>B1</kind>
<name>Enright et al.</name>
<date>20070600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>235379</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2006/0041591</doc-number>
<kind>A1</kind>
<name>Rhoads</name>
<date>20060200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>7071041</main-classification></classification-national>
</citation>
</references-cited>
<number-of-claims>18</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>14</number-of-drawing-sheets>
<number-of-figures>14</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>09705391</doc-number>
<kind>00</kind>
<date>20001102</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>6662226</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>10731277</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Wang</last-name>
<first-name>Jinsheng</first-name>
<address>
<city>Sunnyvale</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Zheng</last-name>
<first-name>Joe</first-name>
<address>
<city>Cupertino</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Zheng</last-name>
<first-name>Joe</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Inbit, Inc.</orgname>
<role>02</role>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Lin</last-name>
<first-name>Wen-Tai</first-name>
<department>2154</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Techniques to facilitate a system to capture, process, and archive a series of user interactive events and subsequently retrieve the stored user interactive events are disclosed. The captured information is indexed and stored for future access either on a terminal device or an accessible remote server device.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="189.06mm" wi="136.48mm" file="US07299281-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="210.40mm" wi="161.46mm" orientation="landscape" file="US07299281-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="153.84mm" wi="192.11mm" file="US07299281-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="149.69mm" wi="156.04mm" file="US07299281-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="151.05mm" wi="156.13mm" file="US07299281-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="147.66mm" wi="157.82mm" file="US07299281-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="150.88mm" wi="156.97mm" file="US07299281-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="150.37mm" wi="158.92mm" file="US07299281-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="152.57mm" wi="159.85mm" file="US07299281-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="156.38mm" wi="158.24mm" file="US07299281-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="217.68mm" wi="164.59mm" orientation="landscape" file="US07299281-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="148.17mm" wi="157.06mm" orientation="landscape" file="US07299281-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="189.23mm" wi="136.48mm" file="US07299281-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="140.89mm" wi="98.81mm" file="US07299281-20071120-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="133.69mm" wi="96.52mm" file="US07299281-20071120-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATION</heading>
<p id="p-0002" num="0001">This is a continuation of U.S. application Ser. No. 09/705,391, filed Nov. 2, 2000, now U.S. Pat. No. 6,662,226.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to interactions with terminal devices having a user interface to display information, and more particularly to a method and system for capturing, tracking, storing, augmenting and replaying the displayed information encountered during one or more interactive session, wherein the one or more interactive session involves a series of screen displays.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">Various information is accessed through wide area networks (WAN) such as the Internet. The content of these wide area networks is dynamic, information is always being added and deleted. Information available at one time may be unavailable at a later time because a user may not save it when it was available or its source may have been deleted, or it may be still available but the user is not quite sure of its location. In other cases, one desires to see how others proceed with interactions with provided information.</p>
<p id="p-0007" num="0006">Computing devices enable users to interact with various information streams such as interaction with various web sites over the Internet. These interactions are typically achieved via hardware devices including a display device and a user interface (i.e., a keyboard and a pointing device). In order to instruct a computing system to perform a task, a user may type a command on a keyboard or make a selection from a menu or button bar using a pointing device (e.g., a mouse or touch pad). In response to the user's input, the computing system may display text on the display device, display an image or play a sound, all of which provides an indication to the users of the results of their interaction.</p>
<p id="p-0008" num="0007">Selectively preserving some of these interactions is akin to transmitting the information associated with a particular interaction from the present to the future. There is therefore a need for information retention, source identification, and processing services associated with the transmitted information from designated terminal devices. Additionally, since this information must be stored for future access, there is also a need for information annotation (i.e., from where, for who and when).</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0009" num="0008">An object of the present invention is to provide a method and system that facilitates an individual, enterprise or business entity to record, store, process and manage information associated with interactions transacted on designated terminal devices. More specifically, individual and sequenced display presentations are captured or recorded and supplemented with associated information such as input control sequences, time stamps, user specific identification information, processing instructions, source information and validation information which may take the form of alpha numeric sequences or machine readable entities either of which may be encrypted.</p>
<p id="p-0010" num="0009">In an embodiment of the present invention, software agents (resident on a user's terminal device and/or a remotely accessible server devices) record the activities associated with a given interactive session where that interactive session comprises a series of screen displays and any associated user interface or network activity. The captured information is indexed, processed (i.e., sensitive information may be encrypted and the captured content may be compressed for efficient storage) and stored for future access (i.e., replay or playback) either on the initiating terminal device or a designated remote server device. Additionally, since source addressing information is retained with the captured information, future modifications to source files associated with the captured information may also be tracked either offline or upon request.</p>
<p id="p-0011" num="0010">The present invention can be implemented in numerous forms. Different implementations of the present invention yield one or more of the following advantages. One advantage of the invention is that an effective digital tracking system is provided to track device interactions (i.e., screen activity over a period of time and associated input and network interactions) associated with user interactions with various information streams accessible through a network such as the Internet or an Intranet. This capturing process may be activated automatically or may be initiated by the user as desired. Another advantage of the present invention is that the captured information can be processed (i.e., encryption, compression) augmented by time stamps, user specific information (i.e., electronic signatures) and validation information which may take the form of alpha-numeric character strings or machine readable entities which may be encrypted. Still another advantage of the present invention is the captured information may be stored and managed on initiating terminal device and/or remotely on a designated server device for future reference.</p>
<p id="p-0012" num="0011">The foregoing and other objects, features and advantages of the invention will become more apparent from the following detailed description of a preferred embodiment, which proceeds with reference to the accompanying drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0013" num="0012">The present invention will be readily understood by the following detailed description in conjunction with the accompanying drawings, wherein like reference numerals designate like structural elements, and in which:</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of a networked communication system which may be used to implement the method and system embodying the invention;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 2</figref> shows a functional diagram of a TSR (Transaction Recording System) Server which may be used in conjunction with the implementation of an embodiment of the present invention;</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. 3A to 3G</figref> illustrate representative screen displays which may be captured, validated and processed in accordance with an embodiment of the present invention;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 4</figref> illustrates a representative series of screen displays which may be captured in accordance with an embodiment of the present invention;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 5</figref> is a flow diagram of the process associated with processing (i.e., encryption, validation and compression) a series of captured screen displays in accordance with an embodiment of the present invention;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 6A</figref> is a process of a terminal device being interacted with a user;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 6B</figref> is a process of a server communicating with the terminal device in <figref idref="DRAWINGS">FIG. 6A</figref>; and</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 6C</figref> shows a process of retrieving the archived file at a terminal associated with the server of <figref idref="DRAWINGS">FIG. 6B</figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0022" num="0021">The invention pertains to a method and a system for capturing, processing and replaying a series of screen displays associated with one or more transactions. As used herein, a transaction means data exchange between two devices. For example, a transaction occurs when a provider accepts an order of certain items from a buyer. Likewise a transaction is deemed to occur when pertinent data/information entered/provided by one side is released to the other side. In general a transaction means a sequence of information exchange and related work (such as database updating) that is treated as a unit for the purposes of satisfying a request and for ensuring database integrity. For a transaction to be completed and database changes to occur, a transaction has to be completed in its entirety. One of the common transactions over the Internet is a catalog merchandise order by a customer. When the order is received on the server side, the order transaction involves checking an inventory database, confirming that the item is available, placing the order, and confirming that the order has been placed and the expected time of shipment. If the order is deemed as a single transaction, then all of the steps must be completed and validated before the transaction is successful and the database is actually changed to reflect the new order.</p>
<p id="p-0023" num="0022">Generally, a transaction is supported by one or more screen displays so that a user can interact with the displays to conduct the transaction. One of the key features in the present invention is to capture such displays including user's interaction. Another feature is to provide a mechanism to store and manage the captured displays. Still another feature is to playback the stored displays so that review of the displays reveals how a user interacts with his/her terminal to proceed with a transaction. In one embodiment, the stored information as a series of captured screen interactive information (i.e., screen displays and user inputs) can be augmented with validation information and played back in a predefined order upon request.</p>
<p id="p-0024" num="0023">Terminal devices, also referred to as computing devices herein, include but are not limited to personal computers, laptop computers, computer terminals, personal digital assistants, palm-sized computing devices, cellular phones, two-way pagers and computer work stations. Such devices typically have a user interface comprised of a display, a keyboard/keypad and a pointing device (e.g., a mouse, a trackball, a joystick, a navigation key-set or a touch-pad).</p>
<p id="p-0025" num="0024">The detailed description of the invention is presented largely in terms of procedures, steps, logic blocks, processing, and other symbolic representations that directly or indirectly resemble the operations of data processing devices coupled to networks. These process descriptions and representations are typically used by those skilled in the art to most effectively convey the substance of their work to others skilled in the art. Reference herein to “one embodiment” or “an embodiment” means that a particular feature, structure, or characteristic described in connection with the embodiment can be included in at least one embodiment of the invention. The appearances of the phrase “in one embodiment” in various places in the specification are not necessarily all referring to the same embodiment, nor are separate or alternative embodiments mutually exclusive of other embodiments. Further, the order of blocks in process flowcharts or diagrams representing one or more embodiments of the invention do not inherently indicate any particular order nor imply any limitations in the invention.</p>
<p id="p-0026" num="0025">Referring now to the drawings, in which like numerals refer to like parts throughout the several views. <figref idref="DRAWINGS">FIG. 1</figref> shows a basic system configuration in which the present invention may be implemented in accordance with a preferred embodiment. Communications system <b>100</b> generally includes a plurality of communications networks such as wireless network <b>102</b> with an associated SMS channel and data network <b>104</b> (i.e., the Internet or a private intranet). These communications networks support communications between a plurality of diverse terminal devices, such as is illustrated by wireless communication device <b>108</b> (i.e., a cell phone), personal digital assistant (PDA) <b>112</b>, personal computer <b>124</b> and a plurality of network servers represented by network server <b>150</b>.</p>
<p id="p-0027" num="0026">According to one embodiment of the present invention, services associated with the capture and storage of a terminal device activities are processed by software modules resident on the initiating terminal device (i.e., PDA <b>112</b>) or on remote server devices such as Transaction Recording System (TRS) Server <b>140</b>. These software modules provide services relating to the acquisition, processing (i.e., compression and encryption), validation and management of screen display content (i.e., a series of screen displays), input commands, device status information, user specific information, source specific information, network information, resource utilization (i.e., printers and external storage devices), time stamps and in general any information associated with the user's interaction with the terminal device. Additionally, the software modules provide services related to the management and utilization of local and remote user specific storage areas.</p>
<p id="p-0028" num="0027">The communication system illustrated in <figref idref="DRAWINGS">FIG. 1</figref> is provided for purposes of illustration and not limitation. It would be understood by one of ordinary skill in the art that the present invention may be practiced in a communications system having configurations and system components that differ from those described above.</p>
<p id="p-0029" num="0028">According to one aspect of the present invention, a user interacting with a terminal device (i.e., PDA <b>112</b>), via an associated user interface (i.e., a touch screen and associated display), may initiate the capture process to capture a series of displays on a screen through a pre-defined user interface interaction (i.e., a soft key on PDA <b>112</b>). Upon process initiation, software modules resident on the terminal device or embedded as an applet or an application cause a series of screen displays and associated device and network interactive event indications to be captured. The captured images and event indications may be supplemented with validation information (i.e., a time stamp, a user specific electronic signature and validation information which may take the form of alpha numeric character strings or machine readable marks) and then processed for storage and future display. The archived event information may be stored locally and/or on a designated remote server device for future reference.</p>
<p id="p-0030" num="0029">It is defined without the loss of generality that an interaction involves activities (i.e., display content, user input/output in response to what is being displayed in the subject terminal device) performed by a user with respect to the user interface of a terminal device that may or may not be networked. Some key advantages of the present invention include the ability to archive device interactions, validate those interactions (i.e., an encrypted alpha numeric character string which encodes a portion of the archived content) and associate the archived information with attribute information such as electronic signatures or time stamps.</p>
<p id="p-0031" num="0030">Referring now to <figref idref="DRAWINGS">FIG. 2</figref>, there is shown a functional block diagram of a TRS server <b>240</b> that may correspond to TRS server <b>140</b> of <figref idref="DRAWINGS">FIG. 1</figref>. A network interface <b>242</b> in TRS server <b>240</b> facilitates a data flow between a data network (i.e., data network <b>104</b> of <figref idref="DRAWINGS">FIG. 1</figref>) and TRS server <b>240</b> and typically executes a special set of rules (a protocol) for the end points in a link to send data back and forth. One of the common protocols is TCP/IP (Transmission Control Protocol/Internet Protocol) commonly used in the Internet. The network interface manages the assembling of a message or file into smaller packets that are transmitted over the associated data network and reassembles received packets into the original message or file. In addition, TRS server <b>240</b> handles the address part of each packet so that it gets to the right destination.</p>
<p id="p-0032" num="0031">TRS server <b>240</b> comprises a processor (or multi-processor) <b>248</b>, a server module <b>242</b> and a storage space <b>246</b>. In practice, any computing device having reasonable computing resources (i.e., processing power and memory capacity) may be utilized as an TRS server. Storage space <b>246</b> may be resident within TRS server <b>240</b> or in a separate accessible server device (not shown). Part of the storage space <b>246</b> is allocated to retain captured information from the client devices and accessible upon request. It should be noted the storage space <b>246</b> may be a single storage device or a cluster of storage devices located locally and/or remotely (e.g. storage space <b>249</b> is connected through a network). In one embodiment, the captured information may be respectively associated with a particular user, type information of the client device, billing information, electronic signatures, device information etc.</p>
<p id="p-0033" num="0032">According to one embodiment of the present invention, server module <b>242</b> is a compiled and linked version of a computer language implementing the present embodiment and loaded in a memory. When executed by TRS server <b>240</b> (i.e. processor <b>248</b>), server module <b>242</b> performs a number of functions to facilitate the operations associated with a preferred embodiment of the present invention.</p>
<p id="p-0034" num="0033">Server module <b>242</b> comprises a management module <b>242</b><i>a</i>, validation module <b>242</b><i>b</i>, attribute module <b>242</b><i>c</i>, security module <b>242</b><i>d</i>, indexing module <b>242</b><i>e </i>and content analysis module <b>242</b><i>f</i>. Management module <b>242</b><i>a </i>provides account initialization, management and service functions for a plurality of user accounts associated with users having access to this service. In one embodiment, management module <b>242</b><i>a </i>is an interface selectively accessible by users and an administrator respectively. Typically, a user is permitted to retrieve the recording of his/her screen activities while an administrator is permitted to retrieve any one's recording.</p>
<p id="p-0035" num="0034">Validation module <b>242</b><i>b </i>provides validation services that serve to generate evidence that the archived event information has not been modified. The evidence may take the form of alphanumeric character strings containing encoded or encrypted information associated with the archival information. For example, a portion of the archived event information may be incorporated into a machine-readable symbol or a certified copy may be accessed via a trusted third party server device. Attribute module <b>242</b><i>c </i>associates additional information (i.e., time stamps, electronic signatures, position information, etc.) with the archived event information. Security module <b>242</b><i>d </i>protects the archived information from unauthorized access. Indexing/Routing module <b>242</b><i>e </i>provides services relating to cataloging and providing an index of available event files. Content analysis module <b>242</b><i>f </i>is used to analyze what is in the captured events (i.e. screens). In one embodiment, content analysis module <b>242</b><i>f </i>employs an OCR engine to perform optical character recognition of one or more selected pages of the captured events. Together with indexing module <b>242</b><i>e</i>, content analysis module <b>242</b><i>f </i>may help automatic indexing of the captured events. It is clear to those skilled in the art that not every element in the module <b>242</b> needs to be implemented to achieve the desired results contemplated by the present invention.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIGS. 3A to 3G</figref> illustrate a series of representative screen displays that may be captured, validated and processed in accordance with an embodiment of the present invention. The screen displays may be displayed on a display screen of a computing device, such as a personal laptop/desktop computer and a personal data assistant (PDA).</p>
<p id="p-0037" num="0036">As used herein, a display screen or a screen is the physical display apparatus in a computing device, such as a 15 inch CRT or LCD screen commonly seen with a computing device. A screen display, a displayed page, a displayed window or simply a display is an image presented on the display screen. For example, a file that constitutes a display may be an HTML file, wherein HTML stands for HyperText Markup Language, an image thereof appears on a display screen when the file is read or executed by a display application.</p>
<p id="p-0038" num="0037">To understand the representative screen displays in <figref idref="DRAWINGS">FIGS. 3A to 3G</figref>, a PDA is used as one of the exemplary computing devices. PDA <b>312</b> may correspond to PDA <b>112</b> of <figref idref="DRAWINGS">FIG. 1</figref> and includes a user interface comprised of a display/touch screen, a navigation key-set, application keys and softkeys which may be used to interact with the PDA <b>312</b>. In accordance with an embodiment of the present invention, the TRS archiving can be initiated through a TRS program key <b>315</b>, a touch of a designated area on a screen display, an entry of a predefined word or web address.</p>
<p id="p-0039" num="0038">In one embodiment, the TRS archiving is initiated when a user logs onto a particular screen display, such as an initial page of a personal account. Once TRS archiving is initialized, user interactions with PDA <b>312</b> (i.e. screen content, user inputs, URI's, and associated cached information) for the series of screen displays illustrated in <figref idref="DRAWINGS">FIGS. 3A to 3G</figref> are sequentially captured.</p>
<p id="p-0040" num="0039">Each of the screen display is captured by a screen capturing process that may be an application or a Java applet embedded in a display. In one embodiment, the screen capturing process is implemented by utilizing calls provided in Microsoft Foundation Class (MFC) supported in MS Windows OS. An example of such implementation is provided as follows:</p>
<p id="p-0041" num="0040">BOOL CaptureCurrentScrollArea(int nHeight)</p>
<p id="p-0042" num="0041">{
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0042">// create a XImage object</li>
        <li id="ul0002-0002" num="0043">// XImage is a predefined class and contains image</li>
        <li id="ul0002-0003" num="0044">// attributes and device dependent bitmap object.</li>
        <li id="ul0002-0004" num="0045">XImage* pImage=new XImage;</li>
        <li id="ul0002-0005" num="0046">// assign the image attributes.</li>
        <li id="ul0002-0006" num="0047">// x_IWidth is the image width being captured.</li>
        <li id="ul0002-0007" num="0048">// nHeight is the height for the scroll area.</li>
        <li id="ul0002-0008" num="0049">// g_uSysBitCount is system graphics bit/pixel setting.</li>
        <li id="ul0002-0009" num="0050">pImage-&gt;x_IWidth=x_IWidth;</li>
        <li id="ul0002-0010" num="0051">pImage-&gt;x_IHeight=nHeight;</li>
        <li id="ul0002-0011" num="0052">pImage-&gt;x_wBitsPixel=g_uSysBitCount;</li>
        <li id="ul0002-0012" num="0053">// create screen DC</li>
        <li id="ul0002-0013" num="0054">// this DC will be used to copy bitmap from the scroll area</li>
        <li id="ul0002-0014" num="0055">CDC dcScr;</li>
        <li id="ul0002-0015" num="0056">dcScr.CreateDC(“DISPLAY”, NULL, NULL, NULL);</li>
        <li id="ul0002-0016" num="0057">// create a device dependent bitmap object.</li>
        <li id="ul0002-0017" num="0058">if (!pImage-&gt;bitmap.CreateCompatibleBitmap
        <ul id="ul0003" list-style="none">
            <li id="ul0003-0001" num="0059">(&amp;dcScr, pImage-&gt;x_IWidth, pImage-&gt;x_IHeight))
            <ul id="ul0004" list-style="none">
                <li id="ul0004-0001" num="0060">return FALSE; // the capture is not successful.</li>
            </ul>
            </li>
        </ul>
        </li>
        <li id="ul0002-0018" num="0061">// an empty bitmap is created.</li>
        <li id="ul0002-0019" num="0062">// now create a compatible memory DC.</li>
        <li id="ul0002-0020" num="0063">CDC dcMem;</li>
        <li id="ul0002-0021" num="0064">BOOL bCreateDC=dcMem.CreateCompatibleDC(&amp;dcScr);</li>
        <li id="ul0002-0022" num="0065">CBitmap* pOldBmp=dcMem.SelectObject(&amp;pImage-&gt;bitmap);</li>
        <li id="ul0002-0023" num="0066">// ready to copy the bitmap from the scroll area.</li>
        <li id="ul0002-0024" num="0067">// BitBIt is the critical function call to do the job.</li>
        <li id="ul0002-0025" num="0068">// g_rcCapture is the global variable that contains the</li>
        <li id="ul0002-0026" num="0069">// coordinates of the current window being captured.</li>
        <li id="ul0002-0027" num="0070">dcMem.BitBlt(0,
        <ul id="ul0005" list-style="none">
            <li id="ul0005-0001" num="0071">0,</li>
            <li id="ul0005-0002" num="0072">pImage-&gt;x_IWidth,</li>
            <li id="ul0005-0003" num="0073">pImage-&gt;x_IHeight,</li>
            <li id="ul0005-0004" num="0074">&amp;dcScr,</li>
            <li id="ul0005-0005" num="0075">g_rcCapture.left,</li>
            <li id="ul0005-0006" num="0076">g_rcCapture.bottom-nHeight,</li>
            <li id="ul0005-0007" num="0077">SRCCOPY);</li>
        </ul>
        </li>
        <li id="ul0002-0028" num="0078">dcMem.SelectObject(pOldBmp);</li>
        <li id="ul0002-0029" num="0079">// the job is done.</li>
        <li id="ul0002-0030" num="0080">// the XImage object contains the captured bitmap of</li>
        <li id="ul0002-0031" num="0081">// the scroll area.</li>
        <li id="ul0002-0032" num="0082">// store the captured image in a local file.</li>
        <li id="ul0002-0033" num="0083">if (!SaveBitmapToTempFile(pImage))
        <ul id="ul0006" list-style="none">
            <li id="ul0006-0001" num="0084">return FALSE; // the capture is not successful.</li>
        </ul>
        </li>
        <li id="ul0002-0034" num="0085">// calculate the total height of the complete image</li>
        <li id="ul0002-0035" num="0086">g_nTotalHeight+=nHeight;</li>
        <li id="ul0002-0036" num="0087">// the saved image file will be used in the image</li>
        <li id="ul0002-0037" num="0088">// concatenation when we stitch individual pieces</li>
        <li id="ul0002-0038" num="0089">// of the document image back into its entirety.</li>
        <li id="ul0002-0039" num="0090">return TRUE; // the capture is successful.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0043" num="0091">}
<ul id="ul0007" list-style="none">
    <li id="ul0007-0001" num="0000">
    <ul id="ul0008" list-style="none">
        <li id="ul0008-0001" num="0092">wherein g_rcCapture is the global variable that contains the coordinates of the active window being captured. The only parameter passed by calling module is the height of the display window that can be readily determined.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0044" num="0093">Once the displays in <figref idref="DRAWINGS">FIGS. 3A to 3G</figref> are captured, the displays or contents therein may be supplemented with attributes such as a time stamp to indicate when the displays or contents are captured. The displays or contents therein may be also processed such that the displays selective or content elements can receive special treatment (e.g. encrypted) and afterwards be compressed using a compression process. In a preferable embodiment, the displays or processed versions thereof are uploaded to a remote server through a network (e.g. a LAN, a wireless network, or the Internet).</p>
<p id="p-0045" num="0094"><figref idref="DRAWINGS">FIG. 4</figref> illustrates a representative series of screen displays that have been captured in accordance with screen displays shown in <figref idref="DRAWINGS">FIGS. 3A to 3G</figref>. Validation information for the series of screen displays may be associated with each individual screen display or may be grouped into a single validation entity that represents the group as a whole. Additionally, there may be separate validation entries for each of the individual screen displays and the series of screen displays as a whole. As shown in <figref idref="DRAWINGS">FIG. 4</figref>, each of the captured displays has been respectively attributed with a time stamp to indicate when the display is captured at the terminal device or arrived at the server.</p>
<p id="p-0046" num="0095"><figref idref="DRAWINGS">FIG. 5</figref> is a functional diagram of a process associated with processing (i.e., encryption, validation and compression) a series of captured screen displays <b>501</b> in accordance with an embodiment of the present invention. Each of screen displays <b>501</b> is initially cached at <b>501</b> and may be processed (e.g. texts are recognized by an OCR process) or parsed so that content elements requiring special treatment may be proceeded. For example, some of the content elements contains classification tags (i.e., “classified” and “unclassified”) then those elements (i.e., credit card numbers, account numbers etc.) can be singled out for special treatment such as encryption. At <b>505</b> validation data such as time stamps or electronic signatures are added and the screen displays (including the attributed ones) may then be compressed. The processed file is stored in a TRS database at <b>507</b> that may be resident on the subject terminal device or a remote server device. Upon request, the stored file can be retrieved and replayed at <b>509</b>. In one application, a viewer can assess what transactions a user (i.e. a person who interacts with the terminal device) has entered and how the user was reacted to the transactions. The assessment may potentially provide useful marketing feedback.</p>
<p id="p-0047" num="0096"><figref idref="DRAWINGS">FIG. 6A</figref> shows a process <b>600</b> of a terminal device being interacted with a user. Generally, the terminal device is coupled to a server and provides a mechanism to the user to perform certain functions. For example, the server is a brokerage (e.g. www.schwab.com) from which the user can trade stocks during business hours or the server is an internal data center with which the user can exchange data through the terminal device. After the user logins onto the server and navigates to a page or display that may be the initial display for a transaction. According to one embodiment, when the initial display embedded with a flag or a signal that can trigger the TRS process comes in at <b>602</b>, a screen capturing application is activated at <b>604</b>. As described above, the screen capturing application may be preinstalled in the terminal device or downloaded with or embedded in the initial display.</p>
<p id="p-0048" num="0097">As the user interacts with the initial display or proceeds with subsequent displays, the displays are automatically captured by the screen capturing application at <b>606</b>. The user's interactions with the terminal device may include an entry of data, one or more words/phrases, a click of a designated area in the display. As an option at <b>608</b>, the captured displays may be attributed with one or more notions that include a timestamp, the user's identity information or device information of the terminal device.</p>
<p id="p-0049" num="0098">At <b>610</b>, it is determined if the respectively captured displays are to be cached. Depending on an exact implementation, each of the captured displays is respectively transported to a storage device at <b>612</b>, hence there is no need for caching a captured display. The storage device may be a server located separately with respect to the terminal device and coupled thereto through a data link under a session (e.g. opened for the transaction). Whenever a display is captured, the image thereof is transported to the storage device. At <b>614</b>, the process <b>600</b> goes to <b>606</b> to capture another display till no more displays need to be captured, which can be indicated within a last display to inactivate the screen capturing application. When no more displays need to be captured, the process <b>600</b> ends.</p>
<p id="p-0050" num="0099">Depending on another implementation that required that all captured displayed are transported together to the server, then a captured display is to be cached at <b>610</b>, and the captured display is stored in a memory space <b>616</b>. At <b>618</b>, the process <b>600</b> may go to <b>606</b> to capture another display till no more displays need to be captured, which can be indicated within a last display to inactivate the screen capturing application. At <b>620</b>, the captured displays are then transported to the server and the process <b>600</b> end.</p>
<p id="p-0051" num="0100">It should be noted that an optional procedure may be provided just before <b>612</b> or <b>620</b> to process the captured display(s). In one embodiment, the captured displays in image format can be compressed using a commonly known image compression technique such as JPEG. In another embodiment, the captured images are compressed using a commonly known image compression technique such as MPEG or other compression to take the advantage of similarity between two immediate displays. The purpose is to reduce the data size so that the transportation of the captured displays to the server is more efficient over the data line. In any event, the captured image or images, regardless processed or not, are referred to as a file that may be resident locally or being transported to the server.</p>
<p id="p-0052" num="0101"><figref idref="DRAWINGS">FIG. 6B</figref> shows a process <b>640</b> of a server communicating with the terminal device as discussed in <figref idref="DRAWINGS">FIG. 6A</figref>. At <b>642</b>, the server awaits a request if any file is upcoming from a terminal device such as the one in <figref idref="DRAWINGS">FIG. 6A</figref>. When a request is received, the server assigns an identification to the file so that a query can be made later to retrieve the file when there is a need to review the file. Depending on an exact implementation or application, the identification may be a session ID, a transaction ID or any ID that can uniquely identify the file. At <b>646</b>, the file is received. At <b>648</b>, it is determined if there is another file related to the arrived file. As described above, sometimes, there are multiple files each comes individually for one transaction and sometime there is only one compounded file. If it is determined that there are no more files, the arrived files are then kept in a storage space at <b>650</b> for future retrieval.</p>
<p id="p-0053" num="0102"><figref idref="DRAWINGS">FIG. 6C</figref> shows a flow process <b>660</b> of retrieving the archived file at a terminal associated with the server. At <b>662</b>, the process <b>660</b> awaits a retrieval or replay request that may come from a terminal operated by an operator. The request may include parameters related to a transaction ID or user identifier information so that a correct file may be located. For example, a business desires to review a user's behavior with respect to its web site, the process <b>600</b> can be used to view how the user interacts with the web site. A request may include a query of the user's ID. When the replay request is received, the process <b>660</b> is preferably instructed how to play back the archived file, namely in a specified order. At <b>666</b>, the process <b>660</b> proceeds to look up for the file. At <b>668</b>, the file is played back and displayed on a screen for review.</p>
<p id="p-0054" num="0103">The invention may be implemented as a method, a system or code on a computer readable medium (i.e. a substrate). The computer readable medium is a data storage device that can store data, which can thereafter, be read by a computer system. Examples of a computer readable medium include read-only memory, random-access memory, CD-ROMs, magnetic tape, optical data storage devices and carrier waves. The computer readable medium can be distributed over a network coupled computer system so that the computer readable code is stored and executed in a distributed fashion.</p>
<p id="p-0055" num="0104">The advantages of the invention are numerous. Different embodiments or implementations may yield one or more of the following advantages. One advantage of the invention is that user's interactions with terminal devices can be archived in a form that could be hardly altered (e.g. an image of a screen display) and validated for future use. Another advantage of the invention is that supplemental information may be associated with the archived content (i.e., time stamps, electronic signatures, location information, subject, and indexing). Still another advantage of the invention is that the individual screen displays may be stored as a single file that can be played back to show how each of the screen displays is formed.</p>
<p id="p-0056" num="0105">The many features and advantages of the present invention are apparent from the written description, and thus, it is intended by the appended claims to cover all such features and advantages of the invention. Further, since numerous modifications and changes will readily occur to those skilled in the art, it is not desired to limit the invention to the exact construction and operation as illustrated and described. Hence, all suitable modifications and equivalents may be considered to fall within the scope of the invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>We claim:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for tracking predetermined activities for a terminal display, the method comprising:
<claim-text>providing a series of displays on the terminal display, at least some of the displays requiring interactions from a user and being referred to as interactive displays;</claim-text>
<claim-text>an embedded module automatically triggered to capture an entire image of one of the interactive displays being displayed on the terminal</claim-text>
<claim-text>display only after the one of the interactive displays has been altered with at least one interaction from the user in accordance with a predetermined requirement, wherein the entire image is in pixel format and includes source information to record when and whom the one of the interactive displays has been interacted with;</claim-text>
<claim-text>continuing to successively display a next one of the interactive displays till a last one of the interactive displays, wherein, if any of the interactive displays between the next one and the last one is captured, each of the captured images includes at least one interaction from the user in accordance with a predetermined requirement; and</claim-text>
<claim-text>sending at least some of the captured images to another computing device where the another computing device is configured to generate an evidence that the captured image has not been modified.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising generating one or more attributes to be associated with the captured image, wherein the source information is included in the one or more attributes.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the one or more attributes includes an alphanumeric character string.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method as recited in <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the alphanumeric character string is encrypted to cause any changes to any part of the captured image to be extremely difficult.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method as recited in <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the alphanumeric character string pertains to a time at which any of the interactive displays was altered.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method as recited in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the one or more attributes include one or more of (1) a time stamp, (2) an electronic signature, (3) terminal device location information, (4) information relating to the terminal display, (5) user information, (6) relative sequence index, or (7) system provided information.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method as recited in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the terminal display is a touch screen and the interaction includes one or more of (i) an entry by the user, or (ii) a click by the user.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method as recited in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sending of at least some of the captured image to the server includes compressing the captured displays into a file according to a compression scheme.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A terminal device for tracking predetermined activities therewith, the terminal device comprising:
<claim-text>a display screen;</claim-text>
<claim-text>a memory space provided with pixelated image data, the data configured to generate a series of displays for the display screen, at least some of the displays requiring interactions from a user and being referred to as interactive displays; and</claim-text>
<claim-text>an embedded module automatically triggered to capture a portion of the data in the memory space of the display screen storing one of the interactive displays after the one of the interactive displays has been altered with at least one interaction from the user in accordance with a predetermined requirement, wherein the one of the interactive displays includes an identity of the user and the time of the interaction, and the embedded module is configured to save the portion of the data and forward a file including the portion of the data to a server that is configurable to verify that there is no modification to any part of the one of the interactive displays.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The terminal device of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the file includes other captured data related to some of the interactive displays.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The terminal device of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the embedded module includes generating one or more attributes to be associated with the portion of the data.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The terminal device of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the one or more attributes includes an alphanumeric character string.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The terminal device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the alphanumeric character string is encrypted.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The terminal device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the alphanumeric character string pertains to a time at which any of the interactive displays was altered.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The terminal device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the one or more attributes include one or more of (1) a time stamp, (2) an electronic signature, (3) terminal device location information, (4) information relating to the terminal display, (5) user information, (6) relative sequence index, or (7) system provided information.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The terminal device of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the interaction includes one or more of (i) an entry by the user, (ii) a click by the user and (iii) a word or phrase.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The terminal device of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the embedded module includes compressing the portion of the data according to a compression scheme.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The terminal device of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the file pertains to image pixels and is subjects to be analyzed by an OCR engine at the server.</claim-text>
</claim>
</claims>
</us-patent-grant>
