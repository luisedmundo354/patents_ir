<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298415-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298415</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11127842</doc-number>
<date>20050511</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<us-term-of-grant>
<us-term-extension>87</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>222</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>6</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>348370</main-classification>
<further-classification>600476</further-classification>
</classification-national>
<invention-title id="d0e53">Structured light imaging apparatus</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4687325</doc-number>
<kind>A</kind>
<name>Corby, Jr.</name>
<date>19870800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>356  309</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>4687352</doc-number>
<kind>A</kind>
<name>Igi et al.</name>
<date>19870800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>400 73</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>4773097</doc-number>
<kind>A</kind>
<name>Suzaki et al.</name>
<date>19880900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5202091</doc-number>
<kind>A</kind>
<name>Lisenbee</name>
<date>19930400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5205291</doc-number>
<kind>A</kind>
<name>Potter</name>
<date>19930400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5242441</doc-number>
<kind>A</kind>
<name>Avitall</name>
<date>19930900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>5319209</doc-number>
<kind>A</kind>
<name>Miyakawa et al.</name>
<date>19940600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5334193</doc-number>
<kind>A</kind>
<name>Nardella</name>
<date>19940800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5414258</doc-number>
<kind>A</kind>
<name>Liang</name>
<date>19950500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>5452723</doc-number>
<kind>A</kind>
<name>Wu et al.</name>
<date>19950900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>5530652</doc-number>
<kind>A</kind>
<name>Croyle et al.</name>
<date>19960600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>700130</main-classification></classification-national>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>5584872</doc-number>
<kind>A</kind>
<name>LaFontaine et al.</name>
<date>19961200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>5594253</doc-number>
<kind>A</kind>
<name>Bueno et al.</name>
<date>19970100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>5636299</doc-number>
<kind>A</kind>
<name>Bueno et al.</name>
<date>19970600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>5637874</doc-number>
<kind>A</kind>
<name>Honzawa et al.</name>
<date>19970600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>5650135</doc-number>
<kind>A</kind>
<name>Contag et al.</name>
<date>19970700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>5661562</doc-number>
<kind>A</kind>
<name>Aharon</name>
<date>19970800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>5672881</doc-number>
<kind>A</kind>
<name>Striepeke et al.</name>
<date>19970900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>5705807</doc-number>
<kind>A</kind>
<name>Throngnumchai et al.</name>
<date>19980100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>5738101</doc-number>
<kind>A</kind>
<name>Sappey</name>
<date>19980400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>5746210</doc-number>
<kind>A</kind>
<name>Benaron et al.</name>
<date>19980500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>5807262</doc-number>
<kind>A</kind>
<name>Papaioannou et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>5812310</doc-number>
<kind>A</kind>
<name>Stewart et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>5818587</doc-number>
<kind>A</kind>
<name>Devaraj et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>5835617</doc-number>
<kind>A</kind>
<name>Ohta et al.</name>
<date>19981100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>5840572</doc-number>
<kind>A</kind>
<name>Copeland et al.</name>
<date>19981100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00027">
<document-id>
<country>US</country>
<doc-number>5867250</doc-number>
<kind>A</kind>
<name>Baron</name>
<date>19990200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00028">
<document-id>
<country>US</country>
<doc-number>5953446</doc-number>
<kind>A</kind>
<name>Opsal et al.</name>
<date>19990900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00029">
<document-id>
<country>US</country>
<doc-number>5963658</doc-number>
<kind>A</kind>
<name>Klibanov et al.</name>
<date>19991000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00030">
<document-id>
<country>US</country>
<doc-number>5970164</doc-number>
<kind>A</kind>
<name>Bamberger et al.</name>
<date>19991000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00031">
<document-id>
<country>US</country>
<doc-number>5999840</doc-number>
<kind>A</kind>
<name>Grimson et al.</name>
<date>19991200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600424</main-classification></classification-national>
</citation>
<citation>
<patcit num="00032">
<document-id>
<country>US</country>
<doc-number>6069698</doc-number>
<kind>A</kind>
<name>Ozawa et al.</name>
<date>20000500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00033">
<document-id>
<country>US</country>
<doc-number>6108576</doc-number>
<kind>A</kind>
<name>Alfano et al.</name>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00034">
<document-id>
<country>US</country>
<doc-number>6175407</doc-number>
<kind>B1</kind>
<name>Sartor</name>
<date>20010100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00035">
<document-id>
<country>US</country>
<doc-number>6205347</doc-number>
<kind>B1</kind>
<name>Morgan et al.</name>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00036">
<document-id>
<country>US</country>
<doc-number>6208886</doc-number>
<kind>B1</kind>
<name>Alfano et al.</name>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00037">
<document-id>
<country>US</country>
<doc-number>6217847</doc-number>
<kind>B1</kind>
<name>Contag et al.</name>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00038">
<document-id>
<country>US</country>
<doc-number>6219566</doc-number>
<kind>B1</kind>
<name>Weersink et al.</name>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00039">
<document-id>
<country>US</country>
<doc-number>6242743</doc-number>
<kind>B1</kind>
<name>DeVito et al.</name>
<date>20010600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00040">
<document-id>
<country>US</country>
<doc-number>6252623</doc-number>
<kind>B1</kind>
<name>Lu et al.</name>
<date>20010600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00041">
<document-id>
<country>US</country>
<doc-number>6264610</doc-number>
<kind>B1</kind>
<name>Zhu</name>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00042">
<document-id>
<country>US</country>
<doc-number>6267477</doc-number>
<kind>B1</kind>
<name>Karpol et al.</name>
<date>20010700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00043">
<document-id>
<country>US</country>
<doc-number>6321111</doc-number>
<kind>B1</kind>
<name>Perelman et al.</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00044">
<document-id>
<country>US</country>
<doc-number>6332087</doc-number>
<kind>B1</kind>
<name>Svenson et al.</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00045">
<document-id>
<country>US</country>
<doc-number>6364829</doc-number>
<kind>B1</kind>
<name>Fulghum</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00046">
<document-id>
<country>US</country>
<doc-number>6373557</doc-number>
<kind>B1</kind>
<name>Mengel et al.</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00047">
<document-id>
<country>US</country>
<doc-number>6377353</doc-number>
<kind>B1</kind>
<name>Ellis</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>356603</main-classification></classification-national>
</citation>
<citation>
<patcit num="00048">
<document-id>
<country>US</country>
<doc-number>6381302</doc-number>
<kind>B1</kind>
<name>Berestov</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00049">
<document-id>
<country>US</country>
<doc-number>6392241</doc-number>
<kind>B1</kind>
<name>Rushbrooke et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00050">
<document-id>
<country>US</country>
<doc-number>6394965</doc-number>
<kind>B1</kind>
<name>Klein</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00051">
<document-id>
<country>US</country>
<doc-number>6415051</doc-number>
<kind>B1</kind>
<name>Callari et al.</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00052">
<document-id>
<country>US</country>
<doc-number>6429943</doc-number>
<kind>B1</kind>
<name>Opsal et al.</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00053">
<document-id>
<country>US</country>
<doc-number>6529627</doc-number>
<kind>B1</kind>
<name>Callari et al.</name>
<date>20030300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00054">
<document-id>
<country>US</country>
<doc-number>6549288</doc-number>
<kind>B1</kind>
<name>Migdal et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00055">
<document-id>
<country>US</country>
<doc-number>6597931</doc-number>
<kind>B1</kind>
<name>Cheng et al.</name>
<date>20030700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00056">
<document-id>
<country>US</country>
<doc-number>6615061</doc-number>
<kind>B1</kind>
<name>Khalil et al.</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00057">
<document-id>
<country>US</country>
<doc-number>6615063</doc-number>
<kind>B1</kind>
<name>Ntziachristos et al.</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00058">
<document-id>
<country>US</country>
<doc-number>6618152</doc-number>
<kind>B2</kind>
<name>Toida</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00059">
<document-id>
<country>US</country>
<doc-number>6618463</doc-number>
<kind>B1</kind>
<name>Schotland et al.</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00060">
<document-id>
<country>US</country>
<doc-number>6628401</doc-number>
<kind>B2</kind>
<name>Toida</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00061">
<document-id>
<country>US</country>
<doc-number>6628747</doc-number>
<kind>B1</kind>
<name>Schotland et al.</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00062">
<document-id>
<country>US</country>
<doc-number>6636755</doc-number>
<kind>B2</kind>
<name>Toida</name>
<date>20031000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00063">
<document-id>
<country>US</country>
<doc-number>6642953</doc-number>
<kind>B1</kind>
<name>Nieto Velasco et al.</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00064">
<document-id>
<country>US</country>
<doc-number>6646678</doc-number>
<kind>B1</kind>
<name>Kobayashi</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3482071</main-classification></classification-national>
</citation>
<citation>
<patcit num="00065">
<document-id>
<country>US</country>
<doc-number>6690520</doc-number>
<kind>B1</kind>
<name>Kusuzawa</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00066">
<document-id>
<country>US</country>
<doc-number>6710770</doc-number>
<kind>B2</kind>
<name>Tomasi et al.</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00067">
<document-id>
<country>US</country>
<doc-number>6775567</doc-number>
<kind>B2</kind>
<name>Cable et al.</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00068">
<document-id>
<country>US</country>
<doc-number>6813030</doc-number>
<kind>B2</kind>
<name>Tanno</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00069">
<document-id>
<country>US</country>
<doc-number>6919919</doc-number>
<kind>B2</kind>
<name>Nelson et al.</name>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00070">
<document-id>
<country>US</country>
<doc-number>6963375</doc-number>
<kind>B1</kind>
<name>Lundberg</name>
<date>20051100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00071">
<document-id>
<country>US</country>
<doc-number>7034303</doc-number>
<kind>B2</kind>
<name>Schotland et al.</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00072">
<document-id>
<country>US</country>
<doc-number>7184047</doc-number>
<kind>B1</kind>
<name>Crampton</name>
<date>20070200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345473</main-classification></classification-national>
</citation>
<citation>
<patcit num="00073">
<document-id>
<country>US</country>
<doc-number>2003/0011701</doc-number>
<kind>A1</kind>
<name>Nilson et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00074">
<document-id>
<country>US</country>
<doc-number>2004/0010192</doc-number>
<kind>A1</kind>
<name>Benaron et al.</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00075">
<document-id>
<country>US</country>
<doc-number>2004/0015062</doc-number>
<kind>A1</kind>
<name>Ntziachristos et al.</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00076">
<document-id>
<country>US</country>
<doc-number>2004/0021771</doc-number>
<kind>A1</kind>
<name>Steams</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00077">
<document-id>
<country>US</country>
<doc-number>2004/0085536</doc-number>
<kind>A1</kind>
<name>Schotland et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00078">
<document-id>
<country>US</country>
<doc-number>2005/0149877</doc-number>
<kind>A1</kind>
<name>Rice et al.</name>
<date>20050700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715764</main-classification></classification-national>
</citation>
<citation>
<patcit num="00079">
<document-id>
<country>US</country>
<doc-number>2005/0283071</doc-number>
<kind>A1</kind>
<name>Ripoll et al.</name>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00080">
<document-id>
<country>US</country>
<doc-number>2006/0173354</doc-number>
<kind>A1</kind>
<name>Ntziachristos et al.</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00081">
<document-id>
<country>EP</country>
<doc-number>1 016 419</doc-number>
<date>20000700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00082">
<document-id>
<country>WO</country>
<doc-number>WO97/40381</doc-number>
<date>19971000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00083">
<document-id>
<country>WO</country>
<doc-number>WO98/34533</doc-number>
<date>19980800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00084">
<document-id>
<country>WO</country>
<doc-number>WO 00/17643</doc-number>
<date>20000300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00085">
<document-id>
<country>WO</country>
<doc-number>WO00/36106</doc-number>
<date>20000600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00086">
<document-id>
<country>WO</country>
<doc-number>WO00/54581</doc-number>
<date>20000900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00087">
<document-id>
<country>WO</country>
<doc-number>WO01/18225</doc-number>
<date>20010300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00088">
<document-id>
<country>WO</country>
<doc-number>WO 01/63247</doc-number>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00089">
<document-id>
<country>WO</country>
<doc-number>WO02/41760</doc-number>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00090">
<othercit>Mahmood et al., “Near-Infrared Optical Imaging of Protease Activity for Tumor Detection,” Radiology, Dec. 1999, pp. 866-870.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00091">
<othercit>Weissleder et al., “Shedding Light Onto Live Molecular Targets,” Nature Medicine, vol. 9, No. 1, Jan. 2003, pp. 123-128.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00092">
<othercit>Takeda et al., Fourier Transform Method of Fringe-Pattern Analysis for Computer-Based Topography and Interferometry, J. Opt. Soc. Am., vol. 72, No. 1, Jan. 1982.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00093">
<othercit>Toyooka et al., “Automatic Profilometry of 3-D Diffuse Objects by Spatial Phase Detection,” Applied Optics, vol. 25, No. 10, May 15, 1986.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00094">
<othercit>Rice et al., “Advances in 2D In Vivo Optical Imaging Instrumentation,” Abstract No. 186, Society for Molecular Imaging 2<sup>nd </sup>Annual Meeting, Aug. 2003.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00095">
<othercit>Frohn, “Super-Resolution Fluorescence Microscopy by Structured Light Illumination,” Dissertation submitted to the Swiss Federal Institute of Technology, Zurich, 2000.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00096">
<othercit>Benaron, David A., “A System for Imaging Infection and Gene Expression in the Body in 3-D,” Biomedical Optical Spectroscopy and Diagnostics, 1998 Technical Digest, 1998, Optical Society of America, pp. 134-135.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00097">
<othercit>Chang et al., “Improved Reconstruction Algorithm for Luminescence Optical Tomography When Background Lumiphore is Present”, Applied Optics, vol. 37, No. 16, Jun. 1, 1998, pp. 3547-3552.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00098">
<othercit>Eppstein et al., “Biomedical Optical Tomography Using Dynamic Parameterization and Bayesian Conditioning on Photon Migration Measurements”, Applied Optics, vol. 38, No. 10, Apr. 1, 1999, pp. 2138-2150.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00099">
<othercit>Ghiglia et al., “Two-Dimensional Phase Unwrapping: Theory, Algorithms, and Software”, Wiley-Interscience publication, 1998, ISBN 0-471-24935-1, p. 312.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00100">
<othercit>Haskell et al., “Boundary Condition for the Diffusion Equation in Radiative Transfer”, Optical Society of America, vol. 11, No. 10, Oct. 1994, pp. 2727-2741.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00101">
<othercit>Ntziachristos et al., “Experimental Three-Dimensional Fluorescence Reconstruction of Diffuse Media by Use of a Normalized Born Approximation”, Optical Society of America, vol. 26, No. 12, Jun. 15, 2001, pp. 893-895.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00102">
<othercit>Research &amp; Development (magazine), vol. 42, No. 9, Sep. 2000, Part 1 of 2.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00103">
<othercit>Rice et al., “In Vivo Imaging of Light-Emitting Probes”, Journal of Biomedical Optics, vol. 6, No. 4, Oct. 2001, p. 432-440.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00104">
<othercit>Yang et al., “Whole-Body Optical Imaging of Green Fluorescent Protein-Expressing Tumors and Metastases”, PNAS, vol. 97, No. 3, Feb. 1, 2000, pp. 1206-1211.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>26</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>34820799</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3482221</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348370</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348373-376</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348 77</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>600407</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>600424</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>600476</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>19</number-of-drawing-sheets>
<number-of-figures>27</number-of-figures>
</figures>
<us-related-documents>
<continuation-in-part>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>09905668</doc-number>
<kind>00</kind>
<date>20010713</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>7113217</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>11127842</doc-number>
</document-id>
</child-doc>
</relation>
</continuation-in-part>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20050237423</doc-number>
<kind>A1</kind>
<date>20051027</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Nilson</last-name>
<first-name>David</first-name>
<address>
<city>Walnut Creek</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Cable</last-name>
<first-name>Michael D.</first-name>
<address>
<city>Danville</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Rice</last-name>
<first-name>Bradley W.</first-name>
<address>
<city>Danville</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="004" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Kearney</last-name>
<first-name>Kevin</first-name>
<address>
<city>Fairport</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Beyer Weaver LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Xenogen Corporation</orgname>
<role>02</role>
<address>
<city>Alameda</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Ye</last-name>
<first-name>Lin</first-name>
<department>2622</department>
</primary-examiner>
<assistant-examiner>
<last-name>Henn</last-name>
<first-name>Timothy J</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The present invention integrates a structured light source into an imaging system for reconstructing surface topography of an object being imaged. The structured light source includes a mechanism for transmitting a set of lines onto the object from an angle. The lines are displaced, or phase shifted relative to a stage, when they encounter an object with finite height, such as a mouse. This phase shift provides structured light information for the object. A camera captures the structured light information. Using software that employs a structured light analysis, surface topography data for the object is determined from the phase shift of the lines.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="148.25mm" wi="172.30mm" file="US07298415-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="64.35mm" wi="116.08mm" file="US07298415-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="93.56mm" wi="120.65mm" file="US07298415-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="235.63mm" wi="175.77mm" file="US07298415-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="95.42mm" wi="186.10mm" file="US07298415-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="99.82mm" wi="88.90mm" file="US07298415-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="210.40mm" wi="151.30mm" file="US07298415-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="251.29mm" wi="146.47mm" file="US07298415-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="174.16mm" wi="173.82mm" file="US07298415-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="162.22mm" wi="169.33mm" file="US07298415-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="196.26mm" wi="140.21mm" file="US07298415-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="201.76mm" wi="179.41mm" file="US07298415-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="227.41mm" wi="174.24mm" file="US07298415-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="236.14mm" wi="145.46mm" file="US07298415-20071120-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="223.10mm" wi="156.80mm" file="US07298415-20071120-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="174.41mm" wi="147.57mm" file="US07298415-20071120-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="177.72mm" wi="159.85mm" file="US07298415-20071120-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="167.89mm" wi="154.86mm" file="US07298415-20071120-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="107.02mm" wi="119.04mm" file="US07298415-20071120-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="241.81mm" wi="148.59mm" file="US07298415-20071120-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading>
<p id="p-0002" num="0001">This application claims priority under 35 U.S.C. §120 from U.S. patent application Ser. No. 09/905,668, filed Jul. 13, 2001 now U.S. Pat. No. 7,113,217 and titled “Multi-View Imaging Apparatus”, which is incorporated herein by reference for all purposes.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention relates generally to imaging systems and their methods of use. More specifically, the present invention relates to imaging systems that include a structured light source.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">One new type of imaging involves the capture of low intensity light from an object. A source of the light indicates a portion of the object where an activity of interest may be taking place. In one example, the object is a small animal such as a mouse and the light source includes tumor cells labeled with light emitting reporters such as firefly luciferase or fluorescent proteins or dyes. This technology is known as in vivo optical imaging.</p>
<p id="p-0005" num="0004">Tomographic reconstruction in in vivo imaging builds a three-dimensional representation of the internal light source inside the surface of the object. Some tomographic reconstruction techniques rely on a three-dimensional representation of the object surface. Imaging small animals such as a mouse may require a new surface representation for each animal and each time the animal is imaged.</p>
<p id="p-0006" num="0005">A system that allows a user to readily obtain a surface representation of an object is not currently available.</p>
<heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0007" num="0006">The present invention integrates a structured light source into an imaging system for reconstructing a surface topography of an object being imaged. The structured light source includes a mechanism for transmitting a set of lines onto the object from an angle. The lines are displaced, or phase shifted relative to a stage, when they encounter an object with finite height, such as a mouse. This phase shift provides structured light information for the object. A camera captures the structured light information. Using software that employs a structured light analysis, surface topography data for the object (over its entire surface or a portion) is determined from the phase shift of the lines.</p>
<p id="p-0008" num="0007">In one aspect, the present invention relates to an imaging system for providing a three-dimensional surface representation of an animal. The imaging system comprises an imaging chamber including a set of walls enclosing an interior cavity and including a camera mount configured to position a camera. The imaging system also comprises a stage configured to support the animal within the interior cavity and within a field of view for the camera. The imaging system further comprises a structured light source configured to produce structured light for transmission onto the animal while the animal rests on the stage. This generates structured light surface information for the animal. The imaging system additionally comprises a processor configured to produce a three-dimensional surface representation of at least a portion of the animal using the structured light surface information obtained by the camera.</p>
<p id="p-0009" num="0008">In another aspect, the present invention relates to an imaging system for providing a three-dimensional representation of an animal. The imaging system comprises a moveable stage apparatus including a transport mechanism and a stage configured to support the animal within the interior cavity. The stage is coupled with the transport mechanism for movement of the animal to one of a plurality of positions in the interior cavity. The imaging system also comprises a structured light source configured to produce structured light for transmission onto the animal while the animal rests on the stage to generate structured light surface information for the animal.</p>
<p id="p-0010" num="0009">In yet another aspect, the present invention relates to an imaging system for providing a three-dimensional representation of an animal. The imaging system comprises a structured light source configured to produce a grid of light lines for transmission onto the animal.</p>
<p id="p-0011" num="0010">These and other features of the present invention will be described in more detail below in the detailed description of the invention and in conjunction with the following figures.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0012" num="0011">The present invention is illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings and in which like reference numerals refer to similar elements and in which:</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a simplified view of structured light transmission from an angle.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 2A</figref> illustrates a structured light source comprising a scanning laser galvanometer in accordance with one embodiment of the present invention.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 2B</figref> illustrates a stage internal to an imaging box that includes the scanning laser galvanometer of <figref idref="DRAWINGS">FIG. 2A</figref> in accordance with one embodiment of the present invention.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 3A</figref> shows internal components of a structured light projector used to produce structured light in accordance with one embodiment of the present invention.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 3B</figref> shows the configuration of the structured light projector used to obtain the subject surface topography.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 3C</figref> shows four different example positions of the stage relative to the light transport device of <figref idref="DRAWINGS">FIGS. 3D and 3E</figref>: 0 degrees, 90 degrees, 180 degrees, and 270 degrees.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 3D</figref> is a cut away perspective view of an imaging having internal components for facilitating multiple views of the sample in accordance with one embodiment of the present invention.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 3E</figref> is a perspective view of the internal components of <figref idref="DRAWINGS">FIG. 3D</figref> for facilitating multiple views of the sample in accordance with one embodiment of the present invention.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 4A</figref> is a perspective view of an imaging system including an imaging box adapted to capture images in accordance with one embodiment of the invention.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 4B</figref> illustrates the structural components of the imaging box of <figref idref="DRAWINGS">FIG. 4A</figref>.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIGS. 4C and 4D</figref> illustrate a perspective view of an imaging system in accordance with another embodiment of the present invention.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 5</figref> illustrates a method of capturing photographic, structured light and luminescent images using an imaging system in accordance with one embodiment of the present invention.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 6A</figref> illustrates a process flow for obtaining surface topography data in accordance with one embodiment of the present invention.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIGS. 6B-6H</figref> illustrate pictorial representations of structured light imaging corresponding to the process flow of <figref idref="DRAWINGS">FIG. 6A</figref>.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 7A</figref> illustrates a top perspective view of components in an imaging box with the exterior walls removed showing the moveable stage directly below a fixed datum in accordance with one embodiment of the present invention.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 7B</figref> illustrates a top perspective view of the components in an imaging box with the exterior walls removed showing the moveable stage below and off-center from the fixed datum in accordance with one embodiment of the present invention.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 7C</figref> illustrates a top perspective view of the components in an imaging box with the exterior walls removed showing the moveable stage above and off center from the fixed datum in accordance with one embodiment of the present invention.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 7D</figref> illustrates a simplified view of light transmission within an imaging box using the light transmission device of <figref idref="DRAWINGS">FIG. 7A</figref>.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIGS. 8A and 8B</figref> illustrate a top and side view, respectively, of a stage included in an imaging box in accordance with one embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0032" num="0031">In the following detailed description of the present invention, numerous specific embodiments are set forth in order to provide a thorough understanding of the invention. However, as will be apparent to those skilled in the art, the present invention may be practiced without these specific details or by using alternate elements or processes. In other instances well known processes, procedures, components, and circuits have not been described in detail so as not to unnecessarily obscure aspects of the present invention.</p>
<heading id="h-0007" level="1">Overview</heading>
<p id="p-0033" num="0032">The present invention relates to imaging systems that comprise a structured light source, which produces structured light for transmission onto an object, such as a small animal. Structured light uses a set of lines of light. In one embodiment, the set of lines is projected down on an object at an angle (at about 30 degrees, for example) to the surface normal. The object generates structured light surface information as each light line reacts to the shape of the animal. Cumulatively, the lines of light each bend or alter in spacing as they pass over the object (<figref idref="DRAWINGS">FIG. 6C</figref>). The structured light surface information can be measured and used to determine the height of the surface at all locations that are illuminated by the structured light source.</p>
<p id="p-0034" num="0033">A camera captures the structured light surface information, digitizes the information and produces one or more structure light images. A processor produces a three-dimensional surface representation of the object—or a portion of the object facing the camera—using the structured light information. More specifically, a processing system, running on stored instructions for generating a topographic representation (a surface map) from the structured light surface information, builds a 3D topographic representation of the object using the structured light surface information. Various reconstruction techniques may be stored in software and used to build a 3D topographic representation. In one embodiment, the surface topography reconstruction produces a surface mesh.</p>
<heading id="h-0008" level="1">Structured Light Source</heading>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. 1</figref> illustrates the projection of structured light onto an object and the generation of structured light surface information. A light source of the present invention transmits light onto an object <b>402</b> in one or more lines <b>404</b> at an angle, θ. Since the projection angle is known, horizontal displacement for each line <b>404</b> is related to the height of object <b>402</b>. More specifically, the height of object <b>402</b> where it intercepts each line <b>404</b> generates structured light information for each line <b>404</b> according to the horizontal displacement caused on the incoming light. By transmitting a grid of lines <b>404</b> of known dimensions onto the facing surface of object <b>402</b>, a map of the facing surface topography may be obtained by quantitatively assessing horizontal bends in the captured light. <figref idref="DRAWINGS">FIG. 6C</figref> illustrates bends in a grid of lines cast onto a mouse sample. The structured light surface information then includes differences between the known spacing for the transmitted array of lines without any interference and the observed pattern captured by the camera. Although the present invention will be described with respect to horizontal differences in the structured light for a horizontal surface normal, it is understood that other systems may transmit structured light from other angles that produce structured light information in another direction (e.g., a vertical surface normal or any angle between a horizontal surface normal and vertical surface normal).</p>
<p id="p-0036" num="0035">The angle of incidence relative to the surface normal may vary. In one embodiment, an angle from about 15° to about 30° is suitable. Angles greater or less than this range may also be used. Preferably, the projection angle is large enough to get sufficient “bend” in the lines to achieve spatial resolution, but small enough that large shadows are not present.</p>
<p id="p-0037" num="0036">Light output by a structured light source of the present invention may vary. In general, the light output may include any lines or shapes suitable for generating structured light surface information that is useful in building a surface topography. In one embodiment, a structured light source transmits a grid of lines onto the animal. Line spacing between line in a parallel grid may be adapted to a specific object or image. A structured light source producing a parallel grid of lines having a line spacing in the range of about 0.5 to about 2 lines per mm is suitable for a mouse. Other line spacings are suitable for use with the present invention. Closer line spacing provides higher resolution, but the lines may be more difficult to track on rough surfaces such as fur. The line spacing may also vary based on the object surface texture and object size.</p>
<p id="p-0038" num="0037">The present invention may use any suitable structured light generating system. In one embodiment, a structured light source used in an imaging system includes a projector that projects a grid of lines <b>404</b>. In another embodiment, a structured light source includes a laser operatively cooperating with a pair of actuated mirrors that rapidly move a single light beam to form the set of lines across the object <b>402</b>. Another suitable structured light projector comprises a laser device that employs diffraction patterns to achieve a desired structured light pattern. Other structured light sources may be used with the present invention.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 2A</figref> illustrates a structured light source comprising a scanning laser galvanometer <b>420</b> in accordance with one embodiment of the present invention. Scanning laser galvanometer <b>420</b> comprises a laser <b>422</b> and a pair of mirrors <b>424</b> and <b>426</b>.</p>
<p id="p-0040" num="0039">Laser <b>422</b> generates light. Laser <b>422</b> is positioned such that output of its linear laser beam transmits onto mirror <b>424</b>. Laser <b>422</b> may include any suitable laser, such as a diode laser or a diode pumped solid-state laser. Any color is also suitable for use with laser <b>422</b>. Common commercially available laser colors include red, green and blue. In a specific embodiment, laser <b>422</b> comprises a green diode pumped solid-state laser, such as one available from a wide variety of commercial vendors.</p>
<p id="p-0041" num="0040">Mirrors <b>424</b> and <b>426</b> each direct light provided by laser <b>422</b>. As shown, mirror <b>424</b> first receives light provided by laser <b>422</b> and reflects the light towards mirror <b>426</b>, which reflects the light into an imaging chamber. The two mirrors cooperate to permit two degrees of freedom for positioning a light beam provided by laser <b>422</b>. A maximum transmission field <b>428</b> defines the spatial range for direction of light by mirrors <b>424</b> and <b>426</b>. Mirrors <b>424</b> and <b>426</b> may create any line, shape, grid or pattern of light within field <b>428</b>. For example, the actuators and mirrors <b>424</b> may form a set of parallel lines normal to the head to toe facing of a mouse (for any position of the mouse). In one embodiment, mirrors <b>424</b> and <b>426</b> receive position control from a computer that determines a specific light pattern output by scanning laser galvanometer <b>420</b>.</p>
<p id="p-0042" num="0041">Actuators <b>430</b> and <b>432</b> position mirrors <b>424</b> and <b>426</b>, respectively. Each actuator <b>430</b> and <b>432</b> may comprise any suitable mechanical actuation responsive to electrical input. For example, motors are suitable for use with actuators <b>430</b> and <b>432</b>. In another specific example, magnetic actuation is suitable for use with actuators <b>430</b> and <b>432</b>. Magnetic actuation provides accurate and rapid response. For galvanometer <b>420</b>, the actuators operate at a high enough speed such that a single beam of light produced by laser <b>422</b> may generate a set of lines. In this case, the mirrors move fast enough such that the laser point sweeps across the surface of the animal quickly enough to register lines as detected by a camera. In a specific embodiment, the grid of lines comprises about one hundred lines and the entire grid is scanned every 2/10ths of a second. Grids of more or less lines are also suitable, as are other scan rates.</p>
<p id="p-0043" num="0042">In one embodiment, scanning laser galvanometer <b>420</b> is custom-designed for use in an imaging chamber of the present invention. In another embodiment, scanning laser galvanometer <b>420</b> comprises a commercially available model. One exemplary scanning laser galvanometer system suitable for use with the present invention is a model 6200H galvanometer scanner and a 67120-0627 MicroMax Model 671XX Servo Driver and Controller as provided by Cambridge Instruments of Cambridge, Mass.</p>
<p id="p-0044" num="0043">Computer control of mirrors <b>424</b> and <b>426</b> for scanning laser galvanometer <b>420</b> also permits custom light output for a structured light source. For example, this permits line spacing to be altered and finely controlled. In this case, computer control may allow a user to increase the density of line spacing and increase the amount of structured light surface information, which results in a more detailed topographic representation. Computer control also permits control of structured light patterns to improve the quality of structured light surface information for an animal. For example, computer-control permits the line spacing to vary to accommodate variations in animal size and fur color or texture for an animal. Computer control also permits control of structured light patterns to adapt for a particular field of view used in imaging or orientation of the animal.</p>
<p id="p-0045" num="0044">Independent control of each mirror <b>424</b> and <b>426</b> also permits a user to steer the light to different locations within the imaging chamber. This is useful when a user places an animal or object in an off-center position. In addition, this is useful when multiple animals are imaged within an imaging box.</p>
<p id="p-0046" num="0045">The projected light pattern produced by scanning laser galvanometer <b>420</b> may also be used for other purposes. For example, the projected pattern may be used to generate an alignment target for positioning an object or animal within the imaging chamber. In this case, scanning laser galvanometer <b>420</b> creates crosshairs or another suitable alignment target for positioning an animal on a stage or floor of the imaging chamber. The light output may also indicate the field of view for the camera.</p>
<p id="p-0047" num="0046">In addition, scanning laser galvanometer <b>420</b> may be used for automated focusing techniques. More specifically, displacement of grid lines on the top surface of a mouse may indicate how tall the mouse is. Since each mouse may be a different height, this provides an automated focus system for the imaging system that permits the camera to adaptively focus to a specific height for each individual mouse.</p>
<p id="p-0048" num="0047">Since mirrors <b>424</b> and <b>426</b> permit flexible re-direction and transmission of light, scanning laser galvanometer <b>420</b> may be flexibly located in an imaging chamber. In one embodiment, scanning laser galvanometer <b>420</b> is disposed at the top of an imaging chamber and reflects the laser beam of light down onto a top surface of the animal. When galvanometer <b>420</b> is disposed outside a top wall <b>423</b> (or sub-wall) of the imaging chamber (see <figref idref="DRAWINGS">FIG. 2B</figref>), the top wall includes a small hole <b>421</b> that permits light from the second mirror to pass through and into the imaging chamber. Proximity between the second mirror and wall <b>423</b> reduces size of hole <b>421</b>, since any structured light pattern or other pattern splaying at some projection angle has not had significant distance to enlarge.</p>
<p id="p-0049" num="0048">Scanning laser galvanometer <b>420</b> may be implemented flexibly in a number of light imaging systems. In one embodiment, scanning laser galvanometer <b>420</b> is disposed above an animal to be imaged and casts light down onto the animal at an angle.</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 2B</figref> illustrates a simplified cross section of a stage internal to an imaging box that includes the scanning laser galvanometer <b>420</b> in accordance with one embodiment of the present invention. The imaging box is illustrated with a movable stage <b>58</b>. In another embodiment, stage <b>58</b> is stationary and comprises the bottom surface of an imaging chamber.</p>
<p id="p-0051" num="0050">Movable stage <b>58</b> supports an object to be imaged. Movable stage <b>58</b> is capable of linear, reciprocal movement between a bottom partition <b>52</b> and a top enclosure panel, and may be retained at any position therebetween for image capture. Thus, moveable stage <b>58</b> has a multiple vertical positions in imaging chamber <b>44</b> having the substantially same horizontal position. In a specific embodiment, movable stage <b>58</b> has a threaded bore that is operably engaged with a worm gear <b>164</b> that provides vertical translation of the moveable stage <b>58</b>. A motor drives the worm gear to move the stage <b>58</b> up and down along a pair of guides <b>140</b>. In another embodiment, the stage <b>58</b> is driven vertically using a belt driven system that provides a faster response than the worm gear. A temperature control element <b>132</b> is provided by a heating blanket placed on top of stage <b>58</b> for controlling the temperature of a mammal placed on stage <b>58</b>. In one embodiment, temperature-adjusting element <b>132</b> includes a thermal sheet that is fixed, e.g. glued, into a cut-away portion of stage <b>58</b>.</p>
<p id="p-0052" num="0051">Scanning laser galvanometer <b>420</b> projects structured light <b>425</b> onto the top surface of stage <b>58</b> (or the temperature control element <b>132</b> thereon). The size of a grid produced on stage <b>58</b> (or an animal resting thereon) will depend on the position of stage <b>58</b> and control of each mirror <b>424</b> and <b>426</b> according to a desired grid size.</p>
<p id="p-0053" num="0052">In another embodiment, a structured light source includes a light projector. <figref idref="DRAWINGS">FIG. 3A</figref> illustrates internal components of a structured light projector <b>170</b> in accordance with another embodiment of the present invention. Structured light projector <b>170</b> comprises a light source and a filter or mask that creates a structured light pattern. In this case, structured light projector <b>170</b> includes a Kohler illumination system where a slide is illuminated by a light source and then an image of the slide is projected onto the sample or background. As shown, structured light projector <b>170</b> includes LEDs <b>172</b>, diffuser <b>173</b>, condenser <b>174</b>, mask <b>175</b>, lenses <b>176</b> and <b>177</b>, and aperture <b>178</b>.</p>
<p id="p-0054" num="0053">LEDs (light emitting diodes) <b>172</b> generate light. In a specific embodiment, LEDs <b>172</b> include multiple LEDs of a single color, such as green. Any color light suitable is suitable for use. LEDs <b>172</b> may include any appropriate number of light emitting diodes to generate sufficient light for creation of a grid pattern. Diffuser <b>173</b> reduces spatial variance in the intensity of light across its surface area to produce light flux at its output surface that has a more even light intensity distribution across the flux area. LEDs <b>172</b> and diffuser <b>173</b> cumulatively provide light of a desired flux with substantially equal intensity distribution.</p>
<p id="p-0055" num="0054">Condenser receives light from diffuser <b>173</b>, condenses the divergent light flux from LEDs <b>172</b> and transmits the light onto mask <b>175</b>. Mask <b>175</b> includes a number of apertures that selectively permit the passage of light therethrough. As shown, mask <b>175</b> includes a series of parallel lines that form a parallel line grid. The spacing and number of lines may vary as described above. Other patterns may be formed by mask <b>175</b> other than parallel lines. The light output of mask <b>175</b> resembles a structured light grid cast onto an object or surface for structured light imaging.</p>
<p id="p-0056" num="0055">Lenses <b>176</b> and <b>177</b> combine to project and cast the light output of mask <b>175</b> onto a desired surface. Output from lenses <b>176</b> and <b>177</b> travels through aperture <b>178</b> and forms the output of structured light projector <b>170</b>. In one embodiment, the grid of lines output from projector <b>170</b> is cast directly onto the imaging surface. In another embodiment, the grid of lines output from projector <b>170</b> is cast onto one or more projector mirrors <b>179</b> before transmission onto an object and the imaging surface. In one embodiment, the grid lines are then projected onto the animal stage with a magnification of approximately 10×. Aperture <b>178</b> controls the size of the pattern leaving projector <b>170</b>. In one embodiment, aperture <b>178</b> is variable and computer controlled.</p>
<p id="p-0057" num="0056">Although <figref idref="DRAWINGS">FIG. 3A</figref> illustrates one specific embodiment of a structured light projection source, other structured light projection sources are also suitable for use with the present invention.</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 3B</figref> shows structured light projector <b>170</b> attached to and rotating with a light transport device <b>120</b> in accordance with one embodiment of the present invention. Structured light projector <b>170</b> produces a grid of light lines for transmission onto animal <b>106</b> while the animal rests on a stage to generate structured light surface information for the animal. In a specific embodiment, structured light projector <b>170</b> consists of a Kohler illumination system where a slide is illuminated by a light source and then an image of the slide is projected onto the animal.</p>
<p id="p-0059" num="0058">The projector module <b>170</b> rides on the back of the rotating light transport device <b>120</b> (see <figref idref="DRAWINGS">FIGS. 3C-3E</figref> for operable rotation of device <b>120</b>), so that lines are always projected on the sample <b>106</b> at all viewing angles. The illumination pattern is projected horizontally and reflects off of a projector mirror <b>173</b> at the base of the larger turning mirror to illuminate sample <b>106</b>. <figref idref="DRAWINGS">FIGS. 7A-7D</figref> describe another embodiment of projector module <b>170</b> attached to the back of the rotating light transport device <b>120</b> in more detail.</p>
<heading id="h-0009" level="1">Exemplary Imaging Systems</heading>
<p id="p-0060" num="0059">In one aspect, the present invention relates generally to improved imaging systems that employ a structured light source. Several embodiments of imaging systems in which are suitable for implementing the techniques of the present invention are described further in U.S. patent application Ser. No. 09/905,668 filed by Nilson et al. on Jul. 13, 2001, entitled MULTI-VIEW IMAGING APPARATUS. The entire disclosure of this application is incorporated herein by reference for all purposes.</p>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. 4A</figref> illustrates an imaging system <b>10</b> adapted to capture photographic, structured light and luminescence images in accordance with one embodiment of the present invention. While specific examples and components of an imaging system will now be described, the present invention is not limited to the specific imaging systems described herein and may comprise more and less complex systems.</p>
<p id="p-0062" num="0061">System <b>10</b> provides user automated control of image capture in an imaging box <b>12</b>. Imaging system <b>10</b> is also useful for capturing and constructing structured light images. Imaging system <b>10</b> comprises an imaging box <b>12</b> adapted to receive a light-emitting object in which low intensity light, e.g., luciferase-based luminescence, is to be detected. Imaging box <b>12</b> includes a housing <b>16</b> on a side vertical wall of the box having a camera mount <b>109</b> adapted to receive a camera. Imaging box <b>12</b> is configured to be “light-tight”, i.e., essentially all external light is prevented from entering the box <b>12</b> from the ambient room.</p>
<p id="p-0063" num="0062">A high sensitivity camera, e.g., an intensified or a charge-coupled device (CCD) camera <b>20</b>, is attached to the imaging box <b>12</b> preferably through the camera mount affixed to housing <b>16</b>. CCD camera <b>20</b> captures photographic, structured light and luminescent images of the object within the imaging box <b>12</b>. CCD camera <b>20</b> may optionally be cooled by a suitable source such as a refrigeration device <b>22</b> that cycles a cryogenic fluid through the CCD camera via conduits <b>24</b>. A suitable refrigeration device is the “CRYOTIGER” compressor, which can be obtained from IGC-APD Cryogenics Inc., Allentown, Pa. Other refrigerants, such as liquid nitrogen or solid state devices, may be used to cool the CCD camera <b>20</b>.</p>
<p id="p-0064" num="0063">An image processing unit <b>26</b> optionally interfaces between camera <b>20</b> and a processing system <b>28</b> through cables <b>30</b> and <b>32</b>, respectively. Processing system <b>28</b>, which may be of any suitable type, typically comprises a main unit <b>36</b> that contains hardware including a processor, memory components such as random-access memory (RAM) and read-only memory (ROM), and disk drive components (e.g., hard drive, CD, floppy drive, etc.). System <b>10</b> also includes a display <b>38</b> and input devices such as a keyboard <b>40</b> and mouse <b>42</b>. Processing system <b>28</b> is in communication with various components in the imaging box <b>12</b> via one or more cables <b>34</b>. System <b>28</b> may also include additional imaging hardware and software, structured light software, and image processing logic and instructions for processing information obtained by camera <b>20</b>. For example, stored instructions run by processing system <b>28</b> may include instructions for i) receiving structured light information, and ii) building a 3D tomographic representation of the object in box <b>12</b> using structured light surface information obtained by camera <b>20</b> while the animal rests on a stage, as will be described in further detail below.</p>
<p id="p-0065" num="0064">To provide control of various components, processing system <b>28</b> includes suitable processing hardware and software configured to provide output for controlling any of the devices in the imaging box <b>12</b>. The processing hardware and software may include an I/O card, control logic for controlling any of the components of the imaging system <b>10</b>, and a suitable graphical user interface for the imaging system <b>10</b>. Processing system <b>28</b> also includes suitable processing hardware and software for camera <b>20</b> such as additional imaging hardware, software, and image processing logic for processing information obtained by camera <b>20</b>. Components controlled by processing system <b>28</b> may include camera <b>20</b>, the motors responsible for camera <b>20</b> focus, one or more motors responsible for position control of a stage supporting the sample, the camera lens, f-stop, etc. The logic in processing system <b>28</b> may take the form of software, hardware or a combination thereof. System <b>28</b> also communicates with a display <b>38</b> for presenting imaging information to the user. By way of example, the display <b>38</b> may be a monitor, which presents a measurement graphical user interface (GUI). The graphical user interface allows a user to view imaging results and also acts an interface to control the imaging system <b>10</b>. One suitable imaging software includes “LivingImage” as provided by Xenogen Corporation of Alameda, Calif.</p>
<p id="p-0066" num="0065">System <b>10</b> provides both topographic and tomographic imaging tools. Topographic imaging refers to the surface characterization of an object. The present invention uses structured light to determine surface topography for an object. Tomographic imaging refers to information inside the surface. This is useful for localizing internal objects in three dimensions inside an object, for example. An exemplary illustration of these two imaging forms uses a 2D planar slice through an object: topography gives the surface (the outer bounding line), while tomography gives everything inside the bounding surface.</p>
<p id="p-0067" num="0066">Processing system <b>28</b> is configured to produce a three-dimensional surface representation of an animal using structured light surface information obtained by camera <b>20</b>. Typically, a processor produces the three-dimensional surface representation using instructions stored in memory that determine how to produce the three-dimensional surface representation from the structured light surface information. Further description of one suitable method and its specific steps taken by a processor to convert structured light information into a three-dimensional surface representation are described below with respect to <figref idref="DRAWINGS">FIG. 6B</figref>. Other systems convert structured light surface information into a three-dimensional surface representation are known to those of skill in the art. Thus, systems of the present invention are not limited to how a processor produces a three-dimensional surface representation of an animal using the structured light surface information obtained by the camera.</p>
<p id="p-0068" num="0067">Imaging system <b>10</b> is suitable for capturing images from a variety of views and positions of the object relative to camera <b>20</b>. These images may be used in in-vivo imaging applications that include analysis of one or more representations of emissions from internal portions of a specimen superimposed on a photographic representation of the specimen. In one embodiment, imaging system <b>10</b> is used for 2-D, 3D and structured light imaging of a low intensity light source, such as luminescence from luciferase-expressing cells, fluorescence from fluorescing molecules, and the like. The low intensity light source may be emitted from any of a variety of light-emitting objects or samples which may include, for example, tissue culture plates, multi-well plates (including 96, 384 and 864 well plates), and animals containing light-emitting molecules. Animals may include any mammal, such as a mouse, cat or rat for example.</p>
<p id="p-0069" num="0068">In one embodiment, the object is a mouse containing light producing cells. The resulting luminescence image may therefore be captured without using any light sources other than the object itself. Luminescence from the object is recorded as a function of position to produce the luminescence image. One approach to generating such composite photographic/luminescence images is described in U.S. Pat. No. 5,650,135 issued to Contag et al. on Jul. 22, 1997. The entire disclosure of that patent is incorporated herein by reference for all purposes.</p>
<p id="p-0070" num="0069">In one particular embodiment, a 2-D or 3D luminescence image represents a collection of emitted photons received by each detector pixel of the CCD camera <b>20</b> over a defined length of time. In other words, the luminescence image may display magnitude values representing the photon counts at the individual detector pixels. Regions of the object emitting radiation (e.g., photons) will appear in the luminescence image. The luminescence images may indicate the presence of a biocompatible entity, for example. The entity can be a molecule, macromolecule, cell, microorganism, a particle or the like. Thus, an in-vivo analysis may include detecting localization of a biocompatible entity in a mammalian subject.</p>
<p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. 4B</figref> illustrates components of imaging box <b>12</b> of <figref idref="DRAWINGS">FIG. 4A</figref> in accordance with one embodiment of the present invention. As shown in <figref idref="DRAWINGS">FIG. 4B</figref>, imaging box <b>12</b> is illustrated with a door <b>18</b> in an open position, showing an imaging chamber <b>44</b> for receiving the object. Imaging chamber <b>44</b> is defined by opposing side enclosure panels <b>103</b>, a light-tight partition <b>52</b> on the bottom, a top panel (not shown), a back enclosure panel <b>47</b>, and a front wall <b>48</b> defining a cavity opening <b>49</b> into the imaging chamber <b>44</b>.</p>
<p id="p-0072" num="0071">Below chamber <b>44</b> is a smaller compartment separated therefrom by the light-tight partition <b>52</b>, the upper surface of which serves as a floor for imaging chamber <b>44</b>. In one embodiment, the smaller compartment provides a housing space which is adapted to slideably receive a drawer <b>54</b> though a front opening <b>55</b> formed in the body <b>14</b>. The drawer <b>54</b> houses electronic components <b>56</b> which are in electrical communication with processing system <b>28</b> (<figref idref="DRAWINGS">FIG. 4A</figref>) and control various components and functions of the box <b>12</b>. In a specific embodiment, the imaging box <b>12</b> has a body <b>14</b> made of a suitable metal such as steel.</p>
<p id="p-0073" num="0072">A latchable door <b>18</b> is pivotally attached to box body <b>14</b> by way of hinges <b>46</b> which permit the door <b>18</b> to be moved from the closed position as shown in <figref idref="DRAWINGS">FIG. 4A</figref> to the open position as shown in <figref idref="DRAWINGS">FIG. 4B</figref>. In the open position, door <b>18</b> enables user access to the cavity <b>44</b> through the opening <b>49</b>. In the closed position, door <b>18</b> prevents access to the cavity interior <b>44</b> through the cavity opening <b>49</b>.</p>
<p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. 4C</figref> illustrates an imaging system <b>100</b> in accordance with another embodiment of the present invention. Imaging system <b>100</b> comprises a combined design that includes components of system <b>10</b> in a single structure.</p>
<p id="p-0075" num="0074">Imaging system <b>100</b> comprises an imaging box <b>102</b> having a door <b>108</b> and inner walls <b>109</b> (<figref idref="DRAWINGS">FIG. 4D</figref>) that define an interior cavity <b>201</b> that is adapted to receive a light-emitting object. Imaging box <b>102</b> is suitable for imaging including the capture of low intensity light on the order of individual photons, for example. Imaging box <b>102</b> seals out essentially all of the external light from the ambient room from entering the box <b>102</b>, and may include one or more seals that prevent light passage into the box when door <b>108</b> is closed. In a specific embodiment, door <b>108</b> comprises one or more light-tight features such as a double baffle seal, while the remainder of chamber <b>102</b> is configured to minimize any penetration of light into cavity <b>201</b>. Objects for structured light imaging are placed within box <b>102</b> by opening door <b>108</b>, inserting the object in chamber <b>201</b>, and closing door <b>108</b>. One suitable imaging system is the IVIS® Imaging System 200 Series as provided by Xenogen Corporation of Alameda, Calif.</p>
<p id="p-0076" num="0075">Imaging box <b>102</b> includes an upper mounted camera <b>20</b>. Housing <b>106</b> is adapted to receive camera <b>20</b> (<figref idref="DRAWINGS">FIG. 4D</figref>). Imaging system <b>100</b> may also comprise a lens (not shown) that collects light from the specimen or phantom device and provides the light to the camera <b>20</b>. A stage <b>205</b> forms the bottom floor of imaging chamber <b>201</b> and includes motors and controls that allow stage <b>205</b> to move up and down to vary the field of view <b>203</b> for camera <b>20</b>. A multiple position filter wheel may also be provided to enable spectral imaging capability. Imaging box <b>102</b> may also include one or more light emitting diodes on the top portion of chamber <b>201</b> to illuminate a sample during photographic image capture. Other features may include a gas anesthesia system and heated sample shelf to maintain an animal's body temperature during image capture and anesthesia.</p>
<p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. 4D</figref> shows system <b>100</b> with the removal of a side panel for imaging box <b>102</b> to illustrate various electronics and processing components included in system <b>100</b>. Imaging system <b>100</b> comprises image processing unit <b>26</b> and processing system <b>28</b>.</p>
<heading id="h-0010" level="1">Imaging System Operation and Structured Light Capture</heading>
<p id="p-0078" num="0077">The present invention may be employed in a wide variety of imaging applications. Generally, the present invention may be applied with any non-invasive methods and compositions for detecting, localizing and tracking light-emitting entities and biological events in a mammalian subject. For example, the imaging system <b>10</b> may be implemented with intensified Charge-Coupled Device (CCD) cameras to detect the localization of light-producing cells (e.g., certain bacteria or tumor cells made bioluminescent by transforming them with luciferase DNA constructs) inside of living animals, such as mice. In such applications, an animal containing the bioluminescent cells is placed inside of box <b>12</b> and on stage <b>204</b>. Camera <b>20</b> is then activated to detect the emitted photons. The photon signal may then be used to construct a luminescent image of photon emission. The luminescent image is constructed without using light sources other than the luminescence from the object itself. This luminescence is recorded as a function of position to produce the luminescence image. The photographic image may also be taken of the same object to aid in position visualization of the luminescent image. One approach to generating such composite photographic/luminescence images is described in U.S. Pat. No. 5,650,135 issued to Contag et al. on Jul. 22, 1997. The entire disclosure of that patent was previously incorporated herein by reference.</p>
<p id="p-0079" num="0078">Turning now to <figref idref="DRAWINGS">FIG. 5</figref>, process flow <b>500</b> illustrates a method of capturing photographic, structured light and luminescent images using the imaging system <b>10</b> in accordance with one embodiment of the present invention. Process flow <b>500</b> begins by placing an object such as an animal to be imaged for light emission on stage <b>204</b> within imaging box <b>12</b> (<b>202</b>). Using computer <b>28</b>, a user inputs a desired position for stage <b>204</b>. Based on the input, transport mechanism <b>202</b> moves stage <b>204</b> to the corresponding position according to a control signal provided by computer <b>28</b> (<b>504</b>). Light transmission device <b>111</b> also re-positions according to a control signal provided by computer <b>28</b>.</p>
<p id="p-0080" num="0079">The imaging box <b>12</b> and associated imaging components are then prepared for photographic image capture of the object. Preparation may include launching imaging and acquisition software (e.g., “LivingImage” as provided by Xenogen Corporation of Alameda, Calif.) on the computer <b>28</b> and initializing camera <b>20</b>. Further preparations may include closing door <b>18</b>, activating the photographic capture option in the software, focusing camera <b>20</b> to a specific depth of the object or animal, and turning on the lights in box <b>12</b>. Preparations may also include focusing lens <b>100</b>, selectively positioning an appropriate lens filter <b>118</b>, setting the f-stop, etc. A photographic image is then captured (<b>508</b>). Upon completion of photographic capture, the photographic image data is transferred to an image processing unit <b>26</b> and/or a processor in computer system <b>28</b>. These may be used to manipulate and store the photographic image data as well as process the data for display on computer monitor <b>38</b>.</p>
<p id="p-0081" num="0080">The imaging box <b>12</b> and associated imaging components are then prepared for structured light image capture of the object. Structured light preparations may include activating the structured light source, specifying structured light image capture parameters such as grid line density, etc. A structured light image is then captured (<b>510</b>). Upon completion of structured light capture, the structured light image data is transferred to an image processing unit <b>26</b> and/or a processor in computer system <b>28</b>.</p>
<p id="p-0082" num="0081">Subsequently, with stage <b>204</b> at the same position, the imaging apparatus <b>10</b> is prepared for luminescence image capture (<b>512</b>). Such preparation may include selecting luminescent exposure time and binning level using the computer <b>28</b>, and turning off the lights in interior cavity <b>44</b>. When ready, the CCD camera <b>20</b> then captures (<b>514</b>) the luminescence image over a set period of time (up to several minutes). The luminescence image data are transferred to the image processing unit <b>26</b> and/or a processor in computer <b>28</b> (<b>516</b>).</p>
<p id="p-0083" num="0082">At this point, a user may manipulate and store the luminescence image data as well as process it for display on the computer display <b>38</b>. The manipulation may also include overlaying the luminescent image with the photographic image and displaying the two images together as a 2-D “overlay” image, with the luminescence data typically shown in pseudocolor to show intensity. This overlay image may then be the basis for user analysis and may be analyzed and manipulated as desired. In particular, an analysis may include a summation of the illumination magnitudes over the pixels within a portion of the luminescence representation. Note that although the discussion will focus on a single luminescence representation for the overlay image, the process flow <b>500</b> may include taking multiple luminescence representations from the same position of stage <b>204</b>, e.g., at the same time or a later time (<b>518</b>).</p>
<p id="p-0084" num="0083">If desired, stage <b>204</b> may then be moved to a second position (<b>520</b>). While the stage is at the second position, one or more photographic and/or luminescence images of the object may be captured as described above. Upon completion of each image capture, a processor in computer <b>28</b> then receives the image data. Image collection may further continue by capturing images of the object from alternate positions and views of the sample.</p>
<p id="p-0085" num="0084">As mentioned, the photon emission data may represent the specific pixels on the CCD camera <b>20</b> that detect photons over the duration of the image capture period. Together, a structured light photographic representation of the object and a luminescence representation of the object may be combined to form a structured light superposition or overlay image. Because the imaging apparatus <b>100</b> is typically used to measure the entire object <b>106</b>, the data in the luminescence representation typically has one or more distinct luminescent portions of interest.</p>
<p id="p-0086" num="0085">An image of the structured light is taken with camera <b>20</b>. After the 2-D structured light images have been captured and stored, computer <b>28</b> may then process the structured light data to generate a surface topography (<b>522</b>). As one of skill in the art will appreciate, there are numerous conventional algorithms for reconstructing a surface from structured light images. For example, the phase shift of each line at all points on the image can be determined from a computationally-efficient 2D Fourier transform. The actual surface height is then computed by “unwrapping” the phase map.</p>
<p id="p-0087" num="0086">Structured light capture and surface topology construction may be flexibly applied. In one embodiment, the present invention builds a surface topography of the animal for a surface that faces the camera only. In another embodiment, the present invention builds a surface topography of the animal for a large surface of the animal that is greater than just the surface facing the camera. In this case, imaging apparatus <b>10</b> captures a sequence of images from multiple positions. This sequence of images is taken at different viewing angles and provides the information necessary to stitch together multiple surface topography portions (see <figref idref="DRAWINGS">FIGS. 7A-7C</figref>).</p>
<p id="p-0088" num="0087">The surface topography may then be used to reconstruct the location, brightness, and size of a light source within the animal. One suitable reconstruction algorithm (or inversion algorithm) suitable for use with the present invention is diffuse optical tomography. Diffuse optical tomography uses the 3D surface topology of the animal and to map the bioluminescent emission onto this 3D surface.</p>
<p id="p-0089" num="0088">Processor <b>28</b> may apply any suitable reconstruction algorithm to the structured light information to obtain a 3D surface topography. As one of skill in the art will appreciate, there are numerous algorithms for reconstructing a surface from structured light images. For example, the phase shift of each line at all points on the image can be determined from a 2D Fourier transform. Such a process is described in detail in the article entitled “Fourier-transform method of fringe-pattern analysis for computer-based topography and interferometry,” by M. Takeda, H. Ina and S. Kobayshi, JOSA 72, 156-160 (1982), which is incorporated herein by reference in its entirety. The actual surface height is then computed by “unwrapping” the phase map. Such a process is described in detail in the textbook entitled “Two-Dimensional Phase Unwrapping, Theory, Algorithms, and Software” by D. C. Ghiglia and M. D. Pritt, (John Wiley and Sons, New York, N.Y., 1998), which is incorporated herein by reference in its entirety.</p>
<p id="p-0090" num="0089">Together, a structured light representation of the sample and a luminescence representation of the sample may be combined to form a structured light superposition or 3D overlay image, with the luminescence data typically shown in pseudocolor to visually characterize intensity.</p>
<p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. 6A</figref> illustrates a process flow <b>530</b> for using a light imaging system to obtain surface topography data in accordance with a specific embodiment of the present invention (<b>502</b> from process flow <b>500</b>). <figref idref="DRAWINGS">FIGS. 6B-6H</figref> illustrate pictorial representations of structured light imaging corresponding to process flow <b>530</b>.</p>
<p id="p-0092" num="0091">Process flow <b>530</b> begins by imaging a structured light reference to produce a pattern without the sample (<b>531</b> and <figref idref="DRAWINGS">FIG. 6B</figref>). This may be performed by applying structured light to a stage or surface that the sample rests upon before the sample is imaged. During image capture of the sample, the stage is moved to common locations as those used in image capture without the sample.</p>
<p id="p-0093" num="0092">Subsequently when the sample is in the imaging chamber, the sample is imaged with structured light (<b>532</b> and <figref idref="DRAWINGS">FIG. 6C</figref>). Structured light uses a series of lines of light that are projected down on a sample at an angle to the surface normal. The lines bend as they pass over the sample, and the bend in the lines can be used to determine the height of the surface at all locations that are illuminated by a structured light projector. The projection angle is large enough to get sufficient “bend” in the lines to achieve spatial resolution, but small enough that large shadows are not present.</p>
<p id="p-0094" num="0093">Process flow <b>530</b> then proceeds by imaging the sample without structured light (<b>533</b> and <figref idref="DRAWINGS">FIG. 6D</figref>). The phase shift of each line at all points on the background and sample may be determined from a 2D Fourier transform.</p>
<p id="p-0095" num="0094">The background data is then converted to a wrapped phase (<b>534</b> and <figref idref="DRAWINGS">FIG. 6E</figref>). Here, the background data is Fourier transformed and filtered before a wrapped phase is calculated. Similarly, the sample data is converted to a wrapped phase (<b>535</b> and <figref idref="DRAWINGS">FIG. 6F</figref>) by Fourier transforming and filtering the sample data, and the calculating a wrapped phase for the sample data.</p>
<p id="p-0096" num="0095">Surface topography for the sample is then calculated (<b>536</b> and <figref idref="DRAWINGS">FIG. 6G</figref>). In this case, this is performed by “unwrapping” the phase map. Several unwrapping algorithms are available to those of skill in the art for this task. For example, the phase shift of each line at all points on the image can be determined from using Fourier profilometry techniques. With these methods, a 2D Fast-Fourier transform (FFT) of the fringe data (<figref idref="DRAWINGS">FIG. 6D</figref>) is taken to determine the phase shift of the lines everywhere in the image (<figref idref="DRAWINGS">FIG. 6F</figref>). Since the phase will shift by many multiples of 2π for a typical object, the phase exhibits 2π jumps as seen in <figref idref="DRAWINGS">FIG. 6F</figref>. These phase jumps are “unwrapped” in order to determine the actual surface.</p>
<p id="p-0097" num="0096">The above processes (<b>531</b>-<b>536</b>) may then be repeated (<b>537</b>) from different views and positions. Imaging a sample from multiple views provides additional information that helps techniques described herein provide a more accurate 3D surface rendering. The multiple images, or the partial surfaces obtained from each view in the 3D imaging system, are then registered together to form a complete 3D surface (<b>538</b> and <figref idref="DRAWINGS">FIG. 6H</figref>). Registering can be accomplished by using non-linear least squares fitting techniques to minimize the distance between mesh elements on two surfaces that are to be connected. Typically, the surfaces should have a starting orientation that is fairly close to the final registered position. In other words, only fine adjustments to the surface positions may be accommodated with this method. Another registration technique is to provide an absolute reference line or fiducial of some kind in the image, which gives the absolute position of any partial surface with respect to the stage, for example. If the absolute positioning of each surface is accurate enough, then the non-linear fitting method described above can be skipped.</p>
<p id="p-0098" num="0097">The surface topography derived from structured light data has many uses. Some users may employ the surface topography to provide a pictorial view of the object surface. The surface topography may also be used in tomographic reconstruction of an internal light source. In this case, using a) one or more luminescent images that relate to a light source internal to the object and b) the orientation of the surface topography or a surface mesh built with the surface topography, photon density just below the surface can be determined. The photon density just below the surface is related to the light intensity emitted from the surface and captured in the luminescent images. A set of volume elements can be constructed in the volume interior to the surface. The source strength in each volume element may then be determined using the photon density just below the surface. Further description of one suitable system for tomographic reconstruction is described in commonly owned pending patent application Ser. No. 10/606,976 and entitled “Method and Apparatus for 3D Imaging of Internal Light Sources”, which was incorporated by reference above.</p>
<p id="p-0099" num="0098">Thus, the processing hardware and software may also be applied to perform tomographic reconstruction and various image processing functions described herein. For example, the processor may be configured to produce a 3D structured light representation using structured light information included in images taken from one or more positions of the stage in the interior cavity. In one embodiment, imaging system <b>10</b> employs a quantitative model that estimates the diffusion of photons in tissue. In one embodiment, the model processes in vivo image data and in order to spatially resolve a 3D representation of the size, shape, and location of the light emitting source. Typically, a tomographic model is stored as instructions in memory of processing system <b>28</b>. Various diffusion and reconstruction models may be implemented by system <b>10</b> to represent photon propagation through a mammalian subject or a phantom device described herein. One suitable tomographic example of software that builds a digital representation of a light source internal to a mammalian sample or phantom device using data from one or more images is described in commonly owned and pending patent application Ser. No. 10/606,976 entitled “Method and Apparatus for 3D Imaging of Internal Light Sources” and naming Brad Rice et al. as inventors. This application is incorporated by reference herein and its entirety for all purposes.</p>
<p id="p-0100" num="0099">Although structured light generation has been described with respect to structured light sources and methods described above, the present invention also relates to machine-readable media that include program instructions, state information, etc. for performing structured light operations described herein. Examples of machine-readable media include, but are not limited to, magnetic media such as hard disks, floppy disks, and magnetic tape; optical media such as CD-ROM disks; magneto-optical media such as floptical disks; and hardware devices that are specially configured to store and perform program instructions, such as read-only memory devices (ROM) and random access memory (RAM). A processor as described above may then be configured to run from the stored instructions and perform many of the methods described above (e.g., process flow <b>530</b>). Examples of program instructions include both machine code, such as produced by a compiler, and files containing higher level code that may be executed by the computer using an interpreter.</p>
<heading id="h-0011" level="1">3D Imaging Apparatus with Structured Light</heading>
<p id="p-0101" num="0100">In one embodiment, the present invention builds a surface topography of the animal for a large surface of the animal that is greater than just the surface facing the camera. In this case, imaging apparatus <b>10</b> captures a sequence of images from multiple positions. This sequence of images is taken at different viewing angles and provides the information necessary to stitch together multiple surface topography portions. Each structured light image provides the surface topology for approximately the facing half of the animal only. By taking images from several viewing angles, e.g., about every 45 degrees, the entire 3D surface of the animal can be reconstructed by “stitching” together the partial surface reconstructions obtained from each view. <figref idref="DRAWINGS">FIGS. 7A-C</figref> illustrate one system suitable for obtaining a sequence of structured light images from multiple viewing angles.</p>
<p id="p-0102" num="0101"><figref idref="DRAWINGS">FIG. 7A</figref> is a top perspective view of internal components in an imaging box with the exterior walls removed showing stage <b>204</b> directly below a fixed datum <b>107</b>. <figref idref="DRAWINGS">FIG. 7B</figref> is a top perspective view of the components in box <b>12</b> with the exterior walls removed showing stage <b>204</b> below and off-center from fixed datum <b>107</b>. <figref idref="DRAWINGS">FIG. 7C</figref> is a top perspective view of the components in box <b>12</b> with the exterior walls removed showing stage <b>204</b> above and off center from fixed datum <b>107</b>.</p>
<p id="p-0103" num="0102">As shown in <figref idref="DRAWINGS">FIG. 7C</figref>, a camera mount <b>109</b> is attached to side housing <b>16</b> of side wall <b>103</b><i>b</i>. Camera mount <b>109</b> is adapted to receive and position camera <b>20</b> relative to fixed datum <b>107</b> for viewing of object <b>106</b> within cavity <b>44</b> by camera <b>20</b>. While camera <b>20</b> is capable of capturing photographic and structured light images, it is also sensitive enough to capture luminescence images thereof.</p>
<p id="p-0104" num="0103">A moveable stage apparatus <b>200</b> is disposed in interior cavity <b>44</b>, and includes a transport mechanism <b>202</b> and a stage <b>204</b> to support the light-emitting object <b>106</b>. Moveable stage apparatus <b>200</b> is capable of two degrees of freedom movement to reposition the stage <b>204</b> (and object <b>106</b>) to a plurality of positions within interior cavity <b>44</b>. Any one position therebetween may be retained for image capture.</p>
<p id="p-0105" num="0104">As shown in <figref idref="DRAWINGS">FIGS. 7A-C</figref>, the transport mechanism <b>202</b> in the embodiment comprises two linear actuators <b>206</b> and <b>208</b> oriented at substantially perpendicular to one another. Each linear actuator <b>206</b> and <b>208</b> is capable of positioning stage <b>204</b> linearly along the respective actuator. Linear actuator <b>206</b> provides vertical positioning for stage <b>204</b> while linear actuator <b>208</b> provides horizontal positioning for stage <b>204</b>. Linear actuator <b>206</b> has a stationary portion attached to box <b>12</b> and a mobile portion attached to linear actuator <b>208</b>. Linear actuator <b>208</b> has a relatively stationary portion attached to linear actuator <b>206</b> and a mobile portion attached to stage <b>204</b>. An example of one such linear actuator suitable for use in the transport mechanism <b>202</b> is a LC-33 produced by Thomson Industries of Port Washington, N.Y.</p>
<p id="p-0106" num="0105">The transport mechanism <b>202</b> preferably includes a set of position sensors that are operably coupled to the computer <b>28</b> to provide position feedback to control the position of stage <b>204</b>. Linear actuators <b>206</b> and <b>208</b>, position sensors <b>212</b>, and computer <b>28</b> combine to provide closed loop position control for stage <b>204</b> within interior cavity <b>44</b>. More specifically, a user, via computer <b>28</b>, may input one or more positions for stage <b>204</b> along a substantially circular path about fixed datum <b>107</b>. In one embodiment, a user provides a viewing angle for stage <b>204</b> relative to fixed datum <b>107</b>. Software included in computer <b>28</b> then converts the viewing angle into control signals for moving each of the linear actuators <b>206</b> and <b>208</b>.</p>
<p id="p-0107" num="0106">Light transmission device <b>111</b> directs light reflected or emitted from object <b>106</b> along the direction of fixed datum <b>107</b> and into lens <b>100</b> for image capture by camera <b>20</b>. Light transmission device <b>111</b> is mounted to housing <b>16</b> using stationary bracket <b>119</b> (<figref idref="DRAWINGS">FIG. 7A</figref>), which includes circumferentially disposed bearings between stationary bracket <b>119</b> and moving bracket <b>126</b> that allow turning mirror assembly <b>120</b> to rotate freely relative to stationary bracket <b>119</b>. Mirror assembly <b>120</b> is thus rotably coupled to housing <b>16</b> and rotates about an axis co-axially aligned with the stationary axis of the fixed datum <b>107</b>.</p>
<p id="p-0108" num="0107">Referring to <figref idref="DRAWINGS">FIG. 7C</figref>, mirror assembly <b>120</b> comprises an angled mirror <b>121</b> that reflects light from object <b>106</b> on stage <b>204</b> in a direction along fixed datum <b>107</b>. Outer wall <b>123</b> is substantially cylindrical and includes aperture <b>122</b> that enables light to pass between stage <b>204</b> and turning mirror <b>121</b>. Outer wall <b>123</b> of mirror assembly <b>120</b> also prevents residual light in interior cavity <b>44</b> not directly associated with the current viewing angle of stage <b>204</b> from reaching lens <b>100</b>. This is partially performed by configuring mirror <b>121</b> to be sufficiently long to span the length of stage <b>204</b>. As the stage is positioned along the circular path about the stationary axis, outer wall <b>123</b> and turning mirror <b>121</b> cooperate to collect light primarily from the angular direction of stage <b>204</b> which is then reflected along fixed datum <b>107</b> for reception by lens <b>100</b>.</p>
<p id="p-0109" num="0108"><figref idref="DRAWINGS">FIG. 7D</figref> illustrates a simplified view of light transmission within box <b>12</b> using light transmission device <b>111</b>. <figref idref="DRAWINGS">FIG. 7D</figref> also show another configuration for a structured light projector <b>170</b>. As shown, structured light <b>175</b>, emitted from structured light projector <b>170</b>, reflects off a mirror <b>173</b>, passes through partially transparent mirror <b>121</b>, and onto object <b>106</b>. In one embodiment, the partial transparence of mirror <b>121</b> is achieved using a half-silvered or partially silvered mirror. In another embodiment, a dichroic mirror having wavelength specific transparency properties is used. The structured light <b>175</b> may then be captured by camera <b>20</b>.</p>
<p id="p-0110" num="0109">The two degrees of freedom movement provided by transport mechanism <b>202</b> allow stage <b>204</b> and object <b>106</b> to be positioned at multiple angles relative to fixed datum <b>107</b> for image capture by camera <b>20</b>. Thus, based on user input via computer <b>28</b>, transport mechanism <b>202</b> and light transmission device <b>111</b> cooperate to direct light from object <b>106</b> on stage <b>204</b> to fixed datum <b>107</b> and lens <b>100</b> to capture image using camera <b>20</b>. In addition to providing full 360 degree angular viewing of object <b>106</b> about the circular path, transport mechanism <b>202</b> is capable of varying the image depth for a given angle of stage <b>204</b> relative to fixed datum <b>107</b>. Together, transport mechanism <b>202</b> and light transmission device <b>111</b> cooperate to provide a field of view for camera <b>20</b> in the range of about 7.5 cm to about 16.5 cm. In a specific embodiment, light transmission device <b>111</b> cooperate to provide a field of view for camera <b>20</b> in the range of about 13 cm to about 16.5 cm. Similar to the user initiated angular position control described above, a user may input a desired focal depth and viewing angle for stage <b>204</b>. Software included in computer <b>28</b> and linear actuators <b>206</b> and <b>208</b> would then combine to position stage <b>204</b> at the desired angle and depth relative to fixed datum <b>107</b>.</p>
<heading id="h-0012" level="1">Stage</heading>
<p id="p-0111" num="0110">As the term is used herein, a stage refers to a structure used to support an object during image capture. Flat surfaces are well suited for use, such as a fixed flat bottom panel in the imaging box (a stationary stage). In another embodiment, the stage is moveable. One suitable vertical posistionable stage was discussed above. In general, the present invention is not limited to any particular stage structure or configuration.</p>
<p id="p-0112" num="0111">Some stages may include transparent portions to permit image capture through the stage. For example, the transport mechanism <b>202</b> described above relies on some transparency in the stage.</p>
<p id="p-0113" num="0112">Referring now to <figref idref="DRAWINGS">FIGS. 8A and 8B</figref>, stage <b>204</b> comprises a frame <b>252</b> and a transparent portion <b>254</b>. Transparent portion <b>254</b> allows light emitted or reflected from object <b>106</b> to be transmitted therethrough with substantially no interference and minimal distortion for any position of stage <b>204</b> about fixed datum <b>107</b>. Transparent portion <b>254</b> preferably, comprises a transparent wire array <b>256</b> that supports object <b>106</b>. In a specific embodiment, transparent wire array <b>256</b> is a single transparent nylon line interwoven through holes <b>258</b> on opposing edges of frame <b>252</b> and secured in a taut manner to support object <b>106</b>. In another embodiment, array <b>256</b> is a mesh that resembles a cross pattern grid similar to a tennis racket mesh.</p>
<p id="p-0114" num="0113">In a specific embodiment, stage <b>204</b> includes hardware based crash protection measures that prevent undesirable contact between stage <b>204</b> and other components within box <b>12</b>. In a specific embodiment, crash pin <b>250</b> is placed on the side of stage <b>204</b> closest to the camera <b>20</b>, as shown in <figref idref="DRAWINGS">FIG. 8A</figref>. Crash pin <b>250</b> prevents contact between stage <b>204</b> and components within cavity <b>44</b>. To prevent contact between stage <b>204</b> and light transmission device <b>111</b>, camera <b>20</b> or wall <b>103</b><i>b</i>, a metal ring <b>260</b> is perimetrically disposed around light transmission device <b>111</b> on stationary bracket <b>119</b>.</p>
<p id="p-0115" num="0114">Although various details have been omitted for brevity's sake, obvious design alternatives may be implemented. For example, although the present invention has been discussed primarily in the context of a structured light source useful for in-vivo imaging applications, the present invention is suitable for other imaging applications and may be tailored correspondingly. Therefore, the present examples are to be considered as illustrative and not restrictive, and the invention is not to be limited to the details given herein, but may be modified within the scope of the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An imaging system for providing a three-dimensional surface representation of an animal, the imaging system comprising:
<claim-text>a camera;</claim-text>
<claim-text>a structured light source configured to produce structured light for transmission onto the animal, wherein interception of the structured light by the animal generates structured light surface information for the animal;</claim-text>
<claim-text>a processor configured to a) produce a three-dimensional surface representation of at least a portion of the animal using the structured light surface information obtained by the camera, and b) use the three-dimensional surface representation of at least the portion of the animal to reconstruct a location, brightness, or size of a light source within the animal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the processor is configured to produce the three-dimensional surface representation of the animal using instructions stored in memory that determine how to produce the three-dimensional surface representation from the structured light surface information.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the processor is further configured to map the location, brightness, or size of the light source onto the three-dimensional surface representation.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the processor is further configured to provide a superposition of the three-dimensional surface representation with the location, brightness, or size of the light source within the animal.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the processor is further configured to employ a quantitative model that estimates the diffusion of photons from the light source in tissue of the animal.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the three-dimensional surface representation includes a surface mesh.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The system of <claim-ref idref="CLM-00006">claim 6</claim-ref> wherein the processor is further configured to relate i) photon density just below an animal surface to ii) light intensity emitted from the three-dimensional surface representation and captured in a luminescent image by the camera.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the structured light source comprises a structured light projector configured to produce the structured light.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising a light transport device that transmits structured light from a surface of the animal to the camera.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The system of <claim-ref idref="CLM-00006">claim 6</claim-ref> wherein the structured light source is coupled to the light transport device.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein the light transport device comprises a mirror configured to intercept light emitted from the animal before receipt by the camera.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the structured light source comprises a scanning laser galvanometer that includes:
<claim-text>a laser that produces a beam of light; and</claim-text>
<claim-text>at least one mirror positionable to reflect the beam of light and cast a grid of lines onto the animal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the processor is configured to reconstruct the location, brightness, or size of the light source within the animal using instructions stored in memory that determine how to reconstruct the location, brightness, or size of the light source using the thee-dimensional surface representation of at least the portion of the animal.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. An imaging system for providing a three-dimensional surface representation of an animal, the imaging system comprising:
<claim-text>a camera;</claim-text>
<claim-text>a structured light source configured to produce structured light for transmission onto the animal, wherein interception of the structured light by the animal generates structured light surface information for the animal;</claim-text>
<claim-text>a processor configured to a) produce a three-dimensional surface representation of at least a portion of the animal using the structured light surface information obtained by the camera, and b) use the three-dimensional surface representation of at least the portion of the animal to reconstruct a location of a light source within the animal.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein the processor is configured to produce the three-dimensional surface representation of the animal using instructions stored in memory that determine how to produce the three-dimensional surface representation from the structured light surface information.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein the processor is configured to reconstruct the location, brightness, or size of the light source within the animal using instructions stored in memory that determine how to reconstruct the location, brightness, or size of the light source using the three-dimensional surface representation of at least the portion of the animal.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein the processor is further configured to map the location, brightness, or size of the light source onto the three-dimensional surface representation.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein the processor is further configured to provide a superposition of the three-dimensional surface representation with the location, brightness, or size of the light source within the animal.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein the processor is further configured to employ a quantitative model that estimates the diffusion of photons from the light source in tissue of the animal.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein the three-dimensional surface representation includes a surface mesh.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The system of <claim-ref idref="CLM-00020">claim 20</claim-ref> wherein the processor is further configured to relate i) photon density just below an animal surface to ii) light intensity emitted from the three-dimensional surface representation and captured in a luminescent image by the camera.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein the structured light source comprises a structured light projector configured to produce the structured light.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref> further comprising a light transport device that transmits structured light from a surface of the animal to the camera.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The system of <claim-ref idref="CLM-00023">claim 23</claim-ref> wherein the structured light source is coupled to the light transport device.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The system of <claim-ref idref="CLM-00024">claim 24</claim-ref> wherein the light transport device comprises a minor configured to intercept light emitted from the animal before receipt by the camera.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein the structured light source comprises a scanning laser galvanometer that includes:
<claim-text>a laser that produces a beam of light; and</claim-text>
<claim-text>at least one minor positionable to reflect the beam of light and cast a grid of lines onto the animal.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
