<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298394-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298394</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10120374</doc-number>
<date>20020412</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2001-187502</doc-number>
<date>20010621</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>849</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>7</main-group>
<subgroup>18</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>348149</main-classification>
</classification-national>
<invention-title id="d0e71">Method and apparatus for processing pictures of mobile object</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5296852</doc-number>
<kind>A</kind>
<name>Rathi</name>
<date>19940300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>340933</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5554983</doc-number>
<kind>A</kind>
<name>Kitamura et al.</name>
<date>19960900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>340937</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6188778</doc-number>
<kind>B1</kind>
<name>Higashikubo et al.</name>
<date>20010200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6317693</doc-number>
<kind>B2</kind>
<name>Kodaka et al.</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>701301</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6430303</doc-number>
<kind>B1</kind>
<name>Naoi et al.</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382104</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6690011</doc-number>
<kind>B2</kind>
<name>Watanabe et al.</name>
<date>20040200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>250330</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6731777</doc-number>
<kind>B1</kind>
<name>Nishigaki et al.</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382106</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6810132</doc-number>
<kind>B1</kind>
<name>Umezaki et al.</name>
<date>20041000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382104</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2002/0126875</doc-number>
<kind>A1</kind>
<name>Naoi et al.</name>
<date>20020900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382104</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>EP</country>
<doc-number>0 505 858</doc-number>
<kind>A1</kind>
<date>19920900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>EP</country>
<doc-number>0 807 914</doc-number>
<kind>A1</kind>
<date>19971100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>JP</country>
<doc-number>2001-148019</doc-number>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>WO</country>
<doc-number>WO 00/31706</doc-number>
<date>20000600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00014">
<othercit>Tieniu Tan, “Locating and recognizing road vehicles”, Optical Engineering, vol. 37, No. 1, (Jan. 1998), XP000736284, pp. 202-207.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00015">
<othercit>Sylvia Gil et al., “Feature Selection for object tracking in traffic scenes”, SPIE vol. 2344 Intelligent Vehicle Highway Systems (1994), XP000689133, pp. 253-266.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00016">
<othercit>Shunsuke Kamijo, et al. “Traffic Monitoring and Accident Detection at Intersections.” IEEE Transactions on Intelligent Transportation Systems, vol. 1, No. 2, Jun. 2000 (pp. 108-118).</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00017">
<othercit>Shunsuke Kamijo, et al. “Incident Detection at Intersections Utilizing Hidden Markov Model.” 6<sup>th </sup>World Congress on Intelligent Transport Systems, Nov. 8-12, 1999, Toronto, Canada (pp. 1-10).</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00018">
<othercit>Shunsuke Kamijo, et al. “Occlusion Robust Vehicle Tracking Utilizing Spatio—Temporal Markov Random Field Model.” 7<sup>th </sup>World Congress on Intelligent Transport Systems, Nov. 6-9, 2000, Turin, Italy (5pp).</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>9</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>348149</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348148</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348135</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348143</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348169</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348118</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348113</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348119</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382104</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382106</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382173</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382270</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382110</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382141</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382154</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382209</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382 30</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382 31</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382372</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382162</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382163</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382164</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382168</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382171</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382172</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382276</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382282</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382107</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>250330</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>250340</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>250331</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>250332</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701117</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701118</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701301</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701119</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701300</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701121</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701302</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701122</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701120</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>19</number-of-drawing-sheets>
<number-of-figures>23</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20020196341</doc-number>
<kind>A1</kind>
<date>20021226</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Kamijo</last-name>
<first-name>Shunsuke</first-name>
<address>
<city>Kawasaki</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Sakauchi</last-name>
<first-name>Masao</first-name>
<address>
<city>Yokohama</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Ikeuchi</last-name>
<first-name>Katsushi</first-name>
<address>
<city>Yokohama</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Staas &amp; Halsey LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Fujitsu Limited</orgname>
<role>03</role>
<address>
<city>Kawasaki</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
<assignee>
<addressbook>
<orgname>The Foundation for the Promotion of Industrial Science</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Vo</last-name>
<first-name>Tung</first-name>
<department>2621</department>
</primary-examiner>
<assistant-examiner>
<last-name>Senfi</last-name>
<first-name>Behrooz</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A feature amount of an inter-mobile unit relative movement are detected as an observation amount by an observation amount detecting section <b>26</b>, time series of the observation amounts are stored as an observation series into a storage section <b>27</b> to calculate a similarity of the observation series to a predetermined collision observation series by a classification section <b>28</b>. A determination section <b>29</b> determines to be a collision accident if, in a case where the similarity is larger than a predetermined value, a mobile unit associated with the similarity is at rest in a stoppage prohibition area set in a storage section <b>30</b> and another mobile unit is moving, and to be a mobile unit failure if collision determination conditions except for the similarity are met. By consisting of not only a first scalar obtained by quantizing a relative velocity vector between mobile units but also a second scalar obtained by quantizing a relative position vector between mobile units as the observation amount, a relative movement between mobile units is classified in more detail. A mobile unit is tracked in units of block by a mobile unit tracking section <b>25</b> to discriminate overlapped mobile units in pictures.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="189.15mm" wi="149.35mm" file="US07298394-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="206.08mm" wi="150.45mm" file="US07298394-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="216.49mm" wi="149.35mm" orientation="landscape" file="US07298394-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="225.55mm" wi="110.15mm" file="US07298394-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="163.32mm" wi="138.09mm" file="US07298394-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="202.69mm" wi="134.03mm" file="US07298394-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="190.42mm" wi="149.44mm" file="US07298394-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="159.85mm" wi="123.02mm" file="US07298394-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="201.42mm" wi="127.17mm" file="US07298394-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="172.04mm" wi="114.13mm" file="US07298394-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="185.17mm" wi="156.04mm" file="US07298394-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="183.56mm" wi="157.99mm" file="US07298394-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="185.67mm" wi="154.69mm" file="US07298394-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="219.63mm" wi="155.19mm" orientation="landscape" file="US07298394-20071120-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="218.69mm" wi="138.09mm" file="US07298394-20071120-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="221.32mm" wi="135.30mm" file="US07298394-20071120-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="223.27mm" wi="137.16mm" file="US07298394-20071120-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="224.54mm" wi="135.30mm" file="US07298394-20071120-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="221.06mm" wi="133.69mm" file="US07298394-20071120-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="219.79mm" wi="132.93mm" file="US07298394-20071120-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">1. Field of the Invention</p>
<p id="p-0003" num="0002">The present invention relates to a method and an apparatus for processing pictures of mobile unit, more particularly, to a method and an apparatus for processing time-series pictures to detect an anomaly such as collision or failure of mobile unit in the pictures.</p>
<p id="p-0004" num="0003">2. Description of the Related Art</p>
<p id="p-0005" num="0004">Early detection of a traffic accident can not only enhance a success rate in life saving by speedy rescue operation, but also alleviate accident-related traffic congestion by speedup of the police inspection at the site. Therefore, various kinds of automation in recognition of traffic accident are expected.</p>
<p id="p-0006" num="0005">In the publication of JP 2001-148019-A whose inventors are the same as those of the present application, there is disclosed a mobile unit anomaly detection method processing time-series pictures to detect an anomaly of mobile unit in pictures, comprising the steps of:</p>
<p id="p-0007" num="0006">(a) identifying mobile units in a frame picture at a time t on the basis of a correlation between frame pictures at times (t−1) and t;</p>
<p id="p-0008" num="0007">(b) detecting a feature amount of a relative movement of a second mobile unit relative to a first mobile unit as an observation amount to store observation amounts in time-series as an observation series;</p>
<p id="p-0009" num="0008">(c) calculating a similarity of the observation series to each reference series to classify a movement between mobile units; and</p>
<p id="p-0010" num="0009">(d) determining that a collision accident has occurred when the similarity of the observation series to a collision reference series is larger than a predetermined value.</p>
<p id="p-0011" num="0010">According to this method, it is possible to automatically detect an anomaly such as a collision accident.</p>
<p id="p-0012" num="0011">However, in a case where a camera angle is low with respect to a road surface, for example, if the second mobile unit approaches the first mobile unit at rest and thereafter, the first mobile unit starts and stops, the second mobile unit overlaps the first mobile unit on pictures at times of the approach and a distance therebetween becomes zero, which is sometimes wrongly determined as a time series pattern of a collision accident</p>
<p id="p-0013" num="0012">Further, in the above publication, a scalar obtained by quantizing V/(d+ε) is used as an observation amount in the step (b), where V denotes a relative motion vector of the second mobile unit with respect to the first mobile unit and ε denotes a constant to avoid the denominator to be zero.</p>
<p id="p-0014" num="0013">By using this observation amount, various kinds of movements between mobile units can be classified with a small number of reference series because of the quantization.</p>
<p id="p-0015" num="0014">However, there has been a problem of impossibility of more detailed classification of movements between mobile units.</p>
<p id="p-0016" num="0015">In the above publication, in the step (a), by using the identification result of a mobile unit in a frame picture at the time (t−1), the mobile unit in a frame picture at the time t can be identified with ease from the correlation.</p>
<p id="p-0017" num="0016">However, in a case where mobile units are shot from the front thereof at a low camera angle with respect to a road surface in order to shoot a wide area with one camera to track the mobile units, overlap between mobile units on a picture frequently occurs as shown in <figref idref="DRAWINGS">FIG. 13</figref>. At the time (t−1), mobile units M<b>1</b> and M<b>2</b> are identified as one cluster without discriminating the mobile units M<b>1</b> and M<b>2</b> from each other. Although a representative motion vector of this cluster is used to identify the cluster including the mobile units M<b>1</b> and M<b>2</b> at the time t on the basis of the above-described correlation, accurate identification is disabled since there is a difference in speed between the mobile units M<b>1</b> and M<b>2</b>. At the next time (t+1), although the mobile unit M<b>2</b> has been separated from the mobile unit M<b>1</b>, the mobile units M<b>2</b> and M<b>3</b> are identified as one cluster since they overlap each other, disabling discrimination of the mobile units M<b>2</b> and M<b>3</b> from each other.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0018" num="0017">Accordingly, it is an object of the present invention to provide a method and an apparatus for processing pictures of mobile unit, capable of automatically detecting anomaly such as a collision accident more accurately.</p>
<p id="p-0019" num="0018">It is another object of the present invention to provide a method and an apparatus for processing pictures of mobile units, capable of performing more detailed classification of various kinds of movements between mobile units with a small number of reference series.</p>
<p id="p-0020" num="0019">It is still another object of the present invention to provide a method and an apparatus for processing pictures of mobile units, capable of identifying different mobile units even if overlapping between the mobile units frequently occurs.</p>
<p id="p-0021" num="0020">In one aspect of the present invention, there is provided a mobile unit anomaly detection method of processing time series pictures to detect an anomaly of a mobile unit in a picture, comprising the steps of:</p>
<p id="p-0022" num="0021">(a) detecting a feature amount of a relative movement of a second mobile unit with respect to a first mobile unit as an observation amount to store a time series of the observation amounts as an observation series;</p>
<p id="p-0023" num="0022">(b) calculating a similarity of the observation series to a predetermined collision observation series; and</p>
<p id="p-0024" num="0023">(c) when the similarity is larger than a predetermined value, determining whether or not a collision accident has happened on the basis of whether or not the first or second mobile unit is at rest in a predetermined stoppage prohibition area.</p>
<p id="p-0025" num="0024">In a case where mobile units approaching each other overlap in a picture even if the mobile units have not collided against each other because of a low camera angle with respect to a road surface, collision accidents are excessively detected when a collision accident is determined only with a similarity between an observation series and a reference series. However, according to this configuration, the collision accident between mobile units is determined more accurately, enabling reduction in excessive detection of the collision accident.</p>
<p id="p-0026" num="0025">In the above step (c), by considering whether or not another mobile unit is moving, chances of excessive detection of the collision accident can be further reduced. when the similarity is smaller than the predetermined value, determining whether or not the first or second mobile unit at rest is in failure on the basis of whether the first or second mobile unit is at rest in the predetermined stoppage prohibition area.</p>
<p id="p-0027" num="0026">Further, in a case where the same conditions for collision determination are met except that the similarity obtained in the above step (b) is smaller than the predetermined value, it can be determined at a higher probability that a mobile unit at rest is in failure. In this case as well, by considering whether or not another mobile unit is moving, it can be determined at a higher probability that a mobile unit at rest is in failure. In another aspect of the present invention, there is provided an inter-mobile unit movement classification method of processing time series pictures to classify a movement between mobile units in at least one of the pictures, comprising the steps of:</p>
<p id="p-0028" num="0027">(a) detecting a feature amount of a relative movement of a second mobile unit with respect to a first mobile unit as an observation amount to store a time series of the observation amounts as an observation series;</p>
<p id="p-0029" num="0028">(b) calculating a similarity of the observation series to a reference series;</p>
<p id="p-0030" num="0029">and (c) classifying a movement of the second object with respect to the first mobile unit according to a value of the similarity; wherein the observation amounts each include: a first scalar obtained by quantizing an amount associated with both a relative velocity V of the second mobile unit with respect to the first mobile unit and a distance d between the first and second mobile units; and a second scalar obtained by quantizing a relative position vector of the second mobile unit with respect to the first mobile unit.</p>
<p id="p-0031" num="0030">With this configuration, since the second scalar obtained by quantizing the relative position vector V is used, relative movements between mobile units can be classified that have been unable to be discriminated from each other only with the first scalar associated with the relative velocity vector, which enables grasping a situation more accurately, leading to a contribution to more accurate detection of a traffic accident.</p>
<p id="p-0032" num="0031">In still another aspect of the present invention, there is provided a mobile unit identification method dividing each of time series pictures to blocks each including a plurality of pixels to process the pictures, wherein the method assigns identification code of a plurality of mobile units included in a frame picture at a time t in units of the block, and obtains motion vectors of the plurality of mobile units in units of the block, in a case where identification code of the plurality of mobile units included in a frame picture at a time (t−1) have been assigned in units of the block, and motion vectors of the plurality of mobile units have been obtained in units of the block, the method comprises the steps of:</p>
<p id="p-0033" num="0032">(a) moving a block j at the time (t−1), whose identification code is IDj and whose motion vector is Vj, by the vector Vj to obtain a substantially corresponding block i at the time t and moving the block i by a vector −Vj to obtain a first box at the time (t−1), to calculate an evaluation value associated with a correlation between an image in the first box at the time (t−1) and an image of the block i at the time t;</p>
<p id="p-0034" num="0033">(b) moving a block k at the time (t−1), whose identification code is IDk and whose motion vector is Vk, by the vector Vk to obtain a substantially corresponding block which is the block i at the time t and moving the block i by a vector −Vk to obtain a second box at the time (t−1), to calculate an evaluation value associated with a correlation between an image in the second box at the time (t−1) and the image of the block i at the time t; and</p>
<p id="p-0035" num="0034">(c) assigning the identification code IDj or IDk to the block i at the time t on the basis of magnitudes of the evaluation values calculated in the steps (a) and (b).</p>
<p id="p-0036" num="0035">With this configuration, since a motion vector of each block is used, it is possible to assign one of a plurality of identification codes to a block within one cluster including a plurality of mobile units having different velocities at a time t; thereby enabling to divide the one cluster into clusters with different identification codes. That is, it becomes possible to track mobile units, for which it was not possible in the prior art, leading to a contribution to more accurate detection of such as a collision accident or a traffic violation.</p>
<p id="p-0037" num="0036">For example, the evaluation value of the step (a) includes a sum over p=1 to Na of a value associated with a value |VCm(t−1)−VBp(t−1)| on the assumption that an identification code of the block i at the time t is IDj, where VCm(t−1) denotes a motion vector of a block m at the time (t−1), the block m at the time (t−1) corresponds to the block i at the time t, and VBp(t−1) denotes a motion vector of a block whose identification code is IDj and which is adjacent to the block m at the time (t−1), wherein the evaluation value of the step (b) includes a sum over q=1 to Nb of a value associated with a value |VCn(t−1)−VBq(t−1)| (for example, |VCn(t−1)−VBq(t−1)|<sup>r</sup>, r&gt;1) on the assumption that an identification code of the block i at the time t is IDk, where VCn(t−1) denotes a motion vector of a block n at the time (t−1), the block n at the time (t−1) corresponds to the block i at the time t, and VBq(t−1) denotes a motion vector of a block whose identification code is IDk which is adjacent to the block n at the time (t−1).</p>
<p id="p-0038" num="0037">With this configuration, even if error of a motion vector at the time (t−1) is large because almost the same pixels distribute, it becomes possible to assign block identification codes more accurately, resulting in contribution to more accurate detection of such as a collision accident or a traffic violation.</p>
<p id="p-0039" num="0038">Other aspects, objects, and the advantages of the present invention will become apparent from the following detailed description taken in connection with the accompanying drawings.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic diagram showing an intersection and an apparatus, placed at the intersection, of an embodiment according to the present invention;</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 2</figref> is a functional block diagram of the mobile unit anomaly detection apparatus in <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 3</figref> is a flow diagram showing a processing of the determination section in <figref idref="DRAWINGS">FIG. 2</figref>;</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 4</figref> is an illustration of slits set at <b>4</b> entrances to the intersection and <b>4</b> exits therefrom and identification codes of mobile units assigned to blocks;</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 5</figref> is an illustration of vectors for explaining a processing at the observation amount detecting section in <figref idref="DRAWINGS">FIG. 2</figref>;</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 6</figref> is an illustration of quantization of a vector V/D;</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 7</figref> is an illustration of quantization of a relative position vector and time-series classification;</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIGS. 8(A) and 8(B)</figref> are both illustrations of classification of movements between mobile units that pass close by each other;</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIGS. 9(A) and 9(B)</figref> are both illustrations of classification of movements between mobile units that pass close by each other;</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. 10</figref> is an illustration of a time-series pattern in a collision accident</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 11</figref> is an illustration of determination of a mobile unit collision accident at an intersection;</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 12</figref> is an illustration of determining a failure of a mobile unit at an intersection;</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. 13</figref> is an illustration of a case where an overlap between mobile units on a picture frequently occurs;</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. 14</figref> is an illustration of preparing an object map;</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 15</figref> is an illustration of preparing an object map;</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. 16</figref> is an illustration of preparing an object map;</p>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. 17</figref> is an illustration of preparing an object map;</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 18</figref> is an illustration of preparing an object map; and</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 19</figref> is an illustration of preparing an object map.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
<p id="p-0059" num="0058">Referring now to the drawings, wherein like reference characters designate like or corresponding parts throughout several views, preferred embodiment of the present invention is described below.</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic diagram showing an intersection and a mobile unit anomaly detection apparatus, placed at the intersection, of an embodiment according to the present invention.</p>
<p id="p-0061" num="0060">This apparatus is provided with an electronic camera <b>10</b> shooting the intersection to output a picture signal and a mobile unit anomaly detection apparatus <b>20</b> processing pictures to automatically detect a collision accident between mobile units and a mobile unit failure.</p>
<p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. 2</figref> is a functional block diagram of the mobile unit anomaly detection apparatus <b>20</b> in <figref idref="DRAWINGS">FIG. 1</figref>. Of constituents of the mobile unit anomaly detection apparatus <b>20</b>, each constituent other than storage sections can also be constructed of computer software or a dedicated hardware. Time series pictures shot by the electronic camera <b>10</b> are stored into an image memory <b>21</b> at a rate of, for example, 12 frames/sec.</p>
<p id="p-0063" num="0062">A background picture generation section <b>22</b> is provided with a storage section and a processing section. This processing section accesses the image memory <b>21</b> to prepare histograms of respective pixels, each histogram having corresponding pixel values of all the frames, for example, over the past 10 minutes to generate a picture with no mobile unit therein as a background picture whose each pixel value is the mode of the corresponding histogram, and to store the background picture into the storage section. This processing is repeated periodically to update the background picture.</p>
<p id="p-0064" num="0063">As shown in <figref idref="DRAWINGS">FIG. 4</figref>, data of the positions and sizes, in a picture frame, of slits EN<b>1</b> to EN<b>4</b> disposed at 4 entrances to an intersection and EX<b>1</b> to EX<b>4</b> disposed at 4 exits therefrom are in advance set in an ID generation/deletion section <b>23</b>. The ID generation/deletion section <b>23</b> reads picture data in the entrance slits EN<b>1</b> to EN<b>4</b> from the picture memory <b>21</b> to determine whether or not a mobile unit exists in the entrance slits in block units. Squares in a mesh of <figref idref="DRAWINGS">FIG. 4</figref> are blocks, each block is of a size of, for example, 8×8 pixels and in a case where one frame is constituted of 480×640 pixels, one frame is divided into 60×80 blocks. Whether or not a mobile unit exists in a block is determined by whether or not a total sum of differences between pixels in the block and corresponding pixels of the background picture is greater than a predetermined value. The determination is also performed in a mobile unit tracking section <b>25</b>.</p>
<p id="p-0065" num="0064">The ID generation/deletion section <b>23</b> assigns a new cluster identification codes ID to a block when determined that a mobile unit exists in the block. when determined that a mobile unit exists in a block adjacent to another block to which ID has been assigned, ID generation/deletion section <b>23</b> assigns the same ID as that of the block having been assigned to this adjacent block. This block to which ID has been assigned may be one adjacent to an entrance slit. For example in <figref idref="DRAWINGS">FIG. 4</figref>, ID=1 is assigned to blocks in the entrance slit EN<b>1</b> in which a mobile unit exists and ID=5 is assigned to blocks in the entrance slit EN<b>4</b> &lt;and their neighboring blocks&gt; in which a mobile unit exists.</p>
<p id="p-0066" num="0065">Assignment of ID is performed to corresponding blocks in an object map storage section <b>24</b>. The object map storage section <b>24</b> is used for storing information (object map) for facilitation of processing in regard each of the blocks 60×80 in the above case, and the information includes flags each indicating whether or not ID has been assigned. In regard to each block, when the ID has been assigned, the information further includes the ID number and a block motion vector described later. Note that without using the flag, ID=0 may be used for indicating no assignment of ID. Further, the most significant bit of ID may be the flag.</p>
<p id="p-0067" num="0066">For each cluster having passed through an entrance slit, the mobile unit tracking section <b>25</b> assigns the same ID to blocks located in a moving direction and deletes the same ID of blocks located in a direction opposite to the movement, that is, performs tracking processing for clusters. The mobile unit tracking section <b>25</b>, as described later, generates an object map at a time t on the basis of an object map and frame picture at a time (t−1).</p>
<p id="p-0068" num="0067">The mobile unit tracking section <b>25</b> performs the tracking processing as far as and within an exist slit for each cluster.</p>
<p id="p-0069" num="0068">The ID generation/deletion section <b>23</b> further checks whether or not ID is assigned to the blocks in the exit slits EX<b>1</b> to EX<b>4</b> on the basis of contents of the object map storage section <b>24</b> and if assigned, deletes the ID when the cluster having the ID has passed though an exit slit. For example, when transition has been performed from a state where an ID is assigned to blocks in the exit slit EX<b>1</b> in <figref idref="DRAWINGS">FIG. 4</figref> to a state where no ID is assigned thereto, ID=3 is deleted. The deleted ID can be used as the next ID to be generated.</p>
<p id="p-0070" num="0069">An observation amount detecting section <b>26</b> obtains a mean motion vector of each cluster on the basis of contents of the object map storage section <b>24</b> as a motion vector of the cluster, obtains a relative motion vector and a relative position vector between clusters, further obtains the shortest distance between the clusters, and thereby obtains an observation amount described below. The observation amount detecting section <b>26</b> stores the observation amount into an observation series storage section <b>27</b> to generate an observation series in regard to each between clusters.</p>
<p id="p-0071" num="0070">As an observation amount, consideration is given to a first scalar obtained by quantizing an amount associated with a relative motion vector and a second scalar obtained by quantizing a relative position vector. First, description will be given of the first scalar and its time series.</p>
<p id="p-0072" num="0071">For example, <figref idref="DRAWINGS">FIG. 5(B)</figref> shows a relative motion vector V of a motion vector V<b>1</b> of a mobile unit M<b>1</b> and a motion vector V<b>2</b> of a mobile unit M<b>2</b> shown in <figref idref="DRAWINGS">FIG. 5(A)</figref>. As shown in <figref idref="DRAWINGS">FIG. 5(A)</figref>, letting d be the shortest distance between the mobile units M<b>1</b> and M<b>2</b>, consider a vector V/D, where D=d+ε and ε is a constant for guaranteeing D&gt;0 when d=0. It will be easy to determine a collision from a time series of vectors V/D since V=0, namely V/D=0 in collision and |V/D| takes large values before and after the collision. In order to simply classify many of relative states between the mobile units M<b>1</b> and M<b>2</b>, the vector V/D is quantized to a scalar as shown in <figref idref="DRAWINGS">FIG. 6</figref>. That is, letting an area divide into regions as shown in <figref idref="DRAWINGS">FIG. 6</figref> with the origin of the vector V/D being the center of the area, and assigning scalars to respective divided regions, the vector V/D is quantized to the scalar of a region to which the tip of the vector belongs.</p>
<p id="p-0073" num="0072">For example, in a case where a time series of V/D=v is v<b>0</b>→v<b>1</b>→v<b>2</b>, which is denoted by (v<b>0</b>, v<b>1</b>, v<b>2</b>) and quantized to (0, 1, 2). The time series of quantized observation amounts is referred to as an observation series. In a collision accident shown in <figref idref="DRAWINGS">FIG. 10</figref>, the observation series over a time t=4 to 9 is denoted by (1, 2, 3, 0, 8, 7). By such quantization, various kinds of collision accidents can be easily recognized since a collision pattern and another collision pattern analogous to it have the same observation series as each other. Further, by the quantization, an observation series is a simple sequence of numerical values, therefore a subsequent recognition process can be simplified.</p>
<p id="p-0074" num="0073">Determination of a collision accident or not is performed by whether or not a similarity between an observation series and a reference series of each of some collision accidents (for example, observation series of each collision accident actually having happened) exceeds a predetermined value. Although the number of necessary reference series can be reduced by the above quantization, in order to further reduce the number, in a case where a time series pattern of a relative movement becomes the same by rotating a stationary coordinate system, an observation series is adjusted to be the same. For this purpose, regarding the above (v<b>0</b>, v<b>1</b>, v<b>2</b>) for example, the reference direction of the first vector v<b>0</b> in the time series, that is, an angle θ to the X axis of <figref idref="DRAWINGS">FIG. 6</figref>, is obtained, followed by a rotation of −θ of the vectors v<b>0</b>, v<b>1</b> and v<b>2</b>. <figref idref="DRAWINGS">FIG. 5(C)</figref> shows the rotation in a case where V/D is the first vector in a time series. by the rotation, an observation amount of the relative vector V/D of the mobile unit M<b>2</b> with respect to the mobile unit M<b>1</b> and an observation amount of the relative vector −V/D of the mobile unit M<b>1</b> with respect to the mobile unit M<b>2</b> are equal to each other.</p>
<p id="p-0075" num="0074">In a case where a mobile unit M<b>1</b> and a mobile unit M<b>2</b> spaced apart from each other approach and pass close by each other, thereafter they are spaced apart from each other, which is one of patterns of <figref idref="DRAWINGS">FIGS. 8(A)</figref>, <b>8</b>(B), <b>9</b>(A) and <b>9</b>(B) and doted lines therein show tracks of the mobile units. Observation series in the respective cases are as follows for example:</p>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. 8(A)</figref>: {1, 1, 2, 2, 3, 1, 1, 1, 1, 1, 1}</p>
<p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. 8(B)</figref>: {1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1}</p>
<p id="p-0078" num="0077"><figref idref="DRAWINGS">FIG. 9(A)</figref>: {1, 1, 2, 2, 3, 1, 1, 1, 1, 1, 1}</p>
<p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. 9(B)</figref>: {1, 1, 2, 2, 3, 1, 1, 1, 1, 1, 1}</p>
<p id="p-0080" num="0079">As is apparent from these observation series, it is not possible to identify these relative movements from each other by the observation series of <figref idref="DRAWINGS">FIGS. 8(A)</figref>, <b>8</b>(B), <b>9</b>(A) and <b>9</b>(B). Therefore, in order to enable to identify the relative movements, a relative position vector of the mobile unit M<b>2</b> with respect to the mobile unit M<b>1</b> is quantized to obtain the second scalar as shown in <figref idref="DRAWINGS">FIG. 7</figref>. That is, an area is divided into regions with dotted lines as shown in <figref idref="DRAWINGS">FIG. 7</figref>, wherein the center of the area is the origin of the relative position vector P<b>12</b> and a reference direction is equal to a direction of the motion vector V<b>1</b> of the mobile unit M<b>1</b>, and scalars are assigned to the respective divided regions. The relative position vector P<b>12</b> is quantized as a scalar of a region to which the tip thereof belongs.</p>
<p id="p-0081" num="0080">In a case of <figref idref="DRAWINGS">FIG. 8(A)</figref> where mobile units M<b>1</b> and M<b>2</b> are moving in opposite directions with passing close by each other, letting a relative position vector P<b>12</b> at the time t be P<b>12</b>(t), a time series of relative position vectors P<b>12</b>(t−1), P<b>12</b>(t) and P<b>12</b>(t+1) of the mobile unit M<b>2</b> with respect to the mobile unit M<b>1</b> are quantized as {20, 80, 60}.</p>
<p id="p-0082" num="0081">The reason why the first scalar is represented by a one-digit numerical value while the second scalar by a two-digit numerical value with the lower digit being 0 is that both can be easily synthesized. For example, in a case where the first scalar is 6 and the second scalar is 20, a value of 26, which is the sum of both, represents an observation amount. In a case where the observation amount is defined as the sum of the first scalar, and the second scalar with respect to the mobile unit M<b>2</b>, the observation series of <figref idref="DRAWINGS">FIGS. 8(A)</figref>, <b>8</b>(B), <b>9</b>(A) and <b>9</b>(B) are represented as follows:</p>
<p id="p-0083" num="0082"><figref idref="DRAWINGS">FIG. 8(A)</figref>: {21, 21, 82, 82, 83, 81, 81, 81, 81, 61, 61}</p>
<p id="p-0084" num="0083"><figref idref="DRAWINGS">FIG. 8(B)</figref>: {21, 21, 41, 41, 41, 41, 41, 41, 41, 61, 61}</p>
<p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. 9(A)</figref>: {61, 61, 42, 42, 43, 41, 41, 41, 41, 21, 21}</p>
<p id="p-0086" num="0085"><figref idref="DRAWINGS">FIG. 9(B)</figref>: {21, 21, 42, 42, 43, 41, 41, 41, 41, 61, 61}</p>
<p id="p-0087" num="0086">In a case where the observation amount is defined as the sum of the first scalar, and the second scalar with respect to the mobile unit M<b>1</b>, the observation series of <figref idref="DRAWINGS">FIGS. 8(A)</figref>, <b>8</b>(B), <b>9</b>(A) and <b>9</b>(B) are represented as follows:</p>
<p id="p-0088" num="0087"><figref idref="DRAWINGS">FIG. 8(A)</figref>: {21, 21, 82, 82, 83, 81, 81, 81, 81, 61, 61}</p>
<p id="p-0089" num="0088"><figref idref="DRAWINGS">FIG. 8(B)</figref>: {21, 21, 41, 41, 41, 41, 41, 41, 41, 61, 61}</p>
<p id="p-0090" num="0089"><figref idref="DRAWINGS">FIG. 9(A)</figref>: {21, 21, 82, 82, 83, 81, 81, 81, 81, 61, 61}</p>
<p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. 9(B)</figref>: {61, 61, 82, 82, 83, 81, 81, 81, 81, 21, 21}</p>
<p id="p-0092" num="0091">As shown in <figref idref="DRAWINGS">FIG. 7</figref> with straight lines each having an arrow, a case where the second scalar changes as 20→80→60 is classified as PASO, a case where the second scalar changes as 20→40→60 is classified as PAS<b>1</b>, a case where the second scalar changes as 60→40→20 is classified as PAS<b>2</b>, and a case where the second scalar changes as 60→80→20 is classified as PAS<b>3</b>. Further, in a case where a change in relative position vector of the mobile unit M<b>2</b> with respect to the mobile unit M<b>1</b> is represented as PASk and a change in relative position vector of the mobile unit M<b>1</b> with respect to the mobile unit M<b>2</b> is represented as PASm, it is denoted by PASkm.</p>
<p id="p-0093" num="0092">In each case of <figref idref="DRAWINGS">FIGS. 8(A) and 8(B)</figref>, a change in relative position vector of the mobile unit M<b>2</b> with respect to the mobile unit M<b>1</b> and a change in relative position vector of the mobile unit M<b>1</b> with respect to the mobile unit M<b>2</b> are the same as each other, which are classified as PAS<b>00</b> and PAS<b>11</b>, respectively. On the other hand, in cases of <figref idref="DRAWINGS">FIGS. 9(A) and 9(B)</figref>, a change in relative position vector of the mobile unit M<b>2</b> with respect to the mobile unit M<b>1</b> and a change in relative position vector of the mobile unit M<b>1</b> with respect to the mobile unit M<b>2</b> differ from each other, which are classified as PAS<b>20</b> and PAS<b>13</b>, respectively.</p>
<p id="p-0094" num="0093">In such a way, although it is not possible to discriminate and recognize the relative movement of mobile units only using the first scalar, this is enabled by classifying the relative movement using the second scalar, which enables more accurate understanding of the states.</p>
<p id="p-0095" num="0094">For example, letting the number of clusters on an object map be 3, and IDs be 1, 2 and 3, and an observation series between clusters of ID=i and ID=j is denoted by OSi,j, observation series OS<b>1</b>,2; OS<b>2</b>,1; OS<b>2</b>,3; OS<b>3</b>,1 and OS,3 are stored in the observation series storage section <b>27</b> of <figref idref="DRAWINGS">FIG. 2</figref>. The reason why OSi,j and OSj,i are both stored is to enable classification of the above PASkm with focusing attention on second scalars in a time series. In the observation series storage section <b>27</b>, each of stored observation series is consisted of a predetermined number, for example, 24, of observation amounts, and every time advance by 1 the most oldest observation amount is deleted and a new observation amount is added in each observation amount.</p>
<p id="p-0096" num="0095">A classification section <b>28</b> reads observation series between clusters stored in the observation series storage section <b>27</b>, to calculate similarities between each of the observation series and each of predetermined reference series of collision accidents and others and to give the calculated similarities to a determination section <b>29</b> as classification results. Each of the observation series is a time series of observation amounts each having a combination of the first scalar and the second scalar, and the reference series are constituted in a similar manner. Note that calculation may be performed on a similarity to each predetermined reference series of a collision accident only with respect to the first scalar of each observation series and on a similarity to each predetermined reference series of an above PASkm with respect to the second scalar thereof to give the determination section <b>29</b> the calculated similarities as classification results.</p>
<p id="p-0097" num="0096">Known pattern similarity calculation methods such as a hidden Markov model (HMM) method and a pattern matching method can be applied. For example, as disclosed in the above-described publication of JP 2001-148019-A, a probability of occurrence of the observation series may be calculated as a similarity by the HMM whose parameters have been determined using observation series of actual collision accidents as learning series.</p>
<p id="p-0098" num="0097">Now, description will be given of detection of a collision accident and a mobile unit failure with reference to <figref idref="DRAWINGS">FIGS. 11 and 12</figref>.</p>
<p id="p-0099" num="0098">In <figref idref="DRAWINGS">FIG. 11</figref>, assume that there has been occurred a collision sequence between mobile units M<b>1</b> and M<b>2</b> as shown in <figref idref="DRAWINGS">FIG. 10</figref> or a non-collision sequence similar to this collision sequence and the mobile units M<b>1</b> and M<b>2</b> is stopping. This collision sequence is similar to that of a case where a mobile unit M<b>3</b> is at rest to make its right turn and at that time, a mobile unit M<b>4</b> approaches the mobile unit M<b>3</b> from the rear, and therefore the mobile unit M<b>3</b> moves a bit forward and stops. In a case where mobile units are shot at a low camera angle with respect to a road surface, the mobile units look like overlapping to each other even when the mobile units are actually spaced apart from each other, so a chance arises where the situation is classified as collision between the mobile units in pictures.</p>
<p id="p-0100" num="0099">However, the mobile units M<b>3</b> and M<b>4</b> are in an area where stoppage is permitted for a right turn. Contrast to this, mobile units M<b>1</b> and M<b>2</b> exist in an area where stopping is prohibited; therefore, there is a high possibility that a collision has happened between the mobile units M<b>1</b> and M<b>2</b>. In this case, there is a possibility that the mobile units M<b>1</b> and M<b>2</b> are at rest since an ambulance or the like is approaching the intersection. Therefore, if there exists another mobile unit passing close by the mobile units M<b>1</b> or M<b>2</b> at rest, a possibility of collision between the mobile units M<b>1</b> and M<b>2</b> becomes higher.</p>
<p id="p-0101" num="0100">From the above consideration, a determination is performed that the case is collision between the mobile units M<b>1</b> and M<b>2</b>: if</p>
<p id="p-0102" num="0101">(1) a relative movement between the mobile units M<b>1</b> and M<b>2</b> is classified as collision;</p>
<p id="p-0103" num="0102">(2) the mobile unit M<b>1</b> or M<b>2</b> is at rest in a stoppage prohibition area; and</p>
<p id="p-0104" num="0103">(3) a mobile unit other than the mobile units M<b>1</b> and M<b>2</b> are moving in the intersection.</p>
<p id="p-0105" num="0104">Further, as shown in <figref idref="DRAWINGS">FIG. 12</figref>, in a case where the mobile unit M<b>1</b> has not collided with another car, but is at rest in the stoppage prohibition area, there is a high possibility that the mobile unit M<b>1</b> is in failure. In this case, if another mobile unit is moving in the intersection, there is a higher possibility that the mobile unit M<b>1</b> is in failure. Therefore, if the above (1) is determined negative but the above (2) and (3) are determined positive, it is determined that the mobile unit at rest is in failure.</p>
<p id="p-0106" num="0105"><figref idref="DRAWINGS">FIG. 3</figref> is a flow diagram showing a processing in the determination section <b>29</b> of <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0107" num="0106">(S<b>1</b>) The determination section <b>29</b> reads a maximum collision similarity CS of a pair of clusters from the classification section <b>28</b>.</p>
<p id="p-0108" num="0107">(S<b>2</b> to S<b>4</b>) If the collision similarity CS is larger than a predetermined value CSO, then a flag F is set, or else the flag F is reset.</p>
<p id="p-0109" num="0108">(S<b>5</b>) An observation series corresponding to the pair of the clusters in the step S<b>1</b>, is read from the observation series storage section <b>27</b>, and if the first scalars of a predetermined number of observation amounts from the latest time are all zero, that is, if a state where a relative motion vector V=0 lasts for over a predetermined time period, then the object map storage section <b>24</b> is referred to investigate whether or not motion vectors of all blocks belonging to the clusters having the IDs are zero, as a result of which if all the motion vectors are zero, it is determined that the mobile unit is at rest. If not at rest, then the process returns to the step S<b>1</b> to read a maximum CS of another pair of clusters, or else the process advances to the step S<b>6</b>.</p>
<p id="p-0110" num="0109">(S<b>6</b>) It is investigated whether or not the cluster at rest exists within any one of the stoppage prohibition areas stored in advance in a stoppage prohibition area storage section <b>30</b>, and if exists, then the process advances to step S<b>7</b>, or else the process returns to the step S<b>1</b>.</p>
<p id="p-0111" num="0110">(S<b>7</b>) In the classification results of the classification section <b>28</b>, if a similarity of a pair of clusters one of which is other than the clusters at the step S<b>1</b> to a reference series of anyone of the PAS<b>00</b>, PAS<b>11</b>, PAS<b>20</b> or PAS<b>13</b> exceeds a predetermined value, then it is determined that there exists a mobile unit moving in the intersection and the process advances to step S<b>8</b>, or else the process returns to the step S<b>1</b>.</p>
<p id="p-0112" num="0111">(S<b>8</b> to S<b>10</b>) If F=<b>1</b>, then it is determined to be an accident, or if F=0, then it is determined that the mobile unit is in failure, and this result is outputted. Then the process returns to step S<b>1</b>.</p>
<p id="p-0113" num="0112">According to such processing, a collision accident and a mobile unit failure can be automatically detected with a high probability.</p>
<p id="p-0114" num="0113">Now, detailed description will be given of a method for preparing an object map at a time t on the basis of an object map and a frame picture at a time (t−1) and a frame picture at the time t in the mobile unit tracking section <b>25</b> of <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0115" num="0114">In a case where a mobile unit is shot from the front thereof at a low camera angle with respect to a road surface in order to shoot a wide area with one camera to track mobile units, overlaps between mobile units in pictures frequently occurs as shown in (A) to (C) of <figref idref="DRAWINGS">FIG. 13</figref>.</p>
<p id="p-0116" num="0115"><figref idref="DRAWINGS">FIGS. 14 and 15</figref> show enlarged pictures of (A) and (B) of <figref idref="DRAWINGS">FIG. 13</figref>, respectively. Dotted lines are for dividing a picture into blocks. In <figref idref="DRAWINGS">FIG. 14</figref>, overlapped mobile units correspond to one cluster C<b>12</b> in the object map storage section <b>24</b> of <figref idref="DRAWINGS">FIG. 2</figref>, and assume that the mobile units M<b>1</b> and M<b>2</b> are not yet discriminated from each other. On the other hand, a cluster <b>3</b> corresponds to one mobile unit M<b>3</b>.</p>
<p id="p-0117" num="0116">A block on the i-th row and the j-th column at a time t is denoted by B(t: i, j). As shown in <figref idref="DRAWINGS">FIG. 14</figref>, motion vectors of blocks B (t−1 : 11, 13) and B (t−1 : 14, 13) are denoted by V<b>2</b> and V<b>3</b>, respectively. The tips of the motion vectors V<b>2</b> and V<b>3</b> both exist in a block (t−1 : 18, 11). In a picture at the time t of <figref idref="DRAWINGS">FIG. 15</figref>, frames SB<b>2</b> and SB<b>3</b> correspond to respective regions where the blocks B (t−1 : 11, 13) and B (t−1 : 14, 13) in the picture of <figref idref="DRAWINGS">FIG. 14</figref> are moved by the motion vectors V<b>2</b> and V<b>3</b>, respectively.</p>
<p id="p-0118" num="0117">Next, the motion vectors V<b>2</b> and V<b>3</b> are translated such that the tips of the motion vectors V<b>2</b> and V<b>3</b> both coincide with the center of the block B (18, 11). Then the motion vectors V<b>2</b> and V<b>3</b> are inversed and the block B (t−1 : 18, 11) which is hatched is moved by vectors −V<b>2</b> and −V<b>3</b> to obtain frames SBR<b>2</b> and SBR<b>3</b>, respectively, as shown in <figref idref="DRAWINGS">FIG. 16</figref>. Images in the boxes SBR<b>2</b> and SBR<b>3</b> are estimated ones on the assumption that an image in the block B (t: 18, 11) of <figref idref="DRAWINGS">FIG. 17</figref> would have belonged to the clusters C<b>12</b> and C<b>3</b> of <figref idref="DRAWINGS">FIG. 16</figref> at the time (t−1). IDs of the clusters C<b>12</b> and C<b>13</b> are denoted by ID<b>12</b> and ID<b>3</b>, respectively.</p>
<p id="p-0119" num="0118">An evaluation value UD associated with a similarity between the image in the box SBR<b>2</b> of <figref idref="DRAWINGS">FIG. 16</figref> and the image in the block B(t: 18, 11) is calculated with the following equation, and the value is denoted by UD (ID<b>12</b>).
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>UD=Σ|SP</i>(<i>t−</i>1<i>: i, j</i>)−<i>BP</i>(<i>t: i, j</i>)|  (1)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where SP(t−1: i, j) and BP(t: i, j) denote pixel values on the i-th row and the j-th column in the box SBR<b>2</b> of <figref idref="DRAWINGS">FIG. 16</figref> and in the block B(t: 18, 11) of <figref idref="DRAWINGS">FIG. 17</figref>, respectively, and Σ denotes a sum over i=1 to 8 and j=1 to 8 (a sum over all pixels in a block or box). The smaller the evaluation value UD is, the higher the correlation is.
</p>
<p id="p-0120" num="0119">Likewise, an evaluation value UD associated with a correlation between the image in the block SBR<b>3</b> of <figref idref="DRAWINGS">FIG. 16</figref> and the image in the block B(t: <b>18</b>, <b>11</b>) of <figref idref="DRAWINGS">FIG. 17</figref> is calculated, and the value is denoted by UD(ID<b>3</b>).</p>
<p id="p-0121" num="0120">In the case of <figref idref="DRAWINGS">FIGS. 16 and 17</figref>, UD(ID<b>3</b>)&lt;UD(ID<b>12</b>) holds and thereby ID<b>3</b> is assigned to the block B(t: 18, 11).</p>
<p id="p-0122" num="0121">In such a way, by using a motion vector of each block, different IDs can be assigned to blocks included in the cluster C<b>123</b> including a plurality of mobile units at the time t, and thereby one cluster C<b>123</b> can be divided into subclusters with different IDs.</p>
<p id="p-0123" num="0122">How to find out the block B(t−1 : 11, 13) in the cluster C<b>12</b> and the block B(t−1 : 14, 13) in the cluster C<b>3</b> both corresponding to the block B(t: 18, 11) belonging to the cluster C<b>123</b> of <figref idref="DRAWINGS">FIG. 15</figref> is as follows: That is, letting a vector from the center of the block B(t−1: i, j) to the center of the block B(t−1 : 18, 11) be V(<b>18</b>−j, <b>11</b>−j) and a motion vector of the block B (t−11: i, j) be V(t−1: i, j), it is equivalent to find out a block B(t−1: i, j) having V(t−1: j, j) satisfying the following expression:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>|<i>V</i>(18−<i>i, </i>11−<i>j</i>)−<i>V</i>(<i>t−</i>1<i>: i, j</i>)|&lt;Δ<i>V </i><?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where ΔV is a constant whose value is, for example, three times the number of pixels on one side of a block. In a case where a plurality of blocks corresponding to the block B(t: 18, 11) exist in the cluster C<b>12</b> or in a case where a plurality of blocks corresponding to the block B(t: 18, 11) exist in the cluster C<b>3</b>, the evaluation value is obtained for each of such blocks and ID corresponding to the least evaluation value is assigned to the block B(t: 18, 11).
</p>
<p id="p-0124" num="0123">The above procedure is applied to other blocks belonging to the cluster C<b>123</b> of <figref idref="DRAWINGS">FIG. 15</figref> in a similar manner.</p>
<p id="p-0125" num="0124">In the above case where ID<b>3</b> is assigned to the block B(t: 18, 11), a motion vector of the block can be estimated to be almost equal to the vector V<b>3</b>. In order to obtain the motion vector of the block B(t: 18, 11) more accurately, the box SBR<b>3</b> is shifted by one pixel at a time in a predetermined range whose center is coincident with that of the box SBR<b>3</b>, the evaluation value is obtained for every shift, and the motion vector of the block B(t: 18, 11) is determined to be a vector whose origin is the center of the box SBR<b>3</b> when the evaluation value assumes the minimum (the highest correlation) and whose tip is the center of the block B(t: 18, 11). A motion vector of a block at a time t is determined by such a block matching each time when ID is assigned to the block.</p>
<p id="p-0126" num="0125">In order to estimate a similarity more accurately, amounts described below are considered.</p>
<p id="p-0127" num="0126">Part of the box SBR<b>3</b> in <figref idref="DRAWINGS">FIG. 16</figref> is outside the cluster <b>3</b> and as the outside area is wider, it can be considered that a probability that ID of the block B(t: 18, 11) of <figref idref="DRAWINGS">FIG. 17</figref> is ID<b>3</b> is low. Therefore, assuming that ID of the block B(t: 18, 11) is equal to ID<b>3</b>, the number S(t−1) of pixels in the box SBR<b>3</b> and belonging to the cluster C<b>3</b> is obtained, and an evaluation value U associated with a correlation between the image in the box SBR<b>3</b> of <figref idref="DRAWINGS">FIG. 16</figref> and the image in the block B(t: 18, 11) of <figref idref="DRAWINGS">FIG. 17</figref> is calculated with the following equation, and the calculated value is denoted by US(ID<b>3</b>):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>US=</i>(<i>S</i>(<i>t−</i>1)−64)<sup>2</sup>  (2)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0128" num="0127">The smaller the evaluation value UD is, the higher the correlation is. Likewise, assuming that ID of the block B(t: 18, 11) is equal to ID<b>12</b> and the number S of pixels in the box SBR<b>2</b> and belonging to the cluster C<b>12</b> is obtained to calculate the evaluation value US, and the value is denoted by US(ID<b>12</b>). In cases of <figref idref="DRAWINGS">FIGS. 16 and 17</figref>, US(ID<b>12</b>)=0 and US(ID<b>3</b>)&gt;US(ID<b>12</b>) hold.</p>
<p id="p-0129" num="0128">U=αUD+βUS which is a linear combination of the above equations (1) and (2) is defined as an evaluation function, and it is determined that the smaller the evaluation value U, the higher the similarity is, where α and β are positive constants and determined on the basis of practical experiences such that the evaluation of similarity becomes more correct.</p>
<p id="p-0130" num="0129">For each block of <figref idref="DRAWINGS">FIG. 17</figref> at the time t, it is determined whether ID<b>12</b> or ID<b>3</b> is assigned to in a similar way as described above. Since a probability of a wrong determination is high in a case where the absolute value of a difference of evaluation values |U(ID<b>12</b>)−U(ID<b>3</b>)| is equal to or less than a predetermined value, no ID is assigned and the following amount is considered with respect to an image at a time t. For example, in a case where it is assumed that ID of the block B(t: 18, 11) of <figref idref="DRAWINGS">FIG. 17</figref>, which has not been determined, is equal to ID<b>3</b>, the number N(t) of blocks assigned with ID<b>3</b> among <b>8</b> blocks adjacent to the block B(t: 18, 11) is obtained, an evaluation value UN is calculated with the following equation, and the value is denoted by UN(ID<b>3</b>):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>UN=</i>(<i>N</i>(<i>t</i>)−8)<sup>2</sup>.  (3)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0131" num="0130">The smaller the evaluation value, the higher the correlation is. Similarly, in a case where it is assumed that ID of the block B(t: 11) of <figref idref="DRAWINGS">FIG. 17</figref> is equal to ID<b>12</b>, the number N of blocks assigned with ID<b>12</b> among 8 blocks adjacent to the block B(t: 18, 11) is obtained, the evaluation value UN is calculated, and the value is denoted by UN(ID<b>12</b>).</p>
<p id="p-0132" num="0131">Further, when the error of a motion vector at a time (t−1) obtained by block matching is large since almost the same pixel values are distributed, a case can be considered where the absolute value |U(ID<b>12</b>)−U(ID<b>3</b>)| of a difference in evaluation values of the linear combination U=αUD+βUS of the above equations (1) to (3) is equal to or less than a predetermined value. Therefore, by paying attention to motion vectors of blocks in the neighborhood of blocks B(t−1 : 14, 13) and B(t−1 : 11, 13) corresponding to the block (t: 18, 11), an evaluation of a similarity is made more correct. That is, an evaluation value UV is calculated using the following equation which includes a motion vector VC(t−1)=V<b>3</b> of the block B(t−1 : 14, 13) at the time (t−1) corresponding to the B(t: 18, 11) on the assumption that the block B(t 18, 11) has ID<b>3</b>; and motion vectors VBi(t−1), for i=1 to NX and NX=NX<b>3</b>, of blocks (blocks each attached with a small black dot in <figref idref="DRAWINGS">FIG. 16</figref>) which are ones among 8 blocks adjacent to the block B(t−1 : 14, 13) and whose ID is equal to ID<b>3</b>, and the evaluation value is denoted by UV(ID<b>3</b>):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>UV=Σ|VC</i>(t−1)−<i>VBi</i>(<i>t−</i>1)|<sup>2</sup><i>/NX</i>  (4)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where Σ denotes a sum over i=1 to NX. The smaller the evaluation value is, the higher the correlation is. Similarly, an evaluation value UV is calculated in regard to a motion vector VC=V<b>2</b> of the block B(t−1 : 11, 13) at the time (t−1) corresponding to the B(t: 18, 11) on the assumption that the block B(t: 18, 11) has ID<b>12</b>; and motion vectors VBj(t−1), for j=1 to NX and NX=NX<b>12</b>, of blocks (blocks each attached with a mark x in <figref idref="DRAWINGS">FIG. 16</figref>) which are ones among 8 blocks adjacent to the block B(t−1 : 11, 13) and whose ID is equal to ID<b>12</b>, and the evaluation value is denoted by UV(ID<b>12</b>).
</p>
<p id="p-0133" num="0132">A linear combination of the above equations (1) to (4),
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>U=αUD+βUS+γUN+ΔUV</i>  (5)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
is used as an evaluation function and it is determined that the smaller the evaluation value, the higher the similarity is, where γ and δ are also positive constants and determined on the basis of practical experiences such that the evaluation of similarity becomes more correct.
</p>
<p id="p-0134" num="0133">In such a way, not only is it determined whether ID is ID<b>12</b> or ID<b>3</b> in each block in the cluster C<b>123</b> of <figref idref="DRAWINGS">FIG. 17</figref>, but a motion vector of each block is also determined. That is, an object map at a time t is determined, and as shown in <figref idref="DRAWINGS">FIG. 18</figref>, even if the mobile unit M<b>2</b> overlaps both of the mobile units M<b>1</b> and M<b>3</b>, the cluster can be divided into clusters with different IDs.</p>
<p id="p-0135" num="0134">Similarly, an object map at the time (t+1) can be obtained from a frame picture and an object map at the time t. Since C<b>12</b> and C<b>3</b> are discriminated from each other at the time t and the mobile unit M<b>1</b> is separated from the mobile unit M<b>2</b> in the frame picture at the time (t+1), as shown in <figref idref="DRAWINGS">FIG. 19</figref>, C<b>1</b> to C<b>3</b> corresponding to the mobile units M<b>1</b> to M<b>3</b>, are discriminated from each other at the time (t+1).</p>
<p id="p-0136" num="0135">Note that in a case where the equation (5) is used, one or more of β, γ and δ may be zero in order to reduce a calculation time.</p>
<p id="p-0137" num="0136">Further, an object map X at a time (t−1) may be copied into a work area as an object map Y prior to preparation of an object map at a time t and a motion vector Vi of each block i whose ID is equal to IDα in the object map X may be replaced with a mean vector (ΣΔVj)/p, for j=1 to p, where ΔV<b>1</b> to ΔVp are motion vectors of all blocks, in the object map Y, including a block corresponding to the block i and blocks adjacent to this corresponding block and having ID=IDα. With such a procedure, in a case where errors of motion vectors are large since a texture in a block is similar to those in adjacent blocks, the errors are reduced. Copying to a work area is for uniquely determining the mean vector.</p>
<p id="p-0138" num="0137">Then, description will be given of a method for obtaining an object map more accurately using the evaluation function of the above equation (5) and an object map at a time t obtained as described above as an initial condition. Since this method itself is the same as disclosed in the above publication except for the evaluation function U, an outline thereof will be given.</p>
<p id="p-0139" num="0138">The blocks in the clusters C<b>12</b> and C<b>3</b> of <figref idref="DRAWINGS">FIG. 18</figref> are denoted by BKi, for i=1 to n. ID of a block BKi is a variable IDi and the U thereof is expressed as U(BKI, IDi). IDi is equal to ID<b>12</b> or ID<b>3</b>. ID<b>1</b> to IDn are determined such that a sum UT of evaluation values U over i=1 to n,
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>UT=ΣU</i>(<i>BKi, IDi</i>),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
takes the minimum. Initial values of ID<b>1</b> to IDn are given by an object map at the time t obtained as described above.
</p>
<p id="p-0140" num="0139">Although preferred embodiment of the present invention has been described, it is to be understood that the invention is not limited thereto and that various changes and modifications may be made without departing from the spirit and scope of the invention.</p>
<p id="p-0141" num="0140">For example, the apparatus of <figref idref="DRAWINGS">FIG. 2</figref> automatically detecting a collision accident and a vehicle failure has characteristics in the determination section <b>29</b> and observation amounts detected by the observation amount detecting section <b>26</b> may be only of the first scalars. Further, a configuration in which an observed value including the first and second scalars are used can be applied for use in an apparatus performing other than determination of a collision accident and a vehicle failure, for example, in an apparatus automatically classifying movements of mobile units to get a statistics. Furthermore, a processing method in the mobile unit tracking section <b>25</b> using the above-described evaluation function U can be applied to various kinds of mobile unit tracking apparatuses.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A mobile unit anomaly detection method of processing time series pictures to detect an anomaly of a mobile unit in a picture, comprising:
<claim-text>detecting a feature amount of a relative movement of a second mobile unit with respect to a first mobile unit as an observation amount to store a time series of said observation amounts as a current observation series;</claim-text>
<claim-text>calculating a similarity of said current observation series to a predetermined collision observation series; and</claim-text>
<claim-text>when said similarity is larger than a predetermined value, determining whether or not a collision accident has happened on the basis of whether or not said first or second mobile unit is at rest in a predetermined stoppage prohibition area.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The mobile unit anomaly detection method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, when said similarity is larger than said predetermined value, it is determined that said collision accident has occurred when said first or second mobile unit is at rest in said predetermined stoppage prohibition area and another mobile unit is moving.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The mobile unit anomaly detection method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>when said similarity is smaller than said predetermined value, determining whether or not said first or said second mobile unit at rest is in failure on the basis of whether said first or second mobile unit is at rest in said predetermined stoppage prohibition area.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The mobile unit anomaly detection method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein, when said similarity is smaller than said predetermined value, it is determined that said first or second mobile unit at rest is in failure when said first or second mobile unit is at rest in said predetermined stoppage prohibition area and another mobile unit is moving.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A mobile unit anomaly detection apparatus comprising:
<claim-text>a picture storage device storing time series pictures; and</claim-text>
<claim-text>a picture processing device processing said time series pictures to detect an anomaly of a mobile unit in at least one of said pictures,</claim-text>
<claim-text>wherein said picture processing device comprises:
<claim-text>an observation amount detecting section detecting a feature amount of a relative movement of a second mobile unit with respect to a first mobile unit as an observation amount;</claim-text>
</claim-text>
<claim-text>an observation series storage section storing a time series of said observation amounts as a current observation series;</claim-text>
<claim-text>a stoppage prohibition area storage section storing a predetermined stoppage prohibition area;</claim-text>
<claim-text>a similarity calculation section calculating a similarity of said current observation series to a predetermined collision observation series; and</claim-text>
<claim-text>a determination section determining, when said similarity is larger than a predetermined value, whether or not a collision accident has happened on the basis of whether or not said first or second mobile unit is at rest in said predetermined stoppage prohibition area, and outputs a result of the determination.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The mobile unit anomaly detection apparatus according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein, when said similarity is larger than said predetermined value, said determination section determines that said collision accident has occurred when said first or second mobile unit is at rest in said predetermined stoppage prohibition area and another mobile unit is moving.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The mobile unit anomaly detection apparatus according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein said determination section, when said similarity is smaller than said predetermined value, determines whether or not said first or second mobile unit at rest is in failure on the basis of whether said first or second mobile unit is at rest in said predetermined stoppage prohibition area, and outputs a result of the determination.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The mobile unit anomaly detection apparatus according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein said determination section, when said similarity is smaller than said predetermined value, determines that said first or second mobile unit at rest is in failure when said first or second mobile unit is at rest in said predetermined stoppage prohibition area and another mobile unit is moving.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A method of detecting an accident, the method comprising:
<claim-text>measuring a current series of movement amounts of a mobile unit with respect to another mobile unit; and</claim-text>
<claim-text>correlating to detect an accident the measured current series of movement amounts to a set of series of movement amounts for known accidents.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
