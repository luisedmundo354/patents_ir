<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298890-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298890</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10472203</doc-number>
<date>20020314</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>DE</country>
<doc-number>101 13 211</doc-number>
<date>20010318</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>883</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>36</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>01</class>
<subclass>C</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382154</main-classification>
<further-classification>382100</further-classification>
<further-classification>382291</further-classification>
<further-classification>702153</further-classification>
</classification-national>
<invention-title id="d0e71">Method and arrangement for the photographically detecting the spatial form of an object</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4745290</doc-number>
<kind>A</kind>
<name>Frankel et al.</name>
<date>19880500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>4825263</doc-number>
<kind>A</kind>
<name>Desjardins et al.</name>
<date>19890400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5127420</doc-number>
<kind>A</kind>
<name>Horvath</name>
<date>19920700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5911126</doc-number>
<kind>A</kind>
<name>Massen</name>
<date>19990600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2003/0142863</doc-number>
<kind>A1</kind>
<name>Massen</name>
<date>20030700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382154</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>AT</country>
<doc-number>3 63 580</doc-number>
<date>19810100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>DE</country>
<doc-number>78 310</doc-number>
<date>19701200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>DE</country>
<doc-number>31 19 857</doc-number>
<date>19821200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>DE</country>
<doc-number>42 32 606</doc-number>
<date>19940300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>DE</country>
<doc-number>43 35 121</doc-number>
<date>19950500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>DE</country>
<doc-number>196 26 889</doc-number>
<date>19980100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>WO</country>
<doc-number>WO 92/08175</doc-number>
<date>19920500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>WO</country>
<doc-number>WO 95/31934</doc-number>
<date>19951100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>WO</country>
<doc-number>WO 97/14932</doc-number>
<date>19970400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>21</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382103</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382154</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382291</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382100</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345420</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701 23</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>396429</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>530350</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>180168</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>340551</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>360 32</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>4352523</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>4353201</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>435  6</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>435 691</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>435325</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>401 41</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>356620</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>283 93</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>702153</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>8</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20040228517</doc-number>
<kind>A1</kind>
<date>20041118</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Massen</last-name>
<first-name>Robert</first-name>
<address>
<city>Ohningen-Wangen</city>
<country>DE</country>
</address>
</addressbook>
<nationality>
<country>DE</country>
</nationality>
<residence>
<country>DE</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Friedman</last-name>
<first-name>Stuart J.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>corpus.e AG</orgname>
<role>03</role>
<address>
<city>Stuttgart</city>
<country>DE</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Chawan</last-name>
<first-name>Sheela</first-name>
<department>2624</department>
</primary-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/EP02/02875</doc-number>
<kind>00</kind>
<date>20020314</date>
</document-id>
<us-371c124-date>
<date>20030922</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO02/074038</doc-number>
<kind>A </kind>
<date>20020926</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method of detecting the 3D shape of an object by photogrammetry, in which a plurality of photogrammetric point markers and a plurality of connecting markers are provided on the surface of the object, each connecting marker connecting a subset of the plurality of point markers with each other, with at least two different types of point markers existing that differ from each other in their optical configuration, and some of the point markers provided along a connecting marker are formed in such a way that the sequence of their optical configurations results in a predetermined code that characterizes the respective connecting marker, a plurality of photogrammetric images of the object are taken from different views, an image processing of the images is performed, in which first the connecting markers mutually corresponding to each other in the images are associated with one another using their respective code, and then the point markers connected with each other by the respective connecting marker are associated with one another with the aid of the connecting marker association in the images, and using the point marker association, the 3D shape of the object is determined by means of a photogrammetric evaluation process. The invention further relates to an arrangement for carrying out the method.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="101.68mm" wi="104.06mm" file="US07298890-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="90.34mm" wi="114.38mm" file="US07298890-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="212.60mm" wi="128.86mm" file="US07298890-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="103.89mm" wi="119.80mm" file="US07298890-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="234.87mm" wi="153.25mm" file="US07298890-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="112.86mm" wi="130.73mm" file="US07298890-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">The invention relates to a method and an arrangement for the photogrammetric detection of the 3D shape of an object.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">In connection with the so-called “mass customization”, i.e. the production and sale of products individually adapted to the body measurements of a customer, the detection of the three-dimensional spatial shape of the body or of body parts is an important problem to be solved in engineering. When the three-dimensional spatial shape of a body part e.g. the torso/leg region of a customer, is known, individual articles of clothing such as pants, shirts, etc. may be manufactured with a very good fit.</p>
<p id="p-0004" num="0003">A number of body scanners have been developed which detect and digitize the three-dimensional shape of the human body or of body parts contactlessly, using various optical methods, e.g. laser triangulation, stereo methods, moirémethods, etc., in which the data records describing the digitization are then made available for the automated production of individually adapted products. As a rule, such body scanners operate with technically very sophisticated and expensive processes which, in addition, require optical calibration and can therefore be employed only by trained specialist staff.</p>
<p id="p-0005" num="0004">The so-called passive methods of short-range photogrammetry are considerably more cost-effective since merely calibrated cameras or digital cameras are required, rather than expensive projection units or precisely calibrated mechanical structures.</p>
<p id="p-0006" num="0005">For instance, the Patent EP 0 760 622, “Sensing Process and Arrangement for the Three-Dimensional Shape in Space of Bodies or Body Parts”, the applicant and inventor of which is Robert Massen, discloses a method which allows an optical detection of the 3D coordinates of a body or body part, involving very little technical expenditure. To this end, the body is covered with an elastic envelope specially marked with precisely located point markers, and photographs of the body are taken from a plurality of camera positions that overlap but are otherwise taken free-handed. By a photogrammetric evaluation of the corresponding point markers in the individual overlapping image areas of the photographs, a 3D data record of the body part may be established.</p>
<p id="p-0007" num="0006">In order to allow a 3D reconstruction of the body part from the point markers provided on the body part or on an envelope pulled over the body part based on two overlapping image recordings using methods of photogrammetry, the pixel coordinates of the so-called homologous point markers, i.e. of the point markers mutually corresponding to each other in the images need to be determined. This process is also referred to as registration. Therefore, in an automatic registration, those point markers which correspond to each other need to be found from two overlapping image recordings using methods of two-dimensional image processing. In previous known methods, this is achieved by the use of individually encoded point markers. The point markers used are circles, for example, that are surrounded by radial segments representing a binary code (in this connection see the left-hand part of <figref idref="DRAWINGS">FIG. 1</figref>). Here, the center of the encoded marker defines the location of the photogrammetric point marker. The radial segments provide a unique characterization for each point marker by a code of its own.</p>
<p id="p-0008" num="0007">In the prior art methods, attempts are made with the aid of automatic image processing to find such point markers in two images, to read their code and to prepare a list of the corresponding point markers, i.e. the homologous point markers. Once preparation of this list is complete, the known methods of image orientation and bundle adjustment may be employed to establish a 3D data record containing the XYZ space coordinates of all homologous point markers.</p>
<p id="p-0009" num="0008">In the photogrammetric measurement of large structures such as vessel hulls, aircraft parts etc., the space required by such encoded point markers is not relevant. However, a disadvantage of the prior art methods for the photogrammetric determination of the 3D shape of an object, which make use of individually encoded point markers that cover a relatively large area consists in that these methods are not suitable for the digitization of very small objects, which need to be covered with many point markers due to the required spatial point density. When using encoded point markers as are illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, for example, in such cases the space offered by the surface of the object is not sufficient for achieving the spatial point density necessary for a good photogrammetric measurement.</p>
<p id="p-0010" num="0009">In German Patent Application Serial Number 100 25 922.7 entitled “Automatische photogrammetrische Digitalisierung von Körpern und Objekten” (“Automatic Photogrammetric Digitization of Bodies and Objects”), the applicant and inventor of which is Robert Massen, it is in addition proposed to provide area markers on the envelope described in EP 0 760 622, which each comprise a plurality of point markers and form a background of the point markers, the surface area of the area markers having a particular color. The use of color image processing methods allows an easy automatic determination of the area markers (regions) corresponding in the different photogrammetric images and then of the corresponding point markers (so-called homologous pixels) therefrom. Once the list of the homologous pixels is available, the 3D data of the entire body part may be calculated using the methods of image orientation and bundle adjustment that are familiar to a person of ordinary skill in the art of photogrammetry.</p>
<p id="p-0011" num="0010">A drawback of this method is that a relatively large number of different colors are needed for marking. Therefore, the color fidelity of the cameras employed must be sufficiently high and stable to be able to adequately differentiate between such multitude of different colors in an automatic recognition. Also, the standards applied to constancy and color fidelity of the illumination are higher than those in a marking technique, which would manage with only very few colors that are distinctly different in the color space. A further disadvantage of this method resides in the relatively high geometric resolution required for optically resolving the color edges and color corners used as markers.</p>
<p id="p-0012" num="0011">Both requirements, high color fidelity and high geometric resolution, can not be satisfied by simple and very low-priced cameras such as for instance by webcams based on CMOS image sensors or image sensors incorporated in future mobile telephones and so-called personal organizers (pocket computers). Thus, it is not possible for such very simple and inexpensive image recording devices to be used for a simple digitization of body parts as described above.</p>
<p id="p-0013" num="0012">Therefore, a technical and economic interest exists in providing a method and an arrangement for the photogrammetric detection of the 3D shape of an object, featuring an improved marking technique that allows a low-cost and simple measurement even of small objects.</p>
<p id="p-0014" num="0013">Furthermore, there exists an interest in a method and an arrangement for the photogrammetric detection of the 3D shape of an object that—with regard to the marking—manage with only few different colors and only relatively rough structures, in order to enable an automatic determination of homologous pixels from a plurality of overlapping image recordings using inexpensive, low color fidelity and low resolution cameras and imaging devices and with an illumination that may be of low definition in respect of the color. This would permit to employ the method even when using low-priced webcams (web cameras) or digital cameras, for example, that are commonly used today and are rather poorly specified as regards color fidelity and resolution.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0015" num="0014">The interest as set forth above in this field of engineering is met in accordance with the invention by a method of detecting the 3D shape of an object by photogrammetry, in which</p>
<p id="p-0016" num="0015">a plurality of photogrammetric point markers and a plurality of connecting markers are provided on the surface of the object, each connecting marker connecting a subset of the plurality of point markers with each other, with at least two different types of point markers existing that differ from each other in their optical configuration, and</p>
<p id="p-0017" num="0016">some of the point markers provided along a connecting marker are formed in such a way that the sequence of their optical configurations results in a predetermined code that characterizes the respective connecting marker,</p>
<p id="p-0018" num="0017">a plurality of photogrammetric images of the object are taken from different views,</p>
<p id="p-0019" num="0018">an image processing of the images is performed, in which first the connecting markers mutually corresponding to each other in the images are associated with one another using their respective code, and then the point markers connected with each other by the respective connecting marker are associated with one another with the aid of the connecting marker association in the images, and</p>
<p id="p-0020" num="0019">using the point marker association, the 3D shape of the object is determined by means of a photogrammetric evaluation process.</p>
<p id="p-0021" num="0020">The interest described above is further satisfied by an arrangement for detecting the 3D shape of an object by photogrammetry, which comprises an imaging system for obtaining photogrammetric images of different views of the object and a system for processing and evaluating the images and for determining the 3D shape of the object and is characterized in that the arrangement further includes a plurality of photogrammetric point markers and a plurality of connecting markers on the surface of the object, each connecting marker connecting a subset of the plurality of point markers with each other, with at least two different types of point markers existing that differ from each other in their optical configuration, and some of the point markers provided along a connecting marker being formed in such a way that the sequence of their optical configurations results in a predetermined code that characterizes the respective connecting marker.</p>
<p id="p-0022" num="0021">Because of the fact that according to the invention it is not the point markers themselves that are encoded individually, but a characteristic sequence of point markers of different types results in a code, an easy automatic photogrammetric detection of even very small objects that require a high point marker density is made possible.</p>
<p id="p-0023" num="0022">Advantageous further developments of the invention are characterized in the dependent claims.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0024" num="0023">Further features and advantages of the invention will be apparent from the following description of an embodiment with reference to the drawings, in which:</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 1</figref> shows two different encoded point markers according to the prior art;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 2</figref> is a side view of a knee to be digitized using the method according to the invention and provided with an envelope, and of a camera in two different imaging positions;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 3</figref> is a top view of the knee illustrated in <figref idref="DRAWINGS">FIG. 2</figref>, with a representation of the imaging positions of a camera radially distributed about the knee;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 4</figref> shows a knee envelope photogrammetrically marked in accordance with a first embodiment of the invention;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 5</figref><i>a </i>shows the knee envelope illustrated in <figref idref="DRAWINGS">FIG. 4</figref>, in a first imaging position:</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 5</figref><i>b </i>shows the knee envelope illustrated in <figref idref="DRAWINGS">FIG. 4</figref>, in a second imaging position;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 6</figref> shows the form of photogrammetric marking used in a further embodiment of the invention;</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 7</figref> shows the form of photogrammetric marking used in a further embodiment of the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0033" num="0032">The invention will now be described by way of example, which is not to be construed in a limiting sense, with reference to the photogrammetric detection of the 3D shape of a knee region for the purpose of an automatic production of a knee orthesis.</p>
<p id="p-0034" num="0033">Assuming, for example, that the knee is covered with an elastic envelope having photogrammetric markers applied thereto. The photogrammetric markers may however also be applied by a variety of other methods. For instance, the markers may be provided on the object by applying paint such as make-up directly onto the object, by projection with the aid of a projection system, or by sticking self-adhesive films onto the object which have the markers applied thereto.</p>
<p id="p-0035" num="0034">The knee <b>1</b> illustrated in <figref idref="DRAWINGS">FIG. 2</figref>, shown with the adjoining thigh and lower leg regions, which is to be digitized by way of example, roughly has a cylindrical basic shape. The required overlapping photographic images are expediently taken in this case in the form of views from all around the cylindrical body part; to ensure sufficient overlap, about 8 to 10 images distributed over the periphery are needed.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 3</figref> shows how a patient's knee region <b>1</b>, clad in a marked elastic envelope (<b>2</b> in <figref idref="DRAWINGS">FIG. 2</figref>), is imaged from eight radial positions, A<b>1</b> to A<b>8</b>, using a camera. <figref idref="DRAWINGS">FIG. 2</figref> shows a side view of the knee in which the camera can be seen only in the positions A<b>3</b> and A<b>7</b>. For the photogrammetric evaluation it is merely important in this connection that the angular overlap area of the individual images includes a sufficient number of homologous, i.e. mutually corresponding, photogrammetric point markers. For obtaining such sequence of images from all around, the camera may for instance be manually guided around the leg at the same level.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. 4</figref> shows the knee region <b>1</b> with the elastic envelope <b>2</b>, which has different photogrammetric markings according to the invention applied to it.</p>
<p id="p-0038" num="0037">In its lower area <b>3</b> the envelope <b>2</b> is dyed in a first color that forms a distinct contrast to the spatial background R likewise acquired by the cameras and is represented by a light shade of gray in <figref idref="DRAWINGS">FIG. 4</figref>. The color selected will suitably be a color that is rather rare in everyday surroundings, such as pink. Grid lines are applied on the light shade of gray, the points of intersection of the vertical and horizontal grid lines <b>4</b> and <b>5</b> forming accurately located photogrammetric point markers which will hereinafter also be referred to as point markers not contributing to encoding because they can not be distinguished from one another and do not contain a code and are unable to serve for encoding.</p>
<p id="p-0039" num="0038">In its upper area <b>6</b> the envelope <b>2</b> is dyed in a second color that forms a sharp contrast to the spatial background R and a sharp contrast to the first color of the lower area <b>3</b> (e.g., light green). The second color is represented by a dark shade of gray in <figref idref="DRAWINGS">FIG. 4</figref>. The vertical lines <b>4</b> of the grid structure of the lower area <b>3</b> also extend into the upper area.</p>
<p id="p-0040" num="0039">In the upper area <b>6</b> the point markers are formed in that a relatively short horizontal line runs toward a vertical line <b>4</b> to end at the vertical line, the meeting point defining the precisely located point marker. As can be seen in <figref idref="DRAWINGS">FIG. 4</figref>, there are two different types of point markers here, namely those in which the relatively short horizontal line runs toward the vertical line of the grid structure from the left and those in which the relatively short horizontal line runs toward the vertical line of the grid structure from the right.</p>
<p id="p-0041" num="0040">Along each vertical line <b>4</b> of the grid structure, in the following also referred to as connecting marker since it connects various point markers with one another, there are arranged in the upper colored area <b>6</b> four point markers whose sequence, i.e. the sequence of the arrangement of their horizontal lines (e.g., running toward the vertical line from the left, from the right, from the left, from the left), uniquely identifies the respective connecting marker. The connecting markers connect point markers located in the upper area <b>6</b> with the point markers located in the lower area <b>3</b>.</p>
<p id="p-0042" num="0041">With the aid of a simple color classification, carried out pixel by pixel, the “KNEE” region in each image recorded can already be automatically segmented from the background based on the first color, and the code region <b>6</b> within the “KNEE” region can be localized by the second color. A person of ordinary skill in the art of image processing knows how to robustly carry out such automatic color segmentations (cf., e.g., Robert Massen: “Form und Farbe: Farbbildverarbeitung für die industrielle Überwachung in Echtzeit” (“Shape and Color: Color Image Processing for Real-Time Industrial Monitoring”), in: Maschinelles Sehen, Europa-Fachpresse publishing house, 1990, ISBN 3-87207-004-5).</p>
<p id="p-0043" num="0042">The markers required for photogrammetric evaluation point and connecting markers) are represented by black high-contrast lines, the size of the width of these lines being selected such that they can still be imaged even by inexpensive cameras usually featuring only low resolution. The points of intersection of the lines and, in the code area <b>6</b>, the points of encounter, respectively, represent the actual photogrammetric point markers. The position of the point markers may be determined with high accuracy with the aid of interpolation methods (sub-pixel interpolation), so that in spite of a poor geometric camera resolution precisely located point marker coordinates may be measured. Using such sub-pixel interpolations known to a person of ordinary skill in the art of image processing, it is possible in this way to determine the XY position of the center of mass of a grid crossing with a precision which is about 5 to 10 times higher man the size of the imaging pixel.</p>
<p id="p-0044" num="0043">The connecting lines between the points of intersection serve as “optical tracks”, along which the automatic image evaluation may proceed systematically from one point of intersection to the next. In this way, they establish the neighborhood relations between the markers that contribute to encoding or the non-encoded markers both in the vertical and horizontal directions.</p>
<p id="p-0045" num="0044">In order to allow a 3D reconstruction of the markers provided and secured on the knee envelope based on two overlapping image recordings using the methods of photogrammetry, the pixel coordinates of the homologous point markers need to be determined, something which is also referred to as registration. In an automatic registration, those markers which correspond to each other need to be found from two overlapping image recordings using methods of 2-dimensional image processing. In the prior art his is achieved by the use of individually encoded, relatively large-surface point markers as are illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, for example. Then, with the aid of automatic image processing according to the prior art, point markers are found in two images, their code is read, and then a list of the corresponding markers, i.e. the homologous point markers, is prepared. When the preparation of this list is complete, a 3D data record containing the XYZ space coordinates of all homologous point markers may be established using the known methods of image orientation and bundle adjustment.</p>
<p id="p-0046" num="0045">In accordance with the invention, on the other hand, a characteristic sequence of simple and very small point markers of different types is used to characterize connecting markers (e.g., lines that connect the point markers with each other) on each of which a specific subset of the point markers and especially the point markers that do not contribute to encoding is arranged in succession. The unique association of the point markers that do not contribute to encoding may be obtained here from the neighborhood relations between the encoded markers.</p>
<p id="p-0047" num="0046">In addition, in accordance with the invention a space-saving encoding is used which is structured in such a way that the individual code positions of the encoded marker may each be used as a photogrammetric point marker. In so doing, a four-digit code, for instance, is formed not only by one point marker, but from four point markers. In the usual method involving point markers encoded with radial segments (see left-hand side in <figref idref="DRAWINGS">FIG. 1</figref>) there is only one single point marker per code (i.e. for all of the code elements together). The method according to the invention therefore multiplies the number of available point markers by the factor N, where N denotes the number of code positions (bit positions in a binary code). Thus, a body part may be digitized considerably more densely because it may be covered with encoded point markers at a higher density.</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIGS. 5</figref><i>a </i>and <b>5</b><i>b </i>show two images of the knee provided with the envelope, taken from the different imaging positions, A<b>5</b> and A<b>4</b> (see <figref idref="DRAWINGS">FIG. 3</figref> in this respect). On the knee to be digitized, which is a more or less cylindrical body and for which the automatic association of corresponding pixels is to be determined from overlapping peripheral images, the vertical grid lines (the lines oriented along the longitudinal axis of the leg) Li are characterized in the code region <b>6</b>, identified by the first color, by a binary code having the following two code elements:
<ul id="ul0001" list-style="none">
    <li id="ul0001-0001" num="0000">
    <ul id="ul0002" list-style="none">
        <li id="ul0002-0001" num="0048">horizontal branching from the grid line to the left=logical ZERO=O</li>
        <li id="ul0002-0002" num="0049">horizontal branching from the grid line to the right=logical ONE=L.</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0049" num="0050">The image A<b>5</b> in <figref idref="DRAWINGS">FIG. 5</figref><i>a </i>shows a four-digit binary code that uniquely encodes each vertical line (connecting marker <b>4</b>):</p>
<p id="p-0050" num="0051">Line L <b>4</b>=(OLOO)</p>
<p id="p-0051" num="0052">Line L <b>0</b>=(OOOO)</p>
<p id="p-0052" num="0053">Line L <b>5</b>=(OLOL)</p>
<p id="p-0053" num="0054">Line L <b>10</b>=(LOLO)</p>
<p id="p-0054" num="0055">Line L <b>6</b>=(OLLO)</p>
<p id="p-0055" num="0056">The first code bit is represented, for instance, by the first grid branching tat is encountered starting from the top. Owing to the clearly defined color transition between the code region <b>6</b>, the surface area of which is dyed with the first color, and the remaining, lower knee region <b>3</b>, the surface area of which is dyed with the second color, the point of encounter for decoding this code can be automatically found by methods of color and half-tone image processing, even when the camera is rotated or tilted between taking the images or is otherwise brought into an unknown imaging position.</p>
<p id="p-0056" num="0057"><figref idref="DRAWINGS">FIG. 5</figref><i>b </i>shows the image A<b>4</b> taken of the knee covered with the envelope, which was obtained from an imaging direction radially offset through 45 degrees with respect to the image A<b>5</b>.</p>
<p id="p-0057" num="0058">By an automatic reading of the code of the connecting marker (i.e., the vertical lines <b>4</b>), the connecting markers mutually corresponding to each other in the two images, A<b>5</b> and A<b>4</b>, i.e., the homologous vertical lines <b>4</b>, can be immediately determined.</p>
<p id="p-0058" num="0059">In the photogrammetric evaluation, now first of all an image processing of the images is performed, in which first the connecting markers <b>4</b> mutually corresponding to each other in the images are associated with one another using their respective code, and then the point markers connected with each other by the respective connecting marker are associated with one another with the aid of the connecting marker association in the images, the 3D shape of the object being determined by means of a photogrammetric evaluation method using the point marker association.</p>
<p id="p-0059" num="0060">In this embodiment of the invention, it is of particular advantage that the “branching” code position may serve at the same time as a photogrammetric point marker. The center of mass of a branching to the left or to the right may be determined in the image evaluation just as precisely as the center of mass of a continuous grid cross. Thus, in contrast to the known methods, this encoding is extremely space-saving.</p>
<p id="p-0060" num="0061">A particular advantage of the invention consists in that each code position represents a point marker. Thus, such a code occupies little of the space required for the digitization because it is spread over a plurality of compact point markers.</p>
<p id="p-0061" num="0062">Of course, this code need not be restricted to a binary code. <figref idref="DRAWINGS">FIG. 6</figref>, for instance, shows an encoding of the connecting markers (vertical lines) using a ternary code which consists of the following elements,
<ul id="ul0003" list-style="none">
    <li id="ul0003-0001" num="0000">
    <ul id="ul0004" list-style="none">
        <li id="ul0004-0001" num="0063">horizontal branching to the left=A</li>
        <li id="ul0004-0002" num="0064">horizontal branching to the right=B</li>
        <li id="ul0004-0003" num="0065">branching to the left and to the right=C</li>
    </ul>
    </li>
</ul>
</p>
<p id="p-0062" num="0066">With the aid of merely <b>3</b> different types of junctions (=code positions) it is already possible to uniquely encode 3*3=9 connecting markers (lines) so that such a code again takes up considerably less space than the binary code.</p>
<p id="p-0063" num="0067">Under some circumstances it may be advantageous to have more codes available than are required for the unique identification of all connecting markers, since additional codes may be used for code protection, error recognition and error correction. The use and interpretation of redundant codes occurring herein for an automatic error correction and error recognition of errors occurring in code reading are known to those of ordinary skill in the art of encoding.</p>
<p id="p-0064" num="0068">It is apparent that the principle in accordance with the invention may be employed in a multitude of different point markers, the point markers not necessarily needing to consist of crosses or lines that encounter each other. All that is required is the provision of at least two different types of point markers, the exact shape of the point markers being irrelevant; conforming to their function as point markers, they only need to be suitable to specify the location of a point on the object.</p>
<p id="p-0065" num="0069">Accordingly, with reference to <figref idref="DRAWINGS">FIG. 7</figref>, an embodiment of the invention is illustrated in which black points having different diameters are employed as point markers, with a point having a small diameter (on the left in <figref idref="DRAWINGS">FIG. 7</figref>) marking a logical zero and a point with a large diameter (in the center of <figref idref="DRAWINGS">FIG. 7</figref>) marking a logical one of the code.</p>
<p id="p-0066" num="0070">In this way, the code “O L L L” is produced, for example, by placing one small and three large black circles one behind the other, see on the right in <figref idref="DRAWINGS">FIG. 7</figref>.</p>
<p id="p-0067" num="0071">It is, of course, not absolutely required to use vertical straight lines as connecting markers connecting the point markers with one another. For instance, horizontal lines or curved lines may be used just as well. What is important is that the connecting markers produce a connection between the point markers that are to be associated with the connecting markers. It is therefore further conceivable for the connecting markers themselves to consist of points.</p>
<p id="p-0068" num="0072">Thus, in accordance with the invention, three objects are achieved by this marking according to the invention: a large-surface area encoding of a structure (heavy grid lines in the example described) is made possible where the encoding is able to be acquired even by a poor resolution camera; such encoding may be utilized at the same time as a multitude of precisely positioned photogrammetric point markers; and an automatic determination of homologous point markers may be carried out with the aid of the determination of homologous connecting markers.</p>
<p id="p-0069" num="0073">In other embodiments of the invention, the areas provided for distinguishing between point markers that contribute to encoding and point markers that do not contribute to encoding may, of course, be made to contrast with each other by the most varied of optical configurations. Such optical configuration need not necessarily consist in a different color, but may also consist in a characteristic half tone, a characteristic texture, i.e. a characteristic pattern or a characteristic structure, a characteristic gloss, a surface coating applied to the surface and having a characteristic degree of polarization, characteristic fluorescence properties, certain spectral signatures, a specific local gloss, a specific local temperature, or a characteristic combination of the above-listed optical configuration features.</p>
<p id="p-0070" num="0074">The high-contrast structures applied for the purpose of photogrammetric marking may further distinguish themselves by reflection characteristics in regard to a spectral range outside the visible range. For instance, they may contrast with the background only in the near infrared range, in the ultraviolet range or in some other range of wavelengths not visible to the human eye. In this way, elastic envelopes may be produced having, e.g. an visible marking or a marking covered by a visible coloration intended for the human eye. They may be in the form of swimsuits, for example, which on the one hand may be designed with an “aesthetic” pattern that is visible to the human eye and, in addition, configured with an invisible surface marking adapted to be detected by photogrammetry and consisting of point and connecting markers.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method of detecting the 3D shape of an object by photogrammetry, comprising the steps of:
<claim-text>providing a plurality of photogrammetric point markers and a plurality of connecting markers on the surface of the object, each connecting marker connecting a subset of the plurality of point markers with each other, with at least two different types of point markers existing that differ from each other in their optical configuration;</claim-text>
<claim-text>some of the point markers provided along a connecting marker being formed in such a way that the sequence of their optical configurations results in a predetermined code that characterizes the respective connecting marker;</claim-text>
<claim-text>taking a plurality of photogrammetric images of the object from different views;</claim-text>
<claim-text>performing an image processing of the images, in which first the connecting markers mutually corresponding to each other in the images are associated with one another using their respective code, and then the point markers connected with each other by the respective connecting marker are associated with one another with the aid of the connecting marker association in the images; and</claim-text>
<claim-text>using the point marker association, determining the 3D shape of the object by means of a photogrammetric evaluation process.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the connecting markers consist of lines.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method as claimed in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the lines are straight.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method as claimed in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the lines are curved.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method as claimed in any of the preceding <claim-ref idref="CLM-00002">claims 2</claim-ref> to <claim-ref idref="CLM-00004">4</claim-ref>, wherein the point markers are each defined by two lines meeting each other, one of which is part of a connecting marker that connect a subset of the point markers with one another.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method as claimed in <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the different optical configuration of the point markers consists in that some point markers run from the one side of the line forming a connecting marker toward such line to end thereat, and some other point markers run from the other side of the line forming a connecting marker toward such line to end thereat, the sequence of point markers running toward the line from the one side or from the other side resulting in the code characterizing the connecting marker.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method as claimed in <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the different optical configuration of the point markers consists in that some point markers run from one side toward a line forming a connecting marker to end at the line, and some point markers cross the line forming a connecting marker, the sequence of point markers running toward the line from one side and crossing point markers resulting in the code characterizing the connecting marker.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method as claimed in any of <claim-ref idref="CLM-00001">claims 1</claim-ref> to <claim-ref idref="CLM-00004">4</claim-ref>, wherein the point markers are formed by circles.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method as claimed in <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the different optical configuration of the point markers consists in that the points have different diameters.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the point markers that form a code are backed by an area having a first type of optical configuration, and the remaining point markers that do not form a code are backed by an area having a second type of configuration that differs from the first type.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method as claimed in <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the different optical configuration of the areas consists in that the areas have different colors.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the point and connecting markers are provided on the object by pulling an elastic envelope having the markers applied thereto over the object.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method as claimed <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the point and connecting markers are provided on the object by applying the markers onto the object using paint.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the point and connecting markers are provided on the object by projecting the markers onto the object.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the point and connecting markers are provided on the object by sticking self-adhesive films having the markers applied thereto onto the surface of the object.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the object is a body part of a human being.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. A system for detecting the 3D shape of an object by photogrammetry, comprising an imaging system for obtaining photogrammetric images of different views of the object and a system for processing and evaluating the images and for determining the 3D shape of the object, wherein the system for detecting the 3D shape of an object by photogrammetry further includes a plurality of photogrammetric point markers and a plurality of connecting markers on the surface of the object, each connecting marker connecting a subset of the plurality of point markers with each other, with at least two different types of point markers existing that differ from each other in their optical configuration, and some of the point markers provided along a connecting marker being formed in such a way that the sequence of their optical configurations results in a predetermined code that characterizes the respective connecting marker.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The system for detecting as claimed in <claim-ref idref="CLM-00017">claim 17</claim-ref>, further including an elastic envelope which has the point and connecting markers applied thereto and is designed such that it can be pulled over the object and adapts to the shape of the object.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The system for detecting as claimed in <claim-ref idref="CLM-00017">claim 17</claim-ref>, further including one or more self-adhesive films having the point and connecting markers applied thereto and designed such that when stuck on the surface of the object, they are in tight-fitting contact with the object.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The system for detecting as claimed in <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising a projection system designed to be used for projecting the point and connecting markers onto die object.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The system for detecting as claimed in <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the object is a body part of a human being.</claim-text>
</claim>
</claims>
</us-patent-grant>
