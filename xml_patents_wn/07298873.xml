<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298873-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298873</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10991352</doc-number>
<date>20041116</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>326</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>05</class>
<subclass>B</subclass>
<main-group>19</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382116</main-classification>
<further-classification>340  583</further-classification>
<further-classification>902  3</further-classification>
</classification-national>
<invention-title id="d0e53">Multimodal biometric platform</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>6289112</doc-number>
<kind>B1</kind>
<name>Jain et al.</name>
<date>20010900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382116</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6393139</doc-number>
<kind>B1</kind>
<name>Lin et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6751733</doc-number>
<kind>B1</kind>
<name>Nakamura et al.</name>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>2003/0031348</doc-number>
<kind>A1</kind>
<name>Kuepper et al.</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>2004/0243567</doc-number>
<kind>A1</kind>
<name>Levy</name>
<date>20041200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  3</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>2005/0138391</doc-number>
<kind>A1</kind>
<name>Mandalia et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713186</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>2005/0265607</doc-number>
<kind>A1</kind>
<name>Chang</name>
<date>20051200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382224</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2006/0171571</doc-number>
<kind>A1</kind>
<name>Chan et al.</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2006/0260988</doc-number>
<kind>A1</kind>
<name>Schneider et al.</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00010">
<othercit>Abstract of Japanese patent application JP 2003178031 (English translation).</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00011">
<othercit>Informational brochure entitled “IWS Biometric Engine”, ImageWare® Systems, Inc., copyright 1999-2004, pp. 1-4.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00012">
<othercit>Ross, A., et al. “Multimodal Biometrics: An Overview”, <i>Proc of 12th European Signal Processing Conference </i>(<i>EUSIPCO</i>) (Vienna, Austria) 2004:1221-1224.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00013">
<othercit>Jain, Anil K., et al. “Multibiometric Systems”, <i>Communications of the ACM, Special Issue on Multimodal Interfaces</i>, (2004) 47(1):34-40.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00014">
<othercit>M. Indovina, et al. “Multimodal Biometric Authentication Methods: A COTS Approach”, <i>Proc. MMUA 2003, Workshop on Multimodal User Authentication</i>, Santa Barbara, CA, Dec. 11-12, 2003, pp. 99-106.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00015">
<othercit>Y. Wang, et al. “Combining Face and Iris Biometrics for Identity Verification”, <i>Proc. of 4th Int'l Conf. on Audio- and Video-Based Biometric Person Authentication </i>(<i>AVBPA</i>), Guilford, UK, Jun. 9-11, 2003, pp. 805-813.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00016">
<othercit>A. Kumar, et al. “Personal Verification Using Palmprint and Hand Geometry Biometric”, <i>Proc. of 4th Int'l Conf. on Audio- and Video-Based Biometric Person Authentication </i>(<i>AVBPA</i>), Guilford, UK, Jun. 9-11, 2003, pp. 668-678.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00017">
<othercit>A. Ross, et al. “Information Fusion in Biometrics”, <i>Pattern Recognition Letters</i>, (2003) 24(13):2115-2125.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00018">
<othercit>A.K. Jain, et al. “Learning User-specific Parameters in a Multibiometric System”, <i>Proc. International Conference on Image Processing </i>(<i>ICIP</i>), Rochester, NY, Sep. 22-25, 2002, pp. 57-60.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00019">
<othercit>A. Ross, et al. “Information Fusion in Biometrics”, <i>Proc. 3rd International Conference on Audio-and Video-Based Person Authentication </i>(<i>AVBPA</i>), Sweden, Jun. 6-8, 2001, pp. 354-359.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>28</number-of-claims>
<us-exemplary-claim>23</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>11</number-of-drawing-sheets>
<number-of-figures>15</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20060104485</doc-number>
<kind>A1</kind>
<date>20060518</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Miller, Jr.</last-name>
<first-name>S. James</first-name>
<address>
<city>Poway</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Willis</last-name>
<first-name>William Frederic</first-name>
<address>
<city>Laguna Nigel</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Lau</last-name>
<first-name>Johann Herbert</first-name>
<address>
<city>Escondido</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="004" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Dlab</last-name>
<first-name>Daniel</first-name>
<address>
<city>Ottawa</city>
<country>CA</country>
</address>
</addressbook>
<nationality>
<country>CA</country>
</nationality>
<residence>
<country>CA</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Townsend &amp; Townsend &amp; Crew LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Imageware Systems, Inc.</orgname>
<role>02</role>
<address>
<city>San Diego</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Mehta</last-name>
<first-name>Bhavesh M</first-name>
<department>2624</department>
</primary-examiner>
<assistant-examiner>
<last-name>Phoenix</last-name>
<first-name>B.</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A multimodal biometric identification or authentication system includes a plurality of biometric clients. Each of the biometric clients may include devices for capturing biometric images of a plurality of types. The system includes a router in communication with the biometric clients. The router receives biometric images from, and returns biometric scores or results to, the biometric clients. The system includes a plurality of biometric matching engines in communication with the router. Each biometric matching engine includes multiple biometric processors. Each biometric processor is adapted to process biometric data of a particular type. The biometric matching engines transmit and receive biometric data to and from the router.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="253.75mm" wi="168.49mm" file="US07298873-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="265.43mm" wi="186.77mm" file="US07298873-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="261.37mm" wi="162.64mm" file="US07298873-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="246.55mm" wi="161.46mm" file="US07298873-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="278.21mm" wi="189.91mm" file="US07298873-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="213.19mm" wi="193.04mm" file="US07298873-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="83.23mm" wi="177.55mm" file="US07298873-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="261.96mm" wi="180.76mm" file="US07298873-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="251.97mm" wi="175.85mm" file="US07298873-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="243.67mm" wi="109.64mm" file="US07298873-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="189.91mm" wi="175.85mm" file="US07298873-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="259.76mm" wi="191.94mm" file="US07298873-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">The present invention relates generally the field of biometric identification and authentication, and more particularly to a multimodal biometric system and method.</p>
<p id="p-0003" num="0002">Biometrics is a generic term for characteristics that can be used to distinguish one individual from another, particularly through the use of digital equipment. An example of a biometric is a fingerprint. Trained analysts have long been able to match fingerprints in order to identify individuals. More recently, computer systems have been developed to match fingerprints automatically. Examples of biometrics that have been, or are now being, used to identify, or authenticate the identity of, individuals include 2D face, 3D face, hand geometry, single fingerprint, ten finger live scan, iris, palm, full hand, signature, ear, finger vein, retina, DNA and voice. Other biometric may include characteristic gaits, lip movements and the like. New biometric are being developed or discovered continually.</p>
<p id="p-0004" num="0003">Biometrics have been used both for identification and authentication. Identification is the process of identifying or detecting the presence of an unknown individual. Identification typically involves a one to N or complete search of stored biometric information. Common uses of identification are law enforcement facial mug shot or fingerprint searches, drivers license facial photo or fingerprint searches to ensure that a particular individual is not issued more than one drivers license, and various crowd scanning schemes to detect criminals or terrorists.</p>
<p id="p-0005" num="0004">Authentication is the process of verifying that an individual is who he says he is. The individual presents something such as a card or computer logon name that identifies him. Then a biometric obtained from the individual is compared to a stored biometric to authenticate the individual's identity. Authentication is useful for controlling access to secure locations and systems and for controlling the uses of credit cards and the like.</p>
<p id="p-0006" num="0005">In these days of heightened security, biometrics are becoming increasingly important. One of the goals in biometrics is increased accuracy so that there are fewer false negative and false positive indications. Every biometric has some limitations. Some biometrics are inherently more accurate than others. It is estimated that approximately 5% of the individuals in most populations do not have legible fingerprints. The accuracy of some face recognition systems may be dependent on ambient lighting and the pose of the subject.</p>
<p id="p-0007" num="0006">A problem in current biometric identification and authentication is “spoofing”, which amounts to tricking the biometric capture device. Some devices may be spoofed by presenting a previously captured authentic image to the capture device. The device may capture the counterfeit image and then identify the wrong individual.</p>
<p id="p-0008" num="0007">One solution both to the accuracy and spoofing concerns is to use multiple biometrics in identifying or authenticating the identity of an individual. For any single biometric, there is a finite probability that multiple individuals will match on that biometric. However, biometrics tend to be independent of each other so that it is unlikely that individuals that match on one biometric would match on multiple biometrics. Accordingly, the likelihood that an individual would score false positives on multiple biometric tests is low. In order to spoof a system that uses multiple biometrics, one would have to have to obtain counterfeit images for each biometric. Thus, there is a desire to provide multimodal biometric platforms. However, there are a number of problems with current attempts to provide a multimodal biometric platform.</p>
<heading id="h-0002" level="1">BRIEF SUMMARY OF THE INVENTION</heading>
<p id="p-0009" num="0008">The present invention provides a multimodal biometric identification and/or authentication system. A system according to the present invention may include a plurality of biometric clients. Each of the biometric client may include devices for capturing biometric images of a plurality of types. Examples of biometric image capture devices are well known and may include digital cameras for capturing images for facial recognition, fingerprint scanners for capturing images for fingerprint recognition, iris scanners for capturing images for iris recognition, hand geometry sensors, and the like. The system includes a router in communication with the biometric clients. Among other things, the router receives biometric images from, and returns biometric scores or results to, the biometric clients. The system includes a plurality of biometric matching engines in communication with the router. Each biometric matching engine may include multiple biometric processors. Each biometric processor is adapted to process biometric data of a particular type. Among other things, the biometric matching engines transmit and receive biometric templates to and from the router.</p>
<p id="p-0010" num="0009">The biometric matching engines may include proprietary, third party, biometric applications that are implemented by means of software development kits (SDKs). The third party applications receive and compare pairs of biometric templates and return proprietary scores based upon the comparison. Each third party application is adapted to perform its work with respect to a particular biometric. For example, there are separate facial, fingerprint and iris applications, each application generally being available from a separate entity. The biometric matching engines include a plugin application for each biometric application. The plugins provide a number of functions. As well as providing a interface between the biometric application and the router, the plugins may create biometric templates from biometric images, cache biometric templates, preferably in physical memory, provide probe templates and enrolled templates to their associated biometric application for comparison and scoring, and return scores to the router. The plugins may also normalize or otherwise process scores received from the biometric applications.</p>
<p id="p-0011" num="0010">The biometric matching engines are organized into groups, based upon their capabilities. Each biometric matching engine of a group can process the same types of biometrics. A biometric matching engine may belong to more than on group.</p>
<p id="p-0012" num="0011">According to the present invention, all communication between the biometric clients and the biometric matching engines goes through the router. The biometric clients and the biometric matching engines see only the router. During an enrollment phase, the biometric clients send biometric and demographic data to the router. The router stores the demographic data and sends the biometric data to a biometric matching engine of an appropriate group. The plugins of the biometric matching engine convert the images of the biometric data to templates and send the templates back to the router. The router sends the templates back to one or all of the biometric matching engines of the group, depending on the configuration of the system. The system may be configured for striped operation, in which case, the templates are sent to one biometric matching engine of the group. In the striped configuration, the router uses a load balancing scheme to ensure that each biometric matching engine of a group has approximately the same number of enrolled templates in its cache. Alternatively, the system may be configured for mirrored operation. In the mirrored configuration, router sends the templates to each biometric matching engine of the group. In either configuration, the biometric matching engines cache the enrolled templates they receive from the router, preferably in physical memory.</p>
<p id="p-0013" num="0012">During a search phase, a biometric client sends target biometric data to the router. The router sends the target biometric data to one or all of the biometric matching engines of an appropriate group, depending on the configuration of the system. If the system is in the striped configuration, the router sends the target data to each biometric matching engine of the group. If the system is in the mirrored configuration, the router sends the target data to a single available biometric matching engine of the group. In either configuration, the biometric matching engine converts the target data to probe templates and then provides a probe template and enrolled templates to the appropriate biometric application for comparison and scoring. The biometric matching engine sends scores back to the router. In the striped configuration, the router accumulates the scores from all the biometric matching engines before reporting the scores back the biometric client.</p>
<p id="p-0014" num="0013">Since the biometric applications of the biometric matching engines generally produce proprietary, non-standardized scores, the present invention provides methods of producing more meaningful combined or normalized scores. In one embodiment, a biometric matching engine implements a search pruning strategy. According to the search pruning strategy, the biometric matching engine compares a probe biometric template of a first type to enrolled biometric templates of the first type to produce a set of first scores. The biometric matching engine saves in a match set biometric data records for which the first score for the data record is greater than a first biometric threshold. The biometric matching engine then compares a probe biometric template of a second type to biometric templates of the second type in said match set to produce a set of second scores. The biometric matching engine saves biometric data records for the second score for the data record is greater than a second biometric threshold. The biometric matching engine repeats the process until all template types have been processed, which results in a set of data records that have score higher than a threshold in each category.</p>
<p id="p-0015" num="0014">In a second embodiment, the system uses statistical analysis of enrollment data to produce normalized scores. Individuals are enrolled in a biometric database by storing for each individual a plurality of biometric templates of one type. The system compares each biometric template in the database with every other biometric template of the database to obtain biometric scores. If a biometric score is obtained by comparing one biometric template of an individual with another biometric template for that same individual, the system puts that score in a matching category. If a biometric score is obtained by comparing a biometric template of an individual with a biometric template for different individual, the system puts that score in a non-matching category. The system analyzes the scores in the matching category to determine the probability that a particular score is a matching score. The system analyzes the scores in the non-matching category to determine a probability that a particular score is not a matching score.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram of an embodiment of the present invention.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram of an embodiment of a biometric matching engine according to the present invention.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 3</figref> is block diagram of an embodiment of a biometric client according to the present invention.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram illustrating biometric matching engine grouping according to the present invention.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 5</figref> is a flowchart of an embodiment of biometric matching engine enrollment processing according to the present invention.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart of an embodiment of biometric matching engine template caching according to the present invention.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 7</figref> is a flowchart of an embodiment of biometric matching engine search processing according to the present invention.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 8</figref> is a flowchart of an embodiment of router enrollment processing according to the present invention.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 9</figref> is a flowchart of an embodiment of router search processing according to the present invention.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 10</figref> illustrates an embodiment of a search pruning table according to the present invention.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 11</figref> is a flowchart of an embodiment of search pruning according to the present invention.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIGS. 12A and 12B</figref> comprise a flowchart of an embodiment of statistical normalization according to the present invention.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 13</figref> is a plot of distributions of matching and non-matching scores.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 14</figref> is a flowchart of an embodiment of statistical normalization refinement according to the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0030" num="0029">Referring now to the drawings, and first to <figref idref="DRAWINGS">FIG. 1</figref>, an embodiment of a system according to the present invention is designated generally by the numeral <b>11</b>. System <b>11</b> includes a plurality of biometric clients <b>13</b>. Biometric clients <b>13</b> comprise computers having installed thereon a suitable operating system and biometric software, preferably implemented in a client software development kit (SDK).</p>
<p id="p-0031" num="0030">Biometric clients <b>13</b> are in communication with a router <b>15</b> through a suitable network, such as Internet Protocol (IP) network <b>17</b>. Router <b>15</b> comprises a computer having installed thereon a suitable operating system and biometric software programmed according to the present invention. Router has associated therewith storage <b>19</b> for storing demographic data.</p>
<p id="p-0032" num="0031">Router <b>15</b> is in communication with a plurality of biometric matching engines <b>21</b> through a suitable network, such as IP network <b>23</b>. Each biometric matching engine <b>21</b> comprises a computer having installed thereon a suitable operating and biometric software according to the present invention. As will be described in detail hereinafter, biometric matching engines <b>21</b> are adapted to process multimodal biometric data. Each biometric matching engine <b>21</b> has associated therewith a cache <b>25</b>, which preferably implemented in physical memory.</p>
<p id="p-0033" num="0032">Referring now to <figref idref="DRAWINGS">FIG. 2</figref>, there is illustrated a block diagram of an embodiment of a biometric matching engine <b>21</b> according to the present invention. Biometric matching engine <b>21</b> communicates with router <b>15</b> (<figref idref="DRAWINGS">FIG. 15</figref>) and moves templates into and out of cache <b>25</b>. Biometric matching engine <b>21</b> converts biometric images into templates at enrollment time and creates probe templates to compare against stored records at search time.</p>
<p id="p-0034" num="0033">In the example of <figref idref="DRAWINGS">FIG. 2</figref>, biometric matching engine <b>21</b> includes a facial recognition SDK <b>27</b>, an iris recognition SDK <b>31</b>, and fingerprint recognition SDK <b>35</b>. SDKs <b>27</b>, <b>31</b> and <b>35</b> are typically proprietary applications provided by third parties. For example, facial recognition SDK <b>27</b> may be a proprietary facial recognition application provided by a vendor such as COGNITEC™. Facial recognition SDK is adapted to compare facial biometric templates and return a score that represents the degree of similarity of the templates. Similarly, iris recognition SDK <b>31</b> may be a proprietary iris recognition application provided by a vendor such as IRIDIAN™. Iris recognition SDK is adapted to compare iris biometric templates and return a score that represents the degree of similarity of the templates. Fingerprint recognition SDK <b>35</b> may be a proprietary fingerprint recognition application provided by a vendor such as IDENTIX™.</p>
<p id="p-0035" num="0034">It will be recognized by those skilled in the art that a biometric matching engine may include any combination of one or more separate biometric algorithms or SDKs. Such SDKs may include 2D face, 3D face, hand geometry, single fingerprint, ten finger live scan, iris, palm, full hand, signature, ear, finger vein, retina, DNA, voice or any other biometric, all available from several well known vendors.</p>
<p id="p-0036" num="0035">Each SDK <b>27</b>, <b>31</b> and <b>35</b> is wrapped in a plugin. Facial recognition SDK <b>27</b> is wrapped in a facial plugin <b>29</b>. Iris recognition SDK <b>31</b> is wrapped in an iris plugin <b>33</b>. Fingerprint recognition SDK <b>35</b> is wrapped in a fingerprint plugin <b>37</b>. Each plugin <b>29</b>, <b>33</b> and <b>37</b> is a modules that adheres to a common interface that allows biometric matching engine <b>21</b> to communicate with the SDK <b>27</b> about which the plugin is wrapped. Because a plugin has a common interface, it can be “plugged in” to the system with extremely minor setup and without the biometric matching engine <b>21</b> having much knowledge about which third party SDK is being wrapped.</p>
<p id="p-0037" num="0036">Facial plugin <b>29</b> and iris plugin <b>33</b> may be referred to as “normal” plugins. Normal plugins are interfaces between biometric matching engine <b>21</b> and their associated SDK. Normal plugins enable biometric matching engine <b>21</b> to supply probe and enrolled templates to their associated SDK for comparison and scoring. Normal plugins further enable biometric matching engine <b>21</b> to receive scores from their associated SDK for transmission to router <b>15</b> (<figref idref="DRAWINGS">FIG. 1</figref>).</p>
<p id="p-0038" num="0037">The combination of fingerprint recognition SDK <b>35</b> and fingerprint plugin <b>37</b> is somewhat different from that described with respect to the facial and iris recognition applications. Historically, fingerprint searching has been aimed at emulating the behavior of Automated Fingerprint Identification System (AFIS) systems, which handle the enrollment, storage, and searching of fingerprints. Most fingerprint matching algorithms and SDKs do not provide a method to simply compare one template to another and generate a score. Rather, they all provide their own special ‘database’ that fingerprints must be enrolled in. In order to make a comparison, a system passes in a probe image, and the SDK produces a score. Accordingly, a plugin of the type of fingerprint plugin <b>37</b> is known as a “pass-through” plugin. Biometric matching engine <b>21</b> passes fingerprint templates through fingerprint plugin for enrollment in the database of fingerprint recognition SDK, rather than storing them in cache <b>25</b>.</p>
<p id="p-0039" num="0038">As shown in <figref idref="DRAWINGS">FIG. 2</figref>, multiple plugins can be used on a single biometric matching engine, so any single biometric matching engine might be responsible for storing any number of different template types. Of course, according to the present invention, a biometric matching engine may comprise different numbers and combinations of SDKs and plugins.</p>
<p id="p-0040" num="0039">Referring now to <figref idref="DRAWINGS">FIG. 3</figref>, there is illustrated a high level block diagram of an example of a biometric client <b>13</b>. Biometric client <b>13</b> is implemented a computer having a suitable operating system and various application programs. Biometric client <b>13</b> includes commercially available biometric input and capture devices, such as a digital camera <b>41</b> for capturing facial images, a fingerprint scanner <b>43</b> and an iris image capture device <b>45</b>. Capture devices generally may include 2D face, 3D face, hand geometry, single fingerprint, ten finger live scan, iris, palm, full hand, signature, ear, finger vein, retina, DNA and voice capture devices. Biometric client <b>13</b> includes a client SDK <b>47</b> that collects and formats biometric data captured by the capture device for transmission to router <b>15</b> (<figref idref="DRAWINGS">FIG. 1</figref>) and presents information returned from router <b>15</b>. Biometric client may include a display <b>49</b> and a user input device <b>51</b>, such as a keypad, keyboard, mouse or the like. Biometric client <b>13</b> may also include an interface to an access control device such as an automatic door lock.</p>
<p id="p-0041" num="0040">As shown in <figref idref="DRAWINGS">FIG. 4</figref>, biometric matching engines <b>21</b> may be organized in groups. A biometric matching engine group comprises one or more biometric matching engines having the same biometric capabilities. In <figref idref="DRAWINGS">FIG. 4</figref> a first biometric matching engine group <b>55</b> comprises biometric matching engines <b>21</b><i>a</i>-<b>21</b><i>d</i>, each of which is adapted to process face and fingerprint biometric data. A second biometric matching engine group <b>57</b> comprises biometric matching engines <b>21</b><i>e</i>-<b>21</b><i>h</i>, each of which is adapted to process iris biometric data. A biometric matching engine group may comprise as many biometric matching engines as are necessary to meet the demands of the system. A system may be scaled up or down simply by adding or removing biometric matching engines. A single biometric matching engine may be in multiple groups. For example, a biometric matching engine with face, fingerprint and iris capabilities would be a member of both groups <b>55</b> and <b>57</b>.</p>
<p id="p-0042" num="0041">Router <b>15</b> may configure the groups to optimize performance in terms of speed or concurrency. Router <b>15</b> can configure a group for striped or mirrored operation. In striped operation, templates are cached in a striped or distributed fashion across the biometric matching engines of the group. Each biometric matching engine caches only part of templates of the group. Router <b>15</b> distributes the templates to the biometric matching engines based upon a load balancing scheme that maintains the number of templates cached by each biometric matching engine approximately equal. In the example of <figref idref="DRAWINGS">FIG. 4</figref>, each biometric matching engine <b>21</b><i>a</i>-<b>21</b><i>d </i>of group <b>55</b> would cache about 25% of the total number of templates in a striped configuration. In performing a search, each biometric matching engine <b>21</b><i>a</i>-<b>21</b><i>d </i>would execute its searching routine. Thus, the search would be completed in 25% of the time it would take a single biometric matching engine to execute its searching routine over all the templates. However, in the striped configuration, the group can do only one search at a time. Thus, if there are concurrent requests for searches, the router <b>15</b> must queue the searches.</p>
<p id="p-0043" num="0042">In the mirrored configuration, the templates are mirrored across the entire query group. Each biometric matching engine <b>21</b><i>a</i>-<b>21</b><i>d </i>of group <b>55</b> would cache every template assigned to the group. In the mirrored configuration, router <b>15</b> instructs a single biometric matching engine <b>21</b> to execute a search. Thus, in the example of <figref idref="DRAWINGS">FIG. 4</figref>, up to four searches can be executed concurrently in the mirrored configuration. without having to queue search requests. However, each search would take four times as long to complete as a search in the striped configuration. Speed and concurrency issues may be addressed by scaling the number of biometric matching engines in a group and configuring the group.</p>
<p id="p-0044" num="0043">Enrollment of templates according to the present invention is illustrated with respect to <figref idref="DRAWINGS">FIGS. 5</figref>, <b>6</b> and <b>8</b>. <figref idref="DRAWINGS">FIGS. 5 and 6</figref> illustrate enrollment from a biometric matching engine's perspective. <figref idref="DRAWINGS">FIG. 8</figref> illustrates enrollment from the router's perspective. From the biometric matching engine's perspective, enrollment comprises two independent processes. Referring to <figref idref="DRAWINGS">FIG. 5</figref>, a biometric matching engine receives a biometric image from the router at block <b>61</b>. The biometric image may be of any type that the router is capable of handling. The biometric image may be a digital photograph of a face, a fingerprint scan, an iris scan, a wave file of a voice, or any other biometric image. The biometric matching engine creates a biometric template from the biometric image at block <b>62</b>. Then, the biometric matching engine returns biometric template to the router at block <b>65</b> and the process ends.</p>
<p id="p-0045" num="0044">The other part of enrollment from the biometric matching engines perspective is template caching, an example of which is illustrated in <figref idref="DRAWINGS">FIG. 6</figref>. A Biometric matching engine receives a template from the router at block <b>67</b>. The biometric matching engine executing the process of <figref idref="DRAWINGS">FIG. 6</figref> may or may not be the same biometric matching engine that executed the process of <figref idref="DRAWINGS">FIG. 5</figref> to create the template. The biometric matching engine tests, at decision block <b>68</b>, if the template of the pass-through type. As explained above, fingerprint recognition SDKs typically maintain their own cache of templates in a proprietary database. Accordingly, the biometric matching engine typically passes templates through a fingerprint SDK for caching by the SDK. If the template is adapted to be passed through to the SDK, the biometric matching engine passes the template to the pass-through plugin for caching in the database maintained by the SDK, as indicated at block <b>69</b>. If the template is not adapted for pass-through, the biometric matching engine caches the template at block <b>70</b> and the process ends.</p>
<p id="p-0046" num="0045">In a preferred embodiment, the biometric matching engine caches templates as part of a record. The record contains a record ID, which specifies an individual, and all biometric templates for that individual. For example, a record could contain face, fingerprint and iris templates for the individual associated with the record ID. Additionally, the record may contain multiple instances of a template type. For example, at enrollment, the system may capture multiple instances of each biometric image type.</p>
<p id="p-0047" num="0046">Referring now <figref idref="DRAWINGS">FIG. 8</figref>, there is illustrated an example of an enrollment process from the router's perspective. The router receives demographic and biometric data from a client at block <b>71</b>. Demographic data may include and individuals name, sex, height, weight, hair color, eye color, etc. The router stores the demographic data in the demographic database <b>19</b> (<figref idref="DRAWINGS">FIG. 1</figref>) at block <b>73</b>. The router sends the biometric data, which includes one or more biometric images, to a biometric matching engine at block <b>75</b>. There is an implicit wait for the query image to return the template or templates. When the router receives the template or templates from the biometric matching engine, as indicated at block <b>77</b>, the biometric matching engine checks, at decision block <b>79</b>, the group is configured for striped or mirror operation. If the configuration is not mirrored (i.e. striped), the router sends the template or templates to on biometric matching engine of the group, based upon a load balancing scheme, at block <b>81</b>. If, at decision block <b>79</b>, the configuration is mirrored, the router sends the biometric template or templates to each biometric matching engine of the group, at block <b>83</b>. Then, the router reports OK to the client, at block <b>85</b>, and enrollment processing ends.</p>
<p id="p-0048" num="0047">Referring now to <figref idref="DRAWINGS">FIGS. 7 and 9</figref>, there illustrated search processing. <figref idref="DRAWINGS">FIG. 7</figref> illustrates searching from a biometric matching engines perspective. <figref idref="DRAWINGS">FIG. 9</figref> illustrates searching from the biometric matching engine's perspective. As shown in <figref idref="DRAWINGS">FIG. 7</figref>, a biometric matching engine receives one or more target biometric images from the router, at block <b>91</b>. The biometric matching engines creates a probe template for each target image received, at block <b>93</b>. Then, the biometric matching engine compares the probe template or templates with each template in its cache, at block <b>95</b>. It will be recalled that an appropriate plugin passes the probe and a template from the cache to the appropriate SDK biometric application. As will be explained in detail hereinafter, the biometric matching engine may normalize the scores provided by the biometric application, as indicated generally at block <b>99</b>. The biometric matching engine then returns the scores, typically above a certain threshold value, to the router, at block <b>99</b>, and the process ends.</p>
<p id="p-0049" num="0048">Referring to <figref idref="DRAWINGS">FIG. 9</figref>, the router receives target biometric data from a client, at block <b>101</b>. The router determines, at decision block <b>103</b>, if the appropriate group is configured for striped or mirrored operation. If the configuration is not mirrored, the biometric matching engine sends the target biometric data to each biometric matching engine of the group, at block <b>105</b>. When the router receives results from all the biometric matching engines of the group, at block <b>107</b>, the router sends the results to the client, at block <b>109</b>, and the process ends. If, as determined at decision block <b>103</b>, the configuration is mirrored, the router sends the biometric data to one available biometric matching engine of the group, at block <b>111</b>. When the router receives the results from the router, at block <b>113</b>, the router sends the results to the client, at block <b>109</b>, and the process ends.</p>
<p id="p-0050" num="0049">Scores produced by proprietary biometric algorithms are themselves proprietary and not standardized. Scores from one biometric algorithm may be in the range from 0 to 10,000 while scores from another biometric algorithm may be in the range of 50 to 100. While the scores in a single mode operation are meaningful in the sense that, with underlying knowledge they can be used to determine whether a score signifies a match, they are in a sense arbitrary. In order to combine scores and produce meaningful multimodal results according to the present invention, there are provided processes for normalizing or otherwise combining the scores.</p>
<p id="p-0051" num="0050">One simple way to normalize the scores is by means of a system of weighted averages. Under such a system, each separate mobile score is multiplied by a weight factor that puts the scores in the same range. Then the weighted scores can be averaged to obtain a composite score. Weighted averaging is not entirely satisfactory due to various nonlinearities and variations in the proprietary scoring algorithms.</p>
<p id="p-0052" num="0051">One method for combining scores is search pruning which is illustrated with respect to <figref idref="DRAWINGS">FIGS. 10 and 11</figref>. In <figref idref="DRAWINGS">FIG. 10</figref> there is a table that specifies a search order and various thresholds for processing the results from a multimodal search according to the present invention. A search order is specified in Column <b>111</b>. Search Order <b>111</b> specifies the order in which the search results are to be pruned. In Column <b>113</b> there is listed the algorithm. The biometric is listed in Column <b>115</b>. Thus, referring to <figref idref="DRAWINGS">FIG. 10</figref>, the first score to be processed is the IDENTIX™ right thumb algorithm. For each biometric there is a pruning threshold, indicated in Column <b>117</b> and a final threshold indicated in Column <b>119</b>. The pruning and final thresholds are set with reference to and knowledge of to the scoring system of each particular proprietary algorithm. The thresholds may be tuned so as not to produce too many or too few final candidates.</p>
<p id="p-0053" num="0052">Referring now to <figref idref="DRAWINGS">FIG. 11</figref>, there is shown a flowchart of an example of search pruning according to the present invention. A match set is initialized at block <b>121</b>. Initially, the match set is all record IDs in the cache. The system orders the probe templates according to the search table, at block <b>123</b>. For example, if the biometrics are iris, face, and left thumb, the system would perform the search on the left thumb first, then the face, and then the iris, as indicated in <figref idref="DRAWINGS">FIG. 10</figref>. The system then lets N equal the number of probe templates and lets index i equal one as indicated at block <b>125</b>. Then, the system tests, at decision block <b>127</b> if i is equal to N. If not, the system compares probe template i with the first or next template in the match set, as indicated at block <b>129</b>. Then, the system determines, at decision block <b>131</b> if the score returned from the comparison is less than the pruning threshold. If so, the system removes the record from the match set, at block <b>133</b>. If, on the other hand, the score is greater than the pruning threshold, then the record ID is left in the match set. The system then determines, at decision block <b>135</b>, if there are more templates in the match set. If so, the process returns to block <b>129</b> to compare template i with the next template in the match set. Processing continues to loop through blocks <b>129</b> to <b>133</b> until there are no more templates in the match set, as determined at decision block <b>135</b>. Then, the system sets i equals i plus one at block <b>137</b> and processing returns to decision block <b>127</b>. If, as determined at block <b>127</b>, index i is not equal to N, then processing resumes at <b>129</b>. If, however, i is equal to N, as determined at decision block <b>127</b>, the system compares probe template i with the first or next template in the match set, as indicated at block <b>139</b>. The system determines, at decision block <b>141</b>, if the score is less than the final threshold determined from the table of <figref idref="DRAWINGS">FIG. 10</figref>. If so, the system removes the record from the match set, at block <b>143</b>. If the score is not less than the final threshold, then the record ID is left in the match set. The system tests, at decision block <b>145</b> if there are more templates in the match set. If so, processing returns to block <b>139</b>. If not, the system returns the match set to the router, at block <b>137</b> and processing ends. The match set returned to the router is the set of record IDs that have passed each threshold.</p>
<p id="p-0054" num="0053">Referring now to <figref idref="DRAWINGS">FIGS. 12A and 12B</figref>, there is illustrated a process for normalizing scores returned from separate proprietary biometric applications. The system is initialized at block <b>151</b> by setting indices i, j, k and l equal to 1 and setting N equal to the number of enrolled individuals in the biometric matching engine group. Indices i and k represent, respectively, record ID numbers. Thus, indices i and k represent unique individuals enrolled in the system. Indices j and l represent template instances enrolled for an individual. Thus, template ij represents the jth template stored in association with the ith individual. According to the present invention, multiple templates of each type are enrolled for each individual.</p>
<p id="p-0055" num="0054">The system sets P equal to the number of templates enrolled for the ith individual, at block <b>153</b>. The system then sets N equal to the number of templates enrolled for individual k, at block <b>155</b>. The system then tests whether index i is equal to index k, at decision block <b>157</b>. Thus, the system determines at decision block <b>157</b> if a template under test belongs to a single individual. If so, the system tests at decision block <b>159</b> if index j equals index l. If so, index l is incremented by one, as indicated at block <b>161</b>. Then the system compares template ij with template kl, as indicated at block <b>163</b>. Thus, at block <b>163</b> a first template of an individual is compared with a second template of that same individual. The system puts the score produced from the comparison at block <b>163</b> into a match category, at block <b>165</b>. The match category contains scores that were produced by matching a template of an individual against another template of that same individual. Thus, the match category contains scores that are known to represent matches. After putting the score in the match category at block <b>165</b>, the system increments index l by one as indicated at block <b>167</b> and tests, at decision block <b>169</b> if l is greater than M. If not, processing returns to decision block <b>159</b>.</p>
<p id="p-0056" num="0055">Returning to decision block <b>157</b>, if index i is not equal to index k, which indicates that individual i is not the same person as individual k, then the system compares template ij to template kl at block <b>171</b>. The system puts the score resulting from the comparison at block <b>171</b> into a non-match category at block <b>173</b>. The non-match category contains the scores that are known not to represent a match. Then, the system increments index l by one, at block <b>175</b>, and tests at decision block <b>177</b> if index l is greater than M. If not, processing returns to block <b>171</b>. Processing continues until index l is determined to be greater than M at decision block <b>169</b> or decision block <b>177</b>. Then, the system sets index k equal to k plus one and index l equal to one at block <b>179</b>. Then the system tests at decision block <b>181</b> if index k is greater than N. If not, processing returns to block <b>155</b> of <figref idref="DRAWINGS">FIG. 12A</figref>. If, as determined at decision block <b>181</b>, index k is greater than N, then the system sets index j equal to j plus one, k equal to one, and l equal to one, at decision block <b>183</b>. Then, the system tests, at decision block <b>185</b>, if index j is greater than P. If not, the system returns to block <b>155</b> of <figref idref="DRAWINGS">FIG. 12A</figref>. If, as determined at decision block <b>185</b>, index j is greater than P, then the system sets index i equal to i plus one, j equal to one, k equal to one and l equal to one, as indicated at block <b>187</b>, and then tests at decision block <b>189</b> if index i is greater than N. If not, processing returns to block <b>153</b> of <figref idref="DRAWINGS">FIG. 12A</figref>.</p>
<p id="p-0057" num="0056">Processing continues through the various loops described until each template enrolled for each individual has been compared with every other template in the system. At the completion of processing described thus far with respect to <figref idref="DRAWINGS">FIGS. 12A and 12B</figref>, the match category contains all scores known to be matches. The non-match category contains all scores known not to be matches. After collecting all the scores in either the match or the non-match category, the system performs statistical analysis of the match category, as indicated at block <b>191</b>, and statistical analysis of the non-match category, as indicated at block <b>193</b>.</p>
<p id="p-0058" num="0057">Referring now to <figref idref="DRAWINGS">FIG. 13</figref>, there is illustrated a plot of the distributions of scores in the non-match and match categories. The distribution of scores in the non-match category is designated by the numeral <b>201</b>. The distribution of the scores in the match category is designated by the numeral <b>203</b>. In <figref idref="DRAWINGS">FIG. 13</figref>, the number of scores is plotted against a range of arbitrary score values. The number of scores goes from 0 to 9,000 and the arbitrary scores go from 0 to 100. Statistical analysis of the distributions is well known to those skilled in the art. However, by inspection of <figref idref="DRAWINGS">FIG. 13</figref>, it can be seen that matching scores lie roughly in the range from 85 to 95. Non-matching scores lie roughly in the range from 10 to about 80. Thus, a score of about 85 would indicate a high probability of a match and a very low probability of a non-match. On the other hand, a score of 70 would indicate a very low probability of a match. Thus, the method of the present invention provides a method for converting arbitrary numerical scores to relatively precise probabilities of matches and non-matches. The probabilities obtained from different biometrics can be combined in a well known way to produce a probability of a match or non-match based on multiple biometrics.</p>
<p id="p-0059" num="0058">Referring now to <figref idref="DRAWINGS">FIG. 14</figref> there is illustrated a flow chart of a dynamic system for improving the accuracy of the method according to the present invention. A biometric matching engine receives a target biometric image from the router at block <b>211</b>. The biometric matching engine creates a probe template in the manner described above at block <b>213</b>. Then, the biometric matching engine compares the template with cached templates at block <b>215</b>. Finally, the biometric matching engine returns a score to the router, at block <b>217</b>, as described above. Then, the biometric matching engine tests at decision block <b>219</b> if the score is above a particular probe threshold. If not, processing stops. However, if the score is above the probe threshold, then the system calls the probe template template xy as indicated at block <b>221</b>. Then, the system sets index k equal to one, index l equal to one and sets the N equal to the number of individuals, at block <b>223</b>. Then, the system sets M equal to the number of templates enrolled for individual k, at block <b>225</b>. The system then tests at decision block <b>227</b> if k is equal to x, which would indicate that the probe template belongs to the same individual as template k. If so, the system compares template xy to template kl, at block <b>229</b>, and puts the score in the match category at block <b>231</b>. Then, the system increments index l to l plus one at block <b>233</b> and tests if l is greater than M, at decision block <b>235</b>. If not, processing returns to block <b>229</b>.</p>
<p id="p-0060" num="0059">If, as determined at decision block <b>227</b>, index k is not equal to index x, then the system compares template xy to template kl at block <b>237</b> and puts the score in the non-match category at block <b>239</b>. Then, the system increments index l to l plus one, at block <b>241</b>, and tests, at decision block <b>243</b> if l is greater than M. If not, processing returns to block <b>237</b>. Processing continues until index l is greater than M, as determined at decision block <b>235</b> or decision block <b>243</b>. Then, the system increments k to k plus one and sets l equal to one, as indicated at block <b>245</b>. The system then tests, at decision block <b>247</b>, if k is greater than N. If not, processing returns to block <b>225</b>. Processing continues until, as determined at decision block <b>247</b>, index k is greater than N, which indicates that the probe template has been tested against all templates cached in the system. Then, the system performs statistical analysis of the match category at block <b>249</b> and statistical analysis of the non-match category at <b>251</b>.</p>
<p id="p-0061" num="0060">From the for going it may be seen that the present invention overcomes the shortcomings of the prior art. The system completely and securely manages personal information and images for any given individual. The system efficiently manages the distribution and searching of assorted biometric templates, which can be optimized for throughput, concurrency, or both depending on the size and demands of the application in question. The system provides its advantages through a plugin based architecture, which enables the addition or switching of biometric plugins to occur easily. The system operates via a distributed architecture consisting of a router and at least one query, which are interconnected via a simple TCP/IP network. System operations are controlled via a client SDK, which also makes connections to the router via a TCP/IP connection. Commands are data transfer is carried out over this connection, enabling biometric functionality to reach infinitely far as the network infrastructure will allow.</p>
<p id="p-0062" num="0061">Those skilled in the art will recognize alternative embodiments given the foregoing description. Accordingly, the foregoing description is for the purpose of illustration and not limitation. Certain features may be used independent of or in combination with other features, all would be apparent to one skilled in the art.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A biometric system, which comprises:
<claim-text>a biometric client, wherein said biometric client captures biometric images in a plurality of modes;</claim-text>
<claim-text>a router in communication with said biometric client to receive biometric images from said biometric client; and,</claim-text>
<claim-text>a plurality of biometric matching engines in communication with said router to receive biometric images from said router, wherein said plurality of biometric matching engines process biometric images in a plurality of modes, wherein:
<claim-text>said plurality of biometric matching engines comprise:
<claim-text>a first group of biometric matching engines, wherein each biometric matching engine of said first group being configured to process a first set of biometric image types, and</claim-text>
<claim-text>a second group of biometric matching engines, wherein each biometric matching engine of said second group being configured to process a second set of biometric image types; and</claim-text>
</claim-text>
<claim-text>said router is configurable to operate in a mode where a biometric template is sent to each biometric matching engine of said first group for storing.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The biometric system as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said plurality of biometric matching engines include:
<claim-text>means for creating biometric templates from biometric images received from said router.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The biometric system as claimed in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein said plurality of biometric matching engines include:
<claim-text>means for sending to said router biometric templates.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The biometric system as claimed in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein said plurality of biometric matching engines include:
<claim-text>means for caching biometric templates received from said router.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The biometric system as claimed in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein said plurality of biometric matching engines include means for caching biometric templates in physical memory.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The biometric system as claimed in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein said plurality of biometric matching engines include means for comparing cached biometric templates with probe templates.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The biometric system as claimed in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein said plurality of biometric matching engines include includes means for normalizing scores resulting from comparison of cached templates with probe templates.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The biometric system as claimed in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein said plurality of biometric matching engines include means for sending to said router scores resulting from comparison probe templates with cached templates.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The biometric system as claimed in <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said router includes means for sending to said biometric client scores received from said plurality of biometric matching engines.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The biometric system as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said plurality of biometric matching engines include:
<claim-text>a first biometric processor for comparing biometric templates of a first type and returning scores based on comparison of biometric templates of said first type;</claim-text>
<claim-text>a first biometric plugin coupled to said first biometric processor;</claim-text>
<claim-text>a second biometric processor for comparing biometric templates of a second type and returning scores based on comparison of biometric templates of said second type; and,</claim-text>
<claim-text>a second biometric plugin coupled to said second biometric processor.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A biometric system, which comprises:
<claim-text>a plurality of biometric clients, each of said biometric client including means for capturing biometric images of a plurality of types;</claim-text>
<claim-text>a router in communication with said biometric clients to receive biometric images from said biometric clients; and,</claim-text>
<claim-text>a plurality of biometric matching engines in communication with said router to receive biometric images from said router, each said biometric matching engine including means for processing biometric images of a plurality of types, wherein:
<claim-text>said plurality of biometric matching engines comprise:
<claim-text>a first group of biometric matching engines, each biometric matching engine of said first group including mean for processing a first set of biometric image types, and</claim-text>
<claim-text>a second group of biometric matching engines, each biometric matching engine of said second group including mean for processing a second set of biometric image types; and</claim-text>
</claim-text>
<claim-text>said router is configurable to operate in a mirrored mode, wherein a biometric template is sent to each biometric matching engine of said first group for caching.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The biometric system as claimed in <claim-ref idref="CLM-00011">claim 11</claim-ref>, where said router includes:
<claim-text>means for sending to one biometric matching engine of said first group a biometric image of one of said first biometric image types.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The biometric system as claimed in <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein each biometric matching engine of said first group includes:
<claim-text>means for creating biometric templates from biometric images of said first set of image types.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The biometric system as claimed in <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein each biometric matching engine of said first group includes:
<claim-text>means for sending to said router biometric templates created from images of said first set of image types.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The biometric system as claimed in <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein said router includes:
<claim-text>means for sending to each biometric matching engine biometric templates created from images of said first set of image types.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The biometric system as claimed in <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein each biometric matching engine of said first group includes:
<claim-text>means for caching biometric templates received from said router.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The biometric system as claimed in <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein each biometric matching engine of said first group includes:
<claim-text>means for comparing cached biometric templates with a probe template.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The biometric system as claimed in <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein each biometric matching engine of said first set includes means for caching biometric templates in physical memory.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The biometric system as claimed in <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein said router includes:
<claim-text>means for sending to a selected one of said biometric matching engines of said first group a biometric template created from a biometric image of said first type.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The biometric system as claimed in <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein said router is configured in said mirrored mode to send to a selected one of said biometric matching engines of said first group a target biometric image of said first type.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. A biometric system which comprises:
<claim-text>a plurality of biometric clients, each of said biometric client including means for capturing biometric images of a plurality of types;</claim-text>
<claim-text>a router in communication with said biometric clients to receive biometric images from said biometric clients; and,</claim-text>
<claim-text>a plurality of biometric matching engines in communication with said router to receive biometric images from said router, each said biometric matching engine including means for processing biometric images of a plurality of types, wherein:
<claim-text>said plurality of biometric matching engines comprise:
<claim-text>a first group of biometric matching engines, each biometric matching engine of said first group including mean for processing a first set of biometric image types, and</claim-text>
<claim-text>a second group of biometric matching engines, each biometric matching engine of said second group including mean for processing a second set of biometric image types; and</claim-text>
</claim-text>
<claim-text>said router is configurable to operate in a striped mode, wherein a biometric template is sent to a selected one of said biometric matching engines of said first group for caching.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The biometric system as claimed <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein said router is configured in said striped mode to send to each of said biometric matching engines of said first group a target biometric image of said first type.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. A method of processing multimodal biometric data, which comprises:
<claim-text>receiving at a router multimodal biometric enrollment data, said multimodal biometric enrollment data comprising a biometric image of a first type and a biometric image of a second type;</claim-text>
<claim-text>sending said biometric image of said first type and a biometric image of said second type to one of a group of multimodal biometric matching engines;</claim-text>
<claim-text>creating from said biometric image of said first type a first biometric template and from said biometric image of said second type a second biometric template;</claim-text>
<claim-text>sending said first and second biometric templates to said router; and</claim-text>
<claim-text>caching each biometric template of first and second types at each biometric matching engine of said group.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method as claimed in <claim-ref idref="CLM-00023">claim 23</claim-ref>, including:
<claim-text>mirroring biometric templates across the multimodal biometric matching engines of said group.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The method of processing multimodal biometric data, which comprises:
<claim-text>receiving at a router multimodal biometric enrollment data, said multimodal biometric enrollment data comprising a biometric image of a first type and a biometric image of a second type;</claim-text>
<claim-text>sending said biometric image of said first type and a biometric image of said second type to one of a group of multimodal biometric matching engines;</claim-text>
<claim-text>creating from said biometric image of said first type a first biometric template and from said biometric image of said second type a second biometric template;</claim-text>
<claim-text>sending said first and second biometric templates to said router; and</claim-text>
<claim-text>sending a target image of said first type and a target image of said second type to each biometric matching engine of said group for processing.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The method as claimed in <claim-ref idref="CLM-00025">claim 25</claim-ref>, including:
<claim-text>striping biometric templates across the multimodal biometric matching engines of said group.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The method as claimed in <claim-ref idref="CLM-00026">claim 26</claim-ref>, wherein striping comprises:
<claim-text>caching a biometric template at a single biometric matching engine of said group.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The method of processing multimodal biometric data, which comprises:
<claim-text>receiving at a router multimodal biometric enrollment data, said multimodal biometric enrollment data comprising a biometric image of a first type and a biometric image of a second type;</claim-text>
<claim-text>sending said biometric image of said first type and a biometric image of said second type to one of a group of multimodal biometric matching engines;</claim-text>
<claim-text>creating from said biometric image of said first type a first biometric template and from said biometric image of said second type a second biometric template;</claim-text>
<claim-text>sending said first and second biometric templates to said router; and</claim-text>
<claim-text>sending a target image of said first type and a target image of said second type to a selected biometric matching engine of said group for processing.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
