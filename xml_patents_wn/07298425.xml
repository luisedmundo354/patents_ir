<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298425-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298425</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>09048933</doc-number>
<date>19980326</date>
</document-id>
</application-reference>
<us-application-series-code>09</us-application-series-code>
<us-term-of-grant>
<us-term-extension>188</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>9</main-group>
<subgroup>64</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>348715</main-classification>
<further-classification>348718</further-classification>
<further-classification>348719</further-classification>
<further-classification>3484121</further-classification>
</classification-national>
<invention-title id="d0e53">Method for assisting video compression in a computer system</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4546383</doc-number>
<kind>A</kind>
<name>Abramatic et al.</name>
<date>19851000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348 19</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5287189</doc-number>
<kind>A</kind>
<name>Ersoz et al.</name>
<date>19940200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348588</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5438374</doc-number>
<kind>A</kind>
<name>Yan</name>
<date>19950800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348620</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5469208</doc-number>
<kind>A</kind>
<name>Dea</name>
<date>19951100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348 27</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5510857</doc-number>
<kind>A</kind>
<name>Kopet et al.</name>
<date>19960400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348699</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5555028</doc-number>
<kind>A</kind>
<name>Kim</name>
<date>19960900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348607</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>5684538</doc-number>
<kind>A</kind>
<name>Nakaya et al.</name>
<date>19971100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348416</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5717615</doc-number>
<kind>A</kind>
<name>Pirson et al.</name>
<date>19980200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348699</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5724441</doc-number>
<kind>A</kind>
<name>Yoshida</name>
<date>19980300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382166</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>5774676</doc-number>
<kind>A</kind>
<name>Stearns et al.</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709247</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>5787199</doc-number>
<kind>A</kind>
<name>Lee</name>
<date>19980700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382203</main-classification></classification-national>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>5812789</doc-number>
<kind>A</kind>
<name>Diaz et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709247</main-classification></classification-national>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>5825423</doc-number>
<kind>A</kind>
<name>Jung</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348313</main-classification></classification-national>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>5909559</doc-number>
<kind>A</kind>
<name>So</name>
<date>19990600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710307</main-classification></classification-national>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>5926223</doc-number>
<kind>A</kind>
<name>Hardiman</name>
<date>19990700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348405</main-classification></classification-national>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>6014181</doc-number>
<kind>A</kind>
<name>Sun</name>
<date>20000100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348699</main-classification></classification-national>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>6040845</doc-number>
<kind>A</kind>
<name>Melo et al.</name>
<date>20000300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345520</main-classification></classification-national>
</citation>
<citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>6118491</doc-number>
<kind>A</kind>
<name>Wu et al.</name>
<date>20000900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348526</main-classification></classification-national>
</citation>
<citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>6151074</doc-number>
<kind>A</kind>
<name>Werner</name>
<date>20001100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3484251</main-classification></classification-national>
</citation>
<citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>6211912</doc-number>
<kind>B1</kind>
<name>Shahraray</name>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348228</main-classification></classification-national>
</citation>
<citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>6246719</doc-number>
<kind>B1</kind>
<name>Agarwal</name>
<date>20010600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>6427194</doc-number>
<kind>B1</kind>
<name>Owen et al.</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711151</main-classification></classification-national>
</citation>
<citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>6987545</doc-number>
<kind>B1</kind>
<name>Klein</name>
<date>20060100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348718</main-classification></classification-national>
</citation>
</references-cited>
<number-of-claims>17</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>348715</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348716</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348717</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348690</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348567</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348568</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3484121</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3484181</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3484301</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348718-719</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348552</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>37524012</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>708203</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>4</number-of-drawing-sheets>
<number-of-figures>4</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20020067427</doc-number>
<kind>A1</kind>
<date>20020606</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Klein</last-name>
<first-name>Dean A.</first-name>
<address>
<city>Eagle</city>
<state>ID</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>TraskBritt</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Micron Technology, Inc.</orgname>
<role>02</role>
<address>
<city>Boise</city>
<state>ID</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Tran</last-name>
<first-name>Trang U.</first-name>
<department>2622</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">One embodiment of the present invention provides a method that facilitates compression of video data in a computer system by performing the time-consuming task of computing the difference between successive frames of video data independently from the central processing unit. This frees the often-overburdened central processing unit from performing this time-consuming compression operation and can thereby improve the handling of video data. Thus, one embodiment of the present invention can be characterized as a method for compressing video data in a computer system. This method includes receiving a stream of data from a current video frame in the computer system. It also includes computing a difference frame from the current video frame and a previous video frame “on-the-fly” as the current video frame streams into the computer system. The method additionally includes storing the difference frame in a memory in the computer system.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="115.65mm" wi="164.76mm" file="US07298425-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="219.54mm" wi="149.94mm" file="US07298425-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="198.37mm" wi="168.15mm" file="US07298425-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="229.62mm" wi="166.96mm" orientation="landscape" file="US07298425-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="174.67mm" wi="178.48mm" file="US07298425-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">RELATED APPLICATION</heading>
<p id="p-0002" num="0001">The subject matter of this application is related to the subject matter in a co-pending non-provisional application by the same inventor as the instant application entitled, “Apparatus for Assisting Video Compression in a Computer System,” having Ser. No. 09/048,932, and filing date Mar. 26, 1998.</p>
<heading id="h-0002" level="1">BACKGROUND</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">The present invention relates to compressing video data, and more specifically to a method that provides assistance to a computer system in compressing a stream of video data on-the-fly, as the video data streams into the computer system.</p>
<p id="p-0005" num="0004">2. Related Art</p>
<p id="p-0006" num="0005">As video data is increasingly used in computer systems in applications such as video conferencing and video recording, computer systems often cannot keep pace with the computational requirements of video data. Video data streams typically have extremely large bandwidth requirements that can tax the capabilities of even the most high-speed processor to compress the video data for storage, or for transmission across a computer network or a telephone system. This compression is typically performed by a central processing unit (CPU) in a computer system with a resulting loss in image clarity due to the failure of the CPU to keep pace with the video data. Complex scenes, having many elements that are in motion represent the greatest challenge because they place a tremendous burden on the CPU during the compression and data transfer processes.</p>
<p id="p-0007" num="0006">A time-consuming step in the compression of video data is to compute differences between successive video frames. A CPU typically computes a difference frame by reading a current video frame into memory and computing the difference between the current video frame and a previous video frame, which was previously stored into a memory in the computer system. Computing the difference typically involves performing an exclusive-OR operation between the current video frame and the previous video frame. In general, any function that effectively represents the difference between two successive video frames can be used with only minor modifications to the related compression algorithm. Hence, a large number of possible functions can be used to compute the difference between successive video frames.</p>
<p id="p-0008" num="0007">What is needed is an apparatus or a method for off-loading the time-consuming task of computing the difference between successive frames of video data from the CPU of a computing system.</p>
<heading id="h-0003" level="1">SUMMARY</heading>
<p id="p-0009" num="0008">One embodiment of the present invention provides a method that facilitates compression of video data in a computer system by performing the time-consuming task of computing the difference between successive frames of video data independently from the central processing unit. This frees the often-overburdened central processing unit from performing this time-consuming compression operation and can thereby improve the handling of video data. Thus, one embodiment of the present invention can be characterized as a method for compressing video data in a computer system. This method includes receiving a stream of data from a current video frame in the computer system. It also includes computing a difference frame from the current video frame and a previous video frame “on-the-fly” as the current video frame streams into the computer system. The method additionally includes storing the difference frame in a memory in the computer system.</p>
<p id="p-0010" num="0009">Another embodiment of the present invention includes storing the current video frame in the memory. In a variation on this embodiment, the current video frame is written over a previous video frame in the memory.</p>
<p id="p-0011" num="0010">In another embodiment of the present invention, computing the difference frame includes performing an exclusive-OR operation between the current video frame and the previous video frame. In another embodiment, computing the difference frame includes computing a difference between a block of data from the current video frame and a block of data from the previous video frame.</p>
<p id="p-0012" num="0011">In another embodiment of the present invention, storing the difference frame in the memory includes storing the difference frame in the memory using block transfers.</p>
<p id="p-0013" num="0012">Another embodiment of the present invention includes compressing the video data using the difference frame to produce compressed video data.</p>
<p id="p-0014" num="0013">Another embodiment of the present invention includes performing color space conversion on the video data. Yet another embodiment includes using the video data in compressed form in a video teleconferencing system. A further embodiment includes storing instructions and data for the computer system in the memory.</p>
<p id="p-0015" num="0014">In another embodiment of the present invention, computing the difference frame includes computing the difference frame in a core logic chip within the computer system. In another embodiment, computing the difference frame includes computing the difference frame in circuitry outside of a central processing unit in the computer system.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">DESCRIPTION OF THE FIGURES</heading>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a computer system including a graphics controller with a difference engine in accordance with an embodiment of the present invention.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 2</figref> illustrates a computer system including a graphics controller incorporated into a core logic unit in accordance with another embodiment of the present invention.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 3</figref> illustrates the internal structure of a portion of the graphics controller that computes the difference between successive video frames in accordance with an embodiment of the present invention.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram illustrating a method for compressing video data in a computer system in accordance with an embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DEFINITIONS</heading>
<p id="p-0020" num="0019">Color space conversion unit—circuitry that maps one set of color values to another set of color values.</p>
<p id="p-0021" num="0020">Computing on-the-fly—performing a computational operation on data streams through a computer system.</p>
<p id="p-0022" num="0021">Core logic unit—circuitry within a computer system that interfaces a processor to a memory and a peripheral bus and performs other functions.</p>
<p id="p-0023" num="0022">Difference engine—circuitry that computes a difference function between successive video frames. This difference function may be an exclusive-OR operation.</p>
<heading id="h-0006" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0024" num="0023">The following description is presented to enable any person skilled in the art to make and use the invention and is provided in the context of a particular application and its requirements. Various modifications to the disclosed embodiments will be readily apparent to those skilled in the art, and the general principles defined herein may be applied to other embodiments and applications without departing from the spirit and scope of the present invention. Thus, the present invention is not intended to be limited to the embodiments shown, but is to be accorded the widest scope consistent with the principles and features disclosed herein.</p>
<p id="h-0007" num="0000">Description of a First Embodiment of the Computer System</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a computer system including a graphics controller with a difference engine <b>106</b> in accordance with an embodiment of the present invention. The embodiment illustrated in <figref idref="DRAWINGS">FIG. 1</figref> includes central processing unit (CPU) <b>120</b>, which is coupled through north bridge <b>118</b> to memory <b>122</b> and bus <b>116</b>. CPU <b>120</b> may be any type of central processing unit that can be used in a computer system. This includes, but is not limited to, a microprocessor CPU, a mainframe CPU and a device controller CPU. North bridge <b>118</b> forms part of the “core logic” for the computer system. This core logic ties together and coordinates operations of components in the computer system. Memory <b>122</b> can be any type of semiconductor memory that can be used in a computer system. Bus <b>116</b> can be any type of computer system bus. In one embodiment, bus <b>116</b> includes a PCI bus.</p>
<p id="p-0026" num="0025">Bus <b>116</b> is also coupled to graphics controller <b>106</b>, which includes a difference engine. In this embodiment, graphics controller <b>106</b> includes circuitry to perform a difference operation between successive video frames. Graphics controller <b>106</b> is also coupled to memory <b>108</b> and video unit <b>102</b>. Graphics controller <b>106</b> additionally produces video output <b>114</b>, which feeds into a computer system monitor.</p>
<p id="p-0027" num="0026">Memory <b>108</b> may be any type of semiconductor memory that may be used in a computer system. In one embodiment of the present invention, memory <b>108</b> is a dedicated graphics memory for graphics controller <b>106</b>, which is separate from memory <b>122</b>. In another embodiment, memory <b>108</b> and memory <b>122</b> are part of the same memory. In the illustrated embodiment, memory <b>108</b> includes an area for storing unmodified video data <b>110</b> and an area for storing XOR video data <b>112</b>. In one embodiment, the area for storing unmodified video data <b>110</b> stores a previous frame of unmodified video, and the area for storing XOR video data <b>112</b> stores a difference frame containing the exclusive-OR of a current frame and the previous frame. Other embodiments of the present invention may use other difference functions besides exclusive-OR.</p>
<p id="p-0028" num="0027">Video unit <b>102</b> receives video input <b>100</b> in analog form and converts it to digital form. In the illustrated embodiment, video unit <b>102</b> receives video input <b>100</b> in either PAL or NTSC format, and produces digital video data in YUV data <b>104</b>. Video unit <b>102</b> may include the BT829 chip produced by Rockwell Semiconductor Systems, Inc. of Newport Beach, Calif. Alternatively, the Rockwell BT848 part may be used to transfer data across a computer system bus into system memory or into a video controller's memory. (In some embodiments, these may be the same memory). Additionally, video data may be received from external sources through serial buses that can stream video data into system memory, usually by transferring data across bus <b>116</b>. These serial buses may include the USB or the IEEE 1394 bus.</p>
<p id="p-0029" num="0028">The embodiment illustrated in <figref idref="DRAWINGS">FIG. 1</figref> operates as follows. Video input <b>100</b> streams into video unit <b>102</b>, which converts video input <b>100</b> into digital YUV data <b>104</b>. YUV data <b>104</b> feeds into graphics controller <b>106</b>, which produces video output <b>114</b> for display on a computer system monitor. Graphics controller <b>106</b> additionally stores unmodified video data into unmodified video data <b>110</b> within memory <b>108</b>. Graphics controller <b>106</b> also computes the difference between a current video frame and a previous video frame and stores this difference information in XOR video data <b>112</b> in memory <b>108</b>. This difference information is used by CPU <b>120</b> to complete the compression process for the video data stream.</p>
<p id="h-0008" num="0000">Description of a Second Embodiment</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 2</figref> illustrates a computer system including a graphics controller incorporated into a core logic unit <b>200</b> in accordance with another embodiment of the present invention. This embodiment is similar to the embodiment illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, except that graphics controller <b>106</b> and north bridge <b>118</b> from <figref idref="DRAWINGS">FIG. 1</figref> are combined into a single core logic unit <b>200</b> with graphics controller. Additionally, memory <b>108</b> and memory <b>122</b> from <figref idref="DRAWINGS">FIG. 1</figref> are combined into a single memory <b>122</b> in <figref idref="DRAWINGS">FIG. 2</figref>.</p>
<p id="p-0031" num="0030">In the embodiment illustrated in <figref idref="DRAWINGS">FIG. 2</figref>, core logic unit <b>200</b> includes circuitry to compute the difference between successive video frames as well as circuitry to perform other graphics controller functions.</p>
<p id="p-0032" num="0031">The embodiment illustrated in <figref idref="DRAWINGS">FIG. 2</figref> operates in the same way as the embodiment illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, except that in <figref idref="DRAWINGS">FIG. 2</figref>, unmodified video data <b>110</b> and XOR video data <b>112</b> are not stored in a separate graphics memory <b>108</b>, but are rather stored in the system memory <b>122</b>. Hence, CPU <b>120</b> does not have to reach out across bus <b>116</b> to retrieve XOR video data <b>112</b> from a separate graphics memory to complete the compression process. It merely has to retrieve the XOR video data <b>112</b> from the system memory.</p>
<p id="h-0009" num="0000">Description of Internal Structure of Graphics Controller</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 3</figref> illustrates the internal structure for a portion of a graphics controller that computes the difference between successive video frames in accordance with an embodiment of the present invention. The circuitry illustrated in <figref idref="DRAWINGS">FIG. 3</figref> can exist in either graphics controller <b>106</b> from <figref idref="DRAWINGS">FIG. 1</figref> or in core logic unit <b>200</b> from <figref idref="DRAWINGS">FIG. 2</figref>. The circuitry illustrated in <figref idref="DRAWINGS">FIG. 3</figref> includes YUV data <b>104</b>, which feeds through color space conversion module <b>302</b>. This module may perform color re-mapping on YUV data <b>104</b>. The output of color space conversion module <b>302</b> feeds into video input buffer <b>304</b>. From video input buffer <b>304</b>, the video data feeds either into XOR unit <b>308</b> and multiplexer (MUX) <b>312</b>. XOR unit <b>308</b> takes another input from previous frame buffer <b>306</b> and generates an output, which feeds into result buffer <b>310</b>. Data from result buffer <b>310</b> feeds through MUX <b>312</b> and I/O buffers <b>316</b> into memory <b>108</b>. MUX <b>312</b> takes another input from other write circuits <b>314</b>. This allows data to be written to memory <b>122</b> from other sources. Data read from memory <b>122</b> feeds into previous frame buffer <b>306</b>, and then into XOR unit <b>308</b>. Alternatively, data read from memory <b>122</b> may feed into other read circuits <b>315</b>, allowing data to be read from memory <b>122</b> by other sources. Data read from memory <b>122</b> may also pass through serializer <b>330</b>, color lookup table <b>332</b> and digital-to-analog converter <b>334</b> before becoming video output <b>114</b> to a monitor. Serializer <b>330</b> converts data read from memory <b>122</b> into a serial bitstream. This bitstream is modified in color lookup table <b>332</b>, and is ultimately converted into analog form in digital-to-analog converter <b>334</b>.</p>
<p id="p-0034" num="0033">The circuitry illustrated in <figref idref="DRAWINGS">FIG. 3</figref> operates as follows. Video data in YUV form <b>104</b> from video unit <b>102</b> streams into video input buffer <b>304</b> through color space conversion module <b>302</b>. From video input buffer <b>304</b>, this video data feeds through MUX <b>312</b> and I/O buffers <b>316</b> into unmodified video data <b>110</b> within memory <b>122</b>. At the same time, data for a previous frame from unmodified video data <b>110</b> in memory <b>122</b> feeds into previous frame buffer <b>306</b> through I/O buffer <b>316</b>. From previous frame buffer <b>306</b>, this data feeds into XOR unit <b>308</b>. XOR unit <b>308</b> computes the difference between data from the previous frame, stored in previous frame buffer <b>306</b>, and data from the current frame, stored in video input buffer <b>304</b>. The output of XOR unit <b>308</b> feeds into result buffer <b>310</b>. From result buffer <b>310</b>, this data feeds through MUX <b>312</b> and I/O buffers <b>316</b> into an area for storing XOR video data <b>112</b> within memory <b>122</b>. CPU <b>120</b> then uses this difference information to compress the video data.</p>
<p id="p-0035" num="0034">In one embodiment, data is processed a block at a time through XOR unit <b>308</b>, wherein a block includes multiple words of data.</p>
<p id="p-0036" num="0035">In the embodiment illustrated in <figref idref="DRAWINGS">FIG. 3</figref>, data for the current frame is overwritten over data for the previous frame as the data for the previous frame is retrieved into previous frame buffer <b>306</b>. This allows the frame data to be stored in one location without using “ping pong” buffers.</p>
<p id="p-0037" num="0036">The embodiment illustrated in <figref idref="DRAWINGS">FIG. 3</figref> also includes registers for storing address A <b>322</b> and address B <b>324</b>. Address A <b>322</b> and address B <b>324</b> are pointers into memory <b>122</b> for keeping track of data within unmodified video data <b>110</b> and XOR video data <b>112</b> within memory <b>122</b>.</p>
<p id="h-0010" num="0000">Description of Method for Compressing Video Data</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 4</figref> is a flow chart illustrating a method for compressing video data in a computer system in accordance with an embodiment of the present invention. This flow chart is divided into two columns. The column on the left-hand-side represents operations of the computational unit, and the column on the right-hand-side represents operations of the memory system. In this embodiment, the system starts in state <b>400</b>. From state <b>400</b>, the computational proceeds to state <b>402</b>. In state <b>402</b>, the computational unit receives a stream of data from a current video frame from a video source. The computational unit next proceeds to state <b>404</b>. In state <b>404</b>, the computational unit performs a color space conversion on the video data. The computational unit next proceeds to state <b>406</b>. In state <b>406</b>, the computational unit computes a difference frame from a current video frame and a previous video frame received from the memory system “on-the-fly” as the current video frame streams into the computer system. In one embodiment, this difference computation takes place without intervention by the CPU <b>120</b>. The computational unit next proceeds to state <b>412</b>. In state <b>412</b>, the computational unit produces compressed video data using the difference frame. The computational unit then loops back around to state <b>402</b> to process more video data.</p>
<p id="p-0039" num="0038">From state <b>400</b>, the memory system proceeds to state <b>422</b>. In state <b>422</b>, the memory system fetches a block of data from the previous frame. This block of data is forwarded to the computational unit for use in state <b>406</b>. The memory system next proceeds to state <b>424</b>, in which the memory system stores the current video frame—received from the computational unit in state <b>404</b>—into memory <b>122</b>. The memory system next proceeds at state <b>426</b>. In state <b>426</b>, the memory system stores the difference frame into memory <b>122</b>. The memory system then loops back around to state <b>422</b> to process more video data.</p>
<p id="p-0040" num="0039">The foregoing descriptions of embodiments of the invention have been presented for purposes of illustration and description only. They are not intended to be exhaustive or to limit the invention to the forms disclosed. Obviously, many modifications and variations will be apparent to practitioners skilled in the art.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for compressing video data in a computer system comprising:
<claim-text>receiving a current video frame at a dedicated video input of a core logic chip in the computer system directly from a video source originating the video frame, the computer system including the core logic chip for directly coupling a processor to a system memory and for coupling the processor and the system memory to a system bus;</claim-text>
<claim-text>computing at the core logic chip a difference frame from the current video frame and a previous video frame as the current video frame streams into the dedicated video input of the core logic chip, the previous video frame being received at the core logic chip as a previous current video frame and retained therein, the difference frame including computing the difference frame in the core logic chip within the computer system, wherein the core logic chip is a north bridge chip;</claim-text>
<claim-text>storing the difference frame directly from the core logic chip to the system memory in the computer system via a dedicated memory interface therebetween; and</claim-text>
<claim-text>the processor retrieving the difference frame directly from the system memory via the core logic chip using a dedicated processor interface therebetween to complete compression of the video data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, including storing the current video frame in the system memory in the computer system.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the current video frame is written over a previous video frame in the system memory.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein computing the difference frame includes computing an exclusive-OR between the current video frame and the previous video frame.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein computing the difference frame includes computing a difference between a block of data from the current video frame and a block of data from the previous video frame.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein storing the difference frame in memory includes storing the difference frame in the system memory using block transfers.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, including compressing the video data using the difference frame to produce compressed video data.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, including performing a color space conversion on the video data.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, including using the video data in compressed form in a video teleconferencing system.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein computing the difference frame includes computing the difference frame in circuitry outside of a central processing unit in the computer system.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A method for compressing video data in a computer system, comprising:
<claim-text>receiving a current video frame at a dedicated video input of a core logic chip in the computer system directly from a video source originating the video frame, the computer system including the core logic chip for directly coupling a processor to a system memory and for coupling the processor and the system memory to a system bus;</claim-text>
<claim-text>computing at the core logic chip a difference frame from the current video frame and a previous video frame as the current video frame streams into the dedicated video input of the core logic chip, the previous video frame being received at the core logic chip as a previous current video frame and retained therein, the difference frame including computing an exclusive-OR between the current video frame and the previous video frame, and wherein computing the difference frame includes computing the difference frame in the core logic chip within the computer system, wherein the core logic chip is a north bridge chip;</claim-text>
<claim-text>storing the difference frame directly from the core logic chip into the system memory in the computer system via a dedicated memory interface therebetween;</claim-text>
<claim-text>storing the current video frame directly from the core logic chip into the system memory in the computer system using a dedicated processor interface therebetween;</claim-text>
<claim-text>the processor retrieving the difference frame directly from the system memory via the core logic chip; and</claim-text>
<claim-text>compressing the video data using the difference frame to produce compressed video data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the current video frame is written over a previous video frame in the system memory.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein computing the difference frame includes computing a difference between a block of data from the current video frame and a block of data from the previous video frame.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein storing the difference frame in system memory includes storing the difference frame in the system memory using block transfers.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, including using the compressed data in a video teleconferencing system.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, including performing a color space conversion on the video data.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, including storing instructions and data for the computer system in the system memory.</claim-text>
</claim>
</claims>
</us-patent-grant>
