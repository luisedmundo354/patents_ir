<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07299337-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07299337</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11128665</doc-number>
<date>20050512</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<us-term-of-grant>
<us-term-extension>183</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>9</main-group>
<subgroup>26</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>711206</main-classification>
<further-classification>711207</further-classification>
</classification-national>
<invention-title id="d0e53">Enhanced shadow page table algorithms</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4456954</doc-number>
<kind>A</kind>
<name>Bullions et al.</name>
<date>19840600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711207</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5724581</doc-number>
<kind>A</kind>
<name>Kozakura</name>
<date>19980300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707202</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2006/0206658</doc-number>
<kind>A1</kind>
<name>Hendel et al.</name>
<date>20060900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711  6</main-classification></classification-national>
</citation>
</references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>711206</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>16</number-of-drawing-sheets>
<number-of-figures>16</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20060259732</doc-number>
<kind>A1</kind>
<date>20061116</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Traut</last-name>
<first-name>Eric P.</first-name>
<address>
<street>17809 SE. 58th Pl.</street>
<city>Bellevue</city>
<state>WA</state>
<postcode>98006</postcode>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Hendel</last-name>
<first-name>Matthew D.</first-name>
<address>
<street>5150 S. Orchard St.</street>
<city>Seattle</city>
<state>WA</state>
<postcode>98118</postcode>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Vega</last-name>
<first-name>Rene Antonio</first-name>
<address>
<street>11014 NE. 41st Dr.</street>
<city>Kirkland</city>
<state>WA</state>
<postcode>98033</postcode>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
</parties>
<examiners>
<primary-examiner>
<last-name>Ellis</last-name>
<first-name>Kevin L.</first-name>
<department>2188</department>
</primary-examiner>
<assistant-examiner>
<last-name>Ahmed</last-name>
<first-name>Hamdy S</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Enhanced shadow page table algorithms are presented for enhancing typical page table algorithms. In a virtual machine environment, where an operating system may be running within a partition, the operating system maintains it's own guest page tables. These page tables are not the real page tables that map to the real physical memory. Instead, the memory is mapped by shadow page tables maintained by a virtualing program, such as a hypervisor, that virtualizes the partition containing the operating system. Enhanced shadow page table algorithms provide efficient ways to harmonize the shadow page tables and the guest page tables. Specifically, by using tagged translation lookaside buffers, batched shadow page table population, lazy flags, and cross-processor shoot downs, the algorithms make sure that changes in the guest pages tables are reflected in the shadow page tables.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="179.24mm" wi="155.02mm" file="US07299337-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="229.87mm" wi="161.04mm" orientation="landscape" file="US07299337-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="221.83mm" wi="133.43mm" file="US07299337-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="175.34mm" wi="170.69mm" file="US07299337-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="203.71mm" wi="159.68mm" orientation="landscape" file="US07299337-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="207.86mm" wi="155.70mm" file="US07299337-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="215.31mm" wi="161.29mm" file="US07299337-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="226.57mm" wi="152.91mm" file="US07299337-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="184.91mm" wi="146.39mm" file="US07299337-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="183.22mm" wi="132.50mm" file="US07299337-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="160.61mm" wi="136.06mm" file="US07299337-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="201.08mm" wi="179.15mm" file="US07299337-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="199.56mm" wi="174.67mm" file="US07299337-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="201.08mm" wi="158.33mm" file="US07299337-20071120-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="198.71mm" wi="162.73mm" file="US07299337-20071120-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="203.62mm" wi="122.77mm" file="US07299337-20071120-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="185.50mm" wi="116.76mm" file="US07299337-20071120-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">COPYRIGHT NOTICE AND PERMISSION</heading>
<p id="p-0002" num="0001">A portion of the disclosure of this patent document may contain material that is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure, as it appears in the Patent and Trademark Office patent files or records, but otherwise reserves all copyright rights whatsoever. The following notice shall apply to this document: Copyright© 2005, Microsoft Corp.</p>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention generally relates to the field of virtual machines and to operating systems that execute in virtual machine environments. More specifically, the present invention is directed to systems and methods for enhancing shadow page table algorithms in such virtual machine environments.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">In a hypervisor environment, where physical memory access is controlled by the hypervisor instead of an operating system running on top of the hypervisor, the performance of memory access algorithms contribute significantly to the overall performance of the system.</p>
<p id="p-0005" num="0004">In a shadow page table environment, the page tables that the operating system operates on are not the real page tables that the machine uses. Instead, access to the page directory root (e.g. the CR3 register on an IA32 system or an AMD64 system that points to a page table) is kept private to the hypervisor, and the operating system's page directory root is virtualized. The hypervisor virtualizes load and store operations to the page directory root, so that the operating system appears to be running atop real hardware. The hypervisor-private page table is called the shadow page table. Conversely, the operating system page table is called the guest page table. When the operating system modifies its guest page table entries, the shadow page table entries must also be modified to correspond to the operating system's modifications.</p>
<p id="p-0006" num="0005">In order to improve virtual-to-physical translations, translation lookaside buffers (TLBs), which are stored on CPUs, are used as caches. Thus, instead of looking up translations in a page table, an operating system can employ the much faster TLB translations. However, such TLBs are very limited in storage, typically containing 128 to 256 entries, so only the most recent and relevant translations are kept in them.</p>
<p id="p-0007" num="0006">On several popular processor architectures, for example, the Intel IA 32 or the x86 or the AMD x64 architecture, the entire TLB cache is discarded when an address space is changed, i.e., when an assignment is made to the page directory root. The reason for this is that the new address space (the switched to address space) gets to use the TLB since it is active and the old address space (the switched from address space) does not since it is not active anymore. Upon such address space switch, shadow page tables are also typically discarded. When a shadow page table is discarded, repopulating it with new translation entries is very costly in terms of processor cycles. Thus, it is advantageous to reduce the high cost associated with populating a shadow page table. Or, put another way, it would be advantageous to reduce the high cost associated with discarding an entire shadow page table when an address space change occurs.</p>
<p id="p-0008" num="0007">Next, to perform efficient paging algorithms, current processors frequently implement mechanisms to determine if a page has been accessed (i.e. whether it has been read) or modified (i.e. whether it has been written to). In most implementations, two flags are maintained in a page table entry: a flag that is set when a page is accessed and a separate flag that is set when a page is modified (the modified flag is often called the dirty flag).</p>
<p id="p-0009" num="0008">In a shadow page table implementation, these accessed and modified flags will be set in the shadow page table, which is invisible to the operating system. For the proper functioning of many operating systems, these accessed and modified flags must be correctly maintained. In most processor architectures, it is impossible to transparently maintain consistency between the accessed and modified flags in the shadow page table and the accessed and modified flags in the guest page table.</p>
<p id="p-0010" num="0009">To correctly maintain the accessed flags, shadow page table algorithms must examine the guest page table's accessed flag. If a guest entry's accessed flag is cleared, the corresponding entry within the shadow page table must be marked as invalid. When the guest accesses this page, the hypervisor receives control and marks the page as valid in the shadow page table and accessed in the operating system's guest page table.</p>
<p id="p-0011" num="0010">Similarly, to correctly maintain the modified flags, a shadow page table implementation must mark a page as read-only, then process the page fault interrupt when an attempt is made to write to the page. Within the interrupt, the shadow page must be marked as writable and the guest page table entry must be marked as modified. Processing these interrupts to maintain the active and modified flags of page table entries is a significant source of slowdown for a shadow page table implementation. Thus, it would be advantageous to reduce the high cost of maintaining accessed and modified flags in the operating system's guest page table entries.</p>
<p id="p-0012" num="0011">Finally, on a multiprocessor system, when a page table entry is modified, the page table entry must be purged not only from the TLB of the processor that modified the entry, but from the TLB of any processor that may have a cached copy of the table entry. In some processor architectures, this cross-processor TLB invalidation is performed explicitly by software using an inter-process interrupt. This cross-processor TLB invalidation is often referred to as a TLB shoot down. TLB shoot down algorithms are very expensive in terms of processor cycles—especially in a virtualized environment. In particular, the current TLB shoot down algorithms require many transitions into the hypervisor to accomplish their task, and require more inter-processor interrupts than may otherwise be required. Thus, it would be advantageous to reduce the high cost of TLB shoot down in a hypervisor (or an equivalent virtualizing program).</p>
<heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0013" num="0012">Enhanced shadow page table algorithms are provided in various aspects of the invention in order to increase the efficiency of typical shadow table routines. In a typical virtual machine environment, a virtualizing program, such as a hypervisor, maintains partitions that may each contain an operating system. The operating system maintains its own guest page tables that map virtual addresses to guest physical addresses. The hypervisor also maintains its own shadow page tables that maps virtual addresses to system physical addresses. Thus, in one aspect of the invention, virtual tagged lookaside buffers (TLBs) are used in order to retain shadow page tables when an operating system switches address spaces by shifting from one guest page table to another guest page table, and hence from one shadow page table to another shadow page table.</p>
<p id="p-0014" num="0013">In other aspects of the invention, batched shadow page table algorithms are presented. Instead of populating just one shadow page table entry upon populating a guest page table, multiple shadow page table entries are populated, thus decreasing hypervisor processing of any subsequent shadow page table entries, hence increasing the efficiency of a virtual machine environment. In yet other aspects of the invention, shadow page table algorithms lazily update accessed and modified flags within the guest page tables to reflect such modified flags set by processors in shadow page tables. Lazy updating uses synchronization commands by a partition operating system to update such guest page tables when it is desired to do so, not upon each setting of the flags in shadow page tables. In still other aspects of the invention, translation lookaside buffer management routines are provided by the virtualizing program in order to perform more efficient inter-processor shoot down. Thus, when multiple TLBs need to be purged, they can be purged by a single hypervisor call. This kind of TLB updating applies not only to the physical TLBs located on physical processors but also in shadow page tables that are embodied by a virtual tagged TLB. Various other aspects also consider a shadow-page-table-per-virtual-processor and a shadow-page-table-per-virtual-machine modes.</p>
<p id="p-0015" num="0014">Other features of the invention are described below.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0016" num="0015">The foregoing summary, as well as the following detailed description of the invention, is better understood when read in conjunction with the appended drawings. In order to illustrate the invention, various aspects of the invention are shown. However, the invention is not limited to the specific systems and methods disclosed. The following figures are included:</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 1</figref> provides a brief general description of a suitable computing device in connection with which the invention may be implemented;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 2</figref> is a block diagram representing the logical layering of the hardware and software architecture for an emulated operating environment in a computer system;</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 3A</figref> is a block diagram representing a virtualized computing system wherein the emulation is performed by the host operating system (either directly or via a hypervisor);</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 3B</figref> is a block diagram representing an alternative virtualized computing system wherein the emulation is performed by a virtual machine monitor running side-by-side with a host operating system;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 4A</figref> illustrates general aspects of guest page tables and shadow page tables;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 4B</figref> illustrates the relationships of the guest page tables and shadow page tables to the various types of memories.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 5</figref> explains the avoidance of the high cost of address switching;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 6A</figref> illustrates an example shadow page table prior to processing a page fault;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 6B</figref> illustrates an example shadow page table after processing a page fault when filling a single page;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 6C</figref> illustrates an example shadow page table after processing a page fault by filling multiple pages;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 7A</figref> illustrates lazy accessed and modified flag propagation prior to synchronization commands;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 7B</figref> illustrates lazy accessed and modified flag propagation after synchronization commands;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 8A</figref> illustrates cross-processor shoot down of physical TLBs;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 8B</figref> illustrates cross-processor shoot down of Shadow Page Tables;</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 9A</figref> illustrates a shadow page table per-virtual processor mode; and</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 9B</figref> illustrates a shadow page table per-partition mode.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION OF ILLUSTRATIVE ASPECTS OF THE INVENTION</heading>
<p id="h-0007" num="0000">Overview</p>
<p id="p-0033" num="0032">Enhanced shadow page table algorithms are disclosed herein. At first, an exemplary computing environment is presented followed by an exemplary virtual machine environment. Next, a detailed discussion of particular aspects of shadow page table algorithms operating in such a virtual machine environment are presented. For example, the following aspects are considered: tagged virtual TLBs that allow for multiple shadow page tables upon address space switches; batched population of such shadow page tables, in lieu of single style population; flag synchronization between shadow page tables and guest page tables; and TLBs and virtual TLBs embodied in shadow page tables that are flushed across a plurality of processors when guest page table entries are modified. These are just a few exemplary aspects discussed below in further detail. Other aspects are also presented.</p>
<p id="h-0008" num="0000">Exemplary Computing Environment</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 1</figref> and the following discussion are intended to provide a brief general description of a suitable computing device in connection with which the invention may be implemented. For example, any of the client and server computers or devices illustrated in <figref idref="DRAWINGS">FIG. 1</figref> may take this form. It should be understood, however, that handheld, portable and other computing devices and computing objects of all kinds are contemplated for use in connection with the present invention, i.e., anywhere from which data may be generated, processed, received and/or transmitted in a computing environment. While a general purpose computer is described below, this is but one example, and the present invention may be implemented with a thin client having network/bus interoperability and interaction. Thus, the present invention may be implemented in an environment of networked hosted services in which very little or minimal client resources are implicated, e.g., a networked environment in which the client device serves merely as an interface to the network/bus, such as an object placed in an appliance. In essence, anywhere that data may be stored or from which data may be retrieved or transmitted to another computer is a desirable, or suitable, environment for operation of the object persistence methods of the invention.</p>
<p id="p-0035" num="0034">Although not required, the invention can be implemented via an operating system, for use by a developer of services for a device or object, and/or included within application or server software that operates in accordance with the invention. Software may be described in the general context of computer-executable instructions, such as program modules, being executed by one or more computers, such as client workstations, servers or other devices. Generally, program modules include routines, programs, objects, components, data structures and the like that perform particular tasks or implement particular abstract data types. Typically, the functionality of the program modules may be combined or distributed as desired in various embodiments. Moreover, the invention may be practiced with other computer system configurations and protocols. Other well known computing systems, environments, and/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers (PCs), automated teller machines, server computers, hand-held or laptop devices, multi-processor systems, microprocessor-based systems, programmable consumer electronics, network PCs, appliances, lights, environmental control elements, minicomputers, mainframe computers and the like.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 1</figref> thus illustrates an example of a suitable computing system environment <b>100</b> in which the invention may be implemented, although as made clear above, the computing system environment <b>100</b> is only one example of a suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of the invention. Neither should the computing environment <b>100</b> be interpreted as having any dependency or requirement relating to any one or combination of components illustrated in the exemplary operating environment <b>100</b>.</p>
<p id="p-0037" num="0036">With reference to <figref idref="DRAWINGS">FIG. 1</figref>, an exemplary system for implementing the invention includes a general purpose computing device in the form of a computer <b>110</b>. Components of computer <b>110</b> may include, but are not limited to, a processing unit <b>120</b>, a system memory <b>130</b>, and a system bus <b>121</b> that couples various system components including the system memory to the processing unit <b>120</b>. The system bus <b>121</b> may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus (also known as Mezzanine bus).</p>
<p id="p-0038" num="0037">Computer <b>110</b> typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer <b>110</b> and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer readable media may comprise computer storage media and communication media. Computer storage media include both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Computer storage media include, but are not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CDROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computer <b>110</b>. Communication media typically embody computer readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and include any information delivery media. The term “modulated data signal” means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media include wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.</p>
<p id="p-0039" num="0038">The system memory <b>130</b> includes computer storage media in the form of volatile and/or nonvolatile memory such as read only memory (ROM) <b>131</b> and random access memory (RAM) <b>132</b>. A basic input/output system <b>133</b> (BIOS), containing the basic routines that help to transfer information between elements within computer <b>110</b>, such as during start-up, is typically stored in ROM <b>131</b>. RAM <b>132</b> typically contains data and/or program modules that are immediately accessible to and/or presently being operated on by processing unit <b>120</b>. By way of example, and not limitation, <figref idref="DRAWINGS">FIG. 1</figref> illustrates operating system <b>134</b>, application programs <b>135</b>, other program modules <b>136</b>, and program data <b>137</b>.</p>
<p id="p-0040" num="0039">The computer <b>110</b> may also include other removable/non-removable, volatile/nonvolatile computer storage media. By way of example only, <figref idref="DRAWINGS">FIG. 1</figref> illustrates a hard disk drive <b>141</b> that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive <b>151</b> that reads from or writes to a removable, nonvolatile magnetic disk <b>152</b>, and an optical disk drive <b>155</b> that reads from or writes to a removable, nonvolatile optical disk <b>156</b>, such as a CD-RW, DVD-RW or other optical media. Other removable/non-removable, volatile/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM and the like. The hard disk drive <b>141</b> is typically connected to the system bus <b>121</b> through a non-removable memory interface such as interface <b>140</b>, and magnetic disk drive <b>151</b> and optical disk drive <b>155</b> are typically connected to the system bus <b>121</b> by a removable memory interface, such as interface <b>150</b>.</p>
<p id="p-0041" num="0040">The drives and their associated computer storage media discussed above and illustrated in <figref idref="DRAWINGS">FIG. 1</figref> provide storage of computer readable instructions, data structures, program modules and other data for the computer <b>110</b>. In <figref idref="DRAWINGS">FIG. 1</figref>, for example, hard disk drive <b>141</b> is illustrated as storing operating system <b>144</b>, application programs <b>145</b>, other program modules <b>146</b> and program data <b>147</b>. Note that these components can either be the same as or different from operating system <b>134</b>, application programs <b>135</b>, other program modules <b>136</b> and program data <b>137</b>. Operating system <b>144</b>, application programs <b>145</b>, other program modules <b>146</b> and program data <b>147</b> are given different numbers here to illustrate that, at a minimum, they are different copies. A user may enter commands and information into the computer <b>110</b> through input devices such as a keyboard <b>162</b> and pointing device <b>161</b>, such as a mouse, trackball or touch pad. Other input devices (not shown) may include a microphone, joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit <b>120</b> through a user input interface <b>160</b> that is coupled to the system bus <b>121</b>, but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). A graphics interface <b>182</b> may also be connected to the system bus <b>121</b>. One or more graphics processing units (GPUs) <b>184</b> may communicate with graphics interface <b>182</b>. A monitor <b>191</b> or other type of display device is also connected to the system bus <b>121</b> via an interface, such as a video interface <b>190</b>, which may in turn communicate with video memory <b>186</b>. In addition to monitor <b>191</b>, computers may also include other peripheral output devices such as speakers <b>197</b> and printer <b>196</b>, which may be connected through an output peripheral interface <b>195</b>.</p>
<p id="p-0042" num="0041">The computer <b>110</b> may operate in a networked or distributed environment using logical connections to one or more remote computers, such as a remote computer <b>180</b>. The remote computer <b>180</b> may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer <b>110</b>, although only a memory storage device <b>181</b> has been illustrated in <figref idref="DRAWINGS">FIG. 1</figref>. The logical connections depicted in <figref idref="DRAWINGS">FIG. 1</figref> include a local area network (LAN) <b>171</b> and a wide area network (WAN) <b>173</b>, but may also include other networks/buses. Such networking environments are commonplace in homes, offices, enterprise-wide computer networks, intranets and the Internet.</p>
<p id="p-0043" num="0042">When used in a LAN networking environment, the computer <b>110</b> is connected to the LAN <b>171</b> through a network interface or adapter <b>170</b>. When used in a WAN networking environment, the computer <b>110</b> typically includes a modem <b>172</b> or other means for establishing communications over the WAN <b>173</b>, such as the Internet. The modem <b>172</b>, which may be internal or external, may be connected to the system bus <b>121</b> via the user input interface <b>160</b>, or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer <b>110</b>, or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation, <figref idref="DRAWINGS">FIG. 1</figref> illustrates remote application programs <b>185</b> as residing on memory device <b>181</b>. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.</p>
<p id="h-0009" num="0000">Virtual Machines</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram representing the logical layering of the hardware and software architecture for a virtualized environment in a computer system. In the figure, a virtualization program <b>210</b> runs directly or indirectly on the physical hardware architecture <b>212</b>. The virtualization program <b>210</b> may be (a) a virtual machine monitor that runs alongside a host operating system or a host operating system with a hypervisor component wherein the hypervisor component performs the virtualization. The virtualization program <b>210</b> virtualizes a guest hardware architecture <b>208</b> (shown as dashed lines to illustrate the fact that this component is a partition or a “virtual machine”), that is, hardware that does not actually exist but is instead virtualized by the virtualizing program <b>210</b>. A guest operating system <b>206</b> executes on the guest hardware architecture <b>208</b>, and a software application <b>204</b> runs on the guest operating system <b>206</b>. In the virtualized operating environment of <figref idref="DRAWINGS">FIG. 2</figref>, the software application <b>204</b> can run in a computer system <b>202</b> even if the software application <b>204</b> is designed to run on an operating system that is generally incompatible with a host operating system and the hardware architecture <b>212</b>.</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 3A</figref> illustrates a virtualized computing system comprising a host operating system (host OS) software layer <b>304</b> running directly above physical computer hardware <b>302</b>, where the host OS <b>304</b> provides access to the resources of the physical computer hardware <b>302</b> by exposing interfaces to partitions A <b>308</b> and B <b>310</b> for the use by operating systems <b>312</b> and <b>314</b>, respectively. This enables the host OS <b>304</b> to go unnoticed by operating system layers <b>312</b> and <b>314</b> running above it. Again, to perform the virtualization, the host OS <b>304</b> may be a specially designed operating system with native virtualization capabilities or, alternately, it may be a standard operating system with an incorporated hypervisor component for performing the virtualization (not shown).</p>
<p id="p-0046" num="0045">Referring again to <figref idref="DRAWINGS">FIG. 3A</figref>, above the host OS <b>304</b> are two partitions, partition A <b>308</b>, which may be, for example, a virtualized Intel <b>386</b> processor, and partition B <b>310</b>, which may be, for example, a virtualized version of one of the Motorola 680X0 family of processors. Within each partition <b>308</b> and <b>310</b> are guest operating systems (guest OSs) A <b>312</b> and B <b>314</b>, respectively. Running on top of guest OS A <b>312</b> are two applications, application A<b>1</b> <b>316</b> and application A<b>2</b> <b>318</b>, and running on top of guest OS B <b>314</b> is application B<b>1</b> <b>320</b>.</p>
<p id="p-0047" num="0046">In regard to <figref idref="DRAWINGS">FIG. 3A</figref>, it is important to note that partition A <b>308</b> and partition B <b>314</b> (which are shown in dashed lines) are virtualized computer hardware representations that exist only as software constructions. They are made possible due to the execution of specialized virtualization software(s) that not only presents partition A <b>308</b> and partition B <b>310</b> to Guest OS A <b>312</b> and Guest OS B <b>314</b>, respectively, but which also performs all of the software steps necessary for Guest OS A <b>312</b> and Guest OS B <b>314</b> to indirectly interact with the real physical computer hardware <b>302</b>.</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 3B</figref> illustrates an alternative virtualized computing system wherein the virtualization is performed by a virtual machine monitor (VMM) <b>304</b>′ running alongside the host operating system <b>304</b>″. In certain cases, the VMM <b>304</b>′ may be an application running above the host operating system <b>304</b>″ and interacting with the computer hardware <b>302</b> only through the host operating system <b>304</b>″. In other cases, as shown in <figref idref="DRAWINGS">FIG. 3B</figref>, the VMM <b>304</b>′ may instead comprise a partially independent software system that on some levels interacts indirectly with the computer hardware <b>302</b> via the host operating system <b>304</b>″ but on other levels the VMM <b>304</b>′ interacts directly with the computer hardware <b>302</b> (similar to the way the host operating system interacts directly with the computer hardware). And yet in other cases, the VMM <b>304</b>′ may comprise a fully independent software system that on all levels interacts directly with the computer hardware <b>302</b> (similar to the way the host operating system interacts directly with the computer hardware) without utilizing the host operating system <b>304</b>″ (although still interacting with the host operating system <b>304</b>″ in order to coordinate use of the computer hardware <b>302</b> and avoid conflicts and the like).</p>
<p id="p-0049" num="0048">All of these variations for implementing the above mentioned partitions are just exemplary implementations, and nothing herein should be interpreted as limiting the invention to any particular virtualization aspect.</p>
<p id="h-0010" num="0000">Aspects of Enhanced Shadow Page Table Algorithms</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 4A</figref> depicts general aspects of exemplary shadow page tables. A guest partition A <b>402</b> and a guest partition B <b>404</b> are illustrated. Each of these partitions <b>402</b> and <b>404</b> have their own operating systems, namely, the guest A OS <b>406</b> and the guest B OS <b>408</b>, respectively. These partitions are maintained and operatively coupled by a virtualizing program, such as a hypervisor <b>420</b>. These partitions <b>402</b> and <b>404</b> also have their own guest (partition) page tables <b>410</b> and <b>414</b>, respectively, which are page tables that the respective partition operating systems operate on. Moreover, the hypervisor <b>420</b> also maintains its own shadow page tables <b>416</b> and <b>418</b>.</p>
<p id="p-0051" num="0050">In such a hypervisor environment, physical memory <b>422</b> access is controlled by the hypervisor <b>420</b> instead of either of the partitions <b>402</b> and <b>404</b> running on top of the hypervisor <b>420</b>. Moreover, the page tables <b>416</b> and <b>418</b> that the operating systems <b>406</b> and <b>408</b> operate on, respectively, are not the real pages tables that a physical machine uses. Instead, the physical memory <b>422</b> is accessed using the shadow page tables <b>416</b> and <b>418</b>. Specifically, access to the page directory root is kept private to the hypervisor <b>420</b>, and the operating system's <b>406</b> and <b>408</b> page directory root is virtualized (where the page directory root, on an x86 or x64 machine, for example, is understood to be the CR3 register). Thus, while the guest page tables <b>410</b> and <b>414</b> are operated on by their respective OSs <b>406</b> and <b>408</b> to access memory, for example, it is in fact the shadow page tables <b>416</b> and <b>418</b> that have access to the physical memory <b>422</b>.</p>
<p id="p-0052" num="0051">In one aspect of this invention, the shadow page tables <b>416</b> and <b>418</b> are notified when changes are made to the guest page tables <b>410</b> and <b>414</b>. This is necessary because when the operating systems <b>406</b> and <b>408</b> modify their respective page table <b>410</b> and <b>414</b> entries, the shadow page tables <b>416</b> and <b>418</b> must also modify its shadow page table entries to correspond to the operating system's <b>406</b> and <b>408</b> modifications.</p>
<p id="p-0053" num="0052">As used herein, as shown in <figref idref="DRAWINGS">FIG. 4B</figref>, a shadow page table is a table that maps guest (partition) virtual addresses <b>407</b> to system physical addresses <b>411</b>. In contrast, guest page table <b>410</b> maps guest virtual addresses <b>407</b> to guest (partition) physical addresses <b>409</b>. While the shadow page table maintains the “real” mappings of virtual address <b>407</b> to the “real” hardware physical memory <b>422</b>, the guest page table <b>410</b> maintains the mappings of the guest virtual addresses <b>407</b> to virtualized guest physical addresses <b>409</b>, that may be numbered from zero up to any designated value by the hypervisor <b>420</b> to make it seem like the guest A OS <b>406</b> is running on “real” hardware when in fact it is running on virtualized guest physical hardware <b>409</b>. Thus, the guest physical addresses <b>409</b> can start at zero and go up to some number N, when in fact they really may start at some non-zero number in the physical memory <b>422</b>, say, number M, and go up to some address number P in the physical memory <b>422</b>.</p>
<p id="p-0054" num="0053">In concrete terms, for example, in any given partition, a guest virtual address may start at address number 800 and may correspond to guest physical address number 0, and that number 0 address may really correspond to system physical address number 550. What the shadow page table accomplishes is a dual translation from the guest virtual address to the guest physical address (800→0) using the guest page table, and then using hypervisor internal data structures it can use the guest physical address to system physical address translations (0→550) to attain the net result of the translation from guest virtual address to the system physical address translations (800→550).</p>
<p id="p-0055" num="0054">One illustrative example of the use of the shadow page table is in the form of a virtual tagged TLB, where the latter is implemented in order to reduce the high cost of switching an address space and the associated flushing of the shadow page table buffers that occurs with an address swap. In a traditional untagged TLB implementation, when a swap of an address space is performed, the entire TLB cache associated with the address space was discarded.</p>
<p id="p-0056" num="0055">By contrast, in a tagged TLB, each TLB entry is tagged with an address space identifying which address space the TLB entry corresponds to. The cost of switching address space is thus reduced because the TLB entries are not necessarily purged from the TLB with an address switch. By implementing a virtual tagged TLB that associates a shadow page table with a specific address space, this aspect of the invention is able to achieve large performance improvements by not discarding the shadow page table when an address is swapped out.</p>
<p id="p-0057" num="0056">Put another way, the tagged TLB remembers which address space a translation is associated with. Thus, address space <b>5</b> might have a virtual-to-physical translation of 800 to 5, whereas address space <b>7</b> might have a virtual-to-physical translation of 800 to 0. The tagged TLB remembers both address space translations and thus allows for the maintenance of two shadow page tables: one for address space <b>5</b> and another one for address space <b>7</b>. Put more broadly, the tagged TLB implementation allows for the maintenance of multiple shadow page tables such that there can be a shadow page table per address space (although this one-to-one correspondence is not required, as is discussed below). The ability to maintain multiple shadow page tables means that they don't have to be discarded when an OS changes address spaces from one to another, or repopulated when the OS changes back to the original address space. The reason that shadow pages would have to be discarded at all is that upon address space switch, the guest page tables change and the shadow pages tables are based to an extent on these operating system page tables.</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 5</figref> illustrates this aspect of the invention discussed directly above, and depicts the scenario of avoiding the high cost of address switching. A guest OS <b>502</b> is running in some partition <b>501</b>, and there are two address spaces present: address space A <b>508</b> and address space B <b>510</b>. There could be, for instance, some application like Word running in address space A <b>508</b> and some other application like Internet Explorer running in address space B <b>510</b>. At some point, upon a switch of address spaces, the guest OS <b>502</b> could switch <b>509</b> from address space A <b>508</b> to address space B <b>510</b>. This switch would entail switching guest page tables, from guest page table A <b>504</b> to guest page table B <b>506</b>. Upon this switch <b>509</b>, a simplistic approach would discard the current shadow page table and come up with a new shadow page table; and if there was ever a switch back to the original address space, namely, address space A <b>508</b>, the shadow page table would have to be repopulated.</p>
<p id="p-0059" num="0058">However, with the use of a virtual tagged TLB <b>516</b>, a shadow page table can be maintained for every address space. As mentioned above, the virtual tagged TLB <b>516</b> associates shadow page tables with a specific address spaces. Thus, shadow page table A <b>515</b> is associated with address space A <b>508</b> (and its guest page table A <b>504</b>), and shadow page table B <b>514</b> is associated with address space B <b>510</b> (and its guest page table B <b>506</b>). This means that upon address space switches, shadow page tables don't have to be discarded; or upon switches back to original address spaces, shadow pages table don't have be repopulated. Maintaining such multiple shadow pages tables through a tagged virtual TLB, allows for the avoidance of the high cost of an address space switching.</p>
<p id="p-0060" num="0059">One way to identify address spaces in the context of tagged TLBs, is to use the value of the CR3 register on an x86-based system, such as the IA32 architecture, which is just a pointer to a current page table. Thus, if the CR3 register is pointing to address 0×11000, for example, then that current address space would have an address space identifier (ASID) of 0×11000 (instead of 7). Likewise, if the CR3 register is pointing to address 0×99000, then 0×99000 is the ASID for the address space where the CR3 is pointing to. This aspect of the invention is based on the assumption that the CR3 register is unique for every address space because every address space has a unique page table. On other systems, such as PowerPC, an ASID may be explicitly provided for software.</p>
<p id="p-0061" num="0060">In another aspect of the invention, the high cost of populating a new entry into the shadow page table is addressed. This problem is mitigated by batching the population of shadow page table entries from the guest page table. As was discussed above, the shadow page table has to be updated to reflect any changes in the guest page table. Specifically, when the hypervisor is notified that a new entry is needed in the shadow page table, instead of populating only a single shadow page table entry (PTE) for the page that caused a fault, the present implementation populates multiple entries. For each entry that is populated, one costly page fault into the hypervisor is potentially avoided.</p>
<p id="p-0062" num="0061"><figref idref="DRAWINGS">FIGS. 6A and 6B</figref> examine the single page entry scenario, and <figref idref="DRAWINGS">FIG. 6C</figref> considers the batched population scenario presented by this aspect of the invention. Specifically, <figref idref="DRAWINGS">FIG. 6A</figref> presents a diagram of a guest page table <b>604</b> and its corresponding shadow page table <b>606</b>. The shadow page table <b>606</b> in this example has no valid entries. Each shadow page table <b>606</b> entry points to a corresponding guest page <b>604</b> table entry.</p>
<p id="p-0063" num="0062">Turning to <figref idref="DRAWINGS">FIG. 6B</figref>, in a system without batched shadow page table population, when a page fault interrupt is received by the hypervisor for the page that maps to physical page number (PFN) <b>103</b> in the guest page table <b>604</b>, the processing of the interrupt will result in the shadow page table <b>606</b> in <figref idref="DRAWINGS">FIG. 6B</figref> with a corresponding PFN <b>103</b> entry.</p>
<p id="p-0064" num="0063">Conversely, <figref idref="DRAWINGS">FIG. 6C</figref> depicts the result of using batched shadow page table population. With batched shadow page table population, instead of populating a single PTE within the shadow page table <b>606</b>, multiple entries are populated, resulting in a shadow page table in <figref idref="DRAWINGS">FIG. 6C</figref>. In <figref idref="DRAWINGS">FIG. 6C</figref>, although the page fault interrupt was sent only for a single page, multiple pages within the shadow page table <b>606</b> were populated.</p>
<p id="p-0065" num="0064">Next, since maintaining accessed and modified flags in a page table entry is quite expensive, to address this problem, another aspect of the invention supports the notion of lazy accessed and modified flag updating. When configured in this manner, the accessed and modified flags are not correctly maintained within the guest page tables. These flags are only updated in response to an explicit request from the operating system.</p>
<p id="p-0066" num="0065"><figref idref="DRAWINGS">FIGS. 7A and 7B</figref> illustrate lazy accessed and modified flag propagation prior to a synchronization command and lazy accessed and modified flag propagation after a synchronization command, respectively. Thus, <figref idref="DRAWINGS">FIG. 7A</figref> provides a diagram that illustrates a guest page table <b>702</b> and a shadow page table <b>704</b> while executing with lazy accessed and modified flag propagation enabled prior to synchronizing the accessed and modified flags between the shadow page table <b>704</b> and the guest page table <b>702</b>. In <figref idref="DRAWINGS">FIG. 7A</figref>, a checked box is used to denote that the accessed flag is set, where an accessed flag means that a page has been read from; and, an unchecked box is used to denote that the accessed flag is not set, where the page has not been read from. Likewise, a checked box is used to denote that the modified flag is set, where a modified flag means that a page has been written to; and, an unchecked box is used to denote that the modified flag is not set, where the page has not been written to.</p>
<p id="p-0067" num="0066">In comparison to <figref idref="DRAWINGS">FIG. 7A</figref>, <figref idref="DRAWINGS">FIG. 7B</figref> illustrates the two page tables <b>702</b> and <b>704</b> after execution of the synchronization command. In <figref idref="DRAWINGS">FIG. 7B</figref>, all the accessed and modified flags within the shadow page table <b>704</b> have been synchronized to the guest page table <b>702</b>. Thus, this example shows that eleven page fault interrupts have been avoided by propagating the accessed and modified flags in a lazy fashion. This can be seen by comparing <figref idref="DRAWINGS">FIGS. 7A to 7B</figref> and counting the unchecked entries in <figref idref="DRAWINGS">FIG. 7A</figref> of the guest page table <b>702</b> and comparing them to the entries of the guest page table <b>702</b> in <figref idref="DRAWINGS">FIG. 7B</figref> which are now checked. In short, by synchronizing these flags between the guest page table <b>702</b> and the shadow page table <b>704</b> all at once, in lazy fashion, i.e., when an operating system requests synchronization and not when each access or modification is made, many fault interrupts can be avoided making the overall system much more efficient.</p>
<p id="p-0068" num="0067">Another aspect of the invention recognizes the fact that invalidation of a TLB entries on a multiprocessor system is a very expensive operation. One reason that this operation is expensive in a virtual machine environment is because TLB shoot down algorithms require multiple entries into the hypervisor per TLB invalidation request. Thus, in this aspect of the invention, the performance of TLB shoot down is improved by providing routines to perform TLB shoot down from within the hypervisor, thus reducing the number of hypervisor calls needed invalidate TLB entries. These routines allow for a single hypervisor call to flush the TLBs of all processors, instead of requiring the guest OS to manually flush the PTE once for each processor.</p>
<p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. 8A</figref> illustrates this cross-processor shoot down aspect of the invention. In <figref idref="DRAWINGS">FIG. 8A</figref>, a guest partition <b>802</b> contains a guest operating system <b>804</b>. The guest operating system <b>804</b> can make changes in a guest page table <b>805</b>. In the illustrated scenario, both of virtual processors, virtual processor A <b>806</b> and virtual processor B <b>808</b>, which correspond to real processors A <b>814</b> and real processor B <b>818</b>, respectively, happen to be pointing to the same guest page table <b>805</b>. If the guest OS <b>804</b> makes a change in the guest page table <b>805</b>, any cached TLB entries that are stored on the processor A <b>814</b> TLBs <b>812</b> and processor B <b>818</b> TLBs <b>816</b> must be changed accordingly, since these TLB entries must reflect the entries in the guest page table <b>805</b> (in its most general sense, a TLB is just a cache of page table entries). Put another way, certain entries in the TLBs may have to be shot down upon changes in guest page tables.</p>
<p id="p-0070" num="0069">In order to perform an efficient shot down across multiple TLBs, the hypervisor can obtain from an enlightened OS (i.e. an OS that is aware it is running in a partition maintained by a hypervisor) requests to shoot down multiple such TLBs and perform such shoot down instead of the OS having to send inter-processor interrupts to processors that need to have their TLBs shot down. For example, if the guest OS <b>804</b> is running on virtual processor A <b>806</b>, if it wanted to shoot down the TLB entries <b>816</b> in processor B <b>818</b>, it would send an inter-processor interrupt to virtual processor B <b>808</b>. If that virtual processor B <b>808</b> was actually scheduled to run on the real processor B <b>818</b>, the hypervisor <b>810</b> would have to process that interrupt; if it was not scheduled it would have to wait an additional time for the virtual processor B <b>808</b> to be scheduled.</p>
<p id="p-0071" num="0070">The typical TLB shoot down algorithm requires many transitions into the hypervisor <b>810</b> per a TLB shoot down request. By providing TLB invalidation routines, the hypervisor <b>410</b> may reduce the number of inter-processor interrupts. The routines allow for a single hypervisor flush <b>820</b> of the cashed page table entries in the TLBs <b>812</b> and <b>816</b> (instead of having the guest OS manually flush all of the TLBs). Moreover, if a virtual processor is not currently resident (i.e., not currently executing on any physical processor) and all the TLBs are invalidated, then when the virtual processor will be scheduled it will become unnecessary to explicitly invalidate any TLB entries corresponding to this virtual processor. The reason is that the TLBs of the corresponding physical processor will be automatically flushed when the virtual processor is eventually scheduled.</p>
<p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. 8B</figref> depicts the same scenario as in <figref idref="DRAWINGS">FIG. 8A</figref>, except instead of TLB shoot down of TLBs on physical processors, shoot down of entries in virtual tagged TLBs is illustrated. Virtual tagged TLBs <b>809</b> are embodied in shadow page tables <b>807</b>, and to the extent that entries are changed in guest page tables <b>805</b> they are changed in shadow page tables <b>807</b>. Thus, just as in <figref idref="DRAWINGS">FIG. 8A</figref>, the hypervisor <b>810</b> allows for a single call to flush cached page table entries in shadow page tables. The shadow page tables <b>807</b> are invisible to the guest OSs, such as guest OS <b>804</b>. The guest OS <b>804</b> interacts with the guest page tables, such as guest page table <b>805</b>. However, to correctly maintain the mapping between virtual guest addresses and physical system addresses, shadow page tables <b>807</b> are updated upon a change in guest page tables, like guest page table <b>805</b>.</p>
<p id="p-0073" num="0072">On a somewhat related note regarding invalidation requests of TLB entries, in other aspects of the invention, the hypervisor provides the following advanced TLB abstractions within a hypervisor to improve the efficiency of a virtual machine environment: (1) invalidate a specific virtual-to-physical mapping; (2) invalidate a list of virtual-to-physical mappings; (3) invalidate a range of virtual-to-physical mappings; and (4) invalidate all virtual-to-physical mappings. Moreover, each of these operations may be performed either for a specific address space or for all address spaces within a partition. Additionally, each operation, as suggested above, may be performed on a list of processors described by the operation.</p>
<p id="p-0074" num="0073">In yet other aspects of the invention, in <figref idref="DRAWINGS">FIG. 9A</figref>, in one operating mode, a per-virtual-processor shadow page table is utilized in order to avoid locking when editing a shadow page table. Thus, a virtual processor A <b>908</b> corresponds to a shadow page table A <b>909</b>, and a virtual processor B <b>910</b> corresponds to a shadow page table B <b>911</b>. Both virtual processors are located in a guest partition <b>902</b>, which in turn is maintained by a hypervisor <b>904</b> virtualizing physical hardware <b>906</b> for the partition <b>902</b>. In this model, each virtual processor has a separate shadow page table, even when a specific address space is being used on multiple virtual processors at the same time. When the shadow page table is allocated on a per-virtual-processor basis, it is not necessary to acquire synchronization locks while processing updates to the shadow page table.</p>
<p id="p-0075" num="0074">In other aspects of the invention, in <figref idref="DRAWINGS">FIG. 9B</figref>, in a different operating mode, a per-virtual-machine shadow page table is utilized in order to allow for sharing between the same address space on two separate virtual processors and to minimize inter-processor interrupts during TLB shoot down. Thus, a virtual processor A <b>908</b> and a virtual processor B <b>910</b> both correspond to a shadow page table <b>913</b> maintained by the hypervisor <b>904</b>, which in turn virtualizes physical hardware <b>906</b> for the guest partition <b>902</b>. This mode saves memory by sharing the same or similar data (i.e. cached page table entries) between two virtual processors instead of maintaining separate instances of the data.</p>
<p id="p-0076" num="0075">A particular virtual processor may dynamically switch between the first mode, illustrated in <figref idref="DRAWINGS">FIG. 9A</figref>, and the second mode, illustrated in <figref idref="DRAWINGS">FIG. 9B</figref>. Such switching depends on a host of external factors. One example includes the amount of memory that is consumed in the overall system on which the shadow page tables are running.</p>
<p id="p-0077" num="0076">While the present invention has been described in connection with the preferred aspects, as illustrated in the various figures, it is understood that other similar aspects may be used or modifications and additions may be made to the described aspects for performing the same function of the present invention without deviating therefrom. For example, in certain aspects of the invention, shadow page table algorithms were discussed, where these algorithms allowed for more efficient switching of process areas within partitions, population of shadow page tables, synchronization of lazy flags between shadow page tables and system visible page tables, and cross-processor shoot down of TLB entries. However, other equivalent devices to this aspect of the invention are also contemplated by the teachings herein. Therefore, the present invention should not be limited to any single aspect, but rather construed in breadth and scope in accordance with the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for employing shadow page table algorithms in order to increase the efficiency of a virtual machine environment, comprising:
<claim-text>using a partition, a page table for mapping partition virtual addresses in the partition to partition physical addresses in the partition, and a virtualizing device, wherein the virtualizing device virtualizes system physical addresses into the partition physical addresses; and</claim-text>
<claim-text>using a shadow page table maintained by the virtualizing device, wherein the shadow page table maps the partition virtual addresses to the system physical addresses, wherein the shadow page table is implemented in a virtual tagged translation lookaside buffer, wherein the virtual tagged translation lookaside buffer associates the shadow page table with an address space in the partition, wherein the address space is associated with the partition physical addresses.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the virtual tagged translation lookaside buffer associates an additional shadow page table with an additional address space, wherein upon a system switch from the address space to the additional address space, the virtual tagged translation lookaside buffer keeps track of the shadow page table.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein upon a switch back from the additional address space to the address space, the system returns to the shadow page table, and wherein the virtual tagged translation lookaside buffer keeps track of the additional shadow page table.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the value of a pointer pointing to the shadow page table is used as the identifier of the address space, wherein the identifier is used by the virtual tagged translation lookaside buffer.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least one of (a) a partition virtual address to a partition physical address mapping is invalidated, (b) a list of partition virtual addresses to partition physical addresses mappings is invalidated, (c) a range of partition virtual addresses to partition physical addresses is invalidated, and (d) all of the partition virtual addresses to the partition physical addresses are invalidated.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the virtual tagged translation lookaside buffer is associated with a virtual processor, wherein the virtual processor is virtualized by the virtualizing program, wherein the virtualizing program virtualizes a physical processor.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the physical processor lacks a physical tagged translation lookaside buffer.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the virtual tagged translation lookaside buffer is associated with a virtual processor, wherein the virtual processor is virtualized by the virtualizing program, and wherein an operating system selects via an interface between a processor with a tagged translation lookaside buffer and a processor with a non-tagged translation lookaside buffer.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising using a first virtual processor and a second virtual processor in the partition, using the shadow page table and an additional shadow page table, wherein in a first modality the shadow page table corresponds to the first virtual processor and the additional shadow page table corresponds to the second virtual processor, and wherein in a second modality the shadow page table corresponds to both the first virtual processor and the second virtual processor.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the system switches between the first modality and the second modality dynamically.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the system operates in the first modality when anticipating the editing of at least one of the shadow page table and the additional shadow page table, and wherein the system operates in the second modality when reducing inter-processor interrupts during a translation lookaside buffer shoot down.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the translation lookaside buffer shoot down entails shooting down the translation lookaside buffer corresponding to the first virtual processor and shooting down the translation lookaside buffer corresponding to the second virtual processor.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. A method for batching shadow page table population in a virtual machine environment, comprising:
<claim-text>using a partition page table with a first partition page table entry and a second partition page table entry; and</claim-text>
<claim-text>using a shadow page table, wherein upon population of the first page table entry in the shadow page table, the second page table entry is also populated.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the first partition page table entry is populated in the shadow page table upon a fault caused in the partition page table entry.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the second partition page table entry avoids the need to be populated in the shadow page table.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. A method for increasing the efficiency of page table entry shoot down across a plurality of processors, comprising:
<claim-text>using a first processor and a second processor, wherein the first processor contains a first translation lookaside buffer, and wherein the second processor contains a second translation lookaside buffer; and</claim-text>
<claim-text>using a virtualizing device for virtualizing the first processor and the second processor to a partition, wherein the virtualizing device is able to shoot down, in a single action, a page table entry in the first translation lookaside buffer and a page table entry in the second translation lookaside buffer upon a request to shoot down the page table entry in the first translation lookaside buffer.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the virtualizing device is able to shoot down the page table entry in the first translation lookaside buffer and the page table entry in the second translation lookaside buffer based on a request to modifty a page table entry in a partition page table located in the partition.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising a virtualized processor in the partition that is scheduled to run on the first processor, wherein the virtualized processor avoids the shoot down of the page table entry in the first translation lookaside buffer based on the virtualized processor being scheduled to run on the first processor.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the virtualizing device is able to shoot down a page table entry in a shadow page table associated with the partition page table.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the shadow page table is embodied as a virtual translation lookaside buffer, and wherein the virtual translation lookaside buffer is tagged.</claim-text>
</claim>
</claims>
</us-patent-grant>
