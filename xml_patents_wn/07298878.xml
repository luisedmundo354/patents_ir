<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298878-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298878</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10312779</doc-number>
<date>20010702</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>2000-198736</doc-number>
<date>20000630</date>
</priority-claim>
<priority-claim sequence="02" kind="national">
<country>JP</country>
<doc-number>2000-314550</doc-number>
<date>20001016</date>
</priority-claim>
<priority-claim sequence="03" kind="national">
<country>JP</country>
<doc-number>2001-002673</doc-number>
<date>20010110</date>
</priority-claim>
<priority-claim sequence="04" kind="national">
<country>JP</country>
<doc-number>2001-57226</doc-number>
<date>20010301</date>
</priority-claim>
<priority-claim sequence="05" kind="national">
<country>JP</country>
<doc-number>2001-187969</doc-number>
<date>20010621</date>
</priority-claim>
</priority-claims>
<us-term-of-grant>
<us-term-extension>703</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382128</main-classification>
<further-classification>382190</further-classification>
<further-classification>378 21</further-classification>
</classification-national>
<invention-title id="d0e143">Image diagnosis supporting device</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5235510</doc-number>
<kind>A</kind>
<name>Yamada et al.</name>
<date>19930800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600300</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5506913</doc-number>
<kind>A</kind>
<name>Ibison et al.</name>
<date>19960400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382132</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5781315</doc-number>
<kind>A</kind>
<name>Yamaguchi</name>
<date>19980700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>358520</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5807256</doc-number>
<kind>A</kind>
<name>Taguchi et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600425</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6441821</doc-number>
<kind>B1</kind>
<name>Nagasawa</name>
<date>20020800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>345426</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6542771</doc-number>
<kind>B2</kind>
<name>Saotome et al.</name>
<date>20030400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>600425</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6748099</doc-number>
<kind>B1</kind>
<name>Kawata</name>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382132</main-classification></classification-national>
</citation>
</references-cited>
<number-of-claims>51</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382128</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382129</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382130</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382131</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382132</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382133</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382168</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382190-194</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382203</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382256</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382260</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382274</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382276</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382291</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382297</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382305</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382181</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>600425</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>600300</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358520</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>378 21</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>378  4</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>80</number-of-drawing-sheets>
<number-of-figures>160</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20030179915</doc-number>
<kind>A1</kind>
<date>20030925</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Goto</last-name>
<first-name>Yoshihiro</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Antonelli, Terry, Stout &amp; Kraus, LLP.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Hitachi Medical Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Azarian</last-name>
<first-name>Seyed</first-name>
<department>2624</department>
</primary-examiner>
</examiners>
<pct-or-regional-filing-data>
<document-id>
<country>WO</country>
<doc-number>PCT/JP01/05703</doc-number>
<kind>00</kind>
<date>20010702</date>
</document-id>
<us-371c124-date>
<date>20030401</date>
</us-371c124-date>
</pct-or-regional-filing-data>
<pct-or-regional-publishing-data>
<document-id>
<country>WO</country>
<doc-number>WO02/02002</doc-number>
<kind>A </kind>
<date>20020110</date>
</document-id>
</pct-or-regional-publishing-data>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An image diagnosis supporting device operates, through digitizing, to apply predetermined image processing to a medical image and to generate a multi-valued image having discrete multiple values. At least one decision making processing routine is then executed on the multi-valued image and/or the medical image; and, from among shadows in the processed image, a focus candidate shadow which is likely to indicate a diseased site is extracted. The extracted focus candidate shadow is then displayed in the medical image so that it is easily identifiable.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="188.21mm" wi="82.55mm" file="US07298878-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="200.41mm" wi="158.92mm" file="US07298878-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="215.56mm" wi="170.60mm" file="US07298878-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="250.36mm" wi="179.92mm" file="US07298878-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="230.29mm" wi="179.49mm" file="US07298878-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="250.36mm" wi="177.04mm" file="US07298878-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="249.17mm" wi="168.23mm" file="US07298878-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="216.75mm" wi="135.47mm" file="US07298878-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="250.70mm" wi="127.34mm" file="US07298878-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="210.23mm" wi="83.65mm" file="US07298878-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="245.70mm" wi="140.63mm" file="US07298878-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="227.58mm" wi="137.84mm" file="US07298878-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="224.62mm" wi="132.08mm" file="US07298878-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="245.62mm" wi="173.82mm" file="US07298878-20071120-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="250.36mm" wi="166.29mm" file="US07298878-20071120-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="249.60mm" wi="139.02mm" file="US07298878-20071120-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="241.13mm" wi="163.49mm" file="US07298878-20071120-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="238.76mm" wi="161.46mm" file="US07298878-20071120-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="243.59mm" wi="169.08mm" file="US07298878-20071120-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="202.18mm" wi="144.61mm" file="US07298878-20071120-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="162.73mm" wi="146.30mm" file="US07298878-20071120-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00021" num="00021">
<img id="EMI-D00021" he="209.38mm" wi="139.78mm" file="US07298878-20071120-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00022" num="00022">
<img id="EMI-D00022" he="233.60mm" wi="179.49mm" file="US07298878-20071120-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00023" num="00023">
<img id="EMI-D00023" he="253.75mm" wi="139.95mm" file="US07298878-20071120-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00024" num="00024">
<img id="EMI-D00024" he="155.36mm" wi="143.85mm" file="US07298878-20071120-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00025" num="00025">
<img id="EMI-D00025" he="222.84mm" wi="164.51mm" file="US07298878-20071120-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00026" num="00026">
<img id="EMI-D00026" he="247.40mm" wi="140.21mm" file="US07298878-20071120-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00027" num="00027">
<img id="EMI-D00027" he="239.10mm" wi="157.65mm" file="US07298878-20071120-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00028" num="00028">
<img id="EMI-D00028" he="237.07mm" wi="179.07mm" file="US07298878-20071120-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00029" num="00029">
<img id="EMI-D00029" he="240.79mm" wi="145.12mm" file="US07298878-20071120-D00029.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00030" num="00030">
<img id="EMI-D00030" he="216.49mm" wi="161.71mm" file="US07298878-20071120-D00030.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00031" num="00031">
<img id="EMI-D00031" he="227.58mm" wi="163.75mm" file="US07298878-20071120-D00031.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00032" num="00032">
<img id="EMI-D00032" he="234.95mm" wi="174.07mm" file="US07298878-20071120-D00032.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00033" num="00033">
<img id="EMI-D00033" he="230.21mm" wi="142.83mm" file="US07298878-20071120-D00033.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00034" num="00034">
<img id="EMI-D00034" he="237.83mm" wi="166.62mm" file="US07298878-20071120-D00034.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00035" num="00035">
<img id="EMI-D00035" he="250.02mm" wi="154.69mm" file="US07298878-20071120-D00035.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00036" num="00036">
<img id="EMI-D00036" he="248.58mm" wi="93.13mm" file="US07298878-20071120-D00036.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00037" num="00037">
<img id="EMI-D00037" he="255.02mm" wi="144.70mm" file="US07298878-20071120-D00037.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00038" num="00038">
<img id="EMI-D00038" he="247.90mm" wi="82.97mm" file="US07298878-20071120-D00038.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00039" num="00039">
<img id="EMI-D00039" he="249.26mm" wi="85.85mm" file="US07298878-20071120-D00039.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00040" num="00040">
<img id="EMI-D00040" he="246.38mm" wi="113.79mm" file="US07298878-20071120-D00040.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00041" num="00041">
<img id="EMI-D00041" he="238.68mm" wi="149.27mm" file="US07298878-20071120-D00041.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00042" num="00042">
<img id="EMI-D00042" he="240.20mm" wi="87.88mm" file="US07298878-20071120-D00042.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00043" num="00043">
<img id="EMI-D00043" he="238.93mm" wi="155.36mm" file="US07298878-20071120-D00043.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00044" num="00044">
<img id="EMI-D00044" he="240.11mm" wi="113.88mm" file="US07298878-20071120-D00044.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00045" num="00045">
<img id="EMI-D00045" he="249.34mm" wi="162.90mm" file="US07298878-20071120-D00045.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00046" num="00046">
<img id="EMI-D00046" he="242.74mm" wi="178.22mm" file="US07298878-20071120-D00046.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00047" num="00047">
<img id="EMI-D00047" he="235.80mm" wi="147.40mm" file="US07298878-20071120-D00047.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00048" num="00048">
<img id="EMI-D00048" he="248.33mm" wi="167.05mm" file="US07298878-20071120-D00048.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00049" num="00049">
<img id="EMI-D00049" he="239.78mm" wi="129.46mm" file="US07298878-20071120-D00049.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00050" num="00050">
<img id="EMI-D00050" he="242.06mm" wi="135.04mm" file="US07298878-20071120-D00050.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00051" num="00051">
<img id="EMI-D00051" he="208.28mm" wi="107.95mm" file="US07298878-20071120-D00051.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00052" num="00052">
<img id="EMI-D00052" he="224.96mm" wi="165.10mm" file="US07298878-20071120-D00052.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00053" num="00053">
<img id="EMI-D00053" he="249.60mm" wi="141.48mm" file="US07298878-20071120-D00053.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00054" num="00054">
<img id="EMI-D00054" he="252.39mm" wi="104.65mm" file="US07298878-20071120-D00054.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00055" num="00055">
<img id="EMI-D00055" he="223.01mm" wi="166.45mm" file="US07298878-20071120-D00055.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00056" num="00056">
<img id="EMI-D00056" he="250.78mm" wi="125.65mm" file="US07298878-20071120-D00056.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00057" num="00057">
<img id="EMI-D00057" he="235.63mm" wi="171.53mm" file="US07298878-20071120-D00057.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00058" num="00058">
<img id="EMI-D00058" he="249.94mm" wi="148.25mm" file="US07298878-20071120-D00058.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00059" num="00059">
<img id="EMI-D00059" he="248.58mm" wi="148.93mm" file="US07298878-20071120-D00059.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00060" num="00060">
<img id="EMI-D00060" he="222.33mm" wi="169.50mm" file="US07298878-20071120-D00060.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00061" num="00061">
<img id="EMI-D00061" he="256.12mm" wi="164.42mm" file="US07298878-20071120-D00061.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00062" num="00062">
<img id="EMI-D00062" he="242.49mm" wi="173.40mm" file="US07298878-20071120-D00062.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00063" num="00063">
<img id="EMI-D00063" he="248.41mm" wi="156.89mm" file="US07298878-20071120-D00063.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00064" num="00064">
<img id="EMI-D00064" he="240.37mm" wi="177.88mm" file="US07298878-20071120-D00064.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00065" num="00065">
<img id="EMI-D00065" he="231.90mm" wi="152.65mm" file="US07298878-20071120-D00065.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00066" num="00066">
<img id="EMI-D00066" he="236.22mm" wi="146.13mm" file="US07298878-20071120-D00066.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00067" num="00067">
<img id="EMI-D00067" he="219.12mm" wi="163.58mm" file="US07298878-20071120-D00067.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00068" num="00068">
<img id="EMI-D00068" he="244.60mm" wi="168.32mm" file="US07298878-20071120-D00068.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00069" num="00069">
<img id="EMI-D00069" he="251.21mm" wi="125.90mm" file="US07298878-20071120-D00069.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00070" num="00070">
<img id="EMI-D00070" he="219.96mm" wi="168.23mm" file="US07298878-20071120-D00070.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00071" num="00071">
<img id="EMI-D00071" he="240.79mm" wi="161.71mm" file="US07298878-20071120-D00071.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00072" num="00072">
<img id="EMI-D00072" he="225.30mm" wi="166.20mm" file="US07298878-20071120-D00072.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00073" num="00073">
<img id="EMI-D00073" he="184.83mm" wi="152.15mm" file="US07298878-20071120-D00073.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00074" num="00074">
<img id="EMI-D00074" he="245.87mm" wi="164.00mm" file="US07298878-20071120-D00074.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00075" num="00075">
<img id="EMI-D00075" he="246.72mm" wi="113.62mm" file="US07298878-20071120-D00075.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00076" num="00076">
<img id="EMI-D00076" he="227.84mm" wi="169.08mm" file="US07298878-20071120-D00076.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00077" num="00077">
<img id="EMI-D00077" he="252.73mm" wi="176.02mm" file="US07298878-20071120-D00077.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00078" num="00078">
<img id="EMI-D00078" he="242.74mm" wi="122.09mm" file="US07298878-20071120-D00078.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00079" num="00079">
<img id="EMI-D00079" he="216.07mm" wi="84.41mm" file="US07298878-20071120-D00079.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00080" num="00080">
<img id="EMI-D00080" he="239.52mm" wi="106.60mm" file="US07298878-20071120-D00080.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD</heading>
<p id="p-0002" num="0001">The present invention relates to an image diagnosis supporting device, which extracts a shadow that serves as a focus candidate (a possibly diseased portion) from a medical image by computerized image processing and displays the extracted shadow as is a focus candidate so that it can be identified.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">A computerized image diagnosis supporting device analyzes shadows in a medical image by using a computer, and displays a medical image containing a focus candidate shadow selected from the shadows, thereby presenting such medical image to a doctor who has been requested to make a diagnosis. The term “medical image” used herein covers photographic images photographed with medical image diagnosis devices, such as CT devices, MRI devices and ultrasonic diagnosis devices, as well as difference images between past images and current images and the like. As to the method of selecting a focus candidate, several examples associated with medical images of lung areas have been reported in meetings and the like. Among the reports, there is a method of discriminating between a blood vessel shadow having an elongated shape and a cancer shadow having a shape close to that of a circle in a medical image of a lung area, for example, a “Quoit Filter” (refer to Journal of Computer Aided Diagnosis of Medical Images, Vol. 9, Page 21, November 1999). During a diagnosis of a medical image of a lung area, since the medical image contains not only a shadow of a cancer candidate, but also shadows such as blood vessels, cross sections of blood vessels and cross sections of bronchi, and various shadows have various sizes and shapes, it is desirable that only the shadow of the cancer candidate be extracted from the other shadows and be presented to the doctor.</p>
<p id="p-0004" num="0003">However, the above-described image diagnosis supporting device is difficult to use, because a lot of time-consuming work is required to adjust the parameters for specifying the sizes and shapes of various shadows.</p>
<p id="p-0005" num="0004">An object of this invention is to provide an image diagnosis supporting device that is capable of reducing the computing time of a computer by handling shadows of different sizes and shapes in an integrated manner when a decision as to whether a shadow is a focus candidate of a medical image is to be automatically made by the use of the computer.</p>
<p id="p-0006" num="0005">Another object of this invention is to provide an image diagnosis supporting device that is capable of easily and instantaneously displaying a shadow which seems to be an extracted focus candidate.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0007" num="0006">To achieve the above object, an image diagnosis supporting device according to this invention includes digitizing means for applying predetermined image processing to a medical image and for generating a multi-valued image, and extracting means for executing at least one decision process on the multi-valued image and/or the medical image generated by the digitizing means and for extracting a shadow which seems to be a candidate for a focus, which device identifiably displays in the medical image the focus candidate shadow extracted by the extracting means.</p>
<p id="p-0008" num="0007">In addition, since the probability that the focus candidate shadow is a focus (focus certainty) can be determined, when the focus candidate shadow is displayed by being enclosed with a marker or the like, the marker is given a size or a thickness corresponding its focus certainty.</p>
<p id="p-0009" num="0008">For example, markers are displayed in different colors in the order of the highness of the focus certainty, like red, yellow and blue, or are flash-displayed in such a manner as to blink their luminance, or are displayed in a combined manner of display in different colors and flash display.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic block diagram of the hardware to which this invention is applied;</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIGS. 2</figref><i>a </i>and <b>2</b><i>b</i>, when combined, comprise a main flowchart of the process of focus candidate extraction and display;</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 3</figref> is an image processing flow diagram showing the processing of a CT image according to the flowchart of <figref idref="DRAWINGS">FIGS. 2</figref><i>a </i>and <b>2</b><i>b; </i></p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 4</figref> is a diagram showing one example of a display on the CRT of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 5</figref> is a detailed flowchart showing the first half of Step S<b>81</b> of <figref idref="DRAWINGS">FIG. 2</figref><i>a; </i></p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 6</figref> is a detailed flowchart showing the second half of Step S<b>81</b> of <figref idref="DRAWINGS">FIG. 2</figref><i>a; </i></p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 7</figref> is a diagram showing a principle view of the multi-valued image processing of <figref idref="DRAWINGS">FIGS. 5 and 6</figref>;</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIGS. 8</figref><i>a </i>to <b>8</b><i>c </i>are diagrams showing the concept of shadow extraction;</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 9</figref> is a detailed flowchart showing Step S<b>83</b> of <figref idref="DRAWINGS">FIG. 2</figref><i>a; </i></p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 10</figref> is a flowchart showing details of the shadow extraction processing of <figref idref="DRAWINGS">FIG. 9</figref>;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 11</figref> is a flowchart showing details of the first to third decision processings of Steps S<b>43</b>, S<b>45</b> and S<b>45</b> of <figref idref="DRAWINGS">FIG. 10</figref>;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 12</figref> is a flowchart showing details of decision making subroutines A<b>1</b> to A<b>3</b> of Steps S<b>72</b>, S<b>74</b> and S<b>75</b> of <figref idref="DRAWINGS">FIG. 11</figref>;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 13</figref><i>a </i>is a conceptual diagram showing the manner of imaginary loops set on a CT image, and <figref idref="DRAWINGS">FIG. 13</figref><i>b </i>is a graph showing pixel values of each of the imaginary loops in the processing of <figref idref="DRAWINGS">FIG. 12</figref>;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIGS. 14</figref><i>a </i>and <b>14</b><i>b </i>are a conceptual diagram showing a method of searching for a pixel whose density is to be found, spirally from the central position of a shadow;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIGS. 15</figref><i>a </i>and <b>15</b><i>b </i>are conceptual diagrams showing another method of searching for a pixel whose density is to be found, spirally from the central position of a shadow;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIGS. 16(</figref><i>a</i>-<b>1</b>), <b>16</b>(<i>a</i>-<b>2</b>) through <b>16</b>(<i>c</i>-<b>1</b>), <b>16</b>(<i>c</i>-<b>2</b>) are conceptual diagrams of sampling points by each of the search methods of <figref idref="DRAWINGS">FIGS. 15 and 16</figref>;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIGS. 17</figref><i>a </i>and <b>17</b><i>b </i>are conceptual diagrams of a method of converting the shape of a shadow in a multi-valued image into the degree of density;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 18</figref> is a graph showing a method of determining whether a shadow is a focus candidate shadow or a normal shadow;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 19</figref> is a diagram showing one example of a CT image in which a focus shadow and a normal shadow exist;</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIGS. 20</figref><i>a </i>and <b>20</b><i>b</i>, when combined, comprise a detailed flowchart of each of the decision making subroutines B<b>1</b> to B<b>3</b> of Steps S<b>72</b>, S<b>74</b> and S<b>75</b> of <figref idref="DRAWINGS">FIG. 11</figref>;</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 21</figref><i>a </i>is a conceptual diagram of the case of abnormal shadow, and <figref idref="DRAWINGS">FIG. 21</figref><i>b </i>is a graph showing the pixel values in each of the decision making subroutines B<b>1</b> to B<b>3</b> of <figref idref="DRAWINGS">FIGS. 20</figref><i>a </i>and <b>20</b><i>b; </i></p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 22</figref><i>a </i>is a conceptual diagram of the case of a blood vessel cross-sectional shadow, and <figref idref="DRAWINGS">FIG. 22</figref><i>b </i>is a graph showing the pixel values in each of the decision making subroutines B<b>1</b> to B<b>3</b> of <figref idref="DRAWINGS">FIGS. 20</figref><i>a </i>and <b>20</b><i>b; </i></p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIGS. 23</figref><i>a </i>and <b>23</b><i>b</i>, when combined, comprise a detailed flowchart of each of the decision making subroutines C<b>1</b> to C<b>3</b> of Steps S<b>72</b>, S<b>74</b> and S<b>76</b> of <figref idref="DRAWINGS">FIG. 11</figref>;</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. 24</figref><i>a </i>is a conceptual diagram and <figref idref="DRAWINGS">FIG. 24</figref><i>b </i>is a graph of the processing of the decision making subroutines C<b>1</b> to C<b>3</b> of <figref idref="DRAWINGS">FIG. 23</figref>;</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 25</figref> is a detailed flowchart of each of decision making subroutines D<b>1</b> to D<b>3</b> of Steps S<b>72</b>, S<b>74</b> and S<b>76</b> of <figref idref="DRAWINGS">FIG. 11</figref>;</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIGS. 26</figref><i>a </i>to <b>26</b><i>d </i>are conceptual diagrams of the processing of the decision making subroutines D<b>1</b> to D<b>3</b> of <figref idref="DRAWINGS">FIG. 25</figref>;</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 27</figref> is a detailed flowchart of a decision making subroutine E<b>1</b> of Step S<b>72</b> of <figref idref="DRAWINGS">FIG. 11</figref>;</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIGS. 28</figref><i>a </i>and <b>28</b><i>b </i>are conceptual diagrams of the processing of the decision making subroutine E<b>1</b> of <figref idref="DRAWINGS">FIG. 27</figref>;</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 29</figref> is a detailed flowchart of a decision making subroutine F<b>1</b> of Step S<b>72</b> of <figref idref="DRAWINGS">FIG. 11</figref>;</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 30</figref><i>a </i>is a conceptual diagram and <figref idref="DRAWINGS">FIG. 30</figref><i>b </i>is a graph of the processing of the decision making subroutine F<b>1</b> of <figref idref="DRAWINGS">FIG. 29</figref>;</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. 31</figref> is an image processing flow diagram, representing a modification of <figref idref="DRAWINGS">FIG. 3</figref>, showing the case where a CT image and images being processed on a bit memory are displayed in a combined form;</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 32</figref> is a diagram showing another example of extracting a normal shadow to be excluded from focus candidate shadows;</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. 33</figref> is a diagram showing an example of the display of all images and focus candidate images in separate windows in a classified manner;</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 34</figref> is a diagram showing one example of a picture for setting the parameters required for the processing of each of the decision making subroutines;</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 35</figref> is a diagram showing an example in which a plurality of circles which enclose a plurality of focus candidate shadows are displayed in a CT image;</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIGS. 36</figref><i>a </i>and <b>36</b><i>b </i>are diagrams conceptually showing a method of processing the plurality of circles shown in <figref idref="DRAWINGS">FIG. 35</figref>, and the drawing of circular arcs so that the circles do not overlap one another, respectively;</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 37</figref> is a flowchart showing one example of the processing of drawing the circular arcs shown in <figref idref="DRAWINGS">FIG. 35</figref>;</p>
<p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. 38</figref> is a diagram showing one example of a case where a detection result picture, in which a focus candidate shadow is indicated by a marker, and a magnified picture in which the portion of the marker is displayed on a magnified scale, are displayed in one picture at the same time;</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. 39</figref> is a diagram showing one example of a display picture in which images are displayed in the order of execution of extraction of focus candidate shadows;</p>
<p id="p-0049" num="0048"><figref idref="DRAWINGS">FIGS. 40</figref><i>a </i>and <b>40</b><i>b </i>are diagrams showing the state in which a CT image is divided into 16 parts in the horizontal and vertical directions, <figref idref="DRAWINGS">FIG. 40(</figref><i>a</i>) being a view showing the case where the 16 parts are assigned numbers in order from top left to bottom left, and <figref idref="DRAWINGS">FIG. 40(</figref><i>b</i>) being a view showing the case where the 16 parts are assigned numbers in order from top left to top right;</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. 41</figref> is a diagram showing one example of a display picture in which a focus candidate shadow is displayed in order from top left to bottom left;</p>
<p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. 42</figref> is a diagram showing one example of a display picture in which a focus candidate shadow is displayed in order from top left to top right;</p>
<p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. 43</figref> is a diagram showing the state in which a CT image is divided into 40 areas in the horizontal and vertical directions;</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIGS. 44</figref><i>a </i>to <b>44</b><i>c </i>are diagrams showing a specific example in which, in the case where it is determined that a shadow is located on a wall portion, a decision is made as to whether the shadow is a focus candidate shadow, on the basis of the length of contact between the shadow and the wall portion;</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIGS. 45(</figref><i>a</i>) to <b>45</b>(<i>c</i>) comprise a diagram and graphs showing another embodiment of the decision making subroutine;</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIGS. 46</figref><i>a </i>to <b>46</b><i>d </i>are diagrams showing yet another embodiment of the decision making subroutine;</p>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIGS. 47</figref><i>a </i>and <b>47</b><i>b </i>are conceptual diagrams of the state where, when a comparatively large focus candidate shadow and blood vessel shadows overlap one another, the blood vessel shadows are excluded by cutting;</p>
<p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. 48</figref> is a flowchart showing details of the blood vessel cutting processing of <figref idref="DRAWINGS">FIGS. 47</figref><i>a </i>and <b>47</b><i>b; </i></p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 49</figref><i>a </i>is a diagram and <figref idref="DRAWINGS">FIG. 49</figref><i>b </i>is a graph showing a specific example of setting a cutting length in <figref idref="DRAWINGS">FIG. 48</figref>;</p>
<p id="p-0059" num="0058"><figref idref="DRAWINGS">FIGS. 50</figref><i>a </i>and <b>50</b><i>b </i>are diagrams showing a first modification of the decision making subroutine;</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. 51</figref><i>a </i>is a table and <figref idref="DRAWINGS">FIG. 51</figref><i>b </i>is a graph showing the result of counting;</p>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. 52</figref><i>a </i>is a diagram and <figref idref="DRAWINGS">FIG. 52</figref><i>b </i>is a graph showing a modification of the decision making subroutine of <figref idref="DRAWINGS">FIGS. 50</figref><i>a </i>and <b>50</b><i>b; </i></p>
<p id="p-0062" num="0061"><figref idref="DRAWINGS">FIGS. 53</figref><i>a </i>to <b>53</b><i>c </i>are diagrams showing the first half of a second modification of the decision making subroutine;</p>
<p id="p-0063" num="0062"><figref idref="DRAWINGS">FIGS. 54</figref><i>a </i>to <b>54</b><i>c </i>are diagrams showing the second half of the second modification of the decision making subroutine;</p>
<p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. 55</figref> is a diagram showing a specific example of the case of identifying a cancer-accompanying shadow which accompanies a cancer;</p>
<p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. 56</figref> is a flowchart showing details of cancer-accompanying object detection processing for detecting a cancer-accompanying shadow;</p>
<p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. 57</figref> is a diagram showing one example of a display picture in which the cancer-accompanying shadow detected by the cancer-accompanying object detection processing of <figref idref="DRAWINGS">FIG. 56</figref> is displayed in the state of overlapping a marker;</p>
<p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. 58</figref><i>a </i>is a diagram and <figref idref="DRAWINGS">FIGS. 58</figref><i>b </i>and <b>58</b><i>c </i>are graphs showing a third modification of the decision making subroutine;</p>
<p id="p-0068" num="0067"><figref idref="DRAWINGS">FIGS. 59</figref><i>a </i>to <b>59</b><i>c </i>are diagrams showing a modification of the decision making subroutine of <figref idref="DRAWINGS">FIGS. 58</figref><i>a </i>to <b>58</b><i>c; </i></p>
<p id="p-0069" num="0068"><figref idref="DRAWINGS">FIGS. 60</figref><i>a </i>and <b>60</b><i>b </i>are diagrams showing another modification of the decision making subroutine of <figref idref="DRAWINGS">FIGS. 58</figref><i>a </i>to <b>58</b><i>c; </i></p>
<p id="p-0070" num="0069"><figref idref="DRAWINGS">FIGS. 61</figref><i>a </i>and <b>61</b><i>b </i>are diagrams showing another embodiment of a focus candidate shadow display in which an arbitrary shadow is displayed with a mouse pointer during the display of a focus candidate shadow;</p>
<p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. 62</figref> is a flowchart showing details of the focus candidate shadow display processing of <figref idref="DRAWINGS">FIGS. 61</figref><i>a </i>and <b>61</b><i>b; </i></p>
<p id="p-0072" num="0071"><figref idref="DRAWINGS">FIGS. 63</figref><i>a </i>and <b>63</b><i>b </i>are diagrams showing a fourth modification of the decision making subroutine;</p>
<p id="p-0073" num="0072"><figref idref="DRAWINGS">FIGS. 64</figref><i>a </i>and <b>64</b><i>b </i>are diagrams showing a specific manner in which needle- or line-shaped shadows called spicules are identified;</p>
<p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. 65</figref> is a conceptual diagram of a processing method, showing a modification of each of the decision making subroutines of <figref idref="DRAWINGS">FIGS. 27 and 29</figref>;</p>
<p id="p-0075" num="0074"><figref idref="DRAWINGS">FIGS. 66</figref><i>a </i>to <b>66</b><i>f </i>are diagrams showing a specific example of the processing method of <figref idref="DRAWINGS">FIG. 65</figref>;</p>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIGS. 67</figref><i>a </i>to <b>67</b><i>d </i>are conceptual diagrams showing a fifth modification of the decision making subroutine;</p>
<p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. 68</figref> is a table showing the contents of a memory which stores data, such as position information relating to detected focus candidate shadows;</p>
<p id="p-0078" num="0077"><figref idref="DRAWINGS">FIGS. 69</figref><i>a </i>and <b>69</b><i>b </i>are diagrams showing a specific example in which focus candidate shadows photographed and extracted in the past are displayed together;</p>
<p id="p-0079" num="0078"><figref idref="DRAWINGS">FIGS. 70</figref><i>a </i>and <b>70</b> are diagrams showing a modification of the manner of displaying a marker;</p>
<p id="p-0080" num="0079"><figref idref="DRAWINGS">FIGS. 71</figref><i>a </i>and <b>71</b><i>b </i>are diagrams showing a specific example of the case where a focus candidate shadow is simply displayed in the state of being enclosed with a marker, and a specific example of the case where a CT image in an area enclosed with a marker is displayed in an emphasized state, respectively;</p>
<p id="p-0081" num="0080"><figref idref="DRAWINGS">FIG. 72</figref> is a flowchart showing a modification of a process where a CT image having an extracted focus candidate shadow and a CT image having no extracted focus candidate shadow are displayed in order as a kinematic image;</p>
<p id="p-0082" num="0081"><figref idref="DRAWINGS">FIG. 73</figref> is a flowchart showing one example of the display processing of displaying the diagnosis result provided by the image diagnosis supporting device according to this invention;</p>
<p id="p-0083" num="0082"><figref idref="DRAWINGS">FIGS. 74</figref><i>a </i>to <b>74</b><i>c </i>are diagrams showing another example of the display processing of displaying the diagnosis result provided by the image diagnosis supporting device according to this invention;</p>
<p id="p-0084" num="0083"><figref idref="DRAWINGS">FIG. 75</figref> is a flowchart showing a modification of a main flowchart of the abnormal shadow detection processing of <figref idref="DRAWINGS">FIG. 9</figref>;</p>
<p id="p-0085" num="0084"><figref idref="DRAWINGS">FIGS. 76</figref><i>a </i>to <b>76</b><i>d </i>are diagrams showing a sixth modification of the decision making subroutine;</p>
<p id="p-0086" num="0085"><figref idref="DRAWINGS">FIG. 77</figref><i>a </i>is a diagram showing the sixth modification of the decision making subroutine, and <figref idref="DRAWINGS">FIG. 77</figref><i>b </i>is a diagram illustrating one example of how to extract a shadow which seems not to be a focus;</p>
<p id="p-0087" num="0086"><figref idref="DRAWINGS">FIG. 78</figref> is a flowchart showing a modification of the display processing of displaying the diagnosis result provided by the image diagnosis supporting device according to this invention;</p>
<p id="p-0088" num="0087"><figref idref="DRAWINGS">FIGS. 79</figref><i>a </i>to <b>79</b><i>c </i>are diagrams showing one example of a display picture which accompanies the display processing of <figref idref="DRAWINGS">FIG. 78</figref>;</p>
<p id="p-0089" num="0088"><figref idref="DRAWINGS">FIGS. 80</figref><i>a </i>to <b>80</b><i>c </i>are diagrams showing a seventh modification of the decision making subroutine and showing one example of the case where the area ratio of the total area of the entire focus candidate shadow to the area of a concave portion formed in an edge portion of the shadow;</p>
<p id="p-0090" num="0089"><figref idref="DRAWINGS">FIGS. 81</figref><i>a </i>and <b>81</b><i>b </i>are diagrams showing a modification of the seventh modification of the decision making subroutine and showing one example of the process of how to extract a bifurcation of a blood vessel shadow;</p>
<p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. 82</figref> is a flowchart showing the seventh modification of the decision making subroutine and a flowchart showing one example of procedures for the case of finding the area ratio of <figref idref="DRAWINGS">FIGS. 80</figref><i>a </i>to <b>80</b><i>c; </i></p>
<p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. 83</figref> is a diagram showing one example of a display picture which accompanies the processing of <figref idref="DRAWINGS">FIGS. 80</figref><i>a </i>to <b>80</b><i>c; </i></p>
<p id="p-0093" num="0092"><figref idref="DRAWINGS">FIGS. 84</figref><i>a </i>and <b>84</b><i>b </i>are diagrams showing a modification of the method of finding the area ratio;</p>
<p id="p-0094" num="0093"><figref idref="DRAWINGS">FIGS. 85</figref><i>a </i>and <b>85</b><i>b </i>are diagrams showing a further modification of the method of finding the area ratio; and</p>
<p id="p-0095" num="0094"><figref idref="DRAWINGS">FIGS. 86</figref><i>a </i>to <b>86</b><i>c </i>are diagrams showing one example of the case where a special shadow including a shadow of a pleural membrane is found.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">BEST MODE FOR CARRYING OUT THE INVENTION</heading>
<p id="p-0096" num="0095">Preferred embodiments of an image diagnosis supporting device according to this invention will be described with reference to the accompanying drawings.</p>
<p id="p-0097" num="0096"><figref idref="DRAWINGS">FIG. 1</figref> is a block diagram showing the overall hardware construction of an image diagnosis supporting device to which this invention is applied. This image diagnosis supporting device displays extracted focus candidate shadows on the basis of a plurality of tomographic images (such as CT images) that are collected from a target area of a sample by means of, for example, an X-ray CT device. The image diagnosis supporting device selectively displays, in addition to focus candidate shadows, shadows of high certainty from among extracted focus candidate shadows or the like, or displays halfway images during this processing.</p>
<p id="p-0098" num="0097">This image diagnosis supporting device is made up of a central processing unit (CPU) <b>40</b> which controls the operation of each constituent element, a main memory <b>42</b> in which a control program for the device is stored, a magnetic disk unit <b>44</b> in which a plurality of tomographic image data and a computer program and the like are stored, a display memory <b>46</b> which temporarily stores image data to be displayed, a CRT display <b>48</b> which serves as a display device to display an image on the basis of image data read out from this display memory <b>46</b>, a mouse <b>50</b> for manipulating software switches on a screen, a controller <b>52</b> for the mouse <b>50</b>, a keyboard <b>54</b> provided with keys and switches for setting various parameters, a speaker <b>58</b>, and a common bus <b>56</b> which connects the above-described constituent elements to one another.</p>
<p id="p-0099" num="0098">In the illustrated example, only the magnetic disk unit <b>44</b> is connected as a storage device other than the main memory unit <b>42</b>, but in addition to this magnetic disk <b>44</b>, a floppy disk drive, a hard disk drive, a CD-ROM drive, a magneto-optical disk (MO) drive, a ZIP drive, a PD drive, a DVD drive and the like may also be connected. Furthermore, the image diagnosis supporting device may also be connected to various communication networks, such as a LAN (local area network), the Internet and a telephone line via a communication interface which, is not shown, so that the image diagnosis supporting device can transmit and receive image data and program data to and from other computers. In addition, the inputting and outputting of image data may also be implemented in such a manner that a medical image diagnosis device, such as an X-ray CT device and an MRI device, capable of collecting tomographic images of samples, is connected to the above-described LAN and the like.</p>
<p id="p-0100" num="0099">An operational example of the image diagnosis supporting device shown in <figref idref="DRAWINGS">FIG. 1</figref> will be described below with reference to the accompanying drawings. <figref idref="DRAWINGS">FIG. 2</figref> is a flowchart showing one example of a process to be executed by the image diagnosis supporting device. The CPU <b>40</b> shown in <figref idref="DRAWINGS">FIG. 1</figref> operates in accordance with this main flowchart. <figref idref="DRAWINGS">FIG. 3</figref> is a view showing how an CT image is processed according to this main flowchart. <figref idref="DRAWINGS">FIG. 4</figref> is a view showing one example of a display picture on the CRT display <b>48</b>. This main flowchart is activated when an operator inputs the name of a patient, who is a target of focus candidate extraction and display processing, in a field “Name of Patient” on the display picture shown in <figref idref="DRAWINGS">FIG. 4</figref> and clicks a button “COMPUTE”. Details of the processing indicated by this flowchart will be described below in the order of the steps thereof.</p>
<p id="p-0101" num="0100">[Step S<b>80</b>] The CPU <b>40</b> reads from the magnetic disk unit <b>44</b> a CT image <b>20</b> (<figref idref="DRAWINGS">FIG. 3</figref> at (a<b>1</b>)) of the patient corresponding to the patient name shown in <figref idref="DRAWINGS">FIG. 4</figref> from among CT images of the patient photographed by a CT device.</p>
<p id="p-0102" num="0101">[Step S<b>81</b>] The CPU <b>40</b> applies digitization processing to a diagnostic target organ in the read CT image, and generates a multi-valued image as shown in <figref idref="DRAWINGS">FIG. 3</figref> at (b<b>1</b>). Details of this digitization processing will be described later.</p>
<p id="p-0103" num="0102">[Step S<b>82</b>] To execute optimum detection processing corresponding to the area of the diagnostic target organ or the kind of organ, the CPU <b>40</b> determines the area or the kind of organ and makes a decision as to whether to proceed to Step S<b>83</b> or Step S<b>84</b>.</p>
<p id="p-0104" num="0103">[Step S<b>83</b>] The CPU <b>40</b> applies various kinds of image processing to the multi-valued image shown in <figref idref="DRAWINGS">FIG. 3</figref> at (b<b>1</b>), selects a focus candidate shadow and detects a shadow inferred to be a focus candidate, i.e., an abnormal shadow <b>22</b>. This abnormal shadow detection processing detects the abnormal shadow <b>22</b> without using the original CT image, on the basis of only the multi-valued image generated in Step S<b>81</b>. Details of this will be described later. By implementing abnormal shadow detection processing on the basis of a multi-valued image as in this embodiment, it is possible to shorten the time required for computer operations and the like, and it is also possible to ease the burden of computer processing.</p>
<p id="p-0105" num="0104">[Step S<b>84</b>] The CPU <b>40</b> applies various kinds of image processing to the CT image of <figref idref="DRAWINGS">FIG. 3</figref> as seen at (a<b>1</b>) and the multi-valued image of <figref idref="DRAWINGS">FIG. 3</figref> as seen at (b<b>1</b>), and selects a focus candidate shadow and detects a shadow inferred to be a focus candidate, i.e., an abnormal shadow <b>22</b>.</p>
<p id="p-0106" num="0105">Incidentally, a decision-in-progress image <b>24</b> indicative of the progress of the abnormal shadow detection processing in each of Steps S<b>83</b> and S<b>84</b> is displayed in parallel form by the side of the CT image <b>20</b> of <figref idref="DRAWINGS">FIG. 3</figref> as seen at (a<b>1</b>) on the CRT display <b>48</b>, as shown in <figref idref="DRAWINGS">FIG. 4</figref>. Incidentally, when the button “COMBINE” shown in <figref idref="DRAWINGS">FIG. 4</figref> is clicked, the decision-in-progress image <b>24</b> is combined with the CT image <b>20</b> in response to the click, and the result is displayed. The displayed contents of the decision-in-progress image <b>24</b> are sequentially changed in accordance with the processing of data on the multi-valued image (i.e., according to the stage of extraction of a focus candidate shadow). When the number of extracted abnormal shadows which are detected through the abnormal shadow detection processing is larger than a predetermined number, the CPU <b>40</b> may also provide a display indicative of decision disabled and bring the processing to an end. The result is constantly recorded on the magnetic disk. Details of this abnormal shadow detection processing will be described later.</p>
<p id="p-0107" num="0106">[Step S<b>85</b>] The CPU <b>40</b> leaves as a focus portion a focus candidate which has been determined to be an abnormal shadow in the above-described Step S<b>83</b> or S<b>84</b>, or deletes a focus candidate which has not been so determined in the above-described Step S<b>83</b> or S<b>84</b>.</p>
<p id="p-0108" num="0107">[Step S<b>86</b>] The CPU <b>40</b> determines whether the three-dimensional image structuring button <b>3</b>D shown in <figref idref="DRAWINGS">FIG. 4</figref> has been clicked, i.e., whether the three-dimensional image structuring flag is “1” or “0”, and proceeds to Step S<b>87</b> in the case of “1” (yes). In the case of “0” (no), the CPU <b>40</b> proceeds to Step S<b>88</b>. Incidentally, the three-dimensional image structuring flag can be set to “1” or “0” if the operator arbitrarily clicks the three-dimensional image structuring button of <figref idref="DRAWINGS">FIG. 4</figref> as the occasion demands.</p>
<p id="p-0109" num="0108">[Step S<b>87</b>] The processing of Step S<b>87</b> is executed in the case where the decision made in Step S<b>86</b> is yes. The CPU <b>40</b> starts structuring processing for a three-dimensional image from a plurality of CT images near the abnormal shadow. The structuring processing for a three-dimensional image is executed in parallel with the processing of Step S<b>88</b>, but after the structuring processing for a three-dimensional image has been completed, the CPU <b>40</b> may also proceed to Step S<b>88</b> to execute the processing of Step S<b>88</b>.</p>
<p id="p-0110" num="0109">[Step S<b>88</b>] In order to enable the abnormal shadow to be easily identified, the CPU <b>40</b> performs a combining processing to display the CT image of <figref idref="DRAWINGS">FIG. 3</figref> as seen at (a<b>1</b>) with color information added thereto, to display the abnormal shadow enclosed with a marker M, or to display a colored extracted focus portion or a marker in the original image (CT image). In <figref idref="DRAWINGS">FIG. 3</figref> at (a<b>2</b>), there is displayed one example of a combined image in which the abnormal shadow is enclosed with the marker M.</p>
<p id="p-0111" num="0110">[Step S<b>89</b>] The CPU <b>40</b> determines whether a multifunction image display button has been turned on, and if the button has been turned on (yes), the CPU <b>40</b> proceeds to Step S<b>8</b>A. If the button has not been turned on (no), the CPU <b>40</b> proceeds to Step S<b>8</b>B.</p>
<p id="p-0112" num="0111">[Step S<b>8</b>A] Since the multifunction image display button is in the “on” state, the CPU <b>40</b> displays the three-dimensional image structured in Step S<b>87</b>.</p>
<p id="p-0113" num="0112">[Step S<b>8</b>B] The CPU <b>40</b> determines whether an instruction to perform the same focus candidate extracting and displaying processing on an image of another patient has been given by the operator. If the CPU <b>40</b> determines that an image of another patient is to be displayed (yes), the CPU <b>40</b> returns to Step S<b>80</b> and repeatedly executes the same processing. If the CPU <b>40</b> determines that an image of another patient is not to be displayed (no), the CPU <b>40</b> proceeds to Step S<b>8</b>C.</p>
<p id="p-0114" num="0113">[Step S<b>8</b>C] The CPU <b>40</b> determines whether the “END” button shown in <figref idref="DRAWINGS">FIG. 4</figref> has been turned on by the operator. If the CPU <b>40</b> determines that the button has not been turned on (no), the CPU <b>40</b> returns to Step S<b>89</b> and continues normal image display or multifunction image display. If the CPU <b>40</b> determines that the button has been turned on (yes), the CPU <b>40</b> brings the processing to an end.</p>
<p id="p-0115" num="0114">The multi-valued image processing of Step S<b>81</b> of <figref idref="DRAWINGS">FIG. 2</figref> is performed on the basis of the CT image <b>20</b> shown in <figref idref="DRAWINGS">FIG. 3</figref>. This multi-valued image processing is, as shown in <figref idref="DRAWINGS">FIG. 3</figref>, intended to apply predetermined thresholding processing to a result obtained by calculating a standard deviation and the like of the original CT image <b>20</b> and produce a multi-valued image as shown in <figref idref="DRAWINGS">FIG. 3</figref> at (a<b>1</b>). <figref idref="DRAWINGS">FIGS. 5 and 6</figref> are flowcharts showing details of the multi-valued image processing for the diagnostic target organ in Step S<b>81</b> of <figref idref="DRAWINGS">FIG. 2</figref>. The most basic binary image processing in the multi-valued image processing will be described hereinbelow.</p>
<p id="p-0116" num="0115">Conventionally, a method of finding a difference between each CT image has been used as one of the image processing methods for emphasizing and displaying shadows. For example, the difference in CT value between pixels at the same address (x, y) is found between two adjacent CT images each having an image size of 512×512, and this difference in CT value is stored at the address (x, y) in the memory, whereby an emphasized image whose shadow is emphasized is obtained. There is also a method using standard deviation (inclusive of variance). These methods do not particularly emphasize the vicinity of the boundary of a shadow, and they extract neither the boundary (edge) of a shadow, nor a shadow only. On the other hand, this embodiment extracts a shadow in a CT image (particularly, the vicinity of the boundary of the shadow), or adopts multi-valued image processing, which enables an extracted shadow to be displayed with emphasis. <figref idref="DRAWINGS">FIG. 7</figref> is a view for theoretically explaining this multi-valued image processing. Details of the processing indicated by this main flowchart will be described below in the order of the steps thereof.</p>
<p id="p-0117" num="0116">[Step S<b>11</b>] The CPU <b>40</b> sets a particular area of predetermined shape to be the initial position on the CT image. For example, as shown in <figref idref="DRAWINGS">FIG. 7</figref>, the CPU <b>40</b> sets particular areas (small areas) <b>12</b>A and <b>12</b>B each having a square shape of 10×10 pixels within the CT image <b>20</b> (a tomographic image of the sample), and sets the areas <b>12</b>A and <b>12</b>B at an initial position at the top left corner of the CT image <b>20</b>. If the coordinates of the central position of each of these small areas <b>12</b>A and <b>12</b>B are (X, Y), the coordinates (X, Y) are respectively set to (0, 0). Incidentally, in <figref idref="DRAWINGS">FIG. 7</figref>, the small area <b>12</b>A is set inside a shadow <b>15</b>, and the small area <b>12</b>B is set to overlap the boundary (edge) of a shadow <b>16</b>. Each of these small areas is not limited to a size of 10×10 pixels, and they may also have, for example, a rectangular shape, a diamond shape or a circular shape, other than a square shape. If the central position of such a small area differs from the weighted center position of the same, the weighted center position is given priority, but either of the central position or the weighted center position may be selected for priority on a case-by-case basis.</p>
<p id="p-0118" num="0117">[Step S<b>12</b>] The CPU <b>40</b> finds an average value AV of the density value (CT value) of the small area. The obtained average value AV exhibits a high value if the small area exists in the shadow <b>15</b> like the small area <b>12</b>A of FIG. <b>7</b>, a low value if the small area does not overlap a shadow, or an approximately middle value if the small area overlaps the shadow <b>16</b> like the small area <b>12</b>B.</p>
<p id="p-0119" num="0118">[Step S<b>13</b>] The CPU <b>40</b> finds the average p (xp, yp) of the coordinate values of pixels whose density values are not smaller than the average density value AV within the small area, as well as an average m (xm, ym) of the coordinate values of pixels whose density values are smaller than the average density value AV. In the case of the small area <b>12</b>A of <figref idref="DRAWINGS">FIG. 7</figref>, average values pA and mA are approximately near the center of the small area <b>12</b>A, and the coordinate positions of both average values pA and mA approximately coincide with each other. On the other hand, in the case of the small area <b>12</b>B, an average value pB is approximately near the center of the portion of the small area <b>12</b>B that is superposed on the shadow <b>16</b>, and an average value mB is approximately near the center of the portion of the small area <b>12</b>B that is not superposed on the shadow <b>16</b>, and the coordinates of both average values pB and mB are removed from each other.</p>
<p id="p-0120" num="0119">[Step S<b>14</b>] The CPU <b>40</b> determines the distance D between the coordinates (xp, xy) of the average value p and the coordinates (xm, xm) of the average value m. In the case of the small area <b>12</b>A of <figref idref="DRAWINGS">FIG. 7</figref>, since the average values pA and mA are the same, the distance D becomes “0”. In the case of the small area <b>12</b>B, since the average value pB and the average value mB are spaced from each other, the distance D becomes a corresponding distance DB. Namely, this distance D tends to be large in the case where the small area is located near the edge of the shadow, or to be small in the case where the small area does not overlap the shadow.</p>
<p id="p-0121" num="0120">[Step S<b>15</b>] To make the above-described tendency more remarkable, in this step S<b>15</b>, the CPU <b>40</b> finds M=g·f(D) as a moment M at the central coordinates (X, Y) of the small area on the basis of the distance D found in Step S<b>14</b>. This moment M is a value related to (X, Y). For example, letting Np be the number of pixels whose density values are not smaller than the above-described average value AV within the small area, and letting Nm be the number of pixels whose density values are smaller than the average value AV, each of the moments M<b>1</b> to M<b>3</b> found on the basis of the following equations is defined as the moment M in Step S<b>15</b>:</p>
<p id="p-0122" num="0121">the moment M<b>1</b> is M<b>1</b>=Np×Nm×D;</p>
<p id="p-0123" num="0122">the moment M<b>2</b> is M<b>2</b>=Nor×D,</p>
<p id="p-0124" num="0123">(where Nor is the larger of Np and Nm); and</p>
<p id="p-0125" num="0124">the moment M<b>3</b> is M<b>3</b>=an existing variance×D,</p>
<p id="p-0126" num="0125">(where D may be the δ-th power of a value of about 1-3.)</p>
<p id="p-0127" num="0126">In general, a computation including D is effective. In addition, even in the decision processing which will be described later, a computation result including D relative to a focus area can be used for decision.</p>
<p id="p-0128" num="0127">[Step S<b>16</b>] The CPU <b>40</b> adds 1 to the central coordinate X of the small area in order to move the small area in the X direction of the image.</p>
<p id="p-0129" num="0128">[Step S<b>17</b>] The CPU <b>40</b> determines whether the value of the coordinate X of the center of the small area is a maximum (a position where the small area is moved beyond the right end of the image), and if the CPU <b>40</b> determines that the value is a maximum (yes), the CPU <b>40</b> proceeds to Step S<b>17</b>. If the CPU <b>40</b> determines that the value is not a maximum (no), the CPU <b>40</b> returns to Step S<b>12</b>, where the CPU <b>40</b> repeats the processing of Step S<b>12</b> to Step S<b>17</b> until the value of the central coordinate X becomes a maximum.</p>
<p id="p-0130" num="0129">[Step S<b>18</b>] Since it has been determined in the above-described step S<b>17</b> that the central coordinate X of the small area is a maximum, the CPU <b>40</b> returns the central coordinate X to an initial value (normally, “0”) in order to return the small area to the left end of the image.</p>
<p id="p-0131" num="0130">[Step S<b>19</b>] The CPU <b>40</b> adds “1” to the central coordinate Y of the small area in order to move the small area in the Y direction of the image.</p>
<p id="p-0132" num="0131">[Step S<b>20</b>] The CPU <b>40</b> determines whether the value of the coordinate Y of the center of the small area is a maximum (a position where the small area is moved beyond the right end of the image), and if the CPU <b>40</b> determines that the value is a maximum (yes), the CPU <b>40</b> brings the processing to an end, and proceeds to Step S<b>21</b> of <figref idref="DRAWINGS">FIG. 6</figref> via a connector A. If the CPU <b>40</b> determines that the value is not a maximum (no), the CPU <b>40</b> returns to Step S<b>12</b>, where the CPU <b>40</b> repeats the processing of Step S<b>12</b> to Step S<b>20</b> until Y becomes a maximum. In this manner, the CPU <b>40</b> scans the small area from the top left to the bottom right of the CT image <b>20</b> and sequentially calculates the moment M at the central coordinate position of the small area.</p>
<p id="p-0133" num="0132">A method of extracting pixels located in a shadow or near the boundary of the shadow from each CT image <b>20</b> by using the moment M obtained in this manner will be described below in accordance with the flowchart shown in <figref idref="DRAWINGS">FIG. 6</figref>.</p>
<p id="p-0134" num="0133">[Step S<b>21</b>] The CPU <b>40</b> reads a constant inputted from the keyboard by the operator, or a constant stored in advance in the magnetic disk <b>44</b> or the like, as a threshold for determining whether each pixel of the CT image <b>20</b> is in a shadow or near the boundary of the shadow, and specifies the read constant as a constant.</p>
<p id="p-0135" num="0134">[Step S<b>22</b>] In order to set a pixel which is a decision target (a decision target pixel) in the initial position which is the top left corner of the CT image <b>20</b>, the CPU <b>40</b> set the coordinates (X, Y) of the decision target pixel) to (0, 0).</p>
<p id="p-0136" num="0135">[Step S<b>23</b>] The CPU <b>40</b> reads the moment M obtained in Step S<b>15</b> of <figref idref="DRAWINGS">FIG. 5</figref> as to a small area centered about the coordinates (X, Y) of the decision target pixel.</p>
<p id="p-0137" num="0136">[Step S<b>24</b>] The CPU <b>40</b> determines whether the read moment M is larger than the constant specified in Step S<b>21</b>. If the CPU <b>40</b> determines that the read moment M is larger (yes), the CPU <b>40</b> proceeds to Step S<b>25</b>, whereas if the CPU <b>40</b> determines that the read moment M is not larger (no), the CPU <b>40</b> jumps to Step S<b>26</b>.</p>
<p id="p-0138" num="0137">[Step S<b>25</b>] The fact that it has been determined in Step S<b>24</b> that the moment M is larger than the constant means that the decision target pixel corresponding to the coordinates (X, Y) corresponds to the shadow or the boundary of the shadow. Accordingly, in this step, the CPU <b>40</b> extracts the coordinates (X, Y) and stores them in the memory (the main memory <b>42</b> or the magnetic disk unit <b>44</b>). Specifically, if the CPU <b>40</b> has determined in Step S<b>24</b> that the moment M is larger than the constant (yes), the CPU <b>40</b> sets a binary high level “1” to the coordinates (X, Y). On the other hand, if the CPU <b>40</b> determines in Step S<b>24</b> that the moment M is not larger than the constant (no), the CPU <b>40</b> sets a binary low level “0” to the coordinates (X, Y). In this manner, each set of coordinates is set to either of a low level “0” or a high level “1” and is binarized. By binarizing each set of coordinates in this manner, it is possible to express each set of coordinates by one bit, whereby it is possible to simplify the following processing.</p>
<p id="p-0139" num="0138">[Step S<b>26</b>] The CPU <b>40</b> adds “1” to the coordinate X in order to move the coordinates of the decision target pixel in the X direction.</p>
<p id="p-0140" num="0139">[Step S<b>27</b>] The CPU <b>40</b> determines whether the value of the coordinate X of the decision target pixel is a maximum (a position beyond the right end of the image), and if the CPU <b>40</b> determines that the value is a maximum (yes), the CPU <b>40</b> proceeds to Step S<b>28</b>. If the CPU <b>40</b> determines that the value is not a maximum (no), the CPU <b>40</b> returns to Step S<b>23</b>, where the CPU <b>40</b> repeats the processing of Step S<b>233</b> to Step S<b>26</b> until X becomes a maximum.</p>
<p id="p-0141" num="0140">[Step S<b>28</b>] Since the CPU <b>40</b> has determined in the above-described step S<b>27</b> that the coordinate X of the decision target pixel is a maximum, the CPU <b>40</b> resets the coordinate X to “0” in order to return the decision target pixel to the left end, and adds “1” to the coordinate Y of the decision target pixel in order to move the decision target pixel in the Y direction.</p>
<p id="p-0142" num="0141">[Step S<b>29</b>] The CPU <b>40</b> determines whether the coordinate Y of the decision target pixel is a maximum (a position beyond the bottom end of the image), and if the CPU <b>40</b> determines that the value is a maximum (yes), the CPU <b>40</b> brings the processing to an end. If the CPU <b>40</b> determines that the value is not a maximum (no), the CPU <b>40</b> returns to Step S<b>23</b>, where the CPU <b>40</b> repeats the processing of Step S<b>23</b> to Step S<b>28</b> until Y becomes a maximum.</p>
<p id="p-0143" num="0142">In this manner, the CPU <b>40</b> scans the decision target pixel from the top left to the bottom right of the CT image <b>20</b> and makes a decision as to whether the decision target pixel corresponds to the shadow or the boundary of the shadow. Through the above-described processing, the central point (X, Y) of the small area having the moment M larger than the constant, i.e., the coordinate point of the pixel lying in the shadow or the boundary of the shadow, is sequentially stored in the memory (the main memory <b>42</b> or the magnetic disk unit <b>44</b>). Incidentally, in the description of <figref idref="DRAWINGS">FIGS. 5 and 6</figref>, reference has been made to binarization using a low level “0” and a high level “1”, but the CT image <b>20</b> can be digitized with an arbitrary number of values by specifying a plurality of constants in Step S<b>21</b>. For example, it is possible to digitize the CT image with four values by specifying three constants C<b>1</b>, C<b>2</b> and C<b>3</b> and determining to which of the following cases the moment M corresponds: the case where the moment M is smaller than the constant C<b>1</b>, the case where the moment M is not smaller than the constant C<b>1</b> and is smaller than the constant C<b>2</b>, the case where the moment M is not smaller than the constant C<b>2</b> and is larger than the constant C<b>3</b>, and the case where the moment M is not smaller than the constant C<b>3</b>. In the case of four-value digitization, one pixel is expressed by two bits. Incidentally, if the CT image is to be digitized with yet another number of values, a plurality of constants may be similarly specified so that the CT image can be digitized on the basis of the constants.</p>
<p id="p-0144" num="0143"><figref idref="DRAWINGS">FIGS. 8</figref><i>a </i>to <b>8</b><i>c </i>show the concept of how a shadow is extracted by the above-described method of extracting a pixel located in a shadow or near the boundary of the shadow. When the above-described processing is executed on a CT image <b>21</b> having a circular shadow which, as shown in <figref idref="DRAWINGS">FIG. 8</figref><i>a</i>, exhibits the highest CT value near the center of the shadow and gradually decreases in CT value in the radius direction, a shadow <b>22</b> of a multi-valued image, the boundary of which is clear, as shown in <figref idref="DRAWINGS">FIG. 8</figref><i>b</i>, is stored in the memory and is also displayed on the CRT display <b>48</b>. In addition, by increasing the constant to be specified in Step S<b>21</b>, a ring-shaped shadow in which a boundary <b>23</b> of the shadow is emphasized, as shown in <figref idref="DRAWINGS">FIG. 8</figref><i>c </i>is extracted. Accordingly, by variously changing the constant to be specified in Step S<b>21</b>, it is possible to extract only the boundary of the shadow or to extract the entire shadow. In addition, the boundary, etc., of the shadow extracted in this manner can also be displayed with emphasis.</p>
<p id="p-0145" num="0144">The abnormal shadow detection processing of Step S<b>83</b> of <figref idref="DRAWINGS">FIG. 2</figref><i>a </i>is performed by using the multi-valued image generated by the above-described multi-valued image processing. In addition, the abnormal shadow detection processing of Step S<b>84</b> of <figref idref="DRAWINGS">FIG. 2</figref><i>a </i>is performed by using this multi-valued image and the CT image <b>20</b>, which is the original image. In the case where abnormal shadow detection processing is performed by using a multi-valued image like that used in Step S<b>83</b>, it is desirable to perform the abnormal shadow detection processing by using a binary image and a multi-valued image digitized with a larger number of values (for example, an eight-valued image or a sixteen-valued image). In the following description, reference will be made to a case where abnormality detection processing is performed by using a binary image and the CT image <b>20</b>. Incidentally, in the case where the abnormal shadow detection processing is to be performed by using only a multi-valued image like in Step S<b>83</b> of <figref idref="DRAWINGS">FIG. 2</figref><i>a</i>, it is similarly possible to cope with the abnormal shadow detection processing by reading the CT image <b>20</b> as the multi-valued image.</p>
<p id="p-0146" num="0145"><figref idref="DRAWINGS">FIG. 9</figref> is a view showing the main flowchart of the abnormal shadow detection processing. The abnormal shadow detection processing of <figref idref="DRAWINGS">FIG. 9</figref> extracts only pixels belonging to the range of predetermined CT values (pixel values) from a medical image and generates a medical image for a decision target, according to a parameter indicative of the kind of shadow, such as a small shadow, a large shadow, a ground glass opacity or a high-density shadow. Namely, there are kinds of shadows, such as a small shadow, a large shadow, a ground glass opacity and a high-density shadow. It is empirically confirmed that each of the shadows distinctively appears in a predetermined pixel value range within a medical image. For example, small shadows and large shadows remarkably appear in the range of pixel values (CT values) from −800 to 0, ground glass opacities in the range of from −800 to −400, and high-density shadows in the range of from −400 to 0. Accordingly, in this embodiment, only pixels belonging to a predetermined range of pixel values are extracted from a medical image according to the kind of shadow, a new target medical image is generated, and extracting processing for a focus candidate shadow is performed on the basis of the new target medical image. In addition, in the case of ground glass opacities, since a focus occurs in many cases in the periphery of a lung region, it is effective to perform separate processing methods on a central portion and on a peripheral portion.</p>
<p id="p-0147" num="0146">Small shadow detection processing performs abnormal shadow detection processing on a shadow in a decision target medical image made up of pixels which belong to the range of CT values from −800 to 0 within the CT image <b>20</b>. Large shadow detection processing performs abnormal shadow detection processing on a shadow in a decision target medical image made up of pixels which belong to the range of CT values from −800 to 0. Glass-shaped shadow detection processing performs abnormal shadow detection processing on a shadow in a decision target medical image made up of pixels which belong to the range of CT values from −800 to −400. High-density shadow detection processing performs abnormal shadow detection processing on a shadow in a decision target medical image made up of pixels which belong to the range of CT values from −400 to 0. Incidentally, the multi-valued image extracting processing of Step S<b>81</b> of <figref idref="DRAWINGS">FIG. 2</figref><i>a </i>may be performed on the basis of this target medical image, so that the abnormal shadow detection processing of Step S<b>83</b> and Step S<b>84</b> of <figref idref="DRAWINGS">FIG. 2</figref><i>a </i>is performed by using the obtained multi-valued image. Accordingly, in the following description, the term “CT image” includes this target medical image and a multi-valued image, and the terms “pixel value” and “density value” include pixel values in a multi-valued image.</p>
<p id="p-0148" num="0147"><figref idref="DRAWINGS">FIG. 10</figref> is a view showing details of each of these types of shadow detection processing. The types of shadow processing executed in the abnormal shadow detection processing shown in <figref idref="DRAWINGS">FIG. 9</figref> are approximately common to one another except that predetermined values Ra and Rb used in Steps S<b>41</b>, S<b>44</b> and S<b>46</b> differ among the types of shadow processing. The size of a shadow is expressed by the number of pixels which constitute the shadow. There exist various focus shadows of different sizes, such as small shadows, large shadows, ground glass opacitys or high-density shadows. In the case where decision processing is performed on these shadows, similar processing is executed on each of the shadows by using a parameter corresponding to the size of each of the shadows. However, in the case where a shadow itself is small or large, or where shadows appear at different locations, there occurs the problem that if the same decision processing is performed with the same parameter, the accuracy becomes lower. Therefore, it is necessary to increase or decrease a parameter according to the size of each shadow. In this embodiment, if a shadow is smaller than the predetermined value Ra, the image of the shadow is enlarged; whereas, if a shadow is larger than the predetermined value Rb, the image of the shadow is reduced, whereby the image of the shadow is converted into a shadow having a size which enables decision processing to be most efficiently performed on the shadow, and the decision processing is performed on the converted shadow. Details of this shadow detection processing will be described below, step by step.</p>
<p id="p-0149" num="0148">[Step S<b>41</b>] The CPU <b>40</b> determines whether the size (in this case, the number of pixels) of a shadow, which constitutes a detection target, is smaller than the predetermined value Ra; and, if the CPU <b>40</b> determines that the size of the shadow is smaller (yes), the CPU <b>40</b> proceeds to Step S<b>42</b>; whereas, if the CPU <b>40</b> determines that the size of the shadow is not smaller (yes), the CPU <b>40</b> jumps to Step S<b>44</b>.</p>
<p id="p-0150" num="0149">[Step S<b>42</b>] Since it has been determined in Step S<b>41</b> that the size of the shadow is smaller, the CPU <b>40</b> enlarges the shadow image to a size corresponding to a parameter to be used in the first decision processing of Step S<b>43</b>. In this case, the pixel value between each pixel is determined by interpolation processing.</p>
<p id="p-0151" num="0150">[Step S<b>43</b>] The CPU <b>40</b> executes the first decision processing on the shadow that was enlarged in Step S<b>42</b>.</p>
<p id="p-0152" num="0151">[Step S<b>44</b>] The CPU <b>40</b> determines whether the size of the shadow, which constitutes a decision target, is not smaller than the predetermined value Ra and not larger than the predetermined value Rb or more, i.e., whether the size of the shadow is within a predetermined range. If the CPU <b>40</b> determines that the size of the shadow is within the predetermined range (yes), the CPU <b>40</b> proceeds to Step S<b>45</b>; whereas, if the CPU <b>40</b> determines that the size of the shadow is not within the predetermined range (no), the CPU <b>40</b> jumps to Step S<b>46</b>.</p>
<p id="p-0153" num="0152">[Step S<b>45</b>] The CPU <b>40</b> executes second decision processing on the shadow whose size is within the predetermined range of Step S<b>44</b>.</p>
<p id="p-0154" num="0153">[Step S<b>46</b>] The CPU <b>40</b> determines whether the size of the shadow extracted according to each CT value is larger than the predetermined value Rb; and, if the CPU <b>40</b> determines that the size of the shadow is larger (yes), the CPU <b>40</b> proceeds to Step S<b>47</b>; whereas, if the CPU <b>40</b> determines that the size of the shadow is not larger (no), the CPU <b>40</b> brings the processing to an end and proceeds to the next shadow decision processing shown in <figref idref="DRAWINGS">FIG. 9</figref>.</p>
<p id="p-0155" num="0154">[Step S<b>47</b>] Since the CPU <b>40</b> determines in Step S<b>46</b> that the size of the shadow is larger than the predetermined value Rb, the CPU <b>40</b> reduces the image of the shadow to a size corresponding to a parameter to be used in the third decision processing of Step S<b>48</b>.</p>
<p id="p-0156" num="0155">[Step S<b>48</b>] The CPU <b>40</b> executes the third decision processing on the shadow that has been reduced in Step S<b>47</b>, and then proceeds to the shadow decision processing shown in <figref idref="DRAWINGS">FIG. 9</figref> (large-shadow detection processing, ground glass opacity detection processing or high-density shadow detection processing). Incidentally, although the number of pixels are used as the size of the shadow, the maximum diameter or the minimum diameter of the shadow may also be used. In this case, it is preferable to set a minimum diameter of about 7 mm to the predetermined value Ra and a maximum diameter of about 21 mm to the predetermined value Rb.</p>
<p id="p-0157" num="0156"><figref idref="DRAWINGS">FIG. 11</figref> is a flowchart showing details of the first to third decision processing of Steps S<b>43</b>, S<b>45</b> and S<b>48</b> of <figref idref="DRAWINGS">FIG. 10</figref>. The first to third decision processing are approximately common to one another except that various different parameters are used in the respective decision making subroutines of Steps S<b>72</b>, S<b>74</b> and S<b>76</b>. The first decision processing is executed on an image which has been enlarged by Step S<b>42</b> of the shadow decision, processing shown in <figref idref="DRAWINGS">FIG. 10</figref>. The second decision processing is executed on an image whose shadow size has been determined as accommodated within a predetermined range, by Step S<b>44</b> of the shadow decision processing shown in <figref idref="DRAWINGS">FIG. 10</figref>. The third decision processing is executed on an image which has been reduced by Step S<b>47</b> of the shadow decision processing shown in <figref idref="DRAWINGS">FIG. 10</figref>. In each of the first to third decision processing, a combination of decision making subroutines is changed according to the slice thickness of each CT image.</p>
<p id="p-0158" num="0157">In a medical image, a shadow such as a cancer, a blood vessel, a cross section of a blood vessel, a cross section of a bronchus and the like are photographed together. As the slice thickness of a medical image is made different, a particular shadow of the shadows contained in the medical image becomes clear or obscure. For example, if the slice thickness is small, a shadow corresponding to a blood vessel extremely diminishes and becomes difficult to recognize. As the slice thickness increases, the shadow of the blood vessel clearly appears. Accordingly, in the case where the slice thickness is small, it is necessary to make a decision as to whether the shadow is a blood vessel shadow or a focus candidate shadow. Contrarily, in the case where the slice thickness is large, it is possible to clearly identify the shadow of a blood vessel, so that decision processing is not needed. In addition, in the case where a shadow is bound to a lung wall, as shown in <figref idref="DRAWINGS">FIG. 44</figref>, it is desirable to change processing according to the location where the shadow is present.</p>
<p id="p-0159" num="0158">Thus, processing is performed with a plurality of specialized decision making subroutines, and, finally, a logical OR operation is carried out with respect to all the subroutine results. This embodiment is provided with first combined processing including decision processing E<b>1</b> and E<b>2</b> necessary for shadow decision in the case of a small slice thickness, as well as second and third combined processing, not including the decision processing E<b>1</b> and E<b>2</b>. One of these first to third processes are appropriately selected according to slice thicknesses Sa and Sb. Details of the first to third decision processing will be described below in the order of the steps thereof.</p>
<p id="p-0160" num="0159">[Step S<b>71</b>] The CPU <b>40</b> determines whether the slice thickness of the CT image <b>20</b> is larger than the predetermined value Sa (for example, 10 mm). If the CPU <b>40</b> determines that the slice thickness is larger (yes), the CPU <b>40</b> proceeds to the next step S<b>72</b>, whereas if the CPU <b>40</b> determines that the slice thickness is not larger (no), the CPU <b>40</b> jumps to Step S<b>73</b>.</p>
<p id="p-0161" num="0160">[Step S<b>72</b>] The CPU <b>40</b> executes the first combined processing, combining decision making subroutines A<b>1</b> to F<b>1</b>.</p>
<p id="p-0162" num="0161">[Step S<b>73</b>] The CPU <b>40</b> determines whether the slice thickness of the CT image <b>20</b> is not larger than the predetermined value Sa and not smaller than the predetermined value Sb, i.e., within a predetermined range. If the CPU <b>40</b> determines that the slice thickness is within the predetermined range (yes), the CPU <b>40</b> proceeds to Step S<b>74</b>; whereas, if the CPU <b>40</b> determines that the slice thickness is not within the predetermined range (no), the CPU <b>40</b> jumps to Step S<b>75</b>.</p>
<p id="p-0163" num="0162">[Step S<b>74</b>] The CPU <b>40</b> executes the second combined processing made up of a combination of the decision making subroutines A<b>2</b> to D<b>2</b>. In this second combined processing, decision making subroutines corresponding to the decision making subroutines E<b>1</b> and F<b>1</b> are not executed. The decision making subroutines E<b>1</b> and F<b>1</b> constitute processing for determining whether a shadow is a shadow corresponding to a blood vessel; and, in the case of small slick thickness, a shadow corresponding to a blood vessel diminishes greatly and the decision making subroutines E<b>1</b> and F<b>1</b> are unable to recognize such shadows. Accordingly, in this step, the decision making subroutines are not executed. Incidentally, it goes without saying that the CPU <b>40</b> may execute the decision making subroutines E<b>2</b> and F<b>2</b> similarly to Step S<b>72</b>.</p>
<p id="p-0164" num="0163">[Step S<b>75</b>] The CPU <b>40</b> determines whether the slice thickness of the CT image <b>20</b> is smaller than the predetermined value Sb. If the CPU <b>40</b> determines that the slice thickness is smaller (yes), the CPU <b>40</b> proceeds to the next step S<b>76</b>; whereas, if the CPU <b>40</b> determines that the slice thickness is not smaller (no), the CPU <b>40</b> brings the processing to an end and proceeds to Step S<b>44</b> or S<b>46</b> of <figref idref="DRAWINGS">FIG. 10</figref>.</p>
<p id="p-0165" num="0164">[Step S<b>76</b>] The CPU <b>40</b> executes the third combined processing made up of a combination of decision making subroutines A<b>3</b> to D<b>3</b>. In this third combined processing, decision making subroutines corresponding to the decision making subroutines E<b>1</b> and F<b>1</b> are not executed. Similarly to the case of the above-described step, since the decision making subroutines E<b>1</b> and F<b>1</b> constitute processing for determining whether a shadow is a shadow corresponding to a blood vessel, decision making subroutines related to the decision making subroutines E<b>1</b> and F<b>1</b> are not executed. Incidentally, it goes without saying that the CPU <b>40</b> may execute the decision making subroutines E<b>3</b> and F<b>3</b> similarly to the case of Step S<b>72</b>.</p>
<p id="p-0166" num="0165">The respective decision making subroutines A<b>1</b> to A<b>3</b> that are executed in Steps S<b>72</b>, S<b>74</b> and S<b>76</b> of <figref idref="DRAWINGS">FIG. 11</figref> will be described below. <figref idref="DRAWINGS">FIG. 12</figref> is a flowchart showing details of each of the decision making subroutines A<b>1</b> to A<b>3</b>. <figref idref="DRAWINGS">FIGS. 13</figref><i>a </i>and <b>13</b><i>b </i>are provided to conceptually show the manner of processing each of these decision making subroutines A<b>1</b> to A<b>3</b>, in which <figref idref="DRAWINGS">FIG. 13(</figref><i>a</i>) is a diagram showing the manner in which imaginary loops are set on a CT image, while <figref idref="DRAWINGS">FIG. 13(</figref><i>b</i>) is a graph showing the pixel values of each of the imaginary loops. In general, although there are some exceptions, the correlation of densities of a shadow located on a loop of radius r from the central position of the shadow exhibits a tendency to become larger in a focus shadow than in a blood vessel cross-sectional shadow. To use this tendency in shadow decision processing, the correlation of density variations of a shadow between adjacent loops spaced a small radius dr apart from each other is found. Namely, it is known that the density of a shadow greatly differs between the vicinity of the center of the shadow and the vicinity of the periphery thereof, so that if the correlation of density values only between adjacent loops is found, it is impossible to find an accurate correlation between both. In this embodiment, the correlation of density variations of the shadow is found. Incidentally, the vicinity of the central position of the shadow is determined on the basis of the multi-valued image (b<b>1</b>) of <figref idref="DRAWINGS">FIG. 3</figref>, and the determined center of the shadow is applied to the CT image <b>20</b> of <figref idref="DRAWINGS">FIG. 3</figref>, as seen at (a<b>1</b>), and then the density on each loop is found. Incidentally, in the case of the Step S<b>83</b> of <figref idref="DRAWINGS">FIG. 2</figref><i>a</i>, multi-valued information indicative of a multi-valued image other than a binary image is used in place of the CT image <b>20</b>. Details of these decision making subroutines A<b>1</b> to A<b>3</b> will be described below in the order of the steps thereof.</p>
<p id="p-0167" num="0166">[Step S<b>1</b>] The CPU <b>40</b> sets a radius r at which to search a shadow, as an initial value. In <figref idref="DRAWINGS">FIG. 13</figref><i>a</i>, for example, a value equivalent to about 1.5 times a square-shaped small area of approximately 10×10 pixels is set as the radius r.</p>
<p id="p-0168" num="0167">[Step S<b>2</b>] The CPU <b>40</b> rotates at the radius r by one degree at one time about the vicinity of the center of the shadow, and it samples and records each pixel value in the range of angles θ=0 to 360 degrees. Incidentally, it is preferable to add a constant value for each loop in order to equalize the density average of each loop.</p>
<p id="p-0169" num="0168">[Step S<b>3</b>] The CPU <b>40</b> sets a radius r+d obtained by adding the radius r to the small radius dr, to obtain the radius r of the next loop. In FIG. <b>13</b><i>a</i>, for example, a value equivalent to about 1.2 times the above-described small area is set as the small radius dr.</p>
<p id="p-0170" num="0169">[Step S<b>4</b>] The CPU <b>40</b> determines whether the radius r is a maximum, and, if the radius r is not a maximum (no), the CPU <b>40</b> jumps to Step S<b>2</b>; whereas, if the radius r is a maximum (yes), the CPU <b>40</b> proceeds to Step S<b>5</b>. Incidentally, the maximum radius is a radius which is set in advance according to, for example, the size of a focus target to be extracted and the kinds of first to third decision processing.</p>
<p id="p-0171" num="0170">[Step S<b>5</b>] The CPU <b>40</b> performs a computation based on a predetermined decision formula. For example, as shown in <figref idref="DRAWINGS">FIG. 13</figref><i>a</i>, the CPU <b>40</b> determines the density differences between pixels at a point P (r, θ) and pixels at a point P′ (r′, θ) in the range of 0 to 360 degrees, and determines the sum of the absolute values of the density differences. Namely, the CPU <b>40</b> finds the correlation of densities between adjacent loops on the basis of the following formula (1):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Σ|density difference between pixels at the same angle on adjacent loops|  (1)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0172" num="0171">As described above, the correlation of shadows between adjacent loops is larger in a focus shadow than in a blood vessel cross-sectional shadow, so that the computation result of the above formula (1) tends to be smaller in a focus shadow than in a blood vessel cross-sectional shadow. This fact can also clearly understood from each curve shown in <figref idref="DRAWINGS">FIG. 13</figref><i>b</i>. Specifically, the curve (solid line) of a loop=1 and the curve (dotted line) of a loop=2 show similar density variations, and, therefore, it can be said that the correlation therebetween is extremely large. On the other hand, the curve (dotted line) of the loop=2 and the curve (dot-dashed line) of a loop=3 show utterly different density variations, and therefore, it can be said that the correlation therebetween is small. Incidentally, the computing formula for finding the correlation between adjacent loops is not limited to the above-described formula (1).</p>
<p id="p-0173" num="0172">On the other hand, although there are some exceptions, the magnitude of a shadow variation in the same loop is smaller in a focus shadow than in a blood vessel cross-sectional shadow. To use this fact in shadow a decision, as shown in <figref idref="DRAWINGS">FIG. 13</figref><i>a</i>, the CPU <b>40</b> determines the density differences between pixels at the point P (r, θ) and pixels at a point P″ (r, θ″) in the range of 0 to 360 degrees, and determines the sum of the absolute values of the density differences. Namely, the CPU <b>40</b> finds the correlation of densities between adjacent pixels on the same loop on the basis of the following formula (2):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Σ|density difference between adjacent pixels on the same loop|  (2)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0174" num="0173">As described above, although there are some exceptions, the magnitude of a shadow variation in the same loop is smaller in a focus shadow than in a blood vessel cross-sectional shadow, so that the computation result of the above formula (2) tends to be smaller in a focus shadow than in a blood vessel cross-sectional shadow. This fact can also clearly understood from each curve shown in <figref idref="DRAWINGS">FIG. 13</figref><i>b</i>. Namely, it can be said that the curve (solid line) of the loop=1 and the curve (dotted line) of the loop=2 show small density variations, whereas the curve (dot-dashed line) of the loop=3 shows large density variations. Incidentally, a computing formula for finding the correlation between adjacent pixels on the same loop is not limited to the above-described formula (2).</p>
<p id="p-0175" num="0174">In this embodiment, the following formula (3), made up of a combination of the above formula (1) and the above formula (2), is used:</p>
<p id="p-0176" num="0175">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <munderover>
            <mo>∏</mo>
            <mrow>
              <mi>i</mi>
              <mo>=</mo>
              <mn>1</mn>
            </mrow>
            <mi>N</mi>
          </munderover>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mi>constant</mi>
              <mo>×</mo>
              <mrow>
                <mover>
                  <munder>
                    <mo>∑</mo>
                    <mn>0</mn>
                  </munder>
                  <mn>359</mn>
                </mover>
                <mo>⁢</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>⁢</mo>
                <mrow>
                  <mrow>
                    <mo></mo>
                    <mi>A</mi>
                    <mo></mo>
                  </mrow>
                  <mo>·</mo>
                  <mrow>
                    <mover>
                      <munder>
                        <mo>∑</mo>
                        <mn>0</mn>
                      </munder>
                      <mn>359</mn>
                    </mover>
                    <mo>⁢</mo>
                    <mstyle>
                      <mspace width="0.3em" height="0.3ex"/>
                    </mstyle>
                    <mo>⁢</mo>
                    <mrow>
                      <mo></mo>
                      <mi>B</mi>
                      <mo></mo>
                    </mrow>
                  </mrow>
                </mrow>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>,</mo>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>3</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0177" num="0176">where A: density difference between pixels at the same angle on adjacent loops i and i+1; and</p>
<p id="p-0178" num="0177">B: density difference between adjacent pixels on the same loop i.</p>
<p id="p-0179" num="0178">The computation result of this formula (3) shows a tendency for a focus shadow to be smaller than a blood vessel cross-sectional shadow. Accordingly, it is possible to make a decision to exclude from focus candidates a shadow whose computation result obtained from the formula (3) is larger than a constant value. Incidentally, a threshold to discriminate between a focus candidate shadow and a normal shadow (the constant of the formula (3)) is experimentally found, and the threshold is previously recorded in the magnetic disk unit <b>44</b> and the like and is used when necessary by being read therefrom.</p>
<p id="p-0180" num="0179">Although in the formula (3), summation is found after the absolute values have been found, the following decision formula (4) of finding the absolute values after having performed the summation may also be used:</p>
<p id="p-0181" num="0180">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <munderover>
          <mo>∏</mo>
          <mrow>
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mi>N</mi>
        </munderover>
        <mo>⁢</mo>
        <mstyle>
          <mspace width="0.3em" height="0.3ex"/>
        </mstyle>
        <mo>⁢</mo>
        <mrow>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mi>constant</mi>
              <mo>×</mo>
              <mrow>
                <mrow>
                  <mo></mo>
                  <mrow>
                    <mover>
                      <munder>
                        <mo>∑</mo>
                        <mn>0</mn>
                      </munder>
                      <mn>359</mn>
                    </mover>
                    <mo>⁢</mo>
                    <mi>A</mi>
                  </mrow>
                  <mo></mo>
                </mrow>
                <mo>·</mo>
                <mrow>
                  <mo></mo>
                  <mrow>
                    <mover>
                      <munder>
                        <mo>∑</mo>
                        <mn>0</mn>
                      </munder>
                      <mn>359</mn>
                    </mover>
                    <mo>⁢</mo>
                    <mi>B</mi>
                  </mrow>
                  <mo></mo>
                </mrow>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
          <mo>.</mo>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>4</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0182" num="0181">[Step S<b>6</b>] The CPU <b>40</b> determines whether the computation result obtained from the decision formula (3) or (4) is larger than a constant value. If the CPU <b>40</b> determines that the computation result is larger (yes), the CPU <b>40</b> proceeds to Step S<b>7</b>; whereas, if the CPU <b>40</b> determines that the computation result is not larger (no), the CPU <b>40</b> brings the processing to an end and proceeds to the next subroutines B<b>1</b> to B<b>3</b>.</p>
<p id="p-0183" num="0182">[Step S<b>7</b>] The CPU <b>40</b> excludes from focus candidate shadows the result of the decision in Step S<b>6</b>, i.e., a shadow whose computation result obtained from the decision formula (3) or (4) is determined to be larger than the constant value (computation result&gt;constant value), and proceeds to the next subroutines B<b>1</b> to B<b>3</b>.</p>
<p id="p-0184" num="0183">In the above description of the decision making subroutines A<b>1</b> to A<b>3</b>, reference has been made to the case where the center of a shadow is determined on the basis of the multi-valued (binary) image (b<b>1</b>) shown in <figref idref="DRAWINGS">FIG. 3</figref> and the center of the shadow is applied to the CT image <b>20</b>, thereby finding densities on a plurality of concentric loops about the center to make a decision as to whether the shadow is a focus candidate shadow. This decision method is merely one example, and various other modifications are available. Some modifications will be described below.</p>
<p id="p-0185" num="0184"><figref idref="DRAWINGS">FIGS. 14</figref><i>a</i>, <b>14</b><i>b </i>and <b>15</b><i>a</i>, <b>15</b><i>b </i>are views showing the concepts of several methods for searching for a pixel whose density is to be found, spirally from the central position of a shadow. As shown in <figref idref="DRAWINGS">FIG. 14</figref><i>a</i>, a corresponding pixel for finding the density of a shadow is identified by selecting the vicinity of the center of a shadow <b>2</b> as a reference point and making a spiral search along loops L<b>1</b>, L<b>2</b> and L<b>3</b>, which rotate clockwise from the reference point toward the edge of the shadow <b>2</b>. Namely, the CPU <b>40</b> makes a search in the order indicated by solid-line arrows along the first loop L<b>1</b>; then it makes search in the order indicated by dotted-line arrows along the second loop L<b>2</b>; and subsequently it makes search in a similar manner along the third loop L<b>3</b> and the following loops (not shown), thereby identifying the corresponding pixel. Incidentally, the starting point of the search and the direction of the search are not limited; and, as shown in <figref idref="DRAWINGS">FIG. 14</figref><i>b</i>, a search may be concentrically made along the loops L<b>1</b>, L<b>2</b> and L<b>3</b> from the edge of the shadow <b>2</b> toward the vicinity of the center of the shadow <b>2</b>. In addition, the search order of one loop is not limited; and, as shown in <figref idref="DRAWINGS">FIG. 15</figref><i>a</i>, as to the loop L<b>2</b>, a search may also be made in the order of Df→Ff→Fb→Db and then in the order of Cf→Bf→Bb→Cb. Incidentally, the capital alphabetical letters indicative of the above-described search order indicate the y coordinate of the CT image <b>20</b>, and the small alphabetical letters indicate the x coordinate of the same. Furthermore, as shown in <figref idref="DRAWINGS">FIG. 15</figref><i>b</i>, while a radius is rotationally continuously increased, passage points may also be used as search point pixels.</p>
<p id="p-0186" num="0185"><figref idref="DRAWINGS">FIGS. 16(</figref><i>a</i>-<b>1</b>) to <b>16</b>(<i>c</i>-<b>2</b>) conceptually show sampling points in the search methods shown in <figref idref="DRAWINGS">FIGS. 14</figref><i>a</i>, <b>14</b><i>b </i>and <b>15</b><i>a</i>, <b>15</b><i>b</i>, show data at the sampling points in the pattern of values “0” and “1”. Specifically, in each of <figref idref="DRAWINGS">FIGS. 16(</figref><i>a</i>-<b>1</b>) to <b>16</b>(<i>c</i>-<b>1</b>), black dots indicate sampling points in each of shadows <b>3</b>-<b>5</b>, respectively. Incidentally, the shadows <b>3</b>-<b>5</b> correspond to an binary image of <figref idref="DRAWINGS">FIG. 16(</figref><i>b</i>-<b>1</b>), and any pixel value on each of the shadows is “1” and the other pixel values are “0”. Numbers attached to the black dots indicate the order of search. The density values of the pixels on the shadows <b>3</b>-<b>5</b> that are sampled in accordance with this search order are shown as graphs in <figref idref="DRAWINGS">FIGS. 16(</figref><i>a</i>-<b>2</b>) to <b>16</b>(<i>c</i>-<b>2</b>). As is apparent from <figref idref="DRAWINGS">FIGS. 16(</figref><i>a</i>-<b>2</b>) to <b>16</b>(<i>c</i>-<b>2</b>), the density value of each of the sampling points assumes a pattern made of “0” and “1”. The CPU <b>40</b> makes a decision as to whether the shadow is a focus candidate shadow, on the basis of this pattern. For example, if the state in which the density value at each sampling point is “1” continuously exists from 1 to 9, as shown in <figref idref="DRAWINGS">FIG. 16(</figref><i>a</i>-<b>1</b>), the shadow is determined as a focus candidate shadow. If, as shown in <figref idref="DRAWINGS">FIG. 16(</figref><i>b</i>-<b>2</b>), the state in which the density value at each sampling point is “1” continuously exists from 1 to 8 and the state in which the density value at each sampling point is “0” continues from 9 to 13, the shadow is determined as not being a focus candidate shadow. If, as shown in <figref idref="DRAWINGS">FIG. 16(</figref><i>c</i>-<b>2</b>), the state in which the density value is “1” and the state in which the density value is “0” are repeated at short cycles, the shadow is determined as not being a focus candidate shadow. Incidentally, it is preferable to make this decision with values previously learned on the basis of actual focus shadows.</p>
<p id="p-0187" num="0186">A method of converting the shape of a shadow in a multi-valued image into the degree of density shall here be explained. <figref idref="DRAWINGS">FIGS. 17</figref><i>a </i>and <b>17</b><i>b </i>are diagrams showing the concept of this converting method. As shown in <figref idref="DRAWINGS">FIG. 17</figref><i>a</i>, when the case where a point <b>10</b> is selected as the starting point of a search is compared with the case where a point <b>12</b> is selected as the starting point of a search, the number of loop turns required to search for a point indicative of a pixel value of zero is larger in the case where the point <b>12</b> is selected as the starting point of the search. Accordingly, by selecting a value proportional to this number of loop turns as the density of the shadow, it is possible to convert the shadow shape of the multi-valued image into density values. Incidentally, in the above-described embodiment, the weighted center portion of a shadow is adopted as the starting point of a search (the center of the shadow), but as shown in <figref idref="DRAWINGS">FIG. 17</figref><i>b</i>, an intersection point <b>14</b> of a curve connecting dots (the circular dots shown in <figref idref="DRAWINGS">FIG. 17</figref><i>b</i>) indicating the center of the vertical length lines of a shadow and a curve connecting dots (the triangular dots shown in <figref idref="DRAWINGS">FIG. 17</figref><i>b</i>) indicating the center of the horizontal length lines of a shadow can also be selected as the center of the shadow. The starting point of a search may also be the center of a circle inscribed in a shadow in addition to the weighted center position of the shadow. In other words, the starting point of a search needs only to be near the center of the shadow. Each of the decision making subroutines may also be executed on the basis of densities converted in this manner.</p>
<p id="p-0188" num="0187">In addition, since the surroundings of an area to be extracted can be viewed, the above-described method can also be used to make a decision as to whether an area to take a value larger than a particular CT value surrounds the area to be extracted.</p>
<p id="p-0189" num="0188"><figref idref="DRAWINGS">FIG. 18</figref> is a view showing a method of determining whether a shadow is a focus candidate shadow (cancer shadow) or a normal shadow. In the graph shown in <figref idref="DRAWINGS">FIG. 18</figref>, the horizontal axis represents the number of loop turns by which a search is made spirally or concentrically, while the vertical axis represents the average value of the densities at sampling points in each loop. The average value of densities is found on the basis of a multi-valued image as shown in <figref idref="DRAWINGS">FIGS. 16(</figref><i>a</i>-<b>1</b>) to <b>16</b>(<i>c</i>-<b>1</b>). Incidentally, such average value may also be found on the basis of the original CT image and be normalized. In general, the density of a shadow tends to be high near the center of the shadow and to become lower toward the periphery thereof. Accordingly, as shown in <figref idref="DRAWINGS">FIG. 18</figref>, as the number of loop turns increases like points n<b>1</b>, n<b>2</b>, n<b>3</b>, n<b>4</b> . . . , or points N<b>1</b>, N<b>2</b>, N<b>3</b>, N<b>4</b> . . . , the average of densities shows a tendency to decrease gradually. Incidentally, in <figref idref="DRAWINGS">FIG. 18</figref>, a curve <b>16</b> represented by the points n<b>1</b>, n<b>2</b>, n<b>3</b>, n<b>4</b> . . . relates to a cancer shadow, while a curve <b>18</b> represented by the points N<b>1</b>, N<b>2</b>, N<b>3</b>, N<b>4</b> . . . relates to a blood vessel cross-sectional shadow. As is apparent from this figure, the cancer shadow <b>16</b>, which is a focus candidate shadow, is smaller than the blood vessel cross-sectional shadow <b>18</b> in the rate of diminishing as the number of the loop is higher. Accordingly, a multiplicity of curve data are measured by using actual cancer shadows in advance, and the measured results are stored in the magnetic disk unit or the like as reference data in advance, and a decision is made as to whether each shadow is a focus candidate shadow, on the basis of these reference data.</p>
<p id="p-0190" num="0189"><figref idref="DRAWINGS">FIG. 19</figref> is a view showing one example of a CT image in which a focus shadow and a normal shadow exist. In the case where the CPU <b>40</b> is to discriminate between shadows <b>16</b><i>a</i>, <b>18</b><i>a </i>and <b>18</b><i>b</i>, as shown in <figref idref="DRAWINGS">FIG. 19</figref>, the CPU <b>40</b> makes a search spirally from the vicinity of the center of each of the shadows <b>16</b><i>a</i>, <b>18</b><i>a </i>and <b>18</b><i>b </i>and finds an average density value for each loop. The CPU <b>40</b> compares each data on the average density value with each reference data of <figref idref="DRAWINGS">FIG. 18</figref>, and makes a decision as to whether the average density value coincides with any one of the reference data. For example, in the case where the data of the average density value of the shadow <b>16</b> coincides with the curve <b>16</b> of <figref idref="DRAWINGS">FIG. 18</figref>, the shadow <b>16</b> is presented to a doctor as a candidate for a cancer shadow. The data of the average density value of each of the shadows <b>18</b><i>a </i>and <b>18</b><i>b </i>approximately coincides with the curve <b>18</b> of <figref idref="DRAWINGS">FIG. 18</figref>, but does not coincide with any of the reference data. In this case, the shadows <b>18</b><i>a </i>and <b>18</b><i>b </i>are deleted from focus candidate shadows, and are not presented to the doctor. Incidentally, the following formula (5) is used to make a decision as to whether the data of the average density data coincides with the reference data:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Σ|<i>Ni−ni</i>|&lt;constant value.  (5)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0191" num="0190">When the above formula (5) is satisfied, the two curves are regarded as coincident with each other. In the formula (5), Ni is an average density value as to actually searched sampling points of a loop number i, and ni is an average density value (reference data) in a cancer shadow of the loop number i. The above absolute value may also be raised to the δ-th power (δ=1 to 2). Incidentally, the decision formula is not limited to this one, and the following formula (6) may also be used:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>Π<i>Ni−ni</i>|&lt;constant value.  (6)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0192" num="0191">Although the above-described example has referred to an examination of a known cancer shadow, another method may be used in which reference data on normal shadows of blood vessel cross sections are prepared; and, when a shadow coincides with the reference data, the shadow is excluded from focus candidates. Furthermore, it is also possible to discriminate between shadows by not only the shape fitting between the number of loop turns and the curve of a graph of an average density value for each loop, but also the shape fitting with the curve of a graph of loop number and maximum value for each loop.</p>
<p id="p-0193" num="0192">The decision making subroutines B<b>1</b> to B<b>3</b> executed in Steps S<b>72</b>, S<b>74</b> and S<b>76</b> of <figref idref="DRAWINGS">FIG. 11</figref> will be described below. <figref idref="DRAWINGS">FIGS. 20</figref><i>a </i>and <b>20</b><i>b </i>constitute a flowchart showing details of each of the decision making subroutines B<b>1</b> to B<b>3</b> for identifying a shadow on the basis of the anisotropy of the shadow. <figref idref="DRAWINGS">FIGS. 21</figref><i>a</i>, <b>21</b><i>b </i>and <b>22</b><i>a</i>, <b>22</b><i>b </i>are views conceptually showing the manner of processing of each of these decision making subroutines B<b>1</b> to B<b>3</b>. <figref idref="DRAWINGS">FIGS. 21</figref><i>a</i>, <b>21</b><i>b </i>relate to the case of a focus shadow, and <figref idref="DRAWINGS">FIGS. 22</figref><i>a</i>, <b>22</b><i>b </i>relate to the case of a blood vessel cross-sectional shadow. Details of these decision making subroutines B<b>1</b> to B<b>3</b> will be described below in the order of the steps thereof.</p>
<p id="p-0194" num="0193">[Step S<b>30</b>] The CPU <b>40</b> initializes an angle θ to, for example, θ=0 degrees. In each of <figref idref="DRAWINGS">FIGS. 21</figref><i>a </i>and <b>22</b><i>a</i>, the angle θ=0 is a line which is shown by an arrow extending from a central position M of a shadow in the rightward horizontal direction.</p>
<p id="p-0195" num="0194">[Step S<b>31</b>] The CPU <b>40</b> determines a density distribution Vr of the shadow located on an α axis at the angle θ and at a radius r from the center M of the shadow, and a density distribution V<b>90</b><i>r </i>of the shadow located on an β axis at the angle θ+90 degrees and at the radius r.</p>
<p id="p-0196" num="0195">[Step S<b>32</b>] In the case of <figref idref="DRAWINGS">FIG. 21</figref><i>a</i>, since the positions of the radius r on the α axis and the β axis lie inside the shadow, the density distributions Vr and V<b>90</b><i>r </i>assume an equal value. On the other hand, in the case of <figref idref="DRAWINGS">FIG. 22</figref><i>a</i>, the position of the radius r on the α axis lies outside the shadow and the position of the radius r on the β axis lies inside the shadow, so that the density distributions Vr and V<b>90</b><i>r </i>assume remarkably different values. Accordingly, the CPU <b>40</b> can make a comparison decision as to these values and determines whether the shadow is a focus candidate shadow. Specifically, in this step S<b>32</b>, the CPU <b>40</b> will substitute the density distribution Vr located at the radius r on the α axis at the angle θ and the density distribution V<b>90</b><i>r </i>located at the radius r on the β axis at the angle θ+90 degrees into the following formula (7) to find the anisotropy (or else correlation) of the shadow:</p>
<p id="p-0197" num="0196">
<maths id="MATH-US-00003" num="00003">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mn>90</mn>
          <mo>⁢</mo>
          <mstyle>
            <mtext>-</mtext>
          </mstyle>
          <mo>⁢</mo>
          <mi>degree</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mi>anisotropy</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.6em" height="0.6ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mrow>
            <mo>(</mo>
            <mi>θ</mi>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow>
          <munderover>
            <mo>∑</mo>
            <mrow>
              <mi>r</mi>
              <mo>=</mo>
              <mi>r0</mi>
            </mrow>
            <mrow>
              <mi>r</mi>
              <mo>=</mo>
              <mi>max</mi>
            </mrow>
          </munderover>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mrow>
            <mrow>
              <mo></mo>
              <mrow>
                <mi>V90r</mi>
                <mo>-</mo>
                <mi>Vr</mi>
              </mrow>
              <mo></mo>
            </mrow>
            <mo>.</mo>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>7</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0198" num="0197">In the above formula (7), after the absolute value has been found, summation processing is performed. A formula such as that which finds an absolute value after having performed summation processing can also be used as a formula which expresses anisotropy. Although <figref idref="DRAWINGS">FIG. 21</figref><i>a </i>shows the case where the radius r is a positive value, the radius r may also be a negative value. A correlation may also be found with respect to only a radius r<b>1</b> in each of <figref idref="DRAWINGS">FIGS. 21</figref><i>b </i>and <b>22</b><i>b</i>. In this case, since the lengths differ, a correlation of average values is found. Furthermore, the angle θ of the 90-degree anisotropy (θ) found by the above formula (7) may also be varied in the range of 0-360 degrees to find the anisotropy expressed by the following formula (8):</p>
<p id="p-0199" num="0198">
<maths id="MATH-US-00004" num="00004">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mi>anisotropy</mi>
        <mo>⁢</mo>
        <mstyle>
          <mspace width="0.6em" height="0.6ex"/>
        </mstyle>
        <mo>=</mo>
        <mrow>
          <munderover>
            <mo>∑</mo>
            <mn>0</mn>
            <mn>359</mn>
          </munderover>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.6em" height="0.6ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mrow>
            <mn>90</mn>
            <mo>⁢</mo>
            <mstyle>
              <mtext>-</mtext>
            </mstyle>
            <mo>⁢</mo>
            <mi>degree</mi>
            <mo>⁢</mo>
            <mstyle>
              <mspace width="0.8em" height="0.8ex"/>
            </mstyle>
            <mo>⁢</mo>
            <mi>anisotropy</mi>
            <mo>⁢</mo>
            <mstyle>
              <mspace width="0.6em" height="0.6ex"/>
            </mstyle>
            <mo>⁢</mo>
            <mrow>
              <mrow>
                <mo>(</mo>
                <mi>θ</mi>
                <mo>)</mo>
              </mrow>
              <mo>.</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>8</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0200" num="0199">Otherwise, the anisotropy expressed by the following formula (9) may also be found instead of the above formula (8):</p>
<p id="p-0201" num="0200">
<maths id="MATH-US-00005" num="00005">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mi>anisotropy</mi>
        <mo>⁢</mo>
        <mstyle>
          <mspace width="0.6em" height="0.6ex"/>
        </mstyle>
        <mo>=</mo>
        <mrow>
          <munderover>
            <mo>∏</mo>
            <mn>0</mn>
            <mn>359</mn>
          </munderover>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mrow>
            <mn>90</mn>
            <mo>⁢</mo>
            <mstyle>
              <mtext>-</mtext>
            </mstyle>
            <mo>⁢</mo>
            <mi>degree</mi>
            <mo>⁢</mo>
            <mstyle>
              <mspace width="0.8em" height="0.8ex"/>
            </mstyle>
            <mo>⁢</mo>
            <mi>anisotropy</mi>
            <mo>⁢</mo>
            <mstyle>
              <mspace width="0.6em" height="0.6ex"/>
            </mstyle>
            <mo>⁢</mo>
            <mrow>
              <mrow>
                <mo>(</mo>
                <mi>θ</mi>
                <mo>)</mo>
              </mrow>
              <mo>.</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mn>9</mn>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0202" num="0201">[Step S<b>33</b>] The CPU <b>40</b> determines whether the anisotropy (or correlation) found in Step S<b>32</b> is larger than the maximum anisotropy (or the minimum correlation) found in the past. If the CPU <b>40</b> determines that the anisotropy (or correlation) is larger than the maximum anisotropy (or the minimum correlation) (yes), the CPU <b>40</b> proceeds to Step S<b>34</b>; whereas, if the CPU <b>40</b> determines that the anisotropy (or correlation) is not larger than the maximum anisotropy (or the minimum correlation) (no), the CPU <b>40</b> jumps to Step S<b>35</b>. Incidentally, even in the case where this processing is in the initial cycle and the maximum anisotropy (or the minimum correlation) does not exist, the CPU <b>40</b> proceeds to Step S<b>34</b>.</p>
<p id="p-0203" num="0202">[Step S<b>34</b>] The CPU <b>40</b> sets the anisotropy (or correlation) found in Step S<b>33</b> as the maximum anisotropy (or the minimum correlation), and updates the value of the maximum anisotropy (or the minimum correlation).</p>
<p id="p-0204" num="0203">[Step S<b>35</b>] The CPU <b>40</b> adds a small angle δ to the angle θ to set the angle θ to an angle (θ+δ). Incidentally, the small angle δ is, for example, one degree, but may also be another value.</p>
<p id="p-0205" num="0204">[Step S<b>36</b>] The CPU <b>40</b> determines whether computations on anisotropy (or correlation) over all angles θ of 0-360 degrees have been completed. If the CPU <b>40</b> determines that the computations have been completed (yes), the CPU <b>40</b> proceeds to Step S<b>37</b>; whereas, if the CPU <b>40</b> determines that the computations have not been completed (no), the CPU <b>40</b> returns to Step S<b>31</b> and repeats similar processing until the angle θ reaches 360 degrees.</p>
<p id="p-0206" num="0205">[Step S<b>37</b>] The CPU <b>40</b> determines whether the maximum anisotropy is larger than a predetermined value (the minimum correlation is smaller than a predetermined value). If the CPU <b>40</b> determines that the maximum anisotropy is larger (the minimum correlation is smaller), the CPU <b>40</b> proceeds to Step S<b>38</b>, whereas if the CPU <b>40</b> determines that the maximum anisotropy is not larger (the minimum correlation is not smaller), the CPU <b>40</b> proceeds to the next subroutines C<b>1</b> to C<b>3</b>. Incidentally, a decision comparison constant in each of the steps is a value determined according to the conditions (such as slice thickness and tube current) of photography with an X-ray CT device, and may also be automatically selected.</p>
<p id="p-0207" num="0206">[Step S<b>38</b>] Since it has been determined in Step S<b>37</b> that the maximum anisotropy is larger than the predetermined value (the minimum correlation is smaller than the predetermined value), the CPU <b>40</b> excludes the shadow from focus candidate shadows, and proceeds to the next subroutines C<b>1</b> to C<b>3</b>. In the case where the above-described anisotropy is calculated on an actual focus shadow, such as a cancer shadow, the value of the anisotropy tends to be small (large in the case of the correlation). Accordingly, shadows other than a focus candidate shadow can be effectively excluded by these decision making subroutines C<b>1</b> to C<b>3</b>. Specifically, actual focus shadows in many cases exhibit shapes close to circles, as shown in <figref idref="DRAWINGS">FIG. 21</figref><i>a</i>, and as shown in <figref idref="DRAWINGS">FIG. 21</figref><i>b</i>, the density difference between a density distribution Vr<b>1</b> of the shadow located at the radius r<b>1</b> at the angle θ and a density distribution V<b>90</b><i>r</i><b>1</b> of the shadow located at the radius r<b>1</b> at the angle θ+90 degrees is comparatively small, and the anisotropy of the shadow tends to be small. On the other hand, blood vessel cross-sectional shadows are elongated, as shown in <figref idref="DRAWINGS">FIG. 22</figref><i>a</i>, and, as shown in <figref idref="DRAWINGS">FIG. 22</figref><i>b</i>, the density difference between the density distribution Vr<b>1</b> of the shadow located at the radius r<b>1</b> at the angle θ and the density distribution V<b>90</b><i>r</i><b>1</b> of the shadow located at the radius r<b>1</b> at the angle θ+90 degrees is comparatively large, and the anisotropy of the shadow tends to be large. Accordingly, the CPU <b>40</b> can easily discriminate between a focus shadow and a blood vessel shadow by a value indicative of the anisotropy found by the above formula (8) or (9).</p>
<p id="p-0208" num="0207">Incidentally, although the above formula (7) uses the absolute value of the difference between the density distribution V<b>90</b><i>r </i>and the density distribution Vr, this invention is not limited to this example, and the absolute value may be raised to the δ-th power (δ=2 to 4). In addition, the correlation is not limited to density distribution, and may also be a correlation of computation results, such as a density gradient correlation. In addition, since the computation result of the above formula (8) or (9) is in general a large value, the computation result may also be multiplied by a predetermined constant, so that it can be rounded off to a small value that is easy to handle. Moreover, although a correlation angle of 90 degrees is an angle most effective in making a decision, this invention is not limited to 90 degrees, and an appropriate angle within the range of 90 degrees±30 degrees may be selected as a correlation angle, so that the anisotropy thereof may be found. Furthermore, the computation result of the above formula (8) or (9) (for example, 90-degree anisotropy) may be used to calculate a standard deviation or the like, and the standard deviation or the like can also used for decision. This invention may use any formula that can find a correlation of shadow densities in two directions spaced substantially 90 degrees apart, and is not limited to the above formula (8) or (9), and may also use the above formula (7).</p>
<p id="p-0209" num="0208">The decision making subroutines C<b>1</b> to C<b>3</b> executed in Steps S<b>72</b>, S<b>74</b> and S<b>76</b> of <figref idref="DRAWINGS">FIG. 11</figref> will be described below. <figref idref="DRAWINGS">FIGS. 23</figref><i>a</i>, <b>23</b><i>b </i>constitute a flowchart showing details of each of the decision making subroutines C<b>1</b> to C<b>3</b> for identifying a shadow on the basis of the ratio of the long radius to the short radius of the shadow. <figref idref="DRAWINGS">FIGS. 24</figref><i>a</i>, <b>24</b><i>b </i>conceptually show the manner of processing of each of these decision making subroutines C<b>1</b> to C<b>3</b>. Although the above-described decision making subroutines B<b>1</b> to B<b>3</b> identify a shadow by using the anisotropy of each of shadow density distributions in two directions spaced substantially 90 degrees apart, these decision making subroutines C<b>1</b> to C<b>3</b> identify a shadow by using the ratio of lengths of a shadow in two directions spaced substantially 90 degrees apart. Details of these decision making subroutines C<b>1</b> to C<b>3</b> will be described below in the order of the steps thereof.</p>
<p id="p-0210" num="0209">[Step S<b>50</b>] The CPU <b>40</b> positions the center of rotation near the center of a shadow density. Namely, as shown in <figref idref="DRAWINGS">FIG. 24</figref><i>a</i>, the CPU <b>40</b> sets the center of rotation of the α axis and the β axis with radii of predetermined lengths to the center M of the shadow. In the case of a focus shadow, since a plurality of peaks generally appear in its density distribution, the vicinity of the center of the shadow is set as the average position of this plurality of peaks. Incidentally, as described previously, on the basis of a binary-image shadow obtained by binarizing the shadow, the center-weight position of the shadow may be set as the central coordinates, or the position found in <figref idref="DRAWINGS">FIG. 17</figref><i>b </i>may also be set as the central coordinates.</p>
<p id="p-0211" num="0210">[Step S<b>51</b>] The CPU <b>40</b> initializes the angle θ to, for example, θ=0 degrees, and initializes the maximum ratio of lengths of the shadow in two directions spaced substantially 90 degrees apart to, for example, “1”. The angle θ=0 is shown by an arrow extending from the center M of the shadow in the rightward horizontal direction in <figref idref="DRAWINGS">FIG. 24</figref><i>a. </i></p>
<p id="p-0212" num="0211">[Step S<b>52</b>] The CPU <b>40</b> initializes a radius R to a small radius R<b>0</b> near 0, and initializes both a first recording flag <b>1</b> and a second recording flag <b>2</b> to “0”.</p>
<p id="p-0213" num="0212">Through the next steps S<b>53</b> to S<b>58</b>, as shown in <figref idref="DRAWINGS">FIG. 24</figref><i>a</i>, the CPU <b>40</b> finds the radius r<b>1</b> on the α axis extending from the center M, which is the reference of the shadow, and where angle θ is given different values and a radius r<b>2</b> on the β axis at the angle θ+90 degrees. The respective radii r<b>1</b> and r<b>2</b> represent the distances from the origin M to the boundary of the shadow, and this boundary is determined by finding the initial positions where the values of density curves α<b>1</b> and β<b>1</b> reach about T % of the density value at the origin, as shown in <figref idref="DRAWINGS">FIG. 24</figref><i>b</i>. Incidentally, the value of T % can be arbitrarily set, and is herein set to T=75%. It goes without saying that CT values or values of a multi-valued image themselves can also be used instead of percent.</p>
<p id="p-0214" num="0213">[Step S<b>53</b>] The CPU <b>40</b> determines whether the first recording flag <b>1</b> is “0” and the density value of a pixel at the radius R in the direction of the α axis is a predetermined value or less. If the CPU <b>40</b> determines that the density value is not larger than the predetermined value (Yes), the CPU <b>40</b> proceeds to Step S<b>54</b>; whereas, if the CPU <b>40</b> determines that the density value is larger than the predetermined value (No), the CPU <b>40</b> jumps to Step S<b>55</b>. Incidentally, this predetermined value is a value obtained by multiplying the density value of the shadow at the origin by the above-described value T. Namely, in this step, the CPU <b>40</b> determines whether a pixel at the radius R lies on the boundary (edge) of the shadow.</p>
<p id="p-0215" num="0214">[Step S<b>54</b>] Since it has been determined in Step S<b>53</b> that the density value of the pixel at the radius R in the direction of the α axis is not larger than the predetermined value, this radius R indicates the distance from the origin M to the boundary of the shadow. Accordingly, the CPU <b>40</b> selects this radius R as the radius r<b>1</b> and sets “1” to the first recording flag <b>1</b>, to define the radius r<b>1</b>.</p>
<p id="p-0216" num="0215">[Step S<b>55</b>] The CPU <b>40</b> determines whether the second recording flag <b>2</b> is “0” and whether the density value of a pixel at the radius R in the direction of the β axis is a predetermined value or less. If the CPU <b>40</b> determines that the density value is not larger than the predetermined value (Yes), the CPU <b>40</b> proceeds to Step S<b>56</b>; whereas, if the CPU <b>40</b> determines that the density value is larger than the predetermined value (No), the CPU <b>40</b> jumps to Step S<b>57</b>.</p>
<p id="p-0217" num="0216">[Step S<b>56</b>] Since it has been determined in the above step S<b>55</b> that the density value of the pixel at the radius R in the direction of the β axis is not larger than the predetermined value, this radius R indicates the distance from the origin M to the boundary of the shadow. Accordingly, the CPU <b>40</b> selects this radius R as the radius r<b>2</b> and sets “1” to the second recording flag <b>2</b>, to define the radius r<b>2</b>.</p>
<p id="p-0218" num="0217">[Step S<b>57</b>] The CPU <b>40</b> adds a small distance ε to the radius R to set the radius R to a radius (R+ε). Namely, the CPU <b>40</b> performs the processing of increasing the radius R by the small increment ε.</p>
<p id="p-0219" num="0218">[Step S<b>58</b>] The CPU <b>40</b> determines whether the radius R is a predetermined maximum value (for example, the maximum radius of a shadow which is a decision target), and, if the CPU <b>40</b> determines that the radius R is not the maximum value (No), the CPU <b>40</b> returns to Step S<b>53</b>; whereas, if the CPU <b>40</b> determines that the radius R is the maximum value (Yes), the CPU <b>40</b> returns to Step S<b>59</b>. The CPU <b>40</b> can find the radius r<b>1</b> on the α axis at the angle θ and the radius r<b>2</b> on the β axis at the angle θ+90 degrees by repeating the processing of Steps S<b>54</b> to S<b>58</b>. Incidentally, in the description of this step, reference has been made to the case where the CPU <b>40</b> leaves the loop of Steps S<b>53</b> to S<b>58</b> depending on the size of the radius R; however, instead of this step S<b>58</b>, the CPU <b>40</b> can be made to leave the loop according to whether both the first recording flag <b>1</b> and the second recording flag <b>2</b> are “1”.</p>
<p id="p-0220" num="0219">[Step S<b>59</b>] The CPU <b>40</b> finds the ratio of the radius r<b>1</b> to the radius r<b>2</b>: r<b>1</b>/r<b>2</b>. In this step, the ratio=r<b>1</b>/r<b>2</b> is found, but since the ratio is made to be not smaller than 1, the larger of the radius r<b>1</b> and the radius r<b>2</b> is made the numerator and the smaller is made the denominator.</p>
<p id="p-0221" num="0220">[Step S] The CPU <b>40</b> determines whether the ratio found in Step S<b>59</b> is larger than a maximum ratio, and if the CPU <b>40</b> determines that the ratio is larger (Yes), the CPU <b>40</b> proceeds to Step S<b>61</b>; while, if the CPU <b>40</b> determines that the ratio is not larger (No), the CPU <b>40</b> jumps to Step S<b>62</b>.</p>
<p id="p-0222" num="0221">[Step S<b>61</b>] Since the ratio found in Step S<b>59</b> is larger than the maximum ratio, the CPU <b>40</b> sets that ratio to be the new maximum ratio. Incidentally, since the value “1” defined as the maximum ratio in Step S<b>51</b> is set in advance, the initially found ratio is recorded as the maximum ratio.</p>
<p id="p-0223" num="0222">[Step S<b>62</b>] The CPU <b>40</b> adds the small angle δ to the angle θ to set the angle θ to the angle (θ+δ). Incidentally, the small angle δ is, for example, one degree, but may also be another value.</p>
<p id="p-0224" num="0223">[Step S<b>63</b>] The CPU <b>40</b> determines whether the angle θ in Step S<b>62</b> has reached 360 degrees, and if the CPU <b>40</b> determines that the angle θ is smaller than 360 degrees (No), the CPU <b>40</b> jumps to Step S<b>52</b>; whereas, if the CPU <b>40</b> determines that the angle θ=360 degrees (Yes), the CPU <b>40</b> proceeds to Step S<b>64</b>. In this manner, it is possible to find the maximum ratio of the radius r<b>1</b> to the radius r<b>2</b> where the angle θ is varied from 0 to 360 degrees.</p>
<p id="p-0225" num="0224">[Step S<b>64</b>] The CPU <b>40</b> determines whether the maximum ratio is larger than a predetermined constant, and if the CPU <b>40</b> determines that the maximum ratio is larger (Yes), the CPU <b>40</b> proceeds to Step S<b>65</b>; whereas, if the CPU <b>40</b> determines that the maximum ratio is not larger (No), the CPU <b>40</b> proceeds to the next decision making subroutines D<b>1</b> to D<b>3</b>.</p>
<p id="p-0226" num="0225">[Step S<b>65</b>] Since it has been determined in Step S<b>64</b> that the maximum ratio is larger than the predetermined constant, the CPU <b>40</b> excludes the shadow from focus candidate shadows and proceeds to the next decision making subroutines D<b>1</b> to D<b>3</b>. In this manner, the CPU <b>40</b> varies the angle θ in the range of 0 to 360 degrees, and if the maximum ratio of the radius r<b>1</b> and the radius r<b>2</b> obtained at this time is larger than the predetermined constant, the CPU <b>40</b> excludes the shadow from focus candidate shadows. This is because focus candidates are small in anisotropy and approximately close to circular shapes and the ratios of their radii r<b>1</b> to their radii r<b>2</b> are in many cases smaller than the predetermined constant. Incidentally, although each of <figref idref="DRAWINGS">FIGS. 21</figref><i>b</i>, <b>22</b><i>b </i>and <b>24</b><i>b </i>shows only anisotropy in the positive direction on the α axis, the case of anisotropy in the negative direction is also included in this invention.</p>
<p id="p-0227" num="0226">In the above-described embodiment, reference has been made to the case where anisotropy (correlation) is found by using shadow density distributions in two directions spaced substantially 90 degrees apart or the ratio of the lengths of shadows in two directions spaced substantially 90 degrees apart, but anisotropy may also be found by using other methods. For example, anisotropy (correlation) may also be found by causing the α axis and the β axis shown in <figref idref="DRAWINGS">FIG. 22</figref><i>a </i>to move like the long hand and the short hand of a clock. In this case, assuming that the α axis and the β axis are the short hand and the long hand, respectively, while the α axis is making one rotation, the β axis makes several hundred rotations. In <figref idref="DRAWINGS">FIG. 22</figref><i>a</i>, the α axis and the β axis are shown to be perpendicular to each other, but this angle may be made an arbitrary angle η. First, a density distribution in the direction of the α axis is found by determining the angle θ, then the angle is changed by η to find a density distribution in the direction of the β axis, and subsequently the anisotropy (correlation) of both density distributions is found. In the case where both the α axis and the β axis are superposed on a blood vessel shadow, the anisotropy is small and pixel values along the α axis and β axis are large, and the distribution of the pixel values is flat. On the other hand, if the shadow is circular, such features are not observed, and pixel values along the α axis and β axis are large and their distribution is flat. Accordingly, if a case of small anisotropy is discovered, it can be inferred that the angle η at this time is the branching angle of a blood vessel. For example, in <figref idref="DRAWINGS">FIG. 22</figref><i>a</i>, when the angle η is about 180 degrees and about 45 degrees, the anisotropy becomes small, so that the shadow is inferred to be a blood vessel and can be excluded from focus candidate shadows.</p>
<p id="p-0228" num="0227">The decision making subroutines D<b>1</b> to D<b>3</b> executed in Step S<b>72</b>, S<b>74</b> and S<b>76</b> of <figref idref="DRAWINGS">FIG. 11</figref> will be described below. <figref idref="DRAWINGS">FIG. 25</figref> is a flowchart showing details of each of the decision making subroutines D<b>1</b> to D<b>3</b>. <figref idref="DRAWINGS">FIGS. 26</figref><i>a </i>to <b>26</b><i>d </i>conceptually show the manner of processing of each of these decision making subroutines D<b>1</b> to D<b>3</b>, of which <figref idref="DRAWINGS">FIG. 26</figref><i>a </i>is a view showing one example of a CT image. <figref idref="DRAWINGS">FIG. 26</figref><i>b </i>is a view showing one example of a binary image obtained by binarizing this CT image. <figref idref="DRAWINGS">FIGS. 26</figref><i>c </i>and <b>26</b><i>d </i>are views showing on an enlarged scale a part of this binary image, and which show how a decision is made by each of the decision making subroutines D<b>1</b> to D<b>3</b>. By applying the binary image processing shown in <figref idref="DRAWINGS">FIGS. 5 and 6</figref> to the CT image shown in <figref idref="DRAWINGS">FIG. 26</figref><i>a</i>, shadows <b>261</b> and <b>262</b>, which seem to be focus candidates, are extracted in the binary image shown in <figref idref="DRAWINGS">FIG. 26</figref><i>b</i>. Since these shadows <b>261</b> and <b>262</b> are the same in size and shape, it is difficult to discriminate between the shadows <b>261</b> and <b>262</b> by means of the above-described decision. However, since the shadow <b>262</b> appears on a wall portion of the shadow, the possibility that the shadow <b>262</b> is a cancer shadow is high. The shadow <b>261</b> appears in the inside of the shadow, and the possibility that the shadow <b>261</b> is a focus candidate is low. For this reason, in the decision making subroutines D<b>1</b> to D<b>3</b>, a decision is made as to whether a shadow is located on a wall portion, and, on the basis of the result of this decision, a decision is made as to whether the shadow is a focus candidate shadow. In the case where a shadow exists near a wall, as a rotating radius passes through the wall, the pixel values of the shadow that cross the radius sharply vary, and the resultant high variation appears at two locations of radii. Accordingly, in the case where the shadow is in contact with the wall, an angle of elevation θ of the radii at these two locations is larger than a reference value, so that the shadow is identified as a focus candidate shadow. On the other hand, in the case where the shadow is inside the wall, the angle of elevation θ of the radius is smaller than the reference value, so that the shadow is not identified as a focus candidate shadow. Details of these decision making subroutines D<b>1</b> to D<b>3</b> will be described below step by step.</p>
<p id="p-0229" num="0228">[Step S<b>91</b>] The CPU <b>40</b> sets the radius r used to search a shadow to an initial value. The radius R in this processing is made to be a value corresponding to the size of each shadow. For example, about 1.5 times the maximum diameter of a shadow, which is a target is set to be the initial value of the radius r.</p>
<p id="p-0230" num="0229">[Step S<b>92</b>] The CPU <b>40</b> rotates a moving radius r by about 5 degrees at one time in the range from θ=0 degrees to θ=360 degrees, and finds density distributions V<b>0</b> to V<b>355</b> of the shadow located at the distance r from the center of the shadow and at the respective angles, and applies predetermined computations on these density distributions V<b>0</b> to V<b>355</b>. Then, if the moving radius of radius r crosses the boundary of the shadow at two or more radii θ<b>1</b> and θ<b>2</b>, the CPU <b>40</b> finds a maximum angle Θ between radii θ<b>1</b> and θ<b>2</b>. The radii θ<b>1</b> and θ<b>2</b> are determined in the following manner. The CPU <b>40</b> subtracts the density distribution V(θ+5) at an angle (θ+5) which is 5 degrees larger than a certain angle θ, from a density distribution Vθ at the angle θ; and, if the difference is a positive value and the absolute value is larger than a predetermined value, the CPU <b>40</b> sets the larger angle (θ+5) to be θ<b>1</b>. In <figref idref="DRAWINGS">FIGS. 26</figref><i>c </i>and <b>26</b><i>d</i>, a moving radius rθ<b>1</b> corresponds to the moving radius at the angle θ<b>1</b>. On the other hand, in the case where the CPU <b>40</b> subtracts the density distribution V(θ+5) from the density distribution Vθ, if the difference is a negative value and the absolute value is larger than the predetermined value, the CPU <b>40</b> sets the smaller angle θ to be θ<b>2</b>. In <figref idref="DRAWINGS">FIGS. 26</figref><i>c </i>and <b>26</b><i>d</i>, a moving radius rθ<b>2</b> corresponds to the moving radius at the angle θ<b>2</b>. After the angle θ<b>1</b> and the angle θ<b>2</b> have been found in this manner, the CPU <b>40</b> defines, as the maximum angle Θ, the angle formed by the moving radius rθ<b>1</b> at the angle θ<b>2</b> in the clockwise direction relative to the moving radius rθ<b>2</b> at the angle θ<b>2</b>. Incidentally, this method of finding the maximum angle Θ is merely one example, and it goes without saying that the maximum angle Θ can be found by other methods. In addition, although the description has been made in connection with the case where the moving radius is rotated 5 degrees at one time, this case is not limiting, and it goes without saying that the angle of rotation may be changed in increments ranging from 1 degree to 10 degrees.</p>
<p id="p-0231" num="0230">[Step S<b>93</b>] The CPU <b>40</b> determines whether the maximum angle Θ found in Step S<b>93</b> is larger than a predetermined constant value, and, if the CPU <b>40</b> determines that the maximum angle Θ is larger (yes), the CPU <b>40</b> proceeds to the next decision making subroutines E<b>1</b> to E<b>3</b>; whereas, if the CPU <b>40</b> determines that the maximum angle Θ is not larger (no), the CPU <b>40</b> proceeds to Step S<b>94</b>. The constant value is herein made 90 degrees. This is because the maximum angle Θ is near 180 degrees in the case of a focus shadow which appears on a wall portion. Accordingly, in such a case, the shadow is left as a focus candidate shadow and is subjected to the processing of the next decision making subroutine.</p>
<p id="p-0232" num="0231">[Step S<b>94</b>] Since it has been determined by the decision in Step S<b>93</b> that the maximum angle Θ is smaller than the predetermined constant value, the CPU <b>40</b> excludes the shadow from focus candidate shadows and proceeds to the next decision making subroutines E<b>1</b> to E<b>3</b>. In many cases, a focus shadow, such as a cancer shadow, appears on a wall portion, but a normal shadow does not appear on a wall portion. Therefore, through this processing, a shadow which does not exist on a wall portion is efficiently excluded from focus candidate shadows.</p>
<p id="p-0233" num="0232">The decision making subroutine E<b>1</b> executed in Step S<b>72</b> of <figref idref="DRAWINGS">FIG. 11</figref> will be described here. <figref idref="DRAWINGS">FIG. 27</figref> is a flowchart showing details of the decision making subroutine E<b>1</b>. <figref idref="DRAWINGS">FIGS. 28</figref><i>a</i>, <b>28</b><i>b </i>conceptually show the manner of processing of this decision making subroutine E<b>1</b>. <figref idref="DRAWINGS">FIG. 28</figref><i>a </i>shows processing for a blood vessel cross-sectional shadow generated by applying the binary image processing of <figref idref="DRAWINGS">FIGS. 5 and 6</figref>, and <figref idref="DRAWINGS">FIG. 28</figref><i>b </i>shows processing for a focus shadow. When the binary image processing of <figref idref="DRAWINGS">FIGS. 5 and 6</figref> is applied to a CT image to exclude the shadow of a blood vessel portion thinner than a predetermined value, the shadow of the remaining portion becomes a shadow which seems to be a focus shadow, as shown in <figref idref="DRAWINGS">FIG. 28</figref><i>a</i>. Therefore, the blood vessel cross-sectional shadow shown in <figref idref="DRAWINGS">FIG. 28</figref><i>a </i>must be excluded from focus candidates. For this reason, in this decision making subroutine E<b>1</b>, this blood vessel cross-sectional shadow is extracted and excluded. Namely, to exclude such a blood vessel cross-sectional shadow from focus candidates, the CPU <b>40</b> finds a long diameter and a short diameter of the shadow from the minimum value and the maximum value of the portion of the rotating straight line which intersects the shadow, and samples pixel values which are respectively located a predetermined distance outward from the shadow along extensions of the long diameter and the short diameter. In the case of the blood vessel cross-sectional shadow, the pixel value on the extension of the long diameter and the pixel value on the extension of the short diameter indicate clearly different values. In the case of the focus shadow, both pixel values indicate approximately the same value. Accordingly, on the basis of this fact, it is possible to determine whether the shadow is a focus candidate shadow. Details of this decision making subroutine E<b>1</b> will be described below, step by step.</p>
<p id="p-0234" num="0233">[Step S<b>101</b>] The CPU <b>40</b> finds the angle Θ relative to the minimum moving radius while rotating the moving radius. The CPU <b>40</b> positions the middle point of the straight line of predetermined length to be close to the center of the shadow density, and sets the middle point of the straight line to be the center of rotation and rotates the straight line about the center of rotation by about 1 degree at one time in the range from θ=0 degrees to θ=360 degrees. During this time, the CPU <b>40</b> sequentially calculates the length of the portion of the radius which crosses the shadow at each of the angles, and finds an angle Φ of the minimum value of the moving radius. Incidentally, this processing is performed on shadows of multi-valued images. The incremental angle of rotation is not limited to 1 degree, and may be other angles.</p>
<p id="p-0235" num="0234">[Step S<b>102</b>] This processing is performed on a CT image which is not yet subjected to multi-valued image processing. The CPU <b>40</b> finds density values (CT values) v<b>1</b> and v<b>2</b> at two points located a predetermined distance “outR” outward from the shadow along the extension of the moving radius at the angle Φ, and finds density values (CT values) v<b>3</b> and v<b>4</b> at two points located a predetermined distance outR outward from the shadow along the extension of a moving radius perpendicular to the moving radius at the angle Φ.</p>
<p id="p-0236" num="0235">[Step S<b>103</b>] The CPU <b>40</b> substitutes the density values found in the previous step S<b>102</b> into the following formula (10) or (11):
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>v</i>3<i>+v</i>4&gt;((<i>v</i>1<i>+v</i>2)+constant),  (10)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>v</i>3<i>+v</i>4&gt;((<i>v</i>1<i>+v</i>2)×constant)  (11)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0237" num="0236">If the CPU <b>40</b> determines that the formula (10) or (11) is satisfied (yes), the CPU <b>40</b> proceeds to Step S<b>104</b>, whereas if the CPU <b>40</b> determines that the formula (10) or (11) is not satisfied (no), the CPU <b>40</b> brings the processing to an end and proceeds to the next decision making subroutine F<b>1</b>. In the case of the blood vessel cross-sectional shadow shown in <figref idref="DRAWINGS">FIG. 28(</figref><i>a</i>), the density values (CT values) v<b>1</b> and v<b>2</b> at the two points located the predetermined distance outR outward from the shadow along the extension of the moving radius at the angle Φ become extremely small values. On the other hand, the density values v<b>3</b> and v<b>4</b> at the two points located the predetermined distance outR outward from the shadow along the extension of the moving radius perpendicular to the moving radius at the angle Φ become comparatively large values, because the density values v<b>3</b> and v<b>4</b> are located on the blood vessel cross-sectional shadow. Accordingly, in the case of the blood vessel cross-sectional shadow shown in <figref idref="DRAWINGS">FIG. 28</figref><i>a</i>, the above-described formula (10) or (11) is satisfied. On the other hand, in the case of the focus shadow shown in <figref idref="DRAWINGS">FIG. 28</figref><i>b</i>, since the density values v<b>1</b> to v<b>4</b> become approximately the same value, the above-described formula (10) or (11) is not satisfied.</p>
<p id="p-0238" num="0237">[Step S<b>104</b>] Since it has been determined by the decision in Step S<b>103</b> that the above-described formula (10) or (11) is satisfied, the CPU <b>40</b> excludes the shadow from focus candidate shadows, and proceeds to the next subroutine F<b>1</b>. Through this processing, the blood vessel cross-sectional shadow, which is generated by the multi-valued image processing of <figref idref="DRAWINGS">FIGS. 5 and 6</figref> and seems to be a focus shadow, is effectively excluded from focus candidate shadows. Incidentally, in the above-described step S<b>102</b>, the density values v<b>3</b> and v<b>4</b> are found at the two points located a predetermined distance outR outward from the shadow along the extension of the moving radius perpendicular to the moving radius at the angle Φ. However, as a result of Step S<b>101</b>, an angle Φ relative to the maximum value of the moving radius may also be used, so that the density values v<b>3</b> and v<b>4</b> may be found at two points located at the predetermined distance outR outward from the shadow along the extension of a moving radius at that angle Φ. In addition, although in the above-described embodiment the density values v<b>1</b> and v<b>2</b> are determined from the moving radius of minimum value, the density values v<b>1</b> and v<b>2</b> may instead be determined from the moving radius of maximum value so that the density values v<b>3</b> and v<b>4</b> may be determined from the moving radius perpendicular to the moving radius of maximum value.</p>
<p id="p-0239" num="0238">The decision making subroutine F<b>1</b> executed in Step S<b>72</b> of <figref idref="DRAWINGS">FIG. 11</figref> will be described below. <figref idref="DRAWINGS">FIG. 29</figref> is a flowchart showing details of the decision making subroutine F<b>1</b>. <figref idref="DRAWINGS">FIGS. 30</figref><i>a </i>and <b>30</b><i>b </i>conceptually show the manner of processing of this decision making subroutine F<b>1</b>. <figref idref="DRAWINGS">FIG. 30</figref><i>a </i>shows processing for a blood vessel cross-sectional shadow generated by applying the multi-valued image processing of <figref idref="DRAWINGS">FIGS. 5 and 6</figref>, and <figref idref="DRAWINGS">FIG. 30</figref><i>b </i>shows the density distribution generated in the course of the processing for this blood vessel cross-sectional shadow. Similarly to the above-described decision making subroutine E<b>1</b>, the decision making subroutine F<b>1</b> performs the processing of extracting and excluding a blood vessel cross-sectional shadow. Details of this decision making subroutine E<b>1</b> will be described below in the order of the steps thereof.</p>
<p id="p-0240" num="0239">[Step S<b>111</b>] The CPU <b>40</b> sets a radius r at which to search a shadow at an initial value. For example, the radius r is set to about 7 mm in the case of the first decision processing of <figref idref="DRAWINGS">FIG. 10</figref> which is performed when the size of the shadow is smaller than the predetermined value Ra, or the radius r is set to about 20 mm in the case of the second decision processing of <figref idref="DRAWINGS">FIG. 10</figref>, which is performed when the size of the shadow is not smaller than the predetermined value Ra and is smaller than the predetermined value Rb, or the radius r is set to about 30 mm in the case of the third decision processing of <figref idref="DRAWINGS">FIG. 10</figref>, which is performed when the size of the shadow is larger than the predetermined value Rb. These values are parameter values which can be variously modified.</p>
<p id="p-0241" num="0240">[Step S<b>112</b>] The CPU <b>40</b> rotates at the radius r by increments of one degree about a point in the vicinity of the center of the shadow, and samples each pixel value in the range of angles θ=0 to 360 degrees and generates a density waveform, as shown in <figref idref="DRAWINGS">FIG. 30</figref><i>b</i>. <figref idref="DRAWINGS">FIG. 30</figref><i>b </i>shows the result obtained by sampling density values at the position of the radius r from the shadow center of the blood vessel cross-sectional shadow shown in <figref idref="DRAWINGS">FIG. 30</figref><i>a. </i></p>
<p id="p-0242" num="0241">[Step S<b>113</b>] The CPU <b>40</b> extracts an angle at which a density peak appears, on the basis of the density waveform generated in Step S<b>113</b>. For example, the CPU <b>40</b> differentiates the density waveform, and extracts an angle relative to the case where the differential value is “0”, as an angle at which a density peak appears. In the case of a blood vessel cross-sectional shadow, since the density near the axis of a blood vessel shows a maximum value, an angle at which a density peak appears and the longitudinal direction of the blood vessel are approximately coincident with each other. In the case of <figref idref="DRAWINGS">FIGS. 30</figref><i>a </i>and <b>30</b><i>b</i>, the angles Θ at which density peaks appear are α=10 degrees, β=170 degrees and γ=210 degrees.</p>
<p id="p-0243" num="0242">[Step S<b>114</b>] The CPU <b>40</b> sums CT values on the radius r at various angles. In <figref idref="DRAWINGS">FIG. 30</figref><i>a</i>=, since density peaks respectively appear at the three angles α, β and γ, the CPU <b>40</b> finds the sums of CT values on the radius r at the respective angles α, β and γ. The sum of CT values on the radius at the angle α is sum(α), the sum of CT values on the radius at the angle β is sum(β), and the sum of CT values on the radius at the angle γ is sum(γ).</p>
<p id="p-0244" num="0243">[Step S<b>115</b>] The CPU <b>40</b> finds the bisector of an angle made by adjacent radii, and finds the sum of CT values on the bisector. In the case of <figref idref="DRAWINGS">FIG. 30</figref><i>a</i>, since the angles at which the respective density peaks appear are the three angles α, β and γ, the bisectors of the radii which are adjacent to each other at the respective angles are a bisector αβ formed between the angle α and the angle β, a bisector βγ formed between the angle β and the angle γ, and a bisector γα formed between the angle γ and the angle α. The CPU <b>40</b> finds the sum of CT values on the bisector αβ, the bisector βγ and the bisector γα. The sum of the CT values on the bisector αβ is sum(αβ), the sum of the of the CT values on the bisector αβ is sum(αβ), the sum of the CT values on the bisector βγ is sum(βγ), and the sum of the CT values on the bisector γα is sum(γα).</p>
<p id="p-0245" num="0244">[Step S<b>116</b>] The CPU <b>40</b> determines whether each of the sums found in the above-described Steps S<b>114</b> and S<b>115</b> satisfies the following predetermined conditions. If the CPU <b>40</b> determines that the following predetermined conditions are satisfied (yes), the CPU <b>40</b> proceeds to the next step S<b>117</b>; whereas, if the CPU <b>40</b> determines that the following predetermined conditions are not satisfied (no), the CPU <b>40</b> brings the processing to an end, and proceeds to Step S<b>73</b> of <figref idref="DRAWINGS">FIG. 11</figref>. In this step, any one of the following predetermined conditions are used.</p>
<p id="p-0246" num="0245">(Predetermined Condition 1)
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>sum(αβ)×constant&lt;sum(α),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>sum(αβ)×constant&lt;sum(β),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>sum(βγ)×constant&lt;sum(β),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>sum(βγ)×constant&lt;sum(γ),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>sum(γα)×constant&lt;sum(γ), and<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>sum(γα)×constant&lt;sum(α).<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0247" num="0246">In the case where all of the above-described condition formulas are satisfied, the predetermined condition 1 is determined as satisfied.</p>
<p id="p-0248" num="0247">(Predetermined Condition 2)
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>sum(αβ)+constant&lt;sum(α),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>sum(αβ)+constant&lt;sum(β),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>sum(βγ)+constant&lt;sum(β),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>sum(βγ)+constant&lt;sum(γ),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>sum(γα)+constant&lt;sum(γ), and<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>sum(γα)+constant&lt;sum(α).<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0249" num="0248">In the case where all of the above-described condition formulas are satisfied, the predetermined condition 2 is determined as satisfied.</p>
<p id="p-0250" num="0249">(Predetermined Condition 3)
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>average(α˜β)+constant&lt;sum(α),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>average(α˜β)+constant&lt;sum(β),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>average(β˜γ)+constant&lt;sum(β),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>average(β˜γ)+constant&lt;sum(γ),<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>average(γ˜α)+constant&lt;sum(γ), and<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>average(γ˜α)+constant&lt;sum(α).<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0251" num="0250">In the case where all of the above-described condition formulas are satisfied, the predetermined condition 3 is determined as satisfied. In the above condition formulas, the term “average(α˜β)” indicates the average value of the CT values contained in a sector from the angle α to the angle β, and the term “average(α)” indicates the average value of the CT values on the radius r at the angle α. Accordingly, in this case, it is necessary to newly add processing for finding the average values. Incidentally, it goes without saying that, in Step S<b>116</b>, the CPU <b>40</b> may determine whether all of these conditions 1 to 3 are satisfied.</p>
<p id="p-0252" num="0251">[Step S<b>117</b>] The CPU <b>40</b> excludes from focus candidate shadows the shadow which has been determined as satisfying the predetermined condition, as a result of the decision of Step S<b>116</b>, brings this processing to an end, and proceeds to Step S<b>73</b> of <figref idref="DRAWINGS">FIG. 11</figref>.</p>
<p id="p-0253" num="0252">In the above-described manner, the shadows other than the focus candidate shadow <b>22</b> shown (b<b>1</b>) to (b<b>3</b>) in <figref idref="DRAWINGS">FIG. 3</figref> are sequentially deleted, and only the focus candidate shadow <b>22</b> is finally left as shown at (b<b>3</b>) in <figref idref="DRAWINGS">FIG. 3</figref>. This focus candidate shadow <b>22</b> is the final selected image (<figref idref="DRAWINGS">FIG. 3</figref> at (b<b>3</b>)), and is combined with the original CT image <b>20</b> (<figref idref="DRAWINGS">FIG. 3</figref> at (a<b>1</b>)), so that the final combined image shown in <figref idref="DRAWINGS">FIG. 3</figref> at (a<b>2</b>) is displayed on the CRT display <b>48</b>. On the image shown in <figref idref="DRAWINGS">FIG. 3</figref> at (a<b>2</b>), the focus candidate shadow <b>22</b> is enclosed with the circular marker M so that the operator's attention is drawn to the focus candidate shadow <b>22</b>. Incidentally, only the focus candidate shadow <b>22</b> need be displayed in color or in a painted-out state. Images which are subjected to the extraction processing of sequentially excluding non-candidate shadows to select the focus candidate shadow <b>22</b> are actually displayed in greater numbers than those shown in <figref idref="DRAWINGS">FIG. 3</figref> at (b<b>2</b>) and <b>3</b> at (b<b>3</b>). <figref idref="DRAWINGS">FIG. 3</figref> merely shows part of the images displayed actually.</p>
<p id="p-0254" num="0253"><figref idref="DRAWINGS">FIG. 31</figref> is a view of a modification of the display picture of <figref idref="DRAWINGS">FIG. 3</figref>, and shows the case where a CT image and images being processed on a bit memory are displayed in combined form. Specifically, <figref idref="DRAWINGS">FIG. 3</figref> sequentially displays images which are being subjected to the extraction processing of sequentially excluding non-candidate shadows to select the focus candidate shadow <b>22</b>; however, in <figref idref="DRAWINGS">FIG. 31</figref>, the original CT image <b>20</b> is combined with each of images which are being processed as shown in <figref idref="DRAWINGS">FIG. 3</figref> at (b<b>1</b>) to <b>3</b> at (b<b>3</b>), and a resultant combined image <b>26</b> is sequentially displayed. Since the combined image is displayed in this manner, the operator (doctor) can serially observe the process of sequentially excluding non-candidate shadows from the CT image <b>20</b> and selecting the focus candidate shadow. Incidentally, the method of extracting and selecting a focus candidate shadow is not limited to this embodiment; and, as shown in <figref idref="DRAWINGS">FIG. 32</figref> by way of example, there is also a method of finding average coordinates a′ and b′ of respective shadows a and b and excluding from focus candidate shadows the shadow a or b if the average coordinates a′ or b′ lie outside that shadow (the shadow b in the example of <figref idref="DRAWINGS">FIG. 32</figref>). Also, a Quoit filter, Mahalanobis distance, Euclidean distance and the like may be used to select a focus candidate shadow. In the case where a focus candidate shadow is presented to the operator (doctor), each image may also be stored in the magnetic disk unit <b>44</b> together with information indicative of an undetected image, an image that is impossible to identify, or candidate image so that undetected images, images that are impossible to identify and candidate images may be displayed in separate windows, classified as shown in <figref idref="DRAWINGS">FIG. 33</figref>, in accordance with an instruction from the operator (doctor). The above-described windows respectively display such images, but in the respective windows, image supplementary information for identifying the images, such as the patient names and the patient IDs of the respective images, may also be displayed in list form. In addition, information for identifying the nature of focus candidate shadows, such as a positive indication that shadow is a focus, a nature close to a positive (apparent-positive) and a negative indicating that a focus candidate shadow is not a focus, may also be displayed as image supplementary information. A display example of such image supplementary information is shown in <figref idref="DRAWINGS">FIG. 83</figref>.</p>
<p id="p-0255" num="0254">Although images are displayed in each of the above-described windows, image supplementary information for identifying the images, such as the patient names and the patient IDs of the respective images, may also be displayed in list form.</p>
<p id="p-0256" num="0255">One example of a picture which is displayed on the CRT display <b>48</b> in the case where the processing of each of the above-described shadow decisions is executed will be described below. <figref idref="DRAWINGS">FIG. 34</figref> is a view showing a display for setting the parameters required for the processing of each of the above-described decision making subroutines. Incidentally, there are optimum parameters depending on the sizes of shadows and the states of densities of shadows; and, when a “SMALL FOCUS” button, a “LARGE FOCUS” button, a “FROSTED-GLASS FOCUS” button or a “HIGH-DENSITY FOCUS” button is selected by a mouse cursor, the corresponding optimum parameters are set. When the setting of the parameters with the display of <figref idref="DRAWINGS">FIG. 34</figref> is completed, a focus candidate extracting and displaying device which is not shown performs sequential or parallel processing in accordance with the main flowchart of <figref idref="DRAWINGS">FIGS. 2</figref><i>a</i>, <b>2</b><i>b </i>by using the parameters set for each of the kinds of shadows, and detects a small focus, a large focus, a ground-glass focus and a high-density focus, and combines each detected shadow with a cross-sectional image of a CT image as shown in <figref idref="DRAWINGS">FIG. 3</figref> to display the combined image on the CRT display <b>48</b>.</p>
<p id="p-0257" num="0256">A display method of indicating a detected shadow portion to which attention is to be directed by enclosing an area of interest, such as a focus candidate shadow, with a marker (circle) will be described below. As shown in <figref idref="DRAWINGS">FIG. 35</figref>, in the case where focus candidate shadows (not shown) on a medical image <b>30</b>, such as a CT image, an MRI image and an ultrasonic image, are enclosed with circles <b>31</b>, <b>32</b> and <b>33</b>, if a plurality of focus candidate shadows are close to one another, the circles overlap and the focus candidate shadows themselves or the peripheries of the focus candidate shadows may become difficult to observe. In this embodiment, instead of overlapping and displaying the plurality of circles <b>31</b>, <b>32</b> and <b>33</b>, markers are displayed as an aggregation of circular arcs <b>34</b>, <b>35</b> and <b>36</b>, as shown in <figref idref="DRAWINGS">FIG. 36</figref><i>b</i>. Specifically, in the case where the circles <b>31</b>, <b>32</b> and <b>33</b> which are respectively centered at focus candidate shadows p<b>1</b>, p<b>2</b> and p<b>3</b>, overlap one another, the circular arcs contained in the overlap are erased and the circles <b>31</b>, <b>32</b> and <b>33</b> are drawn as an aggregation of a plurality of circular arcs <b>34</b>, <b>35</b> and <b>36</b>, as shown in <figref idref="DRAWINGS">FIG. 36</figref><i>b</i>. Incidentally, since focus candidate shadows are generally small, it is preferable that the diameters of the circles be made about 10 times the diameters of the focus candidate shadows.</p>
<p id="p-0258" num="0257"><figref idref="DRAWINGS">FIG. 37</figref> is a flowchart indicating the processing for erasing the overlap among the above-described plurality of circles and for generating an aggregation of the plurality of circular arcs. Namely, this flowchart shows details of the processing for the case of drawing the point q<b>3</b> on the circle <b>33</b> of <figref idref="DRAWINGS">FIG. 36</figref><i>a </i>as the point q<b>3</b> on the circular arc <b>36</b> of <figref idref="DRAWINGS">FIG. 36</figref><i>b. </i></p>
<p id="p-0259" num="0258">[Step S<b>72</b>] The CPU <b>40</b> determines whether the point q<b>3</b> on the circle <b>33</b> that is centered at the focus candidate shadow p<b>3</b> is contained in the circles <b>31</b> and <b>32</b> centered at the other focus candidate shadows (the focus candidate shadows p<b>1</b> and p<b>2</b> in <figref idref="DRAWINGS">FIG. 36</figref><i>a</i>). If the CPU <b>40</b> determines that the point q<b>3</b> is contained (yes), the CPU <b>40</b> proceeds to Step S<b>91</b>; whereas, if the CPU <b>40</b> determines that the point q<b>3</b> is not contained (no), the CPU <b>40</b> proceeds to Step S<b>92</b>.</p>
<p id="p-0260" num="0259">[Step S<b>91</b>] Since the CPU <b>40</b> has determined in the previous step S<b>90</b> that the point q<b>3</b> overlaps the other circles, the CPU <b>40</b> brings the processing to an end without drawing the point q<b>3</b>.</p>
<p id="p-0261" num="0260">[Step S<b>92</b>] Since the CPU <b>40</b> has determined in Step S<b>90</b> that the point q<b>3</b> does not overlap the other circles, the CPU <b>40</b> draws the point q<b>3</b> and brings the processing to an end. In the case where the CPU <b>40</b> draws the circle <b>33</b> that is centered at the focus candidate shadow p<b>3</b>, the CPU <b>40</b> performs the processing of the above-described steps S<b>90</b> to S<b>92</b> on all points on the circle. If the CPU <b>40</b> is to draw the circles <b>31</b> and <b>32</b> that are centered at the focus candidate shadows p<b>1</b> and p<b>2</b>, the CPU <b>40</b> performs similar processing.</p>
<p id="p-0262" num="0261">In addition, in the extraction process of a focus candidate shadow, by taking the inverse proportion of the results of the decision formulas (1) and (2) of Step S<b>5</b> of <figref idref="DRAWINGS">FIG. 12</figref>, it is possible to find the probability that the focus candidate shadow is a focus (focus certainty). Therefore, when the above-described circuit is to be displayed, it is possible to reflect the focus certainty by making the size of the circles proportional to the focus certainty or the size of the shadow. Incidentally, the circle may also be displayed as a thick circle or a large circuit, or in different colors (in the order of the highness of the focus certainty like red, yellow and blue), or in flashing manner, in proportion to the focus certainty irrespective of the size of the circle. Furthermore, the markers are not limited to circles, and may also be rectangles or ellipses. In addition, in the case where a focus itself is extracted, a focus candidate shadow itself may be displayed in different colors or in flashing form to attract the operator's attention, or a buzzer or a sound may also be used to attract the operator's attention.</p>
<p id="p-0263" num="0262">A display method for displaying to the operator (doctor) a CT image from which a focus candidate shadow is extracted, together with the above-described marker, will now be explained. <figref idref="DRAWINGS">FIG. 38</figref> is a view showing one example of a case where a detection result image, in which a focus candidate shadow is enclosed with a marker, and a magnified image, in which the portion within the marker is displayed on a magnified scale, are displayed in one display at the same time. As is apparent from the figure, the detection result image is the picture (a<b>2</b>) of <figref idref="DRAWINGS">FIG. 3</figref> or <figref idref="DRAWINGS">FIG. 31</figref>, and this magnified image displays the portion within the marker in the detection result image in the state of being magnified at a predetermined magnification. By this magnified display, the operator (doctor) can more accurately observe the focus candidate shadow. The display shown in <figref idref="DRAWINGS">FIG. 38</figref> is a standard picture which is designed to enable various display modes to be selected by display mode selecting buttons that are arranged in a column at the left-hand end of the picture. These display mode selecting buttons are respectively provided as icons assigned to six kinds of mode, i.e., standard display mode, horizontal order display mode, vertical order display mode, distance order display mode, spiral order display mode and registration order display mode. Although not shown, there also exists a button for displaying/erasing the marker, but the illustration thereof is omitted.</p>
<p id="p-0264" num="0263">The standard mode is the mode of displaying images in the order in which extraction processing for focus candidate shadows is performed on the images, as shown in <figref idref="DRAWINGS">FIG. 39</figref>; and, if extraction processing is performed in the order of, for example, images a-d, the images a-d are displayed in that order. Switching of pictures is performed by means of the picture switching buttons shown in <figref idref="DRAWINGS">FIG. 38</figref> at the bottom right thereof. A picture switching button on which a downward triangle is displayed is a next-picture display button, and a picture switching button on which an upward triangle is displayed is a previous-picture display button. Incidentally, focus candidate shadows exist in the image c at two locations, and, in this case, a marker display switching button is displayed. In addition, a magnification change button for arbitrarily changing the display magnification of a magnified picture is also displayed, but the illustration thereof is omitted herein.</p>
<p id="p-0265" num="0264">The horizontal order display mode is the mode of dividing a CT image into 16 parts in the horizontal and vertical directions, as shown in <figref idref="DRAWINGS">FIG. 40</figref><i>a</i>, assigning numbers to the 16 parts in order from top left to bottom left, and displaying focus candidate shadows in the ascending order of the numbers. Accordingly, in the case of a focus-candidate-shadow-extracted image, as shown in <figref idref="DRAWINGS">FIG. 39</figref>, a focus candidate shadow is displayed in order from top left to bottom left as shown in <figref idref="DRAWINGS">FIG. 41</figref>. At this time, the image c of <figref idref="DRAWINGS">FIG. 39</figref> is displayed separately in the top and bottom sections of <figref idref="DRAWINGS">FIG. 41</figref>.</p>
<p id="p-0266" num="0265">The distance order display mode is the mode of dividing a CT image into 16 parts in the horizontal and vertical directions, as shown in <figref idref="DRAWINGS">FIG. 40</figref><i>b</i>, assigning numbers to the 16 parts in order from top left to top right, and displaying focus candidate shadows in the ascending order of the numbers. Accordingly, in the case of a focus-candidate-shadow-extracted image as shown in <figref idref="DRAWINGS">FIG. 39</figref>, a focus candidate shadow is displayed in order from top left to top right, as shown in <figref idref="DRAWINGS">FIG. 42</figref>. Incidentally, images having focus candidate shadows at approximately the same division position like the images a and d are displayed in the order of extraction processing.</p>
<p id="p-0267" num="0266">The distance order display mode is the mode of sequentially accessing an image having a focus candidate shadow at the smallest distance to the first displayed focus candidate shadow. The spiral order display mode is the mode of dividing a CT image into 40 parts in the horizontal and vertical directions, as shown in <figref idref="DRAWINGS">FIG. 43</figref>, sequentially assigning numbers to the 40 parts counterclockwise spirally in order from top left to bottom left, and displaying focus candidate shadows in the ascending order of the numbers. The registration order display mode is the mode of displaying images in the order of display registered in advance by an operator. Incidentally, it goes without saying that the above-described horizontal and vertical division number is merely one example and other division numbers may also be adopted. In the case of the spiral order display mode, although images are displayed in order from the outside, images may also be displayed in order from the vicinity of the center toward the outside. The direction of the spiral may be either clockwise or counterclockwise. Furthermore, since the inside of a mark, such as a circle, has a different CT value, the inside of the mark may be set to an area of interest to adjust a display level and a display window and recalculate and modify a display conversion table, thereby easily identifiably displaying the mark.</p>
<p id="p-0268" num="0267">Incidentally, in the decision making subroutines D<b>1</b> to D<b>3</b> of <figref idref="DRAWINGS">FIG. 25</figref>, the CPU <b>40</b> makes a decision as to whether a shadow is located on a wall portion, and identifies the shadow on the basis of the decision. However, in the case where a shadow is located on a wall portion and the distance of the contact of the wall and the shadow with each other is long, the possibility that the shadow is not a focus candidate shadow is high. Contrarily, if the distance by which the wall and the shadow are in contact is short, the possibility that the shadow is a focus candidate shadow is high. For this reason, in a modification of the decision making subroutines D<b>1</b> to D<b>3</b> of <figref idref="DRAWINGS">FIG. 25</figref>, if the CPU <b>40</b> determines from the processing of the decision making subroutines D<b>1</b> to D<b>3</b> that a shadow is located on a wall portion, the CPU <b>40</b> determines whether the length of contact between the shadow and the wall portion is smaller than a predetermined length. If the CPU <b>40</b> determines that the length is smaller, the CPU <b>40</b> determines that the shadow is a focus candidate shadow; whereas, if the CPU <b>40</b> determines that the length is larger, the CPU <b>40</b> excludes the shadow from focus candidate shadows.</p>
<p id="p-0269" num="0268"><figref idref="DRAWINGS">FIGS. 44</figref><i>a </i>to <b>44</b><i>c </i>show a specific example in which, when the CPU <b>40</b> determines that a shadow is located on a wall portion, the CPU <b>40</b> determine whether the shadow is a focus candidate shadow from the length of contact between the shadow and the wall portion. As shown in <figref idref="DRAWINGS">FIG. 44</figref><i>a</i>, in a CT image, shadows <b>441</b> and <b>442</b> exist in contact with a wall portion. By applying the multi-valued image processing and the predetermines decision process of <figref idref="DRAWINGS">FIGS. 5 and 6</figref> to the CT image as shown in <figref idref="DRAWINGS">FIG. 44</figref><i>a</i>, the shadows <b>441</b> and <b>442</b>, as well as a shadow <b>443</b>, all of which seem to be focus candidates, are extracted in a multi-valued image, as shown in <figref idref="DRAWINGS">FIG. 44</figref><i>b</i>. Both of these shadows <b>441</b> and <b>442</b> are in contact with the wall portion and the shadow <b>443</b> is not in contact therewith, so that although the shadow <b>443</b> is excluded by the decision making subroutine of <figref idref="DRAWINGS">FIG. 25</figref>, the CPU <b>40</b> cannot discriminate between the shadows <b>441</b> and <b>442</b>. However, since the distance by which the shadow <b>442</b> is in contact with the wall portion is smaller than that of the shadow <b>441</b>, the possibility that the shadow <b>442</b> is a focus shadow is high. Accordingly, the CPU <b>40</b> finds the distances by which the respective shadows <b>441</b> and <b>442</b> are in contact with the wall portion, and determines whether each of the distances is smaller than a predetermined value, and determines on the basis of the result of the decision whether each of the shadows is a focus candidate. Therefore, since the distance by which the shadow <b>441</b> is in contact with the interior wall portion is larger than the predetermined value, the CPU <b>40</b> determines that the shadow <b>441</b> is not a focus candidate shadow. On the other hand, since the distance by which the shadow <b>442</b> is in contact with the wall portion is substantially smaller than the predetermined value, the CPU <b>40</b> determines that the shadow <b>442</b> is a focus candidate shadow, and, as shown in <figref idref="DRAWINGS">FIG. 44</figref><i>c</i>, only the shadow <b>442</b> is finally extracted as a focus candidate shadow.</p>
<p id="p-0270" num="0269">Referring to <figref idref="DRAWINGS">FIG. 45</figref><i>a</i>, the CPU <b>40</b> rotates a radius of predetermined length by about one degree at one time about a point in the vicinity of the center of a shadow <b>451</b> in the range of angle θ from 0 degrees to 360 degrees. During this time, the CPU <b>40</b> finds the length r at which the radius crosses the edge of the shadow at each angle. On the basis of this length r, as shown in <figref idref="DRAWINGS">FIG. 45</figref><i>b</i>, the CPU <b>40</b> plots a curve against the horizontal axis showing the angle θ and against the vertical axis showing the length r of the radius, and performs Fourier expansion on the curve. On the basis of this Fourier-expanded result, the CPU <b>40</b> generates a broken-line graph in which the horizontal axis shows frequency f and the vertical axis shows the Fourier coefficient C, as shown in <figref idref="DRAWINGS">FIG. 45</figref><i>c</i>. On the basis of this broken-line graph, the CPU <b>40</b> determines whether the shadow is a focus shadow. Namely, in this broken-line graph, a Fourier coefficient at a frequency f<b>0</b> is C<b>0</b>, a Fourier coefficient at a frequency f<b>1</b> is C<b>1</b>, and a Fourier coefficient at a frequency f<b>2</b> is C<b>2</b>. Therefore, the CPU <b>40</b> represents each of the Fourier coefficients as Ci and each of the frequencies as Fi, and finds the absolute value |fi×Ci| of the product of Ci and fi; and, further, it finds the summation Σ|fi×Ci| of the absolute value |fi×Ci|. The CPU <b>40</b> divides the summation Σ|fi×Ci| by the absolute value |Ci| of the Fourier coefficient Ci, to calculate a determined value ff. This determined value ff is expressed by the following expression:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>ff=Σ|fi×Ci|/Σ|Ci|. </i><?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0271" num="0270">The CPU <b>40</b> determines whether the shadow is a focus candidate shadow, according to whether this determined value ff is smaller than a predetermined value. In the case where the shadow is a blood vessel cross-sectional shadow <b>451</b>, as shown in <figref idref="DRAWINGS">FIG. 45</figref><i>a</i>, the Fourier coefficients of high-order frequency components are large in the Fourier expansion. In contrast, if the shadow is like a focus candidate shadow, low-order frequency components are contained in large quantities and high-order frequency components are small in the Fourier expansion. Accordingly, the CPU <b>40</b> can determine on the basis of the value of the determined value ff whether the shadow is a focus candidate shadow or a blood vessel cross-sectional shadow. Incidentally, instead of this determined value ff, a particular |fi×Ci| may also be used as a determined value.</p>
<p id="p-0272" num="0271"><figref idref="DRAWINGS">FIGS. 46</figref><i>a </i>to <b>46</b><i>d </i>show another embodiment of the decision making subroutine. In <figref idref="DRAWINGS">FIG. 46</figref><i>a</i>, the CPU <b>40</b> rotates a radius of predetermined length by about one degree at one time about the vicinity of the center of a shadow <b>461</b> in the range of angles from θ=0 degrees to θ=360 degrees. During this time, the CPU <b>40</b> determines a length of the portion of the radius up to the edge of the shadow at each angle. The minimum value of the determined lengths is set as r. Namely, a short radius r of the shadow <b>461</b> is found. The area (the number of constituent pixels) S of the shadow <b>461</b> is divided by this short radius r. Namely, S/r<sup>2 </sup>is found. The CPU <b>40</b> compares this value with a predetermined value and determines whether the shadow is a focus shadow. Namely, as shown in <figref idref="DRAWINGS">FIG. 46</figref><i>b</i>, if a shadow <b>462</b> is a circle, the value of S/r<sup>2 </sup>is π. As shown in <figref idref="DRAWINGS">FIG. 46</figref><i>c</i>, if a shadow <b>463</b> is a square, the value of S/r<sup>2 </sup>is 4. As shown in <figref idref="DRAWINGS">FIG. 46</figref><i>d</i>, if a shadow <b>464</b> is a rectangle consisting of two squares, the value of S/r<sup>2 </sup>is 8. Therefore, the shadow <b>464</b> having the rectangular shape as shown in <figref idref="DRAWINGS">FIG. 46</figref><i>d </i>must be excluded from focus candidate shadows. Accordingly, when the value of S/r<sup>2 </sup>is smaller than 8, the shadow is selected as a focus candidate shadow, whereas when the value of S/r<sup>2 </sup>is not smaller than 8, the shadow is excluded from focus candidate shadows. Incidentally, these values are one example; and in actual practice, different numerical values may be used. Incidentally, as the above-described short radius r, a value r obtained by dividing the area S of a shadow by a maximum radius rm of the shadow may also be used as an effective short radius r.</p>
<p id="p-0273" num="0272">Incidentally, in the above-described embodiment, the binary image processing of <figref idref="DRAWINGS">FIGS. 5 and 6</figref> is applied to a CT image to perform the processing of excluding the shadow of a blood vessel portion that is thinner than a predetermined value. This processing extracts and deletes a shadow having a predetermined number of pixels or less in the horizontal (X axis) or vertical (Y axis) direction, and so a comparatively large blood vessel which does not conform to this condition is not excluded. Even in the case of the shadow of such a blood vessel portion, an elongated shadow as shown in <figref idref="DRAWINGS">FIG. 28</figref><i>a </i>can be effectively excluded by the decision making subroutine E<b>1</b> of <figref idref="DRAWINGS">FIG. 27</figref>. However, there is a case where, if a comparatively large focus candidate shadow <b>470</b> and blood vessel shadows <b>471</b> and <b>472</b> overlap, as shown in <figref idref="DRAWINGS">FIG. 47</figref><i>a</i>, these blood vessel shadows <b>471</b> and <b>472</b> cannot be excluded. For this reason, in this embodiment, the blood vessel shadows <b>471</b> and <b>472</b>, as shown in <figref idref="DRAWINGS">FIGS. 47</figref><i>a</i>, <b>47</b><i>b </i>are removed by cutting through using the cutting processing shown in <figref idref="DRAWINGS">FIG. 48</figref>.</p>
<p id="p-0274" num="0273">First of all, in the first step S<b>481</b>, the CPU <b>40</b> applies the binary image processing of <figref idref="DRAWINGS">FIGS. 5 and 6</figref> to a CT image, and removes the shadow of a blood vessel portion that is thinner than a predetermined value. After this processing, in Step S<b>482</b>, the CPU <b>40</b> finds a temporary weighted center position of the shadow shown in <figref idref="DRAWINGS">FIG. 47</figref><i>a</i>. The weighted center position may be found by using the above-described various methods. In Step S<b>483</b>, the CPU <b>40</b> finds a minimum length Rmin of a moving radius <b>473</b> in the shadow while rotating the moving radius <b>473</b> in the direction of an arrow <b>476</b>. When the minimum length Rmin is found, in Step S<b>484</b>, the CPU <b>40</b> determines, as a cutting length L, a value obtained by multiplying this minimum length Rmin by a constant. Therefore, the cutting length L=Rmin×constant. When the cutting length L is found, in Step S<b>485</b>, the CPU <b>40</b> executes cutting of the shadows of the blood vessel portions on the basis of this cutting length L. The cutting of the shadows of the blood vessel portions is performed as shown in <figref idref="DRAWINGS">FIG. 47</figref><i>b</i>. First, the CPU <b>40</b> sets decision areas <b>474</b> and <b>475</b>, each made of the number of pixels corresponding to the cutting length L in the horizontal (X axis) direction or the vertical (Y axis) direction, and determines whether any of the shadows <b>470</b> to <b>472</b> is smaller than the decision areas <b>474</b> and <b>475</b>.</p>
<p id="p-0275" num="0274">In the case of <figref idref="DRAWINGS">FIG. 47(</figref><i>b</i>), the number of pixels of the cutting length L is assumed to be about 12 pixels. In the case of the horizontal decision area <b>474</b>, the pixel value of a pixel x<b>1</b> is “1” and the pixel value of a pixel xc is “0”. Accordingly, this decision area <b>474</b> does not become a cutting target, and the pixels x<b>1</b> to xc remain unchanged. On the other hand, in the case of the vertical decision area <b>475</b>, since the pixel values of a pixel y<b>1</b> and a pixel yc are both “0”, the shadow <b>471</b> located in this decision area <b>475</b> becomes a cutting target, and the pixel values of the pixels y<b>1</b> to yc are converted to “0”. The CPU <b>40</b> executes the above-described cutting processing around the shadows <b>470</b> to <b>472</b>. In this manner, the blood vessel shadows <b>471</b> and <b>472</b> are cut from the shadows shown in <figref idref="DRAWINGS">FIG. 47</figref><i>a</i>, and only the focus candidate shadow <b>470</b> is left. Incidentally, a constant for determining the cutting length L is preferably in the range of 0.5-1.5. In <figref idref="DRAWINGS">FIG. 47</figref><i>b</i>, the case where the constant is 1 has been described. In addition, the setting of this constant can also be arbitrarily changed by clicking a rate setting button with a mouse cursor, as shown in <figref idref="DRAWINGS">FIG. 49</figref><i>a</i>. Furthermore, as shown in <figref idref="DRAWINGS">FIG. 49</figref><i>b</i>, the cutting length may also be found on the basis of predetermined function processing with respect to the horizontal axis showing the minimum length Rmin of a moving radius and the vertical axis showing the cutting length.</p>
<p id="p-0276" num="0275"><figref idref="DRAWINGS">FIGS. 50</figref><i>a </i>and <b>50</b><i>b </i>show a first modification of the decision making subroutine. The decision making subroutine of <figref idref="DRAWINGS">FIGS. 50</figref><i>a</i>, <b>50</b><i>b </i>is performed in place of the decision making subroutine E<b>1</b> of <figref idref="DRAWINGS">FIG. 27</figref>, the decision making subroutine F<b>1</b> of <figref idref="DRAWINGS">FIG. 29</figref> and each of the above-described decision making subroutines, or it is performed in parallel with these decision making subroutines. <figref idref="DRAWINGS">FIG. 50</figref><i>a </i>is a view showing one example of the case where the binary image processing of <figref idref="DRAWINGS">FIGS. 5 and 6</figref> is applied to a CT image. <figref idref="DRAWINGS">FIG. 50</figref><i>b </i>is a view showing on a magnified scale the portion enclosed with a circle <b>501</b> in the image subjected to this binary image processing, and it shows how this decision is made. There is a medical image in which a ground glass opacity focus candidate shadow, which is bound to a blood vessel, exists in its binary image, as shown in <figref idref="DRAWINGS">FIG. 50</figref><i>b</i>. Since this shadow is, as shown, bound to the blood vessel, the shadow has a shape provided with a multiplicity of projections toward its periphery as diagrammatically shown in <figref idref="DRAWINGS">FIG. 50(B)</figref>. Therefore, this shadow cannot be easily determined by any of the above-described decision making subroutines.</p>
<p id="p-0277" num="0276">For this reason, the CPU <b>40</b> finds a temporary weighted center position similar to the above-described case. The CPU <b>40</b> finds the minimum length of a moving radius in the shadow, while rotating the moving radius about the weighted center position. When this minimum length is found, the CPU <b>40</b> draws a circle <b>502</b> having a radius determined by adding a predetermined value (a value equivalent to the number of pixels, for example, 1-5 pixels) to the minimum length. The CPU <b>40</b> measures the lengths (run lengths) of circular arcs and the number of the circular arcs in which this circle <b>502</b> and the shadow are superposed on each other. For example, in the case of <figref idref="DRAWINGS">FIG. 50</figref><i>b</i>, the respective run lengths of the circular arcs are found so that the run length of a circular arc p<b>1</b>p<b>2</b> between an intersection point p<b>1</b> and an intersection point p<b>2</b> is defined as “3”, the run length of a circular arc p<b>3</b>p<b>4</b> between an intersection point p<b>3</b> and an intersection point p<b>4</b> is defined as “1”, and the run length of a circular arc p<b>5</b>p<b>6</b> between an intersection point p<b>5</b> and an intersection point p<b>6</b> is defined as “2”. After the measurement of the run lengths and the counting of the number of the circular arcs have been completed, the CPU <b>40</b> draws another circle <b>503</b> having a radius determined by adding another predetermined value to the circle <b>502</b>, and similarly counts the run lengths of circular arcs and the number in which this circle <b>503</b> and the shadow are superposed on each other. In <figref idref="DRAWINGS">FIG. 50</figref><i>b</i>, only intersection points q<b>1</b> and q<b>2</b> are shown as the intersection points of the circle <b>503</b> and the shadow.</p>
<p id="p-0278" num="0277">In this manner, the CPU <b>40</b> gradually increases the radius of the circle and counts the run lengths of circular arcs and the number thereof. <figref idref="DRAWINGS">FIGS. 51</figref><i>a </i>and <b>51</b><i>b </i>show the result of this counting. <figref idref="DRAWINGS">FIG. 51</figref><i>a </i>schematically shows a count memory which uses run lengths as its addresses, and <figref idref="DRAWINGS">FIG. 51</figref><i>b </i>shows characteristic curves plotted against the horizontal axis representing the run lengths of arcs and the vertical axis representing the number of arcs, the run lengths and the number of arcs being the contents of the count memory. In the case of <figref idref="DRAWINGS">FIG. 51</figref><i>a</i>, the count memory shows values, such as 15 circular arcs, each having a run length of “1”, and <b>53</b> circular arcs, each having a run length of “2”. A characteristic curve which corresponds to these values is a characteristic curve <b>511</b> in <figref idref="DRAWINGS">FIG. 51</figref><i>b</i>. Accordingly, in the case where the shadow is a focus candidate shadow, since the number of portions projecting outward from the shadow is extremely large, the shadow exhibits the feature that an extremely large number of circular arcs of short run length exist, and the number of circular arcs of long run length is small. On the other hand, in the case where the shadow is not a focus candidate shadow, the shadow has a shape as shown by a characteristic curve <b>512</b> and exhibits the feature that circular arcs of short run length exist and circular arcs of long run length exist by approximately the same number, unlike the case of the focus candidate shadow. Accordingly, the CPU <b>40</b> can make a decision as to whether the shadow is a focus candidate shadow, by identifying the shadow by using the position of a peak (in the run length) of such a characteristic curve. In addition, the CPU <b>40</b> may make a decision as to the shadow by using the shape of a distribution of the characteristic curve, i.e., half-value widths <b>513</b> and <b>514</b> and the like. Furthermore, the CPU <b>40</b> may provide the value of a run length to the input of a neural network or the like, and make a decision as to the shadow by using the output of the neural network. In addition, although in the above-described embodiment the circular arc lengths obtained in the case where a focus candidate shadow and a circle overlap are used, circular arc lengths obtained where a focus candidate shadow and a circle do not overlap may be used, and further, a combination of both circular arc lengths may also be used. Run lengths may also be found on the basis of whether a CT value is larger or smaller than a threshold value or whether a density gradient is larger or smaller than a threshold value.</p>
<p id="p-0279" num="0278">Incidentally, although in <figref idref="DRAWINGS">FIG. 50</figref> a circle is used to count run lengths and the number of arcs, a closed curve corresponding to the shape of a shadow may be generated in the following manner to count run lengths and the number thereof on the basis of this closed curve. Namely, in the case of a shadow <b>520</b>, as shown in <figref idref="DRAWINGS">FIG. 52</figref><i>a</i>, the CPU <b>40</b> rotates a radius of predetermined length by increments of one degree about a point at the vicinity of the center of the shadow <b>520</b> in the range of an angle θ from 0 degrees to 360 degrees. During this time, the CPU <b>40</b> finds a length R at which the radius crosses the edge of the shadow at each angle. Incidentally, if a plurality of intersection points of the radius and the edge of the shadow exist, the CPU <b>40</b> selects the shortest radius. The CPU <b>40</b> plots a curve with the horizontal axis showing the angle θ and the vertical axis showing the length R of the radius calculated in this manner. This curve may be as shown in <figref idref="DRAWINGS">FIG. 52</figref><i>b</i>. This curve becomes a curve whose apexes and valleys are alternately repeated. Accordingly, the CPU <b>40</b> finds the positions of the respective valleys (the angle θ), and marks them onto the shadow display. The positions of the respective valleys are discrete on the shadow. Therefore, the CPU <b>40</b> generates a closed curve <b>521</b>, as shown in <figref idref="DRAWINGS">FIG. 52</figref><i>a</i>, by performing the processing of interpolation between each of the valleys by means of a spline curve or the like. When the closed curve <b>521</b> is found, the CPU <b>40</b> counts the lengths of short curve segments (run lengths) in portions in each of which this closed circle <b>521</b> and the shadow <b>520</b> are superposed on each other, as well as the number of the curve segments, similar to the above-described case of <figref idref="DRAWINGS">FIGS. 50</figref><i>a</i>, <b>50</b><i>b</i>. After the measurement of the run lengths and the counting of the number of curve segments have been completed as to the circle <b>521</b>, the CPU <b>40</b> draws a closed curve <b>522</b> formed by adding a predetermined value dR to the radius R(θ) of the closed curve <b>521</b>, and similarly counts the run lengths and the number of curve segments in the circle <b>522</b>. In this manner, the CPU <b>40</b> gradually increases the predetermined value dR and sequentially counts the run lengths and the number of the curve segments. Accordingly, since a count memory and characteristic curves similar to those shown in <figref idref="DRAWINGS">FIGS. 51</figref><i>a</i>, <b>51</b><i>b </i>are obtained, the CPU <b>40</b> can make a decision as to whether the shadow is a focus candidate shadow, similar to the above-described case. In addition, although in the above-described embodiment the lengths of the curve segments obtained in the case where a focus candidate shadow and a circle overlap are used, the lengths of curve segments obtained in the case where a focus candidate shadow and a circle do not overlap may be used, and, further, a combination of both may also be used. Curve segments may also be found on the basis of whether a CT value is larger or smaller than a threshold value or whether a density gradient is larger or smaller than a threshold value.</p>
<p id="p-0280" num="0279">In the above description, curve segments of a closed curve are used as a feature by which the decision is made, but a Fourier transform of shadow densities applied to a closed curve can also be used.</p>
<p id="p-0281" num="0280"><figref idref="DRAWINGS">FIGS. 53 and 54</figref> are views showing a second modification of the decision making subroutine. The decision making subroutines of <figref idref="DRAWINGS">FIGS. 53</figref><i>a </i>to <b>53</b><i>c </i>and <b>54</b><i>a </i>to <b>54</b><i>c </i>are performed in place of the decision making subroutine E<b>1</b> of <figref idref="DRAWINGS">FIG. 27</figref>, the decision making subroutine F<b>1</b> of <figref idref="DRAWINGS">FIG. 29</figref> and each of the above-described decision making subroutines, or they are performed in parallel with these decision making subroutines. <figref idref="DRAWINGS">FIGS. 53</figref><i>a </i>to <b>53</b><i>c </i>shows processing to be performed on a blood vessel cross-sectional shadow generated by applying the binary image processing of <figref idref="DRAWINGS">FIGS. 5 and 6</figref> to a CT image, and <figref idref="DRAWINGS">FIGS. 54</figref><i>a </i>to <b>54</b><i>c </i>shows processing to be performed on a focus candidate shadow. There is a case where even if the binary image processing of <figref idref="DRAWINGS">FIGS. 5 and 6</figref> is applied to a CT image to remove the shadow of a blood vessel portion that is thinner than a predetermined value, there may remain a blood vessel cross-sectional shadow <b>530</b> which seems to be a focus shadow, as shown in <figref idref="DRAWINGS">FIG. 53</figref><i>a</i>. Accordingly, the blood vessel cross-sectional shadow <b>530</b> as shown in <figref idref="DRAWINGS">FIG. 53</figref><i>a </i>must be excluded from focus candidates. For this reason, in this modification of the decision making subroutine, this blood vessel cross-sectional shadow <b>530</b> is extracted and excluded. Namely, to exclude the blood vessel cross-sectional shadow <b>530</b> from focus candidates, notice is taken of the density distribution in the shadow. Namely, in the case of the shadow <b>530</b> of a blood vessel cross-section, in a liver or the like, the contours of density in the shadow exhibit a simple form having one peak, as shown in <figref idref="DRAWINGS">FIG. 53</figref><i>a</i>. On the other hand, in the case of a focus candidate shadow <b>540</b>, as shown in <figref idref="DRAWINGS">FIG. 54</figref><i>a</i>, there appear complicated contours having a plurality of peaks in the shadow. Accordingly, as to these shadows, the CPU <b>40</b> finds continuous segments (run lengths) along which there are continuously positive or negative values of density gradient, obtains a subtraction result, or performs a differential or other processing between the CT values of one pixel and the pixel adjacent in the x axis direction from left to right and in the y axis direction from top to bottom, as shown in <figref idref="DRAWINGS">FIGS. 53</figref><i>b </i>and <b>53</b><i>c </i>and <figref idref="DRAWINGS">FIGS. 54</figref><i>a </i>and <b>54</b><i>b</i>. For example, as shown in <figref idref="DRAWINGS">FIG. 53</figref><i>b</i>, the CPU <b>40</b> computes the density gradient of each pixel in order from the left-hand side, on a straight area <b>531</b> along a shadow in the X axis direction. Assuming that the density of an original image, such as a CT image corresponding to the shadow <b>530</b> of <figref idref="DRAWINGS">FIG. 53</figref><i>b </i>is f[y][x], a density gradient g[y][x] of each pixel is found by a difference between the previous and next pixels, as expressed by the following formula:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>g[y][x]=f[y][x+</i>1<i>]−f[y][x−</i>1].<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0282" num="0281">When the computation of the density gradients in the straight area <b>531</b> is completed in this manner, the CPU <b>40</b> sequentially shifts this straight area in the y axis direction to compute density gradients. <figref idref="DRAWINGS">FIG. 53</figref><i>b </i>diagrammatically shows the density gradients in the X axis direction in the case of each of the straight areas <b>531</b> and <b>532</b>. <figref idref="DRAWINGS">FIG. 53</figref><i>c </i>diagrammatically shows the density gradients in the Y axis direction in the case of each of the straight areas <b>533</b> and <b>534</b>. The CPU <b>40</b> finds the positive and negative run length segments in each of the straight lines on the basis of these density gradients. For example, in the case of the straight area <b>531</b>, the positive run length is “11” and the negative run length is “4”. In the case of the straight area <b>532</b>, the positive run length is “7” and the negative run length is “7”. In the case of the straight area <b>533</b>, the positive run length is “6” and the negative run length is “6”. In the case of the straight area <b>532</b>, the positive run length is “6” and the negative run length is “5”. In this manner, the CPU <b>40</b> counts the positive and negative run lengths over the whole of the shadow <b>530</b>. The CPU <b>40</b> similarly finds the density gradients of each straight area of the focus candidate shadow <b>540</b> as shown in <figref idref="DRAWINGS">FIGS. 54</figref><i>a </i>and <b>54</b><i>b</i>, and counts positive and negative run lengths on the basis of the density gradients. In the case of a straight area <b>541</b> of <figref idref="DRAWINGS">FIG. 54</figref><i>a</i>, the positive run lengths are “11” and “2” and the negative run lengths are “3” and “4”. In the case of a straight area <b>542</b>, the positive run lengths are “5” and “2” and the negative run lengths is “2” and “4”. In the case of a straight area <b>543</b>, as seen in <figref idref="DRAWINGS">FIG. 4</figref><i>b</i>, the positive run lengths are “6”, “1” and “1” and the negative run lengths are “3”, “2” and “3”. In the case of a straight area <b>544</b>, the positive run lengths are “5”, “2” and “2” and the negative run lengths are “2”, “2” and “3”. It can be seen from this fact that the focus candidate shadow has shorter length of each run length segment and greater number of run length segments.</p>
<p id="p-0283" num="0282"><figref idref="DRAWINGS">FIG. 54</figref><i>c </i>shows the relationship between the length and the number of run length segments which are calculated in the shadow <b>530</b><i>a </i>of <figref idref="DRAWINGS">FIG. 53</figref> and the focus candidate shadow <b>540</b> of <figref idref="DRAWINGS">FIG. 54</figref><i>a</i>. As is apparent from the curves shown in <figref idref="DRAWINGS">FIG. 54</figref><i>c</i>, the case of the focus candidate shadow exhibits a tendency to have a peak in a number of run length segments where the lengths are comparatively small, while the case of the blood vessel cross-sectional shadow or the like exhibits a tendency to have a peak where the lengths are comparatively large. Accordingly, by utilizing these tendencies, the CPU <b>40</b> can efficiently exclude the blood vessel cross-sectional shadow, as shown in <figref idref="DRAWINGS">FIGS. 53</figref><i>a </i>to <b>53</b><i>c</i>. Incidentally, in the description of this modification, reference has been made to the case where a density gradient is found from the difference between the previous and next pixels, but the density of a pixel may be compared with a predetermined threshold value to determine the density gradient of “+” or “−” according to the magnitude of the density. As this threshold value, the average value of densities in the entire range of a shadow may also be used. Incidentally, in the above-described embodiment, reference has been made to the case where density gradients in the X axis direction and the Y axis direction are calculated, but density gradients as to one arbitrary direction may be found, or density gradients may also be found as to a plurality of directions, such as the X axis direction, the Y axis direction and a direction crossing either of these directions at 45 degrees.</p>
<p id="p-0284" num="0283">The above description has referred to the case where, in the decision making subroutines D<b>1</b> to D<b>3</b> of <figref idref="DRAWINGS">FIG. 25</figref>, a decision is made as to whether a shadow is located on a wall portion; and, further, in <figref idref="DRAWINGS">FIGS. 44</figref><i>a </i>to <b>44</b><i>c</i>, a decision is made as to whether the shadow is a focus candidate shadow, on the basis of the length of contact between the shadow and the wall portion. However, there is a case where shadows <b>551</b> and <b>552</b>, which are in contact with a wall portion, exist in a CT image, as shown at (a) in <figref idref="DRAWINGS">FIG. 55</figref>. Since the distance of the boundary where the shadow <b>551</b> is in contact with the inside of the wall portion is much larger than a predetermined value, it is determined that the shadow <b>551</b> is not a focus candidate shadow. However, the shadow <b>552</b> is not a shadow of a cancer or the like, but is a cancer-accompanying shadow which is concomitant with a cancer (invagination of a pleural membrane), and the cancer-accompanying shadow is characterized by an elongated shape perpendicular to the pleural membrane. Therefore, the possibility that this shadow <b>552</b> is excluded from focus candidate shadows is very high. However, it is known that an indistinct shadow like <b>553</b> in the vicinity of a cancer accompanying shadow, for instance, in contact with a tip of the shadow <b>552</b>, as shown at (a) in <figref idref="DRAWINGS">FIG. 55</figref>, is a focus candidate. This cancer-accompanying shadow <b>553</b> cannot be easily extracted by the above-described processing. For this reason, in this embodiment, this cancer-accompanying shadow <b>552</b> is extracted, and the cancer-accompanying shadow <b>552</b> is displayed in such a manner as to be enclosed with a large marker (a circle or an ellipse), thereby indicating that a shadow acting like a focus exists near the cancer-accompanying shadow <b>552</b>. In this embodiment, the cancer-accompanying shadow detection processing shown in <figref idref="DRAWINGS">FIG. 56</figref> is executed to detect such a cancer-accompanying shadow.</p>
<p id="p-0285" num="0284">[Step S<b>551</b>] First, since a shadow <b>550</b> and the shadows <b>551</b> and <b>552</b>, all of which seem to be focus candidate shadows, are extracted in a multi-valued image, as shown at (b) in <figref idref="DRAWINGS">FIG. 55</figref>, the CPU <b>40</b> determines whether these shadows <b>550</b>, <b>551</b> and <b>552</b> are in contact with the wall portion. If the CPU <b>40</b> determines that each of the shadows <b>550</b>, <b>551</b> and <b>552</b> is in contact (yes), the CPU <b>40</b> proceeds to the next Step S<b>552</b>; whereas, if the CPU <b>40</b> determines that a shadow <b>550</b>, <b>551</b> or <b>552</b> is not in contact (no), the CPU <b>40</b> proceeds to Step S<b>554</b> and deletes the corresponding shadows. Since the shadow <b>550</b> is not in contact, the shadow <b>550</b> is excluded from focus candidates through the shadow deletion processing of Step S<b>554</b>.</p>
<p id="p-0286" num="0285">[Step S<b>552</b>] Then, the CPU <b>40</b> determines the proportion in which each of the shadows is in contact with the wall portion of the pleural membrane, i.e., whether each of their contact lengths is smaller than a predetermined value. If the CPU <b>40</b> determines that each of the contact lengths is smaller (yes), the CPU <b>40</b> proceeds to the next Step S<b>553</b>; whereas, if the CPU <b>40</b> determines that part of the contact lengths is not smaller (no), the CPU <b>40</b> deletes the corresponding shadow. Since the length of contact of the shadow <b>551</b> with the wall portion is larger than the predetermined value, the shadow <b>551</b> is deleted through the shadow deletion processing of Step S<b>554</b>. Since the length of contact of the shadow <b>552</b> with the wall portion is much smaller than that of the shadow <b>551</b>, the CPU <b>40</b> proceeds to the next Step S<b>553</b>.</p>
<p id="p-0287" num="0286">[Step S<b>553</b>] The CPU <b>40</b> extracts a cancer-accompanying shadow from corresponding shadows. Namely, the shadow <b>442</b> of <figref idref="DRAWINGS">FIG. 44</figref><i>a </i>and the shadow <b>552</b> of <figref idref="DRAWINGS">FIG. 55</figref><i>a </i>corresponds to shadows, each of which is in contact with the wall portion in a proportion smaller than the predetermined value. Among such shadows, a cancer-accompanying shadow is a shadow which is too elongated to be determined as a focus candidate shadow. Therefore, the CPU <b>40</b> extracts as a cancer-accompanying shadow a shadow which is in contact with the wall portion in a proportion smaller than the predetermined value and is excluded from focus candidate shadows. Accordingly, as shown at (c) in <figref idref="DRAWINGS">FIG. 55</figref>, the shadow <b>552</b> is extracted as a cancer-accompanying shadow. On the other hand, the shadow <b>442</b> of <figref idref="DRAWINGS">FIG. 44</figref><i>a </i>is extracted as a focus candidate shadow.</p>
<p id="p-0288" num="0287">[Step S<b>554</b>] The CPU <b>40</b> determines the shadows which have been determined as “no” in Step S<b>551</b> and Step S<b>552</b>.</p>
<p id="p-0289" num="0288">[Step S<b>555</b>] The CPU <b>40</b> displays a large marker <b>570</b> (a circle or an ellipse) in such a manner as to superpose the marker <b>570</b> on the original image to enclose the cancer-accompanying shadow detected in Step S<b>553</b>, i.e., a object indicating a focus, as shown in <figref idref="DRAWINGS">FIG. 57</figref>. Incidentally, the size of this marker <b>570</b> can be arbitrarily changed by a scale setting button displayed at the bottom right. The doctor can perform an examination as to whether a focus shadow exists by visually inspecting the portion enclosed by this marker <b>570</b>.</p>
<p id="p-0290" num="0289"><figref idref="DRAWINGS">FIGS. 58</figref><i>a </i>to, <b>60</b><i>b </i>are views showing a third modification of the decision making subroutine. The decision making subroutine of <figref idref="DRAWINGS">FIGS. 58</figref><i>a </i>to <b>60</b><i>b </i>is performed in place of the decision making subroutine E<b>1</b> of <figref idref="DRAWINGS">FIG. 27</figref>, the decision making subroutine F<b>1</b> of <figref idref="DRAWINGS">FIG. 29</figref> and each of the above-described decision making subroutines, or it is carried out in parallel with these decision making subroutines. First of all, the CPU <b>40</b> applies the binary image processing of <figref idref="DRAWINGS">FIGS. 5 and 6</figref> to a CT image and finds a temporary weighted center position. The weighted center position may be found by using the above-described various methods. The CPU <b>40</b> rotates a radius <b>581</b> of predetermined length by increments of 5 degrees in the range of angle θ from 0 degrees to 360 degrees about the temporary weighted center position in the direction of an arrow <b>583</b>. The increment of rotation may be any appropriate value other than 5 degrees. The CPU <b>40</b> finds a variance or standard deviation SDθ of CT values of a shadow located on the radius, while rotating the radius.</p>
<p id="p-0291" num="0290">The result obtained in this manner is plotted in graphs as shown in <figref idref="DRAWINGS">FIGS. 58</figref><i>b </i>and <b>58</b><i>c</i>. The variance or standard deviation SDθ of <figref idref="DRAWINGS">FIG. 58</figref><i>b </i>is that of the focus candidate shadow <b>540</b> shown in <figref idref="DRAWINGS">FIG. 54</figref><i>a</i>. The variance or standard deviation SDθ of <figref idref="DRAWINGS">FIG. 58</figref><i>c </i>corresponds to the blood vessel cross-sectional shadow <b>530</b> shown in <figref idref="DRAWINGS">FIG. 53</figref><i>a</i>. The focus candidate shadow <b>540</b> exhibits complicated contours having a plurality of peaks, as described previously. The variance or standard deviation SDθ assumes various complicated values for the respective angles, as shown in <figref idref="DRAWINGS">FIG. 58</figref><i>b</i>, according to the complicated contours. On the other hand, the blood vessel cross-sectional shadow <b>530</b> exhibits simple contours having one peak. The variance or standard deviation SDθ also assumes simple values which do not greatly vary among the angles, as shown in <figref idref="DRAWINGS">FIG. 58</figref><i>c</i>. Accordingly, the CPU <b>40</b> can determine whether the shadow is a focus candidate shadow or a blood vessel cross-sectional shadow, on the basis of the graphs of the variance or standard deviation SDθ, as shown in <figref idref="DRAWINGS">FIGS. 58</figref><i>b </i>and <b>58</b><i>c. </i></p>
<p id="p-0292" num="0291">Incidentally, the CPU <b>40</b> may also find a secondary variance or standard deviation of the variance or standard deviation SDθ of <figref idref="DRAWINGS">FIGS. 58</figref><i>b </i>and <b>58</b><i>c </i>to determine whether the shadow is a focus candidate shadow or blood vessel cross-sectional shadow, according to whether the secondary variance or standard deviation is larger or smaller than a predetermined value. In addition, as shown in <figref idref="DRAWINGS">FIGS. 59</figref><i>a </i>to <b>59</b><i>c</i>, the CPU <b>40</b> may divide each shadow into areas to find a variance or standard deviation as to each of the divided areas. In the case of <figref idref="DRAWINGS">FIG. 59</figref><i>a</i>, the CPU <b>40</b> divides a shadow into upper and lower shadows along a horizontal line passing through the middle of the shadow, and finds a variance or standard deviation SD-U of CT values of the upper shadow and finds a variance or standard deviation SD-D of CT values of the lower shadow; and, further, it finds the secondary variance or standard deviation of both as a key feature to be used for making a decision as to the shadow. Incidentally, the CPU <b>40</b> may also use as a key determining feature the difference between the variances or standard deviations SD-U and SD-D of the upper and lower shadows or the absolute value of the difference. In the case of <figref idref="DRAWINGS">FIG. 59</figref><i>b</i>, the CPU <b>40</b> divides a shadow into four quadrants along horizontal and vertical lines passing through the shadow, and finds variance or standard deviations SD-<b>1</b> to SD-<b>4</b> of CT values of each of the quadrants as a feature quantity to be used for making a decision as to the shadow. In the case of <figref idref="DRAWINGS">FIG. 59</figref><i>c</i>, the CPU <b>40</b> divides a shadow into areas arranged at equal intervals in the vertical direction, and finds variance or standard deviations SD-<b>1</b> to SD-<b>7</b> of CT values of each of the divided areas; and, further, it finds a secondary variance or standard deviation of these variance or standard deviations SD-<b>1</b> to SD-<b>7</b> as a key feature quantity to be used for making a decision as to the shadow. Incidentally, the CPU <b>40</b> may divide the shadow into areas arranged at equal intervals in the horizontal direction.</p>
<p id="p-0293" num="0292"><figref idref="DRAWINGS">FIGS. 58</figref><i>a </i>to <b>58</b><i>c </i>and <b>59</b><i>a </i>to <b>59</b><i>c </i>show the case where the CPU <b>40</b> uses variance or standard deviation of the shadow to make a decision as to whether a shadow is a focus candidate shadow or a blood vessel cross-sectional shadow. As shown in <figref idref="DRAWINGS">FIGS. 60</figref><i>a </i>and <b>60</b><i>b</i>, the CPU <b>40</b> may also make a decision as to a shadow by using a variance or standard deviation of the shadow and a variance or standard deviation of a predetermined area along the periphery of the shadow. Namely, in the case where the periphery of a shadow is defined by a moving radius circle R(θ), as shown in <figref idref="DRAWINGS">FIGS. 60</figref><i>a </i>and <b>60</b><i>b</i>, the difference from a variance or standard deviation in the area R(θ) to R(θ)+dR outward by a predetermined distance dR from this moving radius circle R(θ) is found as a feature quantity, whereby it is possible to discriminate between the blood vessel cross-sectional shadow shown in <figref idref="DRAWINGS">FIG. 60</figref><i>a </i>and the focus candidate shadow shown in <figref idref="DRAWINGS">FIG. 60</figref><i>b</i>. In the case of the blood vessel cross-sectional shadow shown in <figref idref="DRAWINGS">FIG. 60</figref><i>a</i>, since the area R(θ) to R(θ)+dR traverses the blood vessel cross-sectional shadow, the variance or standard deviation assumes a comparatively large value. In the case of the focus candidate shadow shown in <figref idref="DRAWINGS">FIG. 60</figref><i>a</i>, since a substantial part of the area R(θ) to R(θ)+dR traverses a portion where the shadow does not exist, the variance or standard deviation assumes a comparatively small value. Accordingly, the CPU <b>40</b> finds the difference between a variance or standard deviation inside of the shadow and the variance or standard deviation in the area R(θ) to R(θ)+dR as a key feature quantity to be used for discriminating between the focus candidate and blood vessel shadow. In addition, the CPU <b>40</b> may also set threshold values, respectively, for this key feature and for the variance or standard deviation of the area R(θ) to R(θ)+dR, respectively, to make such a decision. Furthermore, this feature quantity or the variance or standard deviation of the area R(θ) to R(θ)+dR may be used as an input value for Mahalanobis distance, Euclidean distance, neural networks and the like, and the CPU <b>40</b> may make such a decision by using the obtained result.</p>
<p id="p-0294" num="0293">In the above-described embodiment, as a display method for the case where a CT image having an extracted focus candidate shadow and a marker are displayed for the operator (doctor), reference has been made to a method of displaying, at the same time, a detection result image in which a focus candidate shadow is indicated by a marker, as shown in <figref idref="DRAWINGS">FIG. 38</figref> and a magnified image which shows the marker portion on an magnified scale, as well as a method of providing display in various modes as shown in <figref idref="DRAWINGS">FIGS. 39 to 43</figref>. In these methods, in the case where the operator (doctor) arbitrarily selects a portion desired to be displayed, with a mouse cursor or the like, the CPU <b>40</b> may also display focus candidate shadows in the order of their locations relative to the selected portion, from closest to farthest. Details of this focus candidate shadow display processing will be described below with reference to <figref idref="DRAWINGS">FIGS. 61</figref><i>a</i>, <b>61</b><i>b </i>and <b>62</b>.</p>
<p id="p-0295" num="0294">[Step S<b>621</b>] The CPU <b>40</b> sequentially displays combined images, each made up of a marker and a tomographic image as shown in <figref idref="DRAWINGS">FIG. 39</figref>, <b>41</b> or <b>42</b>, in accordance with a display mode selected by the standard mode selecting button on the standard picture of <figref idref="DRAWINGS">FIG. 38</figref>.</p>
<p id="p-0296" num="0295">[Step S<b>622</b>] The CPU <b>40</b> determines whether a mouse has been clicked at an arbitrary position on a combined image being displayed. If the decision result is yes, the CPU <b>40</b> proceeds to the next Step S<b>623</b>, whereas if the decision result is no, the CPU <b>40</b> returns to Step S<b>621</b>. In Step S<b>621</b>, the display of a combined image according to the display mode is continued. Namely, this means that when a mouse pointer <b>611</b> lies at a predetermined position on the combined image as shown in <figref idref="DRAWINGS">FIG. 61</figref><i>a</i>, a decision is made as to whether the button of the mouse has been clicked.</p>
<p id="p-0297" num="0296">[Step S<b>623</b>] Since it has been determined in Step S<b>622</b> that the mouse has been clicked, the CPU <b>40</b> determines whether a focus candidate shadow exists within a circle of radius D from the position of the mouse pointer. Namely, in the case of <figref idref="DRAWINGS">FIG. 61</figref><i>a</i>, a decision is made as to whether a focus candidate shadow exists within a dashed-line circle of radius D centered at the mouse pointer <b>611</b>.</p>
<p id="p-0298" num="0297">[Step S<b>624</b>] Since it has been determined in the decision of Step S<b>623</b> that a focus candidate shadow does not exist within the circle of radius D centered at the mouse pointer, the CPU <b>40</b> displays “No Focus Candidate Shadow Exists”. Since a “CONTINUE” button for determining whether the current display is to be continued without modification and an “END” button for bringing display to an end are included in the display, the CPU <b>40</b> determines whether this “END” button has been manipulated with a click. If the decision result is yes (the “END” button has been clicked), the CPU <b>40</b> brings the processing to an end, whereas if the decision result is no (the “CONTINUE” button has been clicked), the CPU <b>40</b> returns to Step S<b>621</b>.</p>
<p id="p-0299" num="0298">[Step S<b>625</b>] Since it has been determined in the decision of Step S<b>623</b> that a focus candidate shadow exists within the circle of radius D centered at the mouse pointer, the CPU <b>40</b> sequentially displays images in which tomographic images of the focus candidate shadow and markers are combined. In the case of <figref idref="DRAWINGS">FIG. 61</figref><i>a</i>, the focus candidate shadows of the image a and the image c corresponds to the shadow which exists within the dashed-line circle of radius D. The focus candidate shadows of the images b and the images c of <figref idref="DRAWINGS">FIGS. 41 and 42</figref> correspond to the shadow which exists within the dashed-line circle of radius D. Accordingly, as shown in <figref idref="DRAWINGS">FIG. 61</figref><i>b</i>, the images of the existing focus candidate shadows are sequentially displayed in the circle of radius D. In <figref idref="DRAWINGS">FIG. 61</figref><i>b</i>, the images b of <figref idref="DRAWINGS">FIGS. 41 and 42</figref> are displayed. Although not shown, a “NEXT button” is displayed, and when it is clicked, the next image c is displayed. There is also a special case where the radius D is set to be larger than such an image, and when a mouse is clicked with no marker being displayed, all corresponding markers are displayed in response to the click.</p>
<p id="p-0300" num="0299">[Step S<b>626</b>] The CPU <b>40</b> determines whether the mouse has been clicked at an arbitrary position on the combined image being displayed. If the decision result is yes (if the mouse is clicked), the CPU <b>40</b> returns to the previous Step S<b>623</b>; whereas, if the decision result is no, the CPU <b>40</b> returns to Step S<b>625</b>. In Step S<b>625</b>, the display of the focus candidate shadow is continued. When another position is clicked by the mouse pointer, similar processing is performed in this step according to whether a focus candidate shadow exists within a circle of radius D centered at the mouse pointer. In the case where the same position is clicked, similar to the case where the aforementioned “NEXT button” is clicked, the next image c is displayed. To provide such a display, information on x coordinates and y coordinates indicating where extracted focus candidate shadows are located on the image is stored on a predetermined memory space.</p>
<p id="p-0301" num="0300"><figref idref="DRAWINGS">FIG. 63</figref><i>a</i>, <b>63</b><i>b </i>and <figref idref="DRAWINGS">FIG. 64</figref><i>a</i>, <b>64</b><i>b </i>are views showing a fourth modification of the decision making subroutine. Each of the decision making subroutines of <figref idref="DRAWINGS">FIG. 63</figref><i>a</i>, <b>63</b><i>b </i>and <figref idref="DRAWINGS">FIG. 64</figref><i>a</i>, <b>64</b><i>b </i>is performed in place of the decision making subroutine E<b>1</b> of <figref idref="DRAWINGS">FIG. 27</figref>, the decision making subroutine F<b>1</b> of <figref idref="DRAWINGS">FIG. 29</figref> and each of the above-described decision making subroutines, or it is performed in parallel with these decision making subroutines. <figref idref="DRAWINGS">FIG. 63</figref><i>a </i>is a view showing a part of a CT image of the case where a plurality of needle- or line-shaped shadows <b>631</b> to <b>639</b>, called spicules, appear in the periphery of a malignant cancer shadow <b>630</b>.</p>
<p id="p-0302" num="0301">The cancer shadow <b>630</b> is a shadow of comparatively low density, and it is difficult to identify. In contrast, the shadows <b>631</b> to <b>639</b> are shadows of high density and are easy to identify, but they have the disadvantage that they are easily mistaken for shadows of blood vessels. When the binary image processing of <figref idref="DRAWINGS">FIGS. 5 and 6</figref> is applied to the CT image including the spicules as shown in <figref idref="DRAWINGS">FIG. 63</figref><i>a</i>, the cancer shadow <b>630</b> of low density is not extracted and only the needle- or line-shaped shadows <b>631</b> to <b>639</b> are extracted, as shown in <figref idref="DRAWINGS">FIG. 63</figref><i>b</i>. There is a case where these spicula shadows <b>631</b> to <b>639</b> are mistaken for the shadow of a blood vessel portion and are excluded. Therefore, it is necessary to determine whether the shadows <b>631</b> to <b>639</b> shown in <figref idref="DRAWINGS">FIG. 63</figref><i>b </i>are spicula shadows. For this reason, in this embodiment, the CPU <b>40</b> discriminates between such spicula shadows and blood vessel shadows; and, in the case of the spicula shadows, the CPU <b>40</b> finds the weighted center position of the shadows and displays the weighted center position with a marker.</p>
<p id="p-0303" num="0302">First, the CPU <b>40</b> applies the binary image processing of <figref idref="DRAWINGS">FIGS. 5 and 6</figref> to the CT image and finds a temporary weighted center position of the shadows. The weighted center position may be found by using the above-described various methods. The CPU <b>40</b> rotates a straight line about the temporary weighted center position and finds a straight line whose portion crossing each the shadows is the longest, i.e., the long length of each of the shadows, and finds the positions (two points) at which this long length line crosses the edge of its shadow. <figref idref="DRAWINGS">FIG. 64</figref><i>a </i>is a view showing the state where the long diameter of each of the shadows <b>631</b> to <b>639</b> is found and the intersections of the long diameter and each of the shadows are found. As is apparent from <figref idref="DRAWINGS">FIG. 64</figref><i>a</i>, two intersections are found on each of the shadows <b>631</b> to <b>639</b>. Intersections <b>631</b>A and <b>631</b>B exist on the shadow <b>631</b>, and intersections <b>632</b>A and <b>632</b>B exist on the shadow <b>632</b>. Similarly, intersections <b>633</b>A to <b>639</b>A and <b>633</b>B to <b>639</b>B exist on the respective shadows <b>633</b> to <b>639</b>.</p>
<p id="p-0304" num="0303">The CPU <b>40</b> arranges the thus-obtained intersections <b>631</b>A to <b>639</b>A and <b>631</b>B to <b>639</b>B on a pixel memory space, as shown in <figref idref="DRAWINGS">FIG. 64</figref><i>b</i>, and assigns straight strips <b>631</b><i>c </i>to <b>639</b><i>c </i>of predetermined width, which respectively connect the intersections <b>631</b>A and <b>639</b>A to the intersections <b>631</b>B to <b>639</b>B, on the pixel memory space cleared to zero. The CPU <b>40</b> adds “1” to pixels which correspond to these straight strips <b>631</b><i>c </i>to <b>639</b><i>c</i>, for each of the straight strips <b>631</b><i>c </i>to <b>639</b><i>c</i>. Namely, the CPU <b>40</b> adds “1” to a pixel memory corresponding to an area through which the strip-shaped straight line <b>631</b><i>c </i>passes, and adds “1” to a pixel memory corresponding to an area through which the straight strip <b>632</b><i>c </i>passes. Similarly, the CPU <b>40</b> adds “1” to a pixel memory corresponding to each of the areas through which the respective straight strips <b>633</b><i>c </i>to <b>639</b><i>c </i>pass. In this manner, the values of the respective pixel memories at locations corresponding the areas through which the respective straight strips <b>631</b><i>c </i>to <b>639</b><i>c </i>pass are increased.</p>
<p id="p-0305" num="0304">In the case of <figref idref="DRAWINGS">FIG. 64</figref><i>b</i>, the straight strips <b>631</b><i>c </i>to <b>639</b><i>c </i>concentrically pass through a portion enclosed by a circle <b>640</b>, so that the value of the pixel memory of this portion becomes large. Thus, the CPU <b>40</b> extracts a portion in which the value of its pixel memory is, for example, 4 or more, and defines the portion as the weighted center position of the spicula shadows. Incidentally, if portions, in each of which the value of its pixel memory is 4 or more, are close to each other, the portion having the higher value is defined as the weighted center position. When this weighted center position is found, the CPU <b>40</b> displays a marker <b>641</b> centered about the weighted center position, as shown in <figref idref="DRAWINGS">FIG. 63</figref><i>b</i>. In this manner, a malignant cancer shadow having spicula shadows easily mistaken for blood vessel shadows can be displayed as a focus candidate shadow.</p>
<p id="p-0306" num="0305"><figref idref="DRAWINGS">FIGS. 65 and 66</figref><i>a </i>to <b>66</b><i>f </i>are views showing a modification of each of the decision making subroutine E<b>1</b> of <figref idref="DRAWINGS">FIG. 27</figref> and the decision making subroutine F<b>1</b> of <figref idref="DRAWINGS">FIG. 29</figref>, and they show a processing method for extracting and excluding a blood vessel cross-sectional shadow. The processing of <figref idref="DRAWINGS">FIGS. 65 and 66</figref><i>a </i>to <b>66</b><i>f </i>may be executed in parallel with the decision making subroutine E<b>1</b> of <figref idref="DRAWINGS">FIG. 27</figref> or the decision making subroutine F<b>1</b> of <figref idref="DRAWINGS">FIG. 29</figref>. Normally, there is a case in which a CT image of a lung portion (lung region) captures part of the blood vessels which extend so as to spread radially. Accordingly, in this embodiment, recognizing that some blood vessels extend radially, the CPU <b>40</b> extracts and excludes such blood vessel cross-sectional shadows. Namely, in this embodiment, in the case where blood vessels extend radially as shown in <figref idref="DRAWINGS">FIG. 65</figref>, the CPU <b>40</b> compares mutually adjacent tomographic images of predetermined slice thickness to determine whether the tomographic images are blood vessel cross-sectional shadows.</p>
<p id="p-0307" num="0306">As to the blood vessels which extend radially, as shown in <figref idref="DRAWINGS">FIG. 65</figref>, tomographic images respectively corresponding to planes <b>651</b> to <b>653</b> are photographed, as shown in <figref idref="DRAWINGS">FIG. 65</figref>. As to the plane <b>651</b>, blood vessel cross-sectional shadows <b>651</b>A and <b>651</b>B are photographed as tomographic images, as shown in <figref idref="DRAWINGS">FIG. 66</figref><i>a</i>. As to the plane <b>652</b>, blood vessel cross-sectional shadows <b>652</b>A and <b>652</b>B are photographed as tomographic images, as shown in <figref idref="DRAWINGS">FIG. 66</figref><i>b</i>. As to the plane <b>653</b>, blood vessel cross-sectional shadows <b>653</b>A, <b>653</b>B and <b>653</b>C are photographed as tomographic images, as shown in <figref idref="DRAWINGS">FIG. 66</figref><i>c</i>. In the tomographic images of the radially extending blood vessels, the blood vessel cross-sectional shadows sequentially change in position and size. Accordingly, the CPU <b>40</b> superposes mutually adjacent tomographic images, and determines whether the shadows are blood vessel cross-sectional shadows, on the basis of the manner of the changes in the positions and the sizes of the shadows.</p>
<p id="p-0308" num="0307"><figref idref="DRAWINGS">FIG. 66</figref><i>d </i>shows tomographic images corresponding to the plane <b>651</b> and the plane <b>652</b>, which are adjacent to each other, i.e., a superposition of <figref idref="DRAWINGS">FIG. 66</figref><i>a </i>and <figref idref="DRAWINGS">FIG. 66</figref><i>b</i>. <figref idref="DRAWINGS">FIG. 66</figref><i>e </i>shows tomographic images corresponding to the plane <b>652</b> and the plane <b>653</b> which are adjacent to each other, i.e., a superposition of <figref idref="DRAWINGS">FIG. 66</figref><i>b </i>and <figref idref="DRAWINGS">FIG. 66</figref><i>c</i>. For ease of illustration, the blood vessel cross-sectional shadows <b>652</b>A and <b>652</b>B of <figref idref="DRAWINGS">FIG. 66</figref><i>b </i>are represented by dashed lines in <figref idref="DRAWINGS">FIGS. 66</figref><i>d </i>and <b>66</b><i>e</i>. As shown in <figref idref="DRAWINGS">FIG. 66</figref><i>a</i>, the blood vessel cross-sectional shadow <b>651</b>A and the blood vessel cross-sectional shadow <b>652</b>A are partly superposed on each other. In addition, the blood vessel cross-sectional shadow <b>651</b>B and the blood vessel cross-sectional shadow <b>652</b>B are partly superposed on each other. In the case where the shadows of both tomographic images are partly superposed, both are deleted as blood vessel cross-sectional shadows indicative of part of the radially extending blood vessels. In the case of the blood vessel cross-sectional shadow <b>652</b>A and the blood vessel cross-sectional shadow <b>653</b>A of <figref idref="DRAWINGS">FIG. 66</figref><i>e</i>, since they are partly superposed, both shadows are deleted as blood vessel cross-sectional shadows. In the case of the blood vessel cross-sectional shadow <b>652</b>B and the blood vessel cross-sectional shadows <b>653</b>B and <b>653</b>C of <figref idref="DRAWINGS">FIG. 66</figref><i>e</i>, the blood vessel cross-sectional shadows <b>653</b>B and <b>653</b>C branch off from the blood vessel cross-sectional shadow <b>652</b>B, and the blood vessel cross-sectional shadow <b>653</b>B is partly superposed on the blood vessel cross-sectional shadow <b>652</b>B, but the blood vessel cross-sectional shadow <b>653</b>C is not partly superposed on the blood vessel cross-sectional shadow <b>652</b>B. Accordingly, in this case, the blood vessel cross-sectional shadow <b>652</b>B and the blood vessel cross-sectional shadow <b>653</b>B become objects to be deleted as blood vessel cross-sectional shadows, but the blood vessel cross-sectional shadow <b>653</b>C does not become an object to be deleted. Incidentally, in the case where the respective blood vessel cross-sectional shadows <b>652</b>A and <b>652</b>B are superposed on shadows <b>661</b> and <b>662</b> in proportions more than a predetermined proportion, as shown in <figref idref="DRAWINGS">FIG. 66</figref><i>f</i>, all of these shadows are not detected as focus candidate shadows, and become objects for another decision. Incidentally, these proportions are calculated for the respective shadows, and the area of superposition is divided by the area of each of the superposed shadows, and the larger value is adopted. Namely, in the case of the blood vessel cross-sectional shadow <b>652</b>A and the shadow <b>661</b>, the proportion found when the area of their superposition is divided by the area of the blood vessel cross-sectional shadow <b>652</b> and the proportion found when the area of the superposition is divided by the area of the shadow <b>661</b> differ from each other, and the result of division by the shadow <b>661</b> of smaller area is adopted. Incidentally, the proportion of the superposition can be arbitrarily set as a parameter.</p>
<p id="p-0309" num="0308">Incidentally, in X-ray CT devices and the like, there is a case where data of projection on an area in all directions cannot be obtained and a tomographic image must be reconstructed. This case is called a partial volume effect. Even in a decision as to whether a shadow due to this partial volume effect is mistakenly detected, it is effective to find a correlation of mutually adjacent images. In the case of the partial volume effect, since a shadow of high density is imaged in adjacent areas, the proportion of pixels which assumes a larger value than a preset particular CT value in the previously detected area and the corresponding area (the same position) of its adjacent image can be used for the decision.</p>
<p id="p-0310" num="0309"><figref idref="DRAWINGS">FIGS. 67</figref><i>a </i>to <b>67</b><i>d </i>and <b>68</b> are views showing a fifth modification of the decision making subroutine. The decision making subroutine of <figref idref="DRAWINGS">FIGS. 67</figref><i>a </i>to <b>67</b><i>d </i>and <b>68</b> uses three sets of medical images (axial images, sagittal images and coronal images) which are mutually perpendicular, and detection is made as to an abnormal shadow in each of the three sets of medical images; and, if there is a correlation between positions where detected shadows exist, the shadows are displayed or recorded as focus candidate shadows. <figref idref="DRAWINGS">FIG. 67</figref><i>a </i>shows the concept of coaxial planes corresponding to coaxial images. <figref idref="DRAWINGS">FIG. 67</figref><i>b </i>shows one example of a coaxial image corresponding to the coaxial planes shown in <figref idref="DRAWINGS">FIG. 67</figref><i>a</i>. <figref idref="DRAWINGS">FIG. 67</figref><i>c </i>shows sagittal planes corresponding to sagittal images as well as coronal planes. In <figref idref="DRAWINGS">FIG. 67</figref><i>c</i>, the sagittal planes are shown by solid lines, and the coronal planes are shown by dashed lines. <figref idref="DRAWINGS">FIG. 67</figref><i>d </i>shows one example of a sagittal image corresponding to the sagittal plane shown in <figref idref="DRAWINGS">FIG. 67</figref><i>c</i>. Incidentally, a coronal image corresponding to the coronal planes is omitted.</p>
<p id="p-0311" num="0310">The CPU <b>40</b> executes the above-described decision making subroutine on the basis of two kinds of images, the axial image and the sagittal image. As a result, it is assumed that focus candidate shadows <b>671</b> and <b>672</b> are detected on the axial image of <figref idref="DRAWINGS">FIG. 67</figref><i>b </i>and a focus candidate shadow <b>673</b> is detected on the sagittal image of <figref idref="DRAWINGS">FIG. 67</figref><i>d</i>. <figref idref="DRAWINGS">FIG. 68</figref> shows the contents of a memory which stores data, such as position information as to the detected focus candidate shadows <b>671</b> and <b>673</b>. The data stored in the memory are made up of the total of shadows and information as to each of the shadows. Information as to the focus candidate shadows <b>671</b> and <b>673</b> is made up, giving the position coordinates (X, Y, Z) of each of the shadows and the area and the maximum and minimum lengths of each of the shadows, as well as other information. The position coordinates of the focus candidate shadow <b>671</b> on the axial image are (X1, Y1), and the position coordinates of the focus candidate shadow <b>672</b> on the axial image are (X2, Y2). In addition, the position coordinates of the focus candidate shadow <b>673</b> on the sagittal plane are (Z1, Y1+δ).</p>
<p id="p-0312" num="0311">It is assumed here that the z-axis coordinate is not clearly identified on the axial plane and the X-axis coordinate is not clearly identified on the sagittal plane. In this case, when the position coordinates (X1, Y1) of the focus candidate shadow <b>671</b> and the position coordinates (Z1, Y1+δ) of the focus candidate shadow <b>671</b> are compared with each other, their Y-axis coordinates are found to approximate each other. The Y-axis difference between the focus candidate shadow <b>671</b> and the focus candidate shadow <b>673</b> is δ. If this difference δ is smaller than a predetermined value Δ, it is determined that both shadows <b>671</b> and <b>673</b> lie at the same position coordinates and are the same focus candidate shadow, and the shadows <b>671</b> and <b>673</b> are left as a focus candidate shadow. On the other hand, if the difference δ is smaller than the predetermined value Δ, it is determined that both shadows <b>671</b> and <b>673</b> lie at different position coordinates, and the shadows <b>671</b> and <b>673</b> are deleted from focus candidate shadows. Since nothing on the sagittal plane corresponds to the position coordinates (X2, Y2) of the focus candidate shadow <b>672</b>, the focus candidate shadow <b>672</b> in this case is regarded as false and is deleted. Incidentally, in this embodiment, the decision is made according to whether the position coordinates of shadows are the same, but in the case where the position coordinates of shadows are regarded as the same, a decision as to whether both shadows are the same may be made on the basis of the “areas”, the “maximum lengths”, the “minimum lengths” and the like of the shadows.</p>
<p id="p-0313" num="0312"><figref idref="DRAWINGS">FIG. 69</figref> shows the case where a CT image having an extracted focus candidate shadow and a marker are displayed to the operator (doctor) together with a focus candidate shadow photographed and extracted in the past. <figref idref="DRAWINGS">FIG. 69</figref><i>a </i>is a view showing one example of a picture which displays focus candidate shadows detected on the basis of a CT image photographed the latest, as well as markers. <figref idref="DRAWINGS">FIG. 69</figref><i>b </i>shows one example of a picture which displays a marker corresponding to a focus candidate shadow photographed and extracted, for example, one year ago in such a manner that the marker is superposed on the image of <figref idref="DRAWINGS">FIG. 69</figref><i>a </i>at the same time. In <figref idref="DRAWINGS">FIG. 69</figref><i>b</i>, the marker corresponding to the focus candidate shadow extracted in the past is shown by a square. In addition, a figure or a character indicating that circular markers <b>691</b> and <b>692</b> denote the latest photographed objects is displayed at the top left of the picture, while a figure or a character indicating that a square marker <b>693</b> denote the past (previous) photographed object is displayed at the bottom left of the picture. Features, such as the coordinates and the size of the focus candidate shadow photographed and extracted in the past, are recorded on a magnetic disk in the format shown in <figref idref="DRAWINGS">FIG. 68</figref>, and a marker corresponding to the past focus candidate shadow may be displayed on the basis of these features. For example, in the case where CT images are photographed and subjected to cancer detection processing at intervals of one year, when the detection result of this year and the detection result of last year are displayed in a superimposed manner, if a shadow newly appears at a location where no shadow existed last year, a doctor can be made to recognize that the possibility that the shadow is that of a cancer is high. Incidentally, the previous date of photography and the like may also be displayed in association with the marker. In addition, if there exist a plurality of dates of photography, the manner of display, such as the colors, the shapes and the like of markers, may also be changed for the respective dates of photography.</p>
<p id="p-0314" num="0313"><figref idref="DRAWINGS">FIGS. 70</figref><i>a</i>, <b>70</b><i>b </i>and <b>71</b><i>a</i>, <b>71</b><i>b </i>are views showing a modification of the manner of display of a marker. In the above description of the embodiment, reference has been made to the case where the shape of a marker is displayed as a circle or an ellipse. In <figref idref="DRAWINGS">FIG. 70</figref><i>a</i>, the direction of a long diameter <b>701</b> indicative of the maximum length of a focus candidate shadow <b>700</b> and the direction of a long axis <b>703</b> of an elliptical marker <b>702</b> are made coincident with each other, and the elliptical marker <b>702</b> is displayed to surround the focus candidate shadow <b>700</b>. Since the marker is displayed along the shape of the shadow, the shadow is easy to recognize. Incidentally, the length of the long axis of the elliptical marker <b>702</b> may use the value obtained by multiplying the long diameter <b>701</b> of the focus candidate shadow <b>700</b> of the focus candidate shadow by a predetermined coefficient, and the length of the short axis of the elliptical marker <b>702</b> may use the value obtained by multiplying an effective short diameter (the value obtained by dividing the area of the shadow by the maximum long diameter of the shadow) of the focus candidate shadow by a predetermined coefficient. <figref idref="DRAWINGS">FIG. 70</figref><i>b </i>is a view showing one example of the case where an elliptical marker is displayed as an aggregation of elliptical arcs <b>704</b> and <b>705</b>, similar to the case where a marker is shown as an aggregation of circular arcs, as shown in <figref idref="DRAWINGS">FIG. 36</figref><i>b</i>. In this modification, in the case where the ellipses <b>704</b> and <b>705</b>, respectively centered at focus candidate shadows p<b>4</b> and p<b>5</b>, overlap each other, the overlapping portion of the elliptical arcs is deleted to draw the marker as an aggregation of the plurality of elliptical arcs <b>704</b> and <b>705</b>, as shown in <figref idref="DRAWINGS">FIG. 70</figref><i>b</i>. If the focus candidate shadow is only displayed by being enclosed with the marker <b>711</b>, as shown in <figref idref="DRAWINGS">FIG. 71</figref><i>a</i>, there is a case where the location of the focus candidate shadow is difficult to identify. For this reason, as shown in <figref idref="DRAWINGS">FIG. 71</figref><i>b</i>, in, this embodiment, the contrast of the CT image in the area enclosed with the marker <b>711</b> is emphasized or the CT image is subjected to gamma processing, so that the focus candidate shadow can be displayed in a far more clearly emphasized state.</p>
<p id="p-0315" num="0314"><figref idref="DRAWINGS">FIG. 72</figref> is a view showing a modification in which a CT image having an extracted focus candidate shadow and a CT image having no extracted focus candidate shadow are sequentially displayed as a kinematic image. In the above description of the embodiment, reference has been made to the case where a CT image having an extracted focus candidate shadow is displayed in various display modes. However, in this embodiment, modification is applied to the manner of display, here displaying in a kinematic image, which sequentially displays a CT image at a rate of approximately 5 to 14 images/second in the order of photography irrespective of the presence or absence of an extracted focus candidate shadow. Details of this kinematic image display method will be described below with reference to the flowchart of <figref idref="DRAWINGS">FIG. 72</figref>.</p>
<p id="p-0316" num="0315">[Step S<b>721</b>] The CPU <b>40</b> displays the first CT image.</p>
<p id="p-0317" num="0316">[Step S<b>722</b>] The CPU <b>40</b> determines whether an abnormal portion, i.e., a focus candidate shadow, exists in the CT image which is presently displayed. If the decision result is yes, the CPU <b>40</b> proceeds to Step S<b>723</b>, whereas, if the decision result is no, the CPU <b>40</b> proceeds to Step S<b>724</b>.</p>
<p id="p-0318" num="0317">[Step S<b>723</b>] Since it has been determined that the abnormal portion (focus candidate shadow) exists in the image which is presently displayed, the CPU <b>40</b> increases the delay time. The delay time is the time required to display one image during kinematic image display. As the delay time increases, the display time of the image in which the abnormal portion (focus candidate shadow) exists becomes longer than the standard display time. Accordingly, the doctor can intensively observe with ample time the image in which the abnormal portion (focus candidate shadow) exists. Incidentally, in the case where a plurality of abnormal portions (focus candidate shadows) exist in one CT image, the value of the delay time may be determined according to the number of abnormal portions (focus candidate shadows).</p>
<p id="p-0319" num="0318">[Step S<b>724</b>] Since it has been established that an abnormal portion (focus candidate shadow) does not exist in the image which is presently being displayed, the CPU <b>40</b> decreases the delay time. As the delay time is decreased, the display of the image comes to an end earlier than the normal image display. Incidentally, the image may also be displayed with a standard delay time without decreasing the delay time. The value of the delay time in each of Step S<b>723</b> and Step S<b>724</b> can be arbitrarily set.</p>
<p id="p-0320" num="0319">[Step S<b>725</b>] Since the CT image has been displayed for a period of time equivalent to the delay time, the CPU <b>40</b> starts displaying the next image.</p>
<p id="p-0321" num="0320">[Step S<b>726</b>] The CPU <b>40</b> determines whether the image displayed in Step S<b>725</b> is the last image. If the decision result is yes (the image is the last one), the CPU <b>40</b> brings the processing to an end; whereas, if the decision result is no (the image not the last one), the CPU <b>40</b> returns to Step S<b>722</b> and repeats the above-described processing until the last image is displayed. In the above description, reference has been made to the case where an image in which no focus candidate shadow exists is displayed for only a short time. However, such an image may also be displayed for a longer time than the standard display time, so that the doctor can confirm whether a focus candidate shadow really does not exist.</p>
<p id="p-0322" num="0321"><figref idref="DRAWINGS">FIG. 73</figref> is a view showing one example of display processing for the case where a diagnosis result provided by the image diagnosis supporting device according to this invention is displayed. In the case where a diagnosis is to be made on the basis of a medical image photographed with a CT device or the like, two doctors independently perform shadow detection as to the medical image in parallel with each other, and subsequently meet to examine the results of their shadow detections. Both doctors finally make an integrated decision as to whether the image is abnormal. If the result of this integrated decision is that the image is abnormal, the patient undergoes a thorough medical examination. On the other hand, if the result of the integrated decision is that the image is not abnormal, the doctor makes a check as to their diagnosis result or the like by using an image diagnosis supporting device. Namely, the image diagnosis supporting device must assist in the diagnosis of the doctors and detect the presence or absence of an abnormality in a medical image which has undergone shadow detection by the doctors. Accordingly, in this embodiment, display processing which does not display a marker after the shadow detection by the doctor has been completed is adopted. Details of this display processing will be described below with reference to the flowchart of <figref idref="DRAWINGS">FIG. 73</figref>.</p>
<p id="p-0323" num="0322">[Step S<b>731</b>] The CPU <b>40</b> directly displays an original CT image in which a marker is not displayed.</p>
<p id="p-0324" num="0323">[Step S<b>732</b>] The CPU <b>40</b> records “completion of displaying” as to the CT image whose displaying in Step S<b>731</b> has been completed. For example, a flag indicative of “completion of displaying” is added to the field “other information”, as shown in <figref idref="DRAWINGS">FIG. 68</figref>.</p>
<p id="p-0325" num="0324">[Step S<b>733</b>] The CPU <b>40</b> makes a decision as to whether a display complete icon on the picture has been click-manipulated by a mouse. If the decision result is yes (the icon is manipulated), the CPU <b>40</b> brings the display processing to an end, whereas, if the decision result is no (the icon is not manipulated), the CPU <b>40</b> proceeds to Step S<b>734</b>.</p>
<p id="p-0326" num="0325">[Step S<b>734</b>] The CPU <b>40</b> determines whether an icon for displaying a marker (a marker display icon) has been click-manipulated by the mouse. If the decision result is yes (the icon is manipulated), the CPU <b>40</b> proceeds to Step S<b>735</b>; whereas, if the decision result is no (the icon is manipulated), the CPU <b>40</b> returns to Step S<b>733</b> and repeats the processing until the display complete icon or the marker display icon is manipulated.</p>
<p id="p-0327" num="0326">[Step S<b>735</b>] The CPU <b>40</b> determines whether all CT images have been displayed by the processing of Step S<b>731</b> and “completion of displaying” has been recorded by the processing of Step S<b>732</b>. If the decision result is yes, the CPU <b>40</b> proceeds to Step S<b>737</b>, whereas, if the decision result is no, the CPU <b>40</b> proceeds to Step S<b>736</b>.</p>
<p id="p-0328" num="0327">[Step S<b>736</b>] Since it has been determined in the processing of Step S<b>735</b> that all CT images have been displayed, the CPU <b>40</b> sequentially displays images to which markers are added. During the display of the images to which markers are added, the CPU <b>40</b> may display only marker-added CT images, each having an extracted focus candidate shadow, in a predetermined order, or it may sequentially display marker-added CT images and CT images to which no markers are added.</p>
<p id="p-0329" num="0328">[Step S<b>737</b>] Since it has been in the processing of Step S<b>735</b> that all CT images have not been displayed, the CPU <b>40</b> displays a notice indicating that “there is an image which has not yet undergone shadow detection by the doctor”, and informs the operator (doctor) that a marker-added CT image is not displayed, and returns to Step S<b>731</b>. In this manner, shadow detection by the doctor is performed on a CT image which has not yet undergone shadow detection. In addition, when shadow detection by the doctor has been performed on a CT image, a marker-added CT image is displayed.</p>
<p id="p-0330" num="0329"><figref idref="DRAWINGS">FIGS. 74</figref><i>a </i>to <b>74</b><i>c </i>show another example of display processing for the case where a diagnosis result provided by the image diagnosis supporting device according to this invention is displayed. In the description of <figref idref="DRAWINGS">FIG. 73</figref>, reference has been made to the case where the presence or absence of a focus candidate shadow is detected in a medical image which has been undergone shadow detection by the doctor and a focus candidate shadow is displayed with a marker added thereto. In the following description, reference has been made to a display method for the case where a marker is removed from a marker-added CT image. <figref idref="DRAWINGS">FIG. 74</figref><i>a </i>is a view showing one example of a display picture of a marker-added CT image. In <figref idref="DRAWINGS">FIG. 74</figref><i>a</i>, a non-mark icon for selecting the marker-hidden mode, a next-picture icon for displaying the next picture and an end icon for bringing display to an end are displayed on the left-hand side of the picture. As shown in <figref idref="DRAWINGS">FIG. 74</figref><i>b</i>, when the non-mark icon is click-manipulated by a mouse, a marker which has been displayed up to this time disappears and is brought to a hidden state, and the characters “NON-MARK MODE IS ACTIVE”, indicative of the hidden state are displayed on the bottom side of the display. Furthermore, in this embodiment, when the non-mark mode of <figref idref="DRAWINGS">FIG. 74</figref><i>b </i>passes a predetermined time, the picture is restored to the original marker-added CT image, as shown in <figref idref="DRAWINGS">FIG. 74</figref><i>c</i>. This predetermined time can be set in advance as a parameter. Incidentally, a mark display icon may be provided on the upper side of the non-mark icon so that the operator can arbitrarily switch the non-mark mode and a mark mode. As shown in <figref idref="DRAWINGS">FIGS. 71</figref><i>a </i>and <b>71</b><i>b</i>, an icon for switching the emphasized display and the non-emphasized display of a focus candidate shadow may be provided.</p>
<p id="p-0331" num="0330">In the abnormal shadow detection processing of <figref idref="DRAWINGS">FIG. 9</figref>, reference has been made to the case where processing is performed in parallel in functional terms, but in sequence in temporal terms according to the kind of shadow, such as a small shadow, a large shadow, a ground glass opacity and a high-density shadow; however, each processing may also be executed in parallel by using time division processing or a plurality of computers.</p>
<p id="p-0332" num="0331"><figref idref="DRAWINGS">FIG. 75</figref> is a view showing a modification of the main flowchart of the abnormal shadow detection processing of <figref idref="DRAWINGS">FIG. 9</figref>. The abnormal shadow detection processing of <figref idref="DRAWINGS">FIG. 75</figref> executes each kind of processing according to the kind of shadow in parallel. The ground glass opacity of Step S<b>751</b> corresponds to the ground glass opacity processing of <figref idref="DRAWINGS">FIG. 9</figref>. The solid type shadow processing of Step S<b>752</b> corresponds to three kinds of processing shown in <figref idref="DRAWINGS">FIG. 9</figref>, i.e., the small shadow detection processing, the large shadow detection processing and the high-density shadow detection processing. The lung-wall-bound type shadow processing of Step S<b>753</b> corresponds to the decision making subroutines shown in <figref idref="DRAWINGS">FIGS. 25</figref>, <b>26</b><i>a </i>to <b>26</b><i>d </i>and <b>44</b><i>a </i>to <b>44</b><i>c</i>. The specula type shadow processing of Step S<b>754</b> corresponds to the processing shown in <figref idref="DRAWINGS">FIGS. 63</figref><i>a</i>, <b>63</b><i>b </i>and <b>64</b><i>a</i>, <b>64</b><i>b</i>. The blood-vessel-bound type shadow detection processing of Step S<b>755</b> corresponds to the processing shown in <figref idref="DRAWINGS">FIGS. 50 to 53</figref>. The combining processing of Step S<b>756</b> combines the results extracted by the processing of Steps S<b>751</b> to S<b>755</b>. These extracted results include the coordinate position, the area, the maximum length and the minimum length of a shadow, as shown in <figref idref="DRAWINGS">FIG. 68</figref>. Accordingly, in the display storage processing of Step S<b>757</b>, a marker-added CT image, such as the above-described one, is displayed on the basis of the extracted result, and the extracted result is stored in a memory or a magnetic disk.</p>
<p id="p-0333" num="0332"><figref idref="DRAWINGS">FIGS. 76</figref><i>a </i>to <b>76</b><i>d</i>, <b>77</b><i>a </i>and <b>77</b><i>b </i>are views showing a sixth modification of the decision making subroutine. The decision making subroutine shown <figref idref="DRAWINGS">FIGS. 76</figref><i>a </i>to <b>76</b><i>d</i>, <b>77</b><i>a </i>and <b>77</b><i>b </i>is performed in place of the decision making subroutine E<b>1</b> of <figref idref="DRAWINGS">FIG. 27</figref>, the decision making subroutine F<b>1</b> of <figref idref="DRAWINGS">FIG. 29</figref> and each of the above-described decision making subroutines, or it is performed in parallel with these decision making subroutines. This decision making subroutine uses variance or standard deviation in its abnormal shadow detection processing. <figref idref="DRAWINGS">FIGS. 76</figref><i>a </i>to <b>76</b><i>d </i>show the principle of a method of using a variance or standard deviation in abnormal shadow detection processing. <figref idref="DRAWINGS">FIGS. 77</figref><i>a </i>and <b>77</b><i>b </i>illustrate one example of how to extract a shadow which seems not to be a focus.</p>
<p id="p-0334" num="0333">It is known that the possibility that a focus candidate shadow close to a circle is a cancer shadow (abnormal shadow) is high, whereas the possibility that a focus close to a rectangle is a blood vessel shadow (normal shadow) is high. Accordingly, a decision is made by using statistical processing according to the shape of a focus candidate shadow. In this statistical processing, the weighted center point of an area indicative of a focus candidate shadow is found, and the distance from the weighted center point to the edge of the area is found along the entire periphery of the area. A variance or standard deviation of the found distance is computed; and, on the basis of the variance or standard deviation, it is determined whether the shadow is a focus candidate shadow. Namely, as shown in <figref idref="DRAWINGS">FIG. 76</figref><i>a</i>, in the case where an extracted focus candidate shadow is an approximately circular area, since a distance R from the central point to the edge of the area is equal to a radius R<b>0</b> of the circle, a variance Da in this case is 0.</p>
<p id="p-0335" num="0334">As shown in <figref idref="DRAWINGS">FIG. 76</figref><i>b</i>, in the case where an extracted focus candidate shadow is a square, for example, the weighted center point of the square area is set as the central point, and a circle of radius R<b>0</b> that is centered at the central point is drawn. At this time, as shown in <figref idref="DRAWINGS">FIG. 76</figref><i>b</i>, the length of the radius R<b>0</b> is made slightly larger than the radius of a circle which touches the inside of the square area, and it is made slightly smaller then a circle which touches the outside of the square area. Namely, the length of the radius R<b>0</b> is set between the maximum value and the minimum value of the distance from the central point to the edge of the shadow. In the case of <figref idref="DRAWINGS">FIG. 76</figref><i>b </i>as well, a variance Db is found in a similar manner.</p>
<p id="p-0336" num="0335">As shown in <figref idref="DRAWINGS">FIG. 76</figref><i>c</i>, in the case where an extracted focus candidate shadow is a rectangle, a circle of radius R<b>0</b> centered at the central point of the rectangular area is drawn. At this time, as shown in <figref idref="DRAWINGS">FIG. 76</figref><i>c</i>, the length of the radius R<b>0</b> is made slightly larger than the radius of a circle which touches the shorter sides of the rectangular area, and is made slightly smaller then a circle which touches the longer sides of the rectangular area. Namely, in the case of the above-described square area, the length of the radius R<b>0</b> is set between the maximum value and the minimum value of the distance from the central point to the edge of the shadow. In the case of <figref idref="DRAWINGS">FIG. 76</figref><i>c </i>as well, a variance Dc is found in a similar manner.</p>
<p id="p-0337" num="0336">The relationship between the variances Db and Dc in the case of each of <figref idref="DRAWINGS">FIGS. 76</figref><i>b </i>and <b>76</b><i>c </i>is Db&gt;Dc. <figref idref="DRAWINGS">FIG. 76</figref><i>d </i>is a view showing a specific example of the case where the above-described principle is applied to an actual blood vessel shadow. A variance D is defined as D=(Σ(R−R<b>0</b>)<sup>2</sup>)/N. In this formula, R is the distance from the central point of the focus candidate shadow to the edge of the shadow area. R<b>0</b> is the length of the radius of the circle centered at the central point, and corresponds to the average value of a set operation. N is the total number of pixels of the focus candidate shadow. S indicates the summation of the distances to the edge of the focus candidate shadow along the entire periphery of the area.</p>
<p id="p-0338" num="0337"><figref idref="DRAWINGS">FIGS. 77</figref><i>a </i>and <b>77</b><i>b </i>show a modification of the case of finding a variance or standard deviation. In <figref idref="DRAWINGS">FIGS. 77</figref><i>a </i>and <b>77</b><i>b</i>, variance DX in the distances LX from one edge to the other edge of a focus candidate shadow along horizontal lines drawn thereon, and then a variance DY in the distances LY from one edge to the other edge of the focus candidate shadow along vertical lines drawn thereon, are found. Then, on the basis of the relationship in magnitude between each of the variances DX and DY and a predetermined value indicative of the shape of the shadow, a decision is made as to whether the shadow is a cancer shadow, as shown in <figref idref="DRAWINGS">FIG. 77</figref><i>a</i>, or a blood vessel shadow, as shown in <figref idref="DRAWINGS">FIG. 77</figref><i>b</i>. Incidentally, although the variances may be directly used, it goes without saying that the decision can be made by using a standard deviation which is the square root of each of the variances. A method of extracting the edge of a focus candidate shadow may use any of a method using threshold processing or the like for shadows, a method using particular density contours for shaded shadows, and Laplacian processing (refer to MEDICAL IMAGING TECHNOLOGY V01. 16, No. 3, May 1998, pp. 209-219), and, further, these methods may also be arbitrarily combined.</p>
<p id="p-0339" num="0338"><figref idref="DRAWINGS">FIG. 78</figref> is a view showing a modification of display processing for the case where a diagnosis result provided by the image diagnosis supporting device according to this invention is displayed. <figref idref="DRAWINGS">FIGS. 79</figref><i>a </i>to <b>79</b><i>c </i>show one example of a display picture accompanying the display processing of <figref idref="DRAWINGS">FIG. 78</figref>. As described previously in connection with <figref idref="DRAWINGS">FIG. 73</figref>, in the case where a doctor is to make a diagnosis on the basis of a medical image photographed with a CT device or the like, if a decision result found by a computer is presented to the doctor before a diagnosis, the diagnosis has the risk of being influenced by preoccupations. Accordingly, it is desirable that the computer program of this invention not be executed before the diagnosis of the doctor. Details of this display processing will be described below with reference to the flowchart of <figref idref="DRAWINGS">FIG. 78</figref>.</p>
<p id="p-0340" num="0339">[Step S<b>781</b>] The CPU <b>40</b> determines whether an activating button for activating an execution processing program for an image diagnosis supporting device according to this embodiment has been click-manipulated by a mouse. If the decision result is yes (the activating button is activated), the CPU <b>40</b> proceeds to Step S<b>783</b>; whereas, if the decision result is no, the CPU <b>40</b> repeats the processing of this step until the activating button is manipulated.</p>
<p id="p-0341" num="0340">[Step S<b>782</b>] The CPU <b>40</b> determines whether there exits a record whose image has been displayed on the CRT display <b>48</b> (a flag indicative of the completion of displaying), and, if the decision result is yes (such record exists), the CPU <b>40</b> proceeds to Step S<b>784</b>; whereas, if the decision result is no (such record exists), the CPU <b>40</b> proceeds to Step S<b>783</b>. This is because the record whose image has been displayed on the CRT display <b>48</b> is regarded as diagnosed by the doctor. For a far more exact diagnosis, reference may be made to records of shadow detection by the doctor, and the decision may be made on the basis of the records. In this case, if the CPU <b>40</b> determines that there is a record of shadow detection (yes), the CPU <b>40</b> proceeds to Step S<b>784</b>; whereas, if the CPU <b>40</b> determines that there is not a record of shadow detection (no), the CPU <b>40</b> proceeds to Step S<b>783</b>.</p>
<p id="p-0342" num="0341">[Step S<b>783</b>] Since an image which has not yet been diagnosed by the doctor is to be displayed, the CPU <b>40</b> displays an error message, and returns to Step S<b>781</b>. As this error message, an error message, as shown in <figref idref="DRAWINGS">FIG. 79</figref><i>a </i>or <b>79</b><i>b </i>may be displayed. In <figref idref="DRAWINGS">FIG. 79</figref><i>a</i>, an error message indicating that “error: the program can be activated only after shadow detection by the doctor” is displayed on the bottom side of a tomographic image. In <figref idref="DRAWINGS">FIG. 79</figref><i>b</i>, an error message indicating that “note: the program can be activated only when there is a diagnosis record” is displayed on the bottom side of the tomographic image.</p>
<p id="p-0343" num="0342">[Step S<b>784</b>] The CPU <b>40</b> activates an execution processing program.</p>
<p id="p-0344" num="0343">[Step S<b>785</b>] The CPU <b>40</b> finds a focus candidate shadow through a computation on the basis of the execution processing program, and displays the result. The CPU <b>40</b> records the displayed information on a magnetic disk or the like as required. As shown in <figref idref="DRAWINGS">FIG. 79</figref><i>c</i>, the display of the computation result shows the fact that, for example, the first tomographic image has one abnormal portion enclosed with a circle, and a value indicating how many abnormal portions have been found in total inclusive of those in other tomographic images. <figref idref="DRAWINGS">FIG. 79</figref><i>c </i>shows that there are three abnormal portions in total.</p>
<p id="p-0345" num="0344"><figref idref="DRAWINGS">FIGS. 80</figref><i>a </i>to <b>82</b> are views showing a seventh modification of the decision making subroutine. The decision making subroutine of <figref idref="DRAWINGS">FIGS. 80</figref><i>a </i>to <b>82</b> is performed in place of the decision making subroutine E<b>1</b> of <figref idref="DRAWINGS">FIG. 27</figref>, the decision making subroutine F<b>1</b> of <figref idref="DRAWINGS">FIG. 29</figref> and each of the above-described decision making subroutines, or it is performed in parallel with these decision making subroutines. This decision making subroutine uses the area of a shadow and the ratio of areas associated with this shadow, in abnormal shadow detection processing. <figref idref="DRAWINGS">FIGS. 80</figref><i>a </i>to <b>80</b><i>c </i>show one example of the case of finding the area ratio of the total area of the entire focus candidate shadow to the area of a concave portion formed in the edge portion of the shadow. <figref idref="DRAWINGS">FIGS. 81</figref><i>a </i>and <b>81</b><i>b </i>show one example of the process of how a bifurcating portion of a blood vessel shadow is extracted. <figref idref="DRAWINGS">FIG. 82</figref> is a flowchart showing one example of procedures for the case of finding the area ratio of <figref idref="DRAWINGS">FIGS. 80</figref><i>a </i>to <b>80</b><i>c</i>. <figref idref="DRAWINGS">FIG. 83</figref> is a view showing one example of a display which accompanies the processing of <figref idref="DRAWINGS">FIGS. 80</figref><i>a </i>to <b>80</b><i>c. </i></p>
<p id="p-0346" num="0345">An extracted region, as shown in <figref idref="DRAWINGS">FIG. 81</figref><i>b</i>, is obtained by discriminating between the high and low luminances of a CT image as shown in <figref idref="DRAWINGS">FIG. 81</figref><i>a</i>. To identify this extracted region as a blood vessel shadow, this extracted region is binarized by threshold processing. By this binarizing processing, a binarized blood vessel region as shown in <figref idref="DRAWINGS">FIG. 80</figref><i>a </i>is extracted. <figref idref="DRAWINGS">FIG. 80</figref><i>b </i>shows the case where a shadow of a cancer or the like is binarized. When the shadow of the cancer or the like shown in <figref idref="DRAWINGS">FIG. 80</figref><i>b </i>is compared with the shadow or the like of the blood vessel region shown in <figref idref="DRAWINGS">FIG. 80</figref><i>a</i>, the difference therebetween can be readily understood, and it can be understood that the shadow of the cancer or the like has a shape close to that of a circle. In the case of the blood vessel shadow shown in <figref idref="DRAWINGS">FIG. 80</figref><i>a</i>, an area ratio SR of the sum of areas s<b>1</b><i>a</i>, s<b>1</b><i>b </i>and s<b>1</b><i>c </i>of the respective concave portions of the shadow to a total area s<b>2</b> of the shadow is used to make a decision as to a focus candidate shadow. The area ratio SR may be found by the following ratio formula which simply shows the ratio of the area s<b>1</b> to the area s<b>2</b>: SR=s<b>1</b>/s<b>2</b>, or it may also be found by the following ratio formula, which shows the ratio of the total of the area s<b>1</b> and the area s<b>2</b> to the area s<b>2</b>: SR=s<b>2</b>/(s<b>1</b>+s<b>2</b>). In the case of the shadow of the cancer or the like shown in <figref idref="DRAWINGS">FIG. 80</figref><i>b</i>, an area ratio SR=s<b>10</b>/s<b>20</b> of an area <b>10</b><i>s </i>of the concave portion of the shadow to a total area s<b>20</b> of the shadow is used to make a decision as to a focus candidate shadow. <figref idref="DRAWINGS">FIG. 80</figref><i>c </i>shows a method of finding the area of the concave portions. Details of the processing of finding the areas of the concave portions will be described below with reference to the flowchart of <figref idref="DRAWINGS">FIG. 82</figref>.</p>
<p id="p-0347" num="0346">[Step S<b>821</b>] As shown in <figref idref="DRAWINGS">FIG. 80</figref><i>c</i>, the CPU <b>40</b> selects a pair of points p<b>1</b> and p<b>2</b> on the contour of the shadow, and connects both points p<b>1</b> and p<b>2</b> by a straight line. The pair is selected only at the first time in this processing.</p>
<p id="p-0348" num="0347">[Step S<b>822</b>] The CPU <b>40</b> places a point p which moves by a constant length at one time from the point p<b>1</b> toward the point p<b>2</b>, on the straight line which connects the two points p<b>1</b> and p<b>2</b>. Each time the point p moves by the constant length, the CPU <b>40</b> determines whether the point p exists on an extracted region (s<b>2</b>). If the decision result is yes (the p exists on the extracted region s<b>2</b>), the CPU <b>40</b> proceeds to Step S<b>824</b>, whereas, if the decision result is no, the CPU <b>40</b> proceeds to Step S<b>823</b>.</p>
<p id="p-0349" num="0348">[Step S<b>823</b>] Since the point p does not exist on the extracted region (s<b>2</b>), the CPU <b>40</b> records a particular value (for example, “5”) on that portion.</p>
<p id="p-0350" num="0349">[Step S<b>824</b>] The CPU <b>40</b> determines whether the point p has completely moved on the straight line which connects the points p<b>1</b> and p<b>2</b>, and if the decision result is no (the movement of the point p has not yet been completed), the CPU <b>40</b> returns to Step S<b>822</b>; whereas, if the decision result is yes (the movement of the point p has been completed), the CPU <b>40</b> proceeds to Step S<b>825</b>. By the processing of Step S<b>822</b> to Step S<b>824</b>, while the point p is moving from the point p<b>1</b> to the point p<b>2</b>, the particular value (for example, “5”) is recorded in a region, except for the extracted region (s<b>2</b>).</p>
<p id="p-0351" num="0350">[Step S<b>825</b>] In the case where the CPU <b>40</b> sets the point p<b>1</b> as a fixed point and the point p<b>2</b> as a moving point, the CPU <b>40</b> determines whether the moving point p<b>2</b> has moved on the entire contour of the extracted region. In the case where the CPU <b>40</b> sets the point p<b>2</b> as a fixed point and the point p<b>1</b> as a moving point, the CPU <b>40</b> determines whether the moving point p<b>1</b> has moved on the entire contour of the extracted region. If the decision result is no (the movement of the moving point has not yet been completed), the CPU <b>40</b> returns to Step S<b>821</b> and performs similar processing on the next two points. If the decision result is yes, the CPU <b>40</b> proceeds to Step S<b>826</b>.</p>
<p id="p-0352" num="0351">[Step S<b>826</b>] The CPU <b>40</b> finds the area (s<b>1</b>) of the extracted region in which the particular value (for example, “5”) is recorded. This area s<b>1</b> is the area of the concave portions.</p>
<p id="p-0353" num="0352">The CPU <b>40</b> finds an area ratio RS of the area s<b>1</b> to the area s<b>2</b> of the extracted region.</p>
<p id="p-0354" num="0353">[Step S<b>828</b>] The CPU <b>40</b> determines whether the area ratio RS is larger than a preset constant value. If the decision result is yes (larger), the CPU <b>40</b> proceeds to Step S<b>829</b>, whereas, if the decision result is no (smaller or equal), the CPU <b>40</b> proceeds to Step S<b>82</b>A.</p>
<p id="p-0355" num="0354">[Step S<b>829</b>] Since it has been determined in Step S<b>828</b> that the area ratio RS is larger than the constant value, the possibility that the extracted shadow is a blood vessel shadow is high. Accordingly, the CPU <b>40</b> deletes the shadow from focus candidate shadows.</p>
<p id="p-0356" num="0355">[Step S<b>82</b>A] Since it has been determined in Step S<b>828</b> that the area ratio RS is not larger than the constant value, the possibility that the extracted shadow is a focus candidate shadow is high. Accordingly, the CPU <b>40</b> selects the shadow as a focus candidate shadow and saves information, such as the coordinate position thereof.</p>
<p id="p-0357" num="0356">It is preferable to identifiably display the nature of a focus candidate shadow, such as a positive indication that the focus candidate shadow is a focus, a nature close to a positive indication (apparent-positive) or a negative indicating that the focus candidate shadow is not a focus, because the display of the nature supports shadow inspection by a doctor. Accordingly, in the following embodiment, reference will be made to an image diagnosis supporting device that is capable of readily, instantaneously and identifiably displaying the nature of a shadow, which seems to be an extracted focus candidate.</p>
<p id="p-0358" num="0357"><figref idref="DRAWINGS">FIG. 83</figref> is a view showing one example of the case where information for identifying the nature of a focus candidate shadow on the basis of the area ratio RS, such as a positive indicating that the focus candidate shadow can be determined as a focus, a nature close to a positive (apparent-positive) and a negative indicating that the focus candidate shadow is not a focus, is displayed as image supplementary information. In the display of <figref idref="DRAWINGS">FIG. 83</figref>, the left-hand window displays a graph in which the horizontal axis indicates a CT image having a shadow which is to be judged according to the area ratio RS, and the vertical axis corresponds to the area ratio RS. The right-hand window displays the CT image which is the decision target. In the graph, white dots (?) denote the result of a computation on the extracted shadow, and they are displayed at positions corresponding to the magnitude of the area ratio RS. Initially, all marks are displayed as white dots (?) and whether the shadow is positive is in an undetermined state. When a triangle (?) on the bottom side of the graph is moved by a mouse, an arbitrary white dot (?) can be selected on the graph. The white dot (?) selected by the triangle (?) changes to a black dot (?). At the same time, a CT image corresponding to the selected black dot (?) is displayed on the right-hand window. Accordingly, the operator (doctor) who observes this CT image determines whether the shadow is positive or negative, and if the operator (doctor) determines that the shadow is negative, the operator (doctor) clicks a “false” icon on the bottom of the CT image with the mouse. In this manner, the black dot (?) changes to a square ( ). On the other hand, if the operator (doctor) determines that the shadow is positive, the operator (doctor) clicks a “positive” icon with the mouse. In this manner, the black dot (?) changes to an X mark. At this time, the highest one of the area ratios RS indicated by X marks becomes a decision threshold value. On the basis of this decision threshold value, a threshold value is determined. The threshold value is a value obtained by multiplying the decision threshold value by a constant (for example, 1.1). Namely, the threshold=the decision threshold value×the constant. Incidentally, the constant may be found by finding the distribution of squares ( ) and using a standard deviation thereof. Incidentally, in the case where the threshold value is determined, a decision as to white dots (?) is made on the basis of this threshold value. In this case, squares ( ) or X marks to which white dots (?) have changed on the basis of the decision with the threshold value may be displayed in different colors or by dotted lines so that the operator (doctor) can recognize that a decision as to the white dots (?) has been made on the basis of the threshold value. In this embodiment, the display as shown in <figref idref="DRAWINGS">FIG. 83</figref> may also be displayed as an image that is impossible to identify or a focus candidate image as shown in <figref idref="DRAWINGS">FIG. 33</figref>. In this case, the white dots (?) indicative of the undetermined state may be displayed as image supplementary information on the side of the decision-impossible image, and the X marks determined as positive may be displayed as image supplementary information on the side of the candidate image.</p>
<p id="p-0359" num="0358"><figref idref="DRAWINGS">FIGS. 84</figref><i>a</i>, <b>84</b><i>b</i>, <b>85</b><i>a </i>and <b>85</b><i>b </i>show a modification of the method of finding the area ratio. First, as shown in <figref idref="DRAWINGS">FIG. 84</figref><i>a</i>, a circle is generated which is inscribed in the contour of a shadow at three points, and the area ratio RS of the total of areas s<b>1</b> to s<b>3</b> of individual regions into which the shadow is divided by the circle to an area s<b>10</b> of the circle is found. This area ratio RS is calculated on the basis of RS=(s<b>1</b>+s<b>2</b>+s<b>3</b>)/s<b>10</b>. Then, a circle is generated which is circumscribed outside the shadow at three points, and the area ratio RS of the area s<b>0</b> of the circle to the area s<b>2</b> of the shadow is found. This area ratio RS is calculated on the basis of RS=s<b>2</b>/s<b>10</b>.</p>
<p id="p-0360" num="0359">In <figref idref="DRAWINGS">FIG. 85</figref><i>a</i>, a polygon (in <figref idref="DRAWINGS">FIG. 85</figref><i>a</i>, a triangle) is generated which is inscribed in the adjacent lines of a blood vessel shadow, and the area ratio RS of the total of areas t<b>1</b> to t<b>3</b> of individual regions into which the shadow is divided by the polygon to an area t<b>0</b> of the polygon is found. This area ratio RS is calculated by the formula RS=(t<b>1</b>+t<b>2</b>+t<b>3</b>)/t<b>0</b>. In <figref idref="DRAWINGS">FIG. 85</figref><i>b</i>, a polygon (in <figref idref="DRAWINGS">FIG. 85</figref><i>b</i>, a pentagon) which is inscribed in focus candidate shadow is generated, and the area ratio RS of the total of areas t<b>1</b> to t<b>5</b> of individual regions into which the shadow is divided by the polygon to an area T<b>0</b> of the polygon is found. This area ratio RS is calculated by the formula RS=(t<b>1</b>+t<b>2</b>+t<b>3</b>+t<b>4</b>+t<b>5</b>)/T<b>0</b>. To find the area ratio, in addition to the above-described areas t<b>0</b> to t<b>3</b> and T<b>0</b> to T<b>5</b>, the areas s<b>1</b><i>a</i>, s<b>1</b><i>b</i>, s<b>1</b><i>c </i>and a<b>10</b> of the respective concave portions formed outside the shadows may be arbitrarily used.</p>
<p id="p-0361" num="0360">Furthermore, the concave portions have another feature. Namely, when a concave portion of a bifurcation of a blood vessel is found, there is a case where three separate regions are obtained. By using this fact, it is possible to delete a blood vessel bifurcation.</p>
<p id="p-0362" num="0361">In the description of this embodiment, reference has been made to the case where the contour edge of a binary image is used. However, since the contour edge of a binary image corresponds to the isosbestic line of a multi-valued image shadow, it is possible to perform similar processing on the isosbestic line without binarization. Although the magnitude of this key feature quantity may be directly used in a decision, the key feature quantity may be provided as an input signal to a neural network together with other key feature quantities, and the output signal from this neural network may also be used in decision making means for selecting a suitable method from among a method using a variance and a method using an area ratio, according to the area of a sample to which the method is to be applied; for example, a selecting menu or the like may be selected with a mouse to improve the manipulability of doctor's diagnosis supporting software.</p>
<p id="p-0363" num="0362">In addition, by combining a method using a variance and a method using an area ratio, it is possible to discriminate between a cancer shadow and a blood vessel shadow with far higher accuracy, whereby it is possible to improve the reliability of the diagnosis supporting software. In addition, in the extraction of a shadow, in the case where a special shadow, including a shadow of a pleural membrane, is to be found, processing which allows for specialty is needed, as shown in <figref idref="DRAWINGS">FIGS. 86</figref><i>a </i>to <b>86</b><i>c</i>. <figref idref="DRAWINGS">FIGS. 86</figref><i>a </i>to <b>86</b><i>c </i>show one example of the case where a special shadow, including a shadow of a pleural membrane, is found. In a CT image as shown in <figref idref="DRAWINGS">FIG. 86</figref>, there exist a shadow <b>861</b> due to inflammation or the like, a shadow <b>552</b> of a blood vessel or the like and a shadow <b>553</b> perpendicular to the pleural membrane. The CT image shown in <figref idref="DRAWINGS">FIG. 86</figref><i>a </i>is binarized into an image as shown in <figref idref="DRAWINGS">FIG. 86</figref><i>b</i>. Furthermore, as shown in <figref idref="DRAWINGS">FIG. 86</figref><i>c</i>, when only a contour <b>865</b> of the pleural membrane is taken out and the relationship between the shadows <b>861</b> to <b>863</b> and the contour <b>865</b> of the pleural membrane is viewed, the normal blood vessel shadow <b>861</b> is deleted on condition that it is not in contact with the contour <b>865</b> of the pleural membrane. Furthermore, it is possible to discriminate between the wide shadow <b>862</b> due to inflammation and the shadow <b>863</b>, which is in perpendicular contact with the contour <b>865</b> of the pleural membrane, because the wide shadow <b>862</b> and the shadow <b>863</b> differ in the length of contact with the contour <b>865</b> of the pleural membrane. By designating a particular range of threshold values for the CT image and emphasizing the image, it is possible to extract the contour <b>865</b>, as shown in <figref idref="DRAWINGS">FIG. 86</figref><i>c</i>. After the contour <b>865</b> has been extracted, the extracted contour <b>865</b> is cut and isolated to identify each of the blood vessel shadows <b>861</b> to <b>863</b> on the basis of the state of connection of the contour <b>865</b> of the pleural membrane with each of the blood vessel shadows <b>861</b> to <b>863</b>. In this manner, it is possible to identify the kinds of shadows from the relationship between each of the shadows and the contour of the pleural membrane.</p>
<p id="p-0364" num="0363">In the case where the above-described various feature quantities are used to make a decision as to whether a shadow is a focus candidate, even if processing, such as statistical processing or neural networks, are adopted in an intermediate step, there is a case where it is finally necessary to determine accurate parameters for thresholding processing or the like. In this case, it goes without saying that it is common practice to adopt so-called “learning” in which parameters are made more accurate through operations in an inverse direction from normal processing, from images obtained every day.</p>
<p id="p-0365" num="0364">In addition, according to this invention, it is possible to provide novel feature quantities for identifying focus shadows and processing procedures using such feature quantities.</p>
<p id="p-0366" num="0365">As described above, according to the image diagnosis supporting device of this invention, the above-described various kinds of shadows can be handled in an integrated manner, and so it becomes easy to adjust parameters for improving the discrimination capability, and it also becomes easy to create computer programs.</p>
<p id="p-0367" num="0366">In addition, since a focus candidate shadow can be selected from shadows by simple processing, the computation time of a computer can be reduced, whereby an accurate focus candidate can be rapidly extracted and an extracted focus candidate can be instantaneously displayed for a doctor. Accordingly, the image diagnosis supporting device is useful in the early finding of cancers or the like or the inspection of the effect of treatment.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US07298878-20071120-M00001.NB">
<img id="EMI-M00001" he="10.92mm" wi="76.20mm" file="US07298878-20071120-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US07298878-20071120-M00002.NB">
<img id="EMI-M00002" he="10.92mm" wi="76.20mm" file="US07298878-20071120-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00003" nb-file="US07298878-20071120-M00003.NB">
<img id="EMI-M00003" he="8.47mm" wi="76.20mm" file="US07298878-20071120-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00004" nb-file="US07298878-20071120-M00004.NB">
<img id="EMI-M00004" he="8.81mm" wi="76.20mm" file="US07298878-20071120-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00005" nb-file="US07298878-20071120-M00005.NB">
<img id="EMI-M00005" he="8.81mm" wi="76.20mm" file="US07298878-20071120-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. An image diagnosis supporting device characterized by:
<claim-text>digitizing means for applying predetermined image processing to a medical image and generating a multi-valued image comprising discrete multiple values;</claim-text>
<claim-text>extracting means for executing at least one decision making processing routine on the multi-valued image generated by the digitizing means and extracting from among shadows a focus candidate shadow, a shadow which is likely to indicate a diseased site; and</claim-text>
<claim-text>display means for displaying in the medical image the focus candidate shadow extracted by the extracting means so that it is easily identifiable; and</claim-text>
<claim-text>image generating means for extracting from the medical image only pixels belonging to a pixel value range corresponding to the kind of shadow made by a target being searched and generating a medical image of the target.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the extracting means extracts the focus candidate shadow from the multi-valued image generated by the digitizing means and the medical image.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further characterized by the digitizing means applying predetermined mage processing to the target image and generating the multi-valued image, the extracting means extracting the focus candidate shadow from the multi-valued image and the decision target medical image on the basis of the multi-valued image generated by the digitizing means.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further characterized in that the extracting means adjusts a magnification ratio or a reduction ratio of the multi-valued image according to a size of a shadow which is a target, and extracts the focus candidate shadow from the multi-valued image that has been so adjusted.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the extracting means selects a combination of at least one of the above decision making processing routines according to the slice thickness of the medical image, and extracts the focus candidate shadow from the multi-valued image through the selected combined processing routines.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means detects a center or a weighted center of a shadow on the basis of the multi-valued image, rotates on the shadow in the multi-valued image a radius of predetermined length about a reference point near the center or the weighted center of the shadow, samples pixels of the shadow in the multi-valued image which intersect the radius as it is rotated, and makes a decision as to whether the shadow is a focus candidate shadow, on the basis of the pixel values.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. An image diagnosis supporting device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, characterized by sampling the values of pixels forming a spiral or forming concentric circles as the radius rotates, finding a representative value of each of loops formed by the rotation on the basis of the individual pixel values, comparing the representative value with a reference value stored in advance, and making a decision as to the nature of the shadow.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. An image diagnosis supporting device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, characterized by causing a radius of predetermined length to make rotations on each of the plurality of shadows in the multi-valued image about a reference point near a detection point of each of the shadows in the multi-valued image, sampling pixel values which intersect the radius, checking correlation of the pixel values of mutually adjacent loops formed by the rotations, and making a decision as to each of the shadows on the basis of the correlation.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means detects the center or the weighted center of a shadow on the basis of the multi-valued image, rotates two straight lines which are at a predetermined angle η to each other about a reference point near the center or the weighted center of a shadow in the multi-valued image, the medical image or the target medical image, samples pixel values of the shadow which intersect the two straight lines, searches for anisotropy of the shadow on the basis of the pixel values corresponding to the two straight lines, and makes a decision as to whether the shadow is a focus candidate shadow.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means detects a center or a weighted center of a shadow on the basis of the multi-valued image, causes a radius of predetermined length to make rotations about a reference point near the center or the weighted center of a shadow in the multi-valued image, samples pixel values of the shadow where it intersects the radius, detects at least two radii at which the pixel values sharply change with the rotation and finds the angle of elevation, the angle between these radii, and compares the angle of elevation with a reference value stored in advance, and makes a decision as to whether the shadow is a focus candidate shadow.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. An image diagnosis supporting device according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, characterized in that in the case where the decision making means compares the angle of elevation with the reference value stored in advance and determines that the shadow is a focus candidate shadow, the decision making means finds the length of contact between the shadow and a wall portion and determines on the basis of the length of contact whether the shadow is a focus candidate shadow or a shadow of an object accompanying a focus.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means detects a center or a weighted center of a shadow on the basis of the multi-valued image, rotates a straight line of predetermined length about a reference point near the center or the weighted center of a shadow in the multi-valued image to find the maximum value or minimum value, or both, of a length of the portion of the straight line which intersects the shadow in the multi-valued image, samples first and second pixel values in the multi-valued image which are located a predetermined distance outward from the shadow along an extension of a straight line which passes through the reference point and is approximately perpendicular to a straight line with the above minimum value as well as third and fourth pixel values in the multi-valued image which are located a predetermined distance outward from the shadow along an extension of the straight line of the minimum value, fifth and sixth pixel values in the multi-valued image which are located a predetermined distance outward from the shadow along an extension of a straight line which passes through the reference point and is approximately perpendicular to the straight line with the above maximum value as well as seventh and eighth pixel values in the multi-valued image which are located a predetermined distance outward from the shadow along an extension of the straight line of the maximum value, or ninth to twelfth pixel values in the multi-valued image which are located a predetermined distance outward from the shadow along the extensions of the straight lines of the maximum value and the minimum value, and makes a decision as to whether the shadow is a focus candidate shadow, on the basis of the first to fourth pixel values, the fifth to eighth pixel values or the ninth to twelfth pixel values.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means detects a center or a weighted center of a shadow on the basis of the multi-valued image, rotates a radius of predetermined length about a reference point near the center or the weighted center of the shadow on the shadow in the multi-valued image to sample pixel values of the shadow which intersects the radius in the multi-valued image, generates a density waveform on the basis of the pixel values, finds the radii of at least two locations corresponding to angles at which peaks of the density waveform appear, finds the bisector of an angle made by the detected radii, and makes a decision as to whether the shadow is a focus candidate shadow on the basis of the sum of the pixel values on the detected radii and the sum of the pixel values on the bisector.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means detects a center or a weighted center of a shadow on the basis of the multi-valued image, rotates a radius of predetermined length about a reference point near the center or the weighted center of the shadow on the shadow in the multi-valued image to sample pixel values of the shadow which intersect the radius, generates a density waveform on the basis of the pixel values, finds radii lying at least two locations at which peaks of the density waveform appear, and makes a decision as to whether the shadow is a focus candidate shadow on the basis of the average value of the pixel values on the detected radii and the average value of the pixel values on radii other than the detected radii.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means detects a center or a weighted center of a shadow on the basis of the multi-valued image, rotates a straight line of predetermined length about a reference point near the center or the weighted center of the shadow on the shadow to find the length of the portion of the straight line which intersects the shadow in the multi-valued image, performs Fourier expansion on a curve describing the length of the straight line portion with varying angle of rotation, and makes a decision as to whether the shadow is a focus candidate shadow on the basis of a result of this Fourier expansion.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. An image diagnosis supporting device according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, characterized by rotating the straight line of predetermined length on the shadow in the multi-valued image, plotting a curve where the vertical axis represents the length of the portion of the straight line which intersects the shadow and the horizontal axis represents the angle, detecting a positions of valleys of the curve, and performing interpolation between the values with a predetermined curve to draw the curve.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means detects a center or a weighted center of a shadow on the basis of the multi-valued image, rotates a straight line of predetermined length about a reference point near the center or the weighted center of the shadow to find a minimum value of the length of the portion of the straight line which intersects the shadow, divides the area of the shadow by the second power of the minimum value, and makes a decision as to whether the shadow is a focus candidate shadow, on the basis of the divided area.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the extracting means detects a center or a weighted center of a shadow on the basis of the multi-valued image, rotates a straight line of predetermined length about a reference point near the center or the weighted center of the shadow to find a minimum value of length of the portion of the straight line which intersects the shadow, finds a cutting length on the basis of the minimum value, and excludes an elongated shadow of the cutting length which touches the main shadow.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means detects a center or a weighted center of a shadow on the basis of the multi-valued image, draws a closed curve corresponding to a shape of the shadow about a reference point near the center or the weighted center of the shadow, finds short curve lengths in a case where the closed curve is superposed on the shadow or short curve lengths in a case where the closed curve is not superposed on the shadow as well as the number of the short curve lengths, and makes a decision as to whether the shadow is a focus candidate shadow on the basis of the relationship between the short curve lengths and the number of the short curve lengths.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means samples pixel values in the medical image which intersect at least one straight line passing through the shadow and extending in a predetermined direction, find a positive or negative density gradient of each pixel on the straight line on the basis of the pixel values, defines the number of pixels in which the positive gradient continues as a positive run length and defines the number of pixels by which the negative gradient continues as a negative run length, finds positive and negative run lengths and the number of the positive run lengths and the number of positive run lengths, and makes a decision as to whether the shadow is a focus candidate shadow on the basis of the relationship between the positive and negative run lengths and the number of the positive run lengths and the number of positive run lengths.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means finds a variance or a standard deviation of pixel values of a shadow in the multi-valued image, and makes a decision as to whether the shadow is a focus candidate shadow on the basis of the variance or the standard deviation.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. An image diagnosis supporting device according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, characterized by detecting a center or a weighted center of a shadow on the basis of the multi-valued image, rotating a straight line of predetermined length about a reference point near the center or the weighted center of the shadow to sample pixel values of the shadow which intersect the straight line in the multi-valued image, and finding the standard deviation of the pixel values which intersect the straight line at a predetermined angle, for making the decision as to the shadow.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. An image diagnosis supporting device according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, characterized by dividing a shadow in the multi-valued image into a plurality of regions and finding a variance or a standard deviation of the pixel values in each of the regions, for making the decision as to the shadow.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. An image diagnosis supporting device according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, characterized by finding an outside-shadow variance or an outside-shadow standard deviation of pixel values in a predetermined region outside a shadow in the multi-valued image, for making the decision as to the shadow.</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. An image diagnosis supporting device according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, characterized by detecting a center or a weighted center of a shadow in the multi-valued image and finding a variance or a standard deviation of distance from the center or the weighted center to an edge of the shadow along the entire periphery of the shadow, for making the decision as to the shadow.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. An image diagnosis supporting device according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, characterized by finding a variance or a standard deviation of a distance from an edge to an edge of a shadow in the horizontal and vertical directions, for making the decision as to the shadow.</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the extracting means performs processing which detects a center or a weighted center of a shadow on the basis of the multi-valued image, rotates a straight line of predetermined length about a reference point near the center or the weighted center of a shadow on the multi-valued image, the medical image or the decision target medical image, finds a maximum value of length of the portion of the straight line which intersects the shadow, sets a strip-shaped extended line approximately parallel with a straight line of the maximum value, and adds a predetermined value to a pixel memory located on the strip-shaped extension, repeatedly executing this processing a number of times equal to the number of the shadows.</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means compares shadows existing in two multi-valued images adjacent to each other in a slice-thickness direction of the medical image, and makes a decision as to whether each of the shadows is a focus candidate shadow, on the basis of whether the shadows overlap each other in more than a predetermined proportion.</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means uses at least two sets from among a set of axial images, a set of sagittal images and a set of coronal images which are perpendicular to one another, and extracts a focus candidate shadow from each of the at least two sets and makes a decision as to whether the shadow is a focus candidate shadow, on the basis of the position of the focus candidate shadow extracted in each of the images.</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. An image diagnosis supporting device according to <claim-ref idref="CLM-00029">claim 29</claim-ref>, characterized by, in the case where the shadow is a focus candidate shadow, storing in a memory the coordinate position of the focus candidate shadow and information on the focus candidate shadow.</claim-text>
</claim>
<claim id="CLM-00031" num="00031">
<claim-text>31. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means finds the area of the shadow region and also finds an area of a concave region formed in an edge portion of the shadow region, finds a ratio of the area of the shadow region to the area of the concave region, and makes a decision as to whether the shadow is a focus candidate shadow, on the basis of the found ratio.</claim-text>
</claim>
<claim id="CLM-00032" num="00032">
<claim-text>32. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means finds an area of a circle or a polygon inscribed in an edge of the shadow region and the area of separated regions into which the shadow is divided by the circle or the polygon, and finds the ratio of the area of the circle or the polygon to the area of the separated regions of the shadow, and makes a decision as to whether the shadow is a focus candidate shadow, on the basis of the found ratio.</claim-text>
</claim>
<claim id="CLM-00033" num="00033">
<claim-text>33. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the decision making means finds an area of a circle or a polygon circumscribed to the outer edge of the shadow region, finds a ratio of the area of the circle to the area of the shadow, and makes a decision as to whether the shadow is a focus candidate shadow, on the basis of the found ratio.</claim-text>
</claim>
<claim id="CLM-00034" num="00034">
<claim-text>34. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the display means displays a shadow determined as the focus candidate shadow through the decision making processing routines in the medical image or in an area other than the medical image each time one processing of the decision making processing routines is completed.</claim-text>
</claim>
<claim id="CLM-00035" num="00035">
<claim-text>35. An image diagnosis supporting device according to <claim-ref idref="CLM-00034">claim 34</claim-ref>, characterized in that a first display area for displaying a focus candidate shadow or image supplementary information, a second display area for displaying an undetected image in which a focus candidate is not detected or image supplementary information, and a third display area for displaying an image impossible to identify and image supplementary information are provided on a picture of the display means.</claim-text>
</claim>
<claim id="CLM-00036" num="00036">
<claim-text>36. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the display means displays a magnified image of a vicinity of the focus candidate shadow in the medical image or in an area other than the medical image.</claim-text>
</claim>
<claim id="CLM-00037" num="00037">
<claim-text>37. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the display means displays the medical image by controlling the order of display thereof according to the position of the focus candidate shadow in the medical image.</claim-text>
</claim>
<claim id="CLM-00038" num="00038">
<claim-text>38. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the display means displays the medical images having the focus candidate shadow in an order controlled by a pointing device, according to the movement the pointing device in the medical image with the focus candidate shadow.</claim-text>
</claim>
<claim id="CLM-00039" num="00039">
<claim-text>39. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the display means displays a marker line which encloses the extracted focus candidate shadow.</claim-text>
</claim>
<claim id="CLM-00040" num="00040">
<claim-text>40. An image diagnosis supporting device according to <claim-ref idref="CLM-00039">claim 39</claim-ref>, characterized in that the extracting means calculates the probability that a shadow is a focus, and the display means changes displays the marker line in the display on the basis of the focus certainty.</claim-text>
</claim>
<claim id="CLM-00041" num="00041">
<claim-text>41. An image diagnosis supporting device according to <claim-ref idref="CLM-00039">claim 39</claim-ref>, characterized in that in the case where markers overlap to enclose a plurality of focus candidate shadows, the display means displays the markers with an overlapping portion thereof erased.</claim-text>
</claim>
<claim id="CLM-00042" num="00042">
<claim-text>42. An image diagnosis supporting device according to <claim-ref idref="CLM-00039">claim 39</claim-ref>, characterized in that the display means performs contrast emphasis processing or gamma emphasis processing on the area enclosed with the marker and clearly displays the focus candidate shadow.</claim-text>
</claim>
<claim id="CLM-00043" num="00043">
<claim-text>43. An image diagnosis supporting device according to <claim-ref idref="CLM-00039">claim 39</claim-ref>, characterized in that in the case where a hidden mode in which display of the marker is disabled is selected, the display means stops displaying the marker and displays, on a picture, information indicating that the hidden mode is presently active, and automatically displays the marker when a predetermined time elapses after the hidden mode has been started.</claim-text>
</claim>
<claim id="CLM-00044" num="00044">
<claim-text>44. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the extracting means finds length of contact between the extracted focus candidate shadow and a wall portion and determines on the basis of the length of contact whether the shadow is a shadow of an object accompanying a focus, the display means displaying the shadow of an object accompanying a focus enclosed with a marker.</claim-text>
</claim>
<claim id="CLM-00045" num="00045">
<claim-text>45. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the display means displays focus candidate shadows respectively extracted from medical images photographed at mutually different points of time, with the respective focus candidate shadows enclosed with markers which makes it possible to discriminate between the points of time of photography.</claim-text>
</claim>
<claim id="CLM-00046" num="00046">
<claim-text>46. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the display means displays a marker having an elliptical shape whose long-axis direction coincides with a long-axis direction of the extracted focus candidate shadow, with the focus candidate shadow enclosed with the marker.</claim-text>
</claim>
<claim id="CLM-00047" num="00047">
<claim-text>47. An image diagnosis supporting device according to <claim-ref idref="CLM-00046">claim 46</claim-ref>, characterized in that in the case where markers overlap one another to enclose a plurality of focus candidate shadows, respectively, the display means displays the markers with the overlapping portion thereof erased.</claim-text>
</claim>
<claim id="CLM-00048" num="00048">
<claim-text>48. An image diagnosis supporting device according to <claim-ref idref="CLM-00046">claim 46</claim-ref>, characterized in that the display means performs contrast emphasis processing or gamma emphasis processing on an area enclosed with the markers and clearly displays the focus candidate shadows.</claim-text>
</claim>
<claim id="CLM-00049" num="00049">
<claim-text>49. An image diagnosis supporting device according to <claim-ref idref="CLM-00046">claim 46</claim-ref>, characterized in that in the case where a hidden mode in which display of the markers is disabled is selected, the display means stops displaying the markers and displays information indicating that the hidden mode is presently active, and automatically displays the markers when a predetermined time elapses after the hidden mode has been started.</claim-text>
</claim>
<claim id="CLM-00050" num="00050">
<claim-text>50. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the display means displays a medical image in which the focus candidate shadow exists and a medical image in which the focus candidate shadow does not exist, by moving image display with different display times allocated for the respective medical images.</claim-text>
</claim>
<claim id="CLM-00051" num="00051">
<claim-text>51. An image diagnosis supporting device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that the display means does not display a medical image which has not yet undergone shadow detection by a doctor so that it can be identified.</claim-text>
</claim>
</claims>
</us-patent-grant>
