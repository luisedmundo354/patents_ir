<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07299324-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07299324</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10702916</doc-number>
<date>20031105</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>310</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>13</main-group>
<subgroup>18</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>12</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>711158</main-classification>
<further-classification>710  6</further-classification>
<further-classification>710 40</further-classification>
<further-classification>711  5</further-classification>
</classification-national>
<invention-title id="d0e53">Reactive placement controller for interfacing with banked memory storage</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5276838</doc-number>
<kind>A</kind>
<name>Rao et al.</name>
<date>19940100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711117</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5822772</doc-number>
<kind>A</kind>
<name>Chan et al.</name>
<date>19981000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711158</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6564304</doc-number>
<kind>B1</kind>
<name>Van Hook et al.</name>
<date>20030500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711154</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>7010654</doc-number>
<kind>B2</kind>
<name>Blackmon et al.</name>
<date>20060300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>711158</main-classification></classification-national>
</citation>
</references-cited>
<number-of-claims>13</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>None</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>7</number-of-drawing-sheets>
<number-of-figures>8</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20050097265</doc-number>
<kind>A1</kind>
<date>20050505</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Shrader</last-name>
<first-name>Steven</first-name>
<address>
<city>Boise</city>
<state>ID</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>McKeon</last-name>
<first-name>Michael</first-name>
<address>
<city>Cedar Park</city>
<state>TX</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Patent Venture Group</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<last-name>Brock, II</last-name>
<first-name>Joe A.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Denali Software, Inc.</orgname>
<role>02</role>
<address>
<city>Palo Alto</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Portka</last-name>
<first-name>Gary</first-name>
<department>2188</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">An invention is provided for a reactive placement controller for interfacing with a banked memory storage. The reactive placement controller includes a read/write module, which is coupled to a command control module for a banked memory device. A command queue is included that comprises a plurality of queue entries coupled in series, with a top queue entry coupled to the read/write module. Each queue entry is capable of storing a memory command. Each queue entry includes its own queue control logic that functions to control storage of new memory commands into the command queue to reduce latency of commands in the command queue.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="135.72mm" wi="182.88mm" file="US07299324-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="252.22mm" wi="201.68mm" file="US07299324-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="252.65mm" wi="170.52mm" orientation="landscape" file="US07299324-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="169.50mm" wi="167.56mm" file="US07299324-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="241.98mm" wi="171.20mm" orientation="landscape" file="US07299324-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="184.07mm" wi="162.39mm" orientation="landscape" file="US07299324-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="265.43mm" wi="192.70mm" file="US07299324-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="252.31mm" wi="183.64mm" orientation="landscape" file="US07299324-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is related to 1) U.S. patent application Ser. No. 10/663,328, filed Sep. 16, 2003, and entitled “Method and Apparatus for Multi-Port Memory Controller,” and 2) U.S. patent application Ser. No. 10/663,327, filed Sep. 16, 2003, and entitled “Port Independent Data Transaction Interface For Multi-Port Devices,” each of which is incorporated herein be reference.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">This invention relates generally to memory interfaces, and more particularly to a reactive placement controller for ordering and inserting data transfer commands for banked memory storage.</p>
<p id="p-0005" num="0004">2. Description of the Related Art</p>
<p id="p-0006" num="0005">Many memory devices are designed to have a banking nature in order to increase the density of the memory. Unfortunately, the banking nature of the memory devices requires additional cycles to perform setup operations for memory access operations. For example, <figref idref="DRAWINGS">FIG. 1</figref> is a schematic diagram showing a prior art dynamic random access memory (DRAM) <b>100</b>. The exemplary DRAM <b>100</b> includes a plurality of memory banks <b>102</b><i>a</i>-<b>102</b><i>d</i>, each associated with a page holder <b>104</b><i>a</i>-<b>104</b><i>d. </i></p>
<p id="p-0007" num="0006">Each memory bank <b>102</b><i>a</i>-<b>102</b><i>d </i>is divided into a plurality of pages <b>108</b><i>a</i>-<b>108</b><i>b </i>of data. For example, a particular DRAM could store 32 megabits of data in each memory bank <b>102</b><i>a</i>-<b>102</b><i>d</i>. In this case, each memory bank <b>102</b><i>a</i>-<b>102</b><i>d </i>stores about four thousand pages <b>108</b><i>a</i>-<b>108</b><i>b</i>, with each page <b>108</b><i>a</i>-<b>108</b><i>b </i>having about four thousand bits of data.</p>
<p id="p-0008" num="0007">The DRAM <b>100</b> is a very dense memory array, however data access to the DRAM <b>100</b> can be slow because of the setup time required to access the memory banks <b>102</b><i>a</i>-<b>102</b><i>d</i>. For example, to access stored data, a request is made for a particular page within a particular memory bank. This request typically takes the form of a row address corresponding to the selected page, and a bank address corresponding to the selected bank. For example, a read request can be received for data stored in page <b>108</b><i>a </i>of memory bank <b>102</b><i>a</i>. In response, page <b>108</b><i>a </i>is transferred to the page holder <b>104</b><i>a</i>, which is associated with memory bank <b>102</b><i>a</i>. To access particular data within the selected page <b>108</b><i>a</i>, a column address is provided that points to the desired data. Each column address points to a segment of data within the selected page that is the width of the DRAM. For example, if the output <b>106</b> of the DRAM <b>100</b> is sixteen bits, each column address points to sixteen bits of data within the page <b>108</b><i>a </i>stored in the page holder <b>104</b><i>a</i>. Increased efficiency is obtained by associating a page holder <b>104</b><i>a</i>-<b>104</b><i>d </i>with each memory bank <b>102</b><i>a</i>-<b>102</b><i>d</i>, allowing each memory bank <b>102</b><i>a</i>-<b>102</b><i>d </i>to operate independently.</p>
<p id="p-0009" num="0008">In a DRAM, such as illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, the worst efficiency occurs when two memory access operations are received for different pages in the same memory bank, as illustrated next in <figref idref="DRAWINGS">FIG. 2A</figref>. <figref idref="DRAWINGS">FIG. 2A</figref> is a timing diagram illustrating a prior art DRAM access of two different pages in the same memory bank. In a first clock cycle <b>1</b>, the DRAM receives a request for data located on page <b>108</b><i>a </i>of memory bank <b>102</b><i>a</i>. In this example it is assumed four cycles are required to transfer the requested page from the memory bank to the associated page holder. Thus, in clock cycle <b>5</b> a read request can be processed for page holder <b>104</b><i>a</i>, which is associated with memory bank <b>102</b><i>a </i>and currently stores page <b>108</b><i>a</i>. Here, sixty-four bits of data are requested requiring four cycles to complete.</p>
<p id="p-0010" num="0009">The process of pushing a page from a memory bank to a page holder erases the page data from the memory bank. Hence, when a second page is to be pushed into the same page holder, the first page must be stored back into the memory bank if the data is to be retained. This is referred to as a precharge or refresh. Hence, after the requested data is read, page <b>108</b><i>a </i>is stored back into memory bank <b>102</b><i>a </i>requiring, in this example, two additional clock cycles. Thereafter, on cycle <b>12</b>, the request for data located on page <b>108</b><i>a</i>′ of memory bank <b>102</b><i>a </i>can begin processing.</p>
<p id="p-0011" num="0010">After twelve clock cycles only four sixteen-bit data chunks have been received, which is unacceptable for many systems. To decrease this latency, systems have been developed to “look ahead” in the data stream to more efficiently send requests to the banked memory device. <figref idref="DRAWINGS">FIG. 2B</figref> is a timing diagram illustrating a prior art DRAM access of two different pages in the same memory bank wherein an additional memory access command is inserted to increase data access efficiency. In the example of <figref idref="DRAWINGS">FIG. 2B</figref>, the memory interface has determined that a third request for a page located in memory bank <b>102</b><i>b </i>has been received. Since memory banks <b>102</b><i>a </i>and <b>102</b><i>b </i>can operate independently, memory access can be improved by processing both data requests together. Thus, the request for page <b>108</b><i>b </i>in memory bank <b>102</b><i>b </i>is inserted in clock cycle <b>2</b>. As above, it is assume four cycles are required to transfer page <b>108</b><i>b </i>from the memory bank <b>102</b><i>b </i>to the associated page holder <b>104</b><i>b</i>. Although the requested data is available on clock cycle <b>6</b>, the DRAM output is being utilized in that clock cycle to output the data from page <b>108</b><i>a</i>. Thus, the output for page <b>108</b><i>b </i>begins after the data for page <b>108</b><i>a </i>is read, in clock cycle <b>10</b>. Now, after twelve clock cycles seven sixteen-bit data chunks have been output from the DRAM, which is improved from <figref idref="DRAWINGS">FIG. 2A</figref>.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. 3</figref> is a schematic diagram showing an exemplary prior art DRAM controller <b>300</b> for reordering memory access commands to increase DRAM efficiency. The DRAM controller <b>300</b> includes a command input <b>302</b>, a plurality of queue entries <b>304</b> coupled to a multiplexer <b>308</b>, and a queue control <b>306</b> that provides control signals to the multiplexer <b>308</b>. The multiplexer <b>308</b> also is coupled to a read/write control <b>312</b>, which provides data to a command control <b>314</b>. In addition, the queue control <b>306</b> is coupled to a bank control <b>310</b> that also provides data to the command control <b>314</b>.</p>
<p id="p-0013" num="0012">As illustrated in <figref idref="DRAWINGS">FIG. 3</figref>, most queues for DRAM controllers are based on a standard circular queue with separate bank control module. In the DRAM controller <b>300</b>, the queue entries <b>304</b> only contain data for an individual command such as address, length, and read/write flag. The queue control module <b>306</b> has a direct connection to each queue entry <b>304</b> to determine which queue entry data to send to the read/write control module <b>312</b>. The queue control module <b>306</b> selects which command to execute and tells the bank control module <b>310</b> to prepare the bank. When the bank is prepared queue control <b>306</b> selects the command to be sent to the read/write control module <b>312</b>.</p>
<p id="p-0014" num="0013">Unfortunately, the DRAM bank control presents a major problem in the prior art DRAM controller <b>300</b>. As illustrated in <figref idref="DRAWINGS">FIG. 2B</figref>, commands to the memory to set up banks need to be ahead of the read/write command by a number of cycles. Because of this, the jobs of the queue control <b>306</b> and bank control <b>310</b> processes are difficult. A command needs to be selected a long time in advance in order to have the bank control module <b>310</b> address the bank to the correct address. When the number of banks in the system increases because of the controller <b>300</b> being configured for multiple ranks, the problem of bank control goes up exponentially.</p>
<p id="p-0015" num="0014">The difficulty with the DRAM controller <b>300</b> is that as the number of queue entries <b>304</b> is expanded the multiplexer <b>308</b> to select the number of queue entries <b>304</b> also grows. This problem is increased also due to the fact that the multiplexer <b>308</b> is muxing a very large number of bits. The address, length, and read/write flag alone typically is about 40 bits. For example, if the number of queue entries <b>304</b> is sixteen, the total number of bits to mux is 16*40=640 bits. This large number of bits presents a problem in synthesis. Furthermore, the queue control module <b>306</b> adds additional time to the selection process because of the complex task the queue control module <b>306</b> performs. That is, selecting the correct command based on the command type and bank status and priority. The timing for the queue control module <b>306</b> also increases as the number of queue entries <b>304</b> increases.</p>
<p id="p-0016" num="0015">In view of the foregoing, there is a need for a DRAM controller for ordering and inserting data transfer commands for banked memory storage that avoids exponential increases in complexity as the “look ahead” functionality increases. The DRAM controller should allow a linear progression of complexity as the number of queue entries increases instead of an exponential increase as is experienced in the prior art.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0017" num="0016">Broadly speaking, the present invention fills these needs by providing a reactive placement controller for ordering and inserting data transfer commands for banked memory storage. In one embodiment, a reactive placement controller for interfacing with a banked memory storage is disclosed. The reactive placement controller includes a read/write module, which is coupled to a command control module for a banked memory device. A command queue also is included that comprises a plurality of queue entries coupled in series, with a top queue entry coupled to the read/write module. Each queue entry is capable of storing a memory command. Each queue entry includes its own queue control logic that functions to control storage of new memory commands into the command queue to reduce latency of commands in the command queue. In one aspect, the queue control logic for each queue entry can group new inbound commands into brackets, each bracket being a soft division of the command queue based on command data. For example, the queue control logic for each queue entry can group new inbound commands into priority brackets based on a priority value of the command. Within the priority brackets, the queue control logic can group new inbound commands into read/write brackets based on a priority value of the command and a type of the command. Further, within the read/write brackets, read commands can be grouped with read commands and write commands can be grouped with write commands. In addition, the queue control logic for each queue entry can group new inbound commands into bank split brackets based on a priority value of the command, a type of the command, and bank collision proximity to other commands in the command queue.</p>
<p id="p-0018" num="0017">A method for placing commands within a queue of a placement controller is disclosed in a further embodiment of the present invention. The method includes receiving a new inbound command for a banked memory device, where the new inbound command has an associated priority value, a command type, and an address for the memory. A determination is then made as to whether a priority bracket exists for the priority value of the new inbound command. When a priority bracket exists for the priority value, a determination is made as to whether a read/write bracket exists within the priority bracket for the command type of the new inbound command. Then, when a read/write bracket exists for the command type, a determination is made as to whether the new inbound command addresses a different page in a memory bank addressed by a command in an adjacent queue entry. In one aspect, the new inbound command can be placed within the command queue based on existing priority brackets when a priority bracket does not exist for the priority value of the new inbound command. Also, the current executing command can be interrupted when the priority value of the new inbound command is higher than the priority of the current executing command. When a read/write bracket does not exist within the priority bracket for the command type of the new inbound command, a read/write bracket can be created and the new inbound command can be placed in a queue entry within the priority bracket. Also, the new inbound command generally is placed in a queue entry in the read/write bracket such that the new inbound command is not adjacent to a command addressing a different page in the memory bank addressed by the new inbound command.</p>
<p id="p-0019" num="0018">A further reactive placement controller for interfacing with a banked memory storage is disclosed in an additional embodiment. The reactive placement controller includes a read/write module coupled to a command control module for a banked memory device. Also, a command queue is included that has a plurality of queue entries coupled in series. As above, the plurality of queue entries includes a top queue entry coupled to the read/write module, and each queue entry is capable of storing a memory command. In addition, each queue entry is coupled to a plurality of priority chains. Each priority chain includes a plurality of AND gates in a chain, and is capable of allowing higher priority queue entries to disable lower priority queue entries. In one aspect, the plurality of priority chains includes a “Priority” priority chain that is controlled by a command priority value of commands. The “Priority” priority chain is capable of disabling queue entries storing commands having a higher priority than a new inbound command. The plurality of priority chains can also include a bank split priority chain that is controlled by an address value of commands. The bank split priority chain is capable of disabling queue entries storing commands causing a bank conflict between adjacent queue entries.</p>
<p id="p-0020" num="0019">Other aspects and advantages of the invention will become apparent from the following detailed description, taken in conjunction with the accompanying drawings, illustrating by way of example the principles of the invention.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0021" num="0020">The invention, together with further advantages thereof, may best be understood by reference to the following description taken in conjunction with the accompanying drawings in which:</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic diagram showing a prior art dynamic random access memory (DRAM);</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 2A</figref> is a timing diagram illustrating a prior art DRAM access of two different pages in the same memory bank;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 2B</figref> is a timing diagram illustrating a prior art DRAM access of two different pages in the same memory bank wherein an additional memory access command is inserted to increase data access efficiency;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 3</figref> is a schematic diagram showing an exemplary prior art DRAM controller for reordering memory access commands to increase DRAM efficiency;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 4</figref> is a high-level schematic diagram of the components of a multi-port memory controller in accordance with one embodiment of the invention;</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 5</figref> is a schematic diagram showing a placement controller, in accordance with an embodiment of the present invention;</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart showing a method for placing commands within the queue of the placement controller, in accordance with an embodiment of the present invention; and</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 7</figref> is a schematic diagram of priority chains, in accordance with an embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0030" num="0029">An invention is disclosed for a reactive placement controller for ordering and inserting data transfer commands for banked memory storage. Embodiments of the present invention place queue control logic in each queue entry. Since each queue control logic is only required to examine data bits from itself and adjacent queue entries, embodiments of the present invention allow a linear progression of complexity as the number of queue entries increases instead of an exponential increase as is experienced in the prior art.</p>
<p id="p-0031" num="0030">In the following description, numerous specific details are set forth in order to provide a thorough understanding of the present invention. It will be apparent, however, to one skilled in the art that the present invention may be practiced without some or all of these specific details. In other instances, well known process steps have not been described in detail in order not to unnecessarily obscure the present invention.</p>
<p id="p-0032" num="0031">In one embodiment, a reactive placement controller of the present invention can be utilized in a multi-port memory controller to enhance usage of a banked memory device. <figref idref="DRAWINGS">FIG. 4</figref> is a high-level schematic diagram of the components of a multi-port memory controller <b>400</b> in accordance with one embodiment of the invention. The memory controller <b>400</b> includes an initiator block <b>404</b>, a placement controller and write data queue block <b>406</b>, and a DRAM command arbitration block <b>408</b>. A programmable register settings block <b>402</b>, which is in communication with initiator block <b>404</b>, placement controller and write data queue block <b>406</b>, and DRAM command arbitration block <b>408</b> also is included. The initiator block <b>404</b> is configured to receive data from port zero through port N, and is configured to arbitrate requests from the multiple ports through a feedback loop that enables the consideration of past bandwidth usage of each of the ports, that may be in addition to fairness considerations. Additional details of the initiator block <b>404</b> can be found in co-pending U.S. patent application Ser. No. 10/663,328, filed Sep. 16, 2003, and entitled “Method and Apparatus for Multi-Port Memory Controller,” which is incorporated herein by reference.</p>
<p id="p-0033" num="0032">In one embodiment, each of ports zero through port N is assigned a bandwidth requirement along with a priority. These values may be stored as programmable registers in programmable register setting block <b>402</b> and written upon initialization of memory controller <b>400</b> after reset. In another embodiment, the bandwidth requirement is defined as the maximum percentage bandwidth the port will be allowed to have. Once this level is exceeded, initiator block <b>404</b> is configured to no longer accept requests from the corresponding port until the bandwidth levels drop below a predefined threshold. In one embodiment, the priority of the port, along with the port arbitration logic, determines which ports are allowed to register a request to placement controller and write data queue block <b>406</b>.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 5</figref> is a schematic diagram showing a placement controller <b>406</b>, in accordance with an embodiment of the present invention. The placement controller <b>406</b> includes a command input <b>500</b> coupled to a plurality of queue entries <b>502</b><i>a</i>-<b>502</b><i>d </i>that form a queue. Each queue entry <b>502</b><i>a</i>-<b>502</b><i>d </i>includes queue control logic <b>504</b>, which functions to control placement of new commands from the command input <b>500</b>. The top queue entry, queue entry <b>502</b><i>a </i>in <figref idref="DRAWINGS">FIG. 5</figref>, is coupled to a read/write module <b>506</b> and a bank control module <b>508</b>. Finally, both the read/write module <b>506</b> and the bank control module <b>508</b> are coupled to output control module <b>510</b>. In operation, the placement controller monitors all requests in the queue in order to take advantage of precharging or activating banks in the memory devices to reduce latency of commands in the command queue.</p>
<p id="p-0035" num="0034">The placement controller <b>406</b> dramatically reduces the problems of the prior art DRAM controllers discussed above with reference to <figref idref="DRAWINGS">FIG. 3</figref>. The placement controller <b>406</b> is based on a premise that DRAM devices should have a planed ordering in order to do bank prepping before a read/write command is actually issued.</p>
<p id="p-0036" num="0035">In operation, the placement controller <b>406</b> places inbound commands into the queue entries <b>502</b><i>a</i>-<b>502</b><i>d </i>based on the requirements of the command and the programmed operation of the queue control logic <b>504</b>. The placement controller <b>406</b> uses a migration queue in that all commands migrate from left to right as the read/write module <b>506</b> accepts commands. As mentioned above, the far right queue entry <b>502</b><i>a </i>in <figref idref="DRAWINGS">FIG. 5</figref> is the top of the queue. Because the top queue position is a physical position, no multiplexer is required. That is, each command will be in the top queue entry <b>502</b><i>a </i>before the command goes to the read/write module <b>506</b>.</p>
<p id="p-0037" num="0036">Timing for the read/write module <b>506</b> generally does not change as the number of queue entries <b>502</b><i>a</i>-<b>502</b><i>d </i>increases because each queue entry <b>502</b><i>a</i>-<b>502</b><i>d </i>only has three busses that the queue entry <b>502</b><i>a</i>-<b>502</b><i>d </i>processes. In particular, each queue entry <b>502</b><i>a</i>-<b>502</b><i>d </i>interfaces with the command input module <b>500</b>, the previous queue entry and the next entry. For example, in <figref idref="DRAWINGS">FIG. 5</figref>, queue entry <b>502</b><i>b </i>generally is only required to interface with the command input module <b>500</b>, queue entry <b>502</b><i>a</i>, and queue entry <b>502</b><i>c</i>. Moreover, the output from the top queue entry is generated from flops and therefore the queue itself does not impede on the downstream timing of the bank prediction or read/write logic stages.</p>
<p id="p-0038" num="0037">Each queue entry <b>502</b><i>a</i>-<b>502</b><i>d </i>advantageously includes its own queue control logic <b>504</b> to manage the particular queue entry <b>502</b><i>a</i>-<b>502</b><i>d</i>. The queue control logic <b>504</b> determines on each clock cycle where to load data for the queue among the inbound busses or its own data stored in the particular queue entry <b>502</b><i>a</i>-<b>502</b><i>d</i>. The queue control logic <b>504</b> also has the ability to modify the contents of the queue data to generate status information that migrates with the stored command data. The combined logic for all the queue control logic <b>504</b> in all of the queue entries <b>502</b><i>a</i>-<b>502</b><i>d </i>determines where each command is placed when a new command is applied from the command input module <b>500</b>. Each time a new command arrives from the command input module <b>500</b>, all the queue entries <b>502</b><i>a</i>-<b>502</b><i>d </i>collectivity determine what they will do with the command and where the command will be placed within the queue.</p>
<p id="p-0039" num="0038">For example, in <figref idref="DRAWINGS">FIG. 5</figref>, if three of the four queue entries <b>502</b><i>a</i>-<b>502</b><i>d </i>are full and queue entry <b>502</b><i>b </i>should receive the new command from the command input module <b>500</b>, then the entry data for queue entry <b>502</b><i>c </i>is placed in queue entry <b>502</b><i>d</i>, entry data for queue entry <b>502</b><i>b </i>is placed in queue entry <b>502</b><i>c</i>, queue entry <b>502</b><i>b </i>loads the new command, and queue entry <b>502</b><i>a </i>keeps its own data. This all happens in the same clock cycle. When the read/write module <b>506</b> accepts a command, all the queue entries <b>502</b><i>a</i>-<b>502</b><i>d </i>are shifted on the same clock cycle reducing the number of full entries by one and clearing the entry in queue entry <b>502</b><i>d. </i></p>
<p id="p-0040" num="0039">Because each queue entry <b>502</b><i>a</i>-<b>502</b><i>d </i>can change the data in the queue entry, status or control data migrates with the command. Also, bank status migrates with the command along with an age count. If the bank status migrates with the command, higher priority commands that are placed near the front of the queue may use a bank of a command in the queue further down the queue and re-address the bank. The command further down the queue will detect that the bank was re-addressed and, when the bank lock is released, the command that was further down will again re-address the bank for its usage. A bank lock is an indication that this queue entry has been allocated use of a particular bank in memory. Each queue entry <b>502</b><i>a</i>-<b>502</b><i>d </i>solves the problem of bank addressing by making sure that its bank is addressed properly at all times based on where the command is in the queue. Each queue entry <b>502</b><i>a</i>-<b>502</b><i>d </i>indicates whether or not it has been allocated a bank. The bank prediction can therefore operate on all the valid queue entries at once. An age count is maintained with the command and when the age count underflows, the command's priority is made higher. This process prevents a command remaining in the queue indefinitely.</p>
<p id="p-0041" num="0040">Each command is accompanied by a source ID and a priority. The source ID is utilized to keep the queue from re-ordering commands from the same source. Priority is utilized to lower the latency of the command. There is no association between the source ID and the priority. Hence, each command from any source could be at any priority. Additional details of source IDs and priority can be found in co-pending U.S. patent application Ser. No. 10/663,327, filed Sep. 16, 2003, and entitled “Port Independent Data Transaction Interface For Multi-Port Devices,” which is incorporated herein by reference.</p>
<p id="p-0042" num="0041">Commands of like priority are normally placed in the queue in groups. The commands of higher priority are grouped to the right of the queue, with lower priority commands grouped to the left of the queue. Within each priority group, read commands are grouped together and write are grouped together. Within each grouping of reads, and writes, commands to the same bank with a different row (page) are separated with other commands. This layered approach will be referred to hereinafter as “brackets” or “bracketing.”</p>
<p id="p-0043" num="0042">In one embodiment, the brackets utilized are 1) priority—to control the latency of the command, 2) read/write—to increase bandwidth because reads can be chained, and 3) bank split—to increase bandwidth by lowering bank overhead. In the placement controller <b>406</b>, each bracket is a soft division of the queue. The entire queue may have all different priorities or all the same priority. Because each queue entry <b>502</b><i>a</i>-<b>502</b><i>d </i>has its own queue control logic <b>504</b> for detecting the above conditions, with control flags, each of the conditions can be easily disabled providing for a large degree of control of how commands in the queue are grouped.</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. 6</figref> is a flowchart showing a method <b>600</b> for placing commands within the queue of the placement controller, in accordance with an embodiment of the present invention. In an initial operation <b>602</b>, preprocess operations are performed. Preprocess operations can include arbitrating requests from multiple ports, assigning a source ID and priority to the command, and other preprocess operations that will be apparent to those skilled in the art after a careful reading of the present disclosure.</p>
<p id="p-0045" num="0044">Once a command is received, the command's priority is examined, in operation <b>604</b>. If a priority bracket for the command's priority currently exists within the queue, the method <b>600</b> continues to operation <b>608</b>. Otherwise, the method <b>600</b> branches to operation <b>606</b>.</p>
<p id="p-0046" num="0045">In operation <b>606</b>, the priority of the command is examined to determine if the command's priority is the highest priority in the queue. If an incoming command is of highest priority in the command queue, this command interrupts the current command and executes immediately. The interrupted command resumes processing after the higher priority command completes or when there are no more interrupting high priority commands. If an incoming command is not the highest priority in the command queue, the command is placed in the queue based on the existing brackets within the queue. As mentioned above, higher priority commands are placed ahead of lower priority commands. In one embodiment, if a high priority request detects a data coherency issue, all commands previously in the queue ahead of the command that caused the coherency violation are executed before the new high priority command regardless of their priority.</p>
<p id="p-0047" num="0046">In operation <b>608</b>, a decision is made as to whether a read/write bracket exists within the priority bracket for the new command. If a read/write bracket exists within the priority bracket for the new command, the method <b>600</b> continues with operation <b>612</b>. Otherwise, the method <b>600</b> branches to operation <b>610</b>.</p>
<p id="p-0048" num="0047">In operation <b>610</b>, a read/write bracket is created based on the type of the new command (read or write) and the new command is placed within the priority bracket. Commands with like priorities are placed such that read commands are grouped with read commands and write commands are grouped with write commands. The order of the read verses write grouping is determined by the order in which the commands are sent to the placement controller. For example, if a read command at a particular priority is accepted before a write command at the same priority, the read commands will be placed ahead of write commands. On the other hand, if the write command is accepted before the read command, the write commands will be ahead of the read commands for that particular priority level.</p>
<p id="p-0049" num="0048">A decision is then made as to whether the new command causes a bank conflict within the read/write bracket, in operation <b>612</b>. If the new command causes a bank conflict within the read/write bracket, the method <b>600</b> branches to operation <b>616</b>. Otherwise, the method <b>600</b> continues with operation <b>614</b>.</p>
<p id="p-0050" num="0049">When the new command causes a bank conflict within the read/write bracket, the new command is placed within the read/write bracket so as to remove the bank conflict on consecutive commands if possible, in operation <b>616</b>. As mentioned above, a bank conflict occurs when consecutive commands attempt to access different pages (rows) within the same memory bank. Hence, embodiments of the present invention place commands with like priorities and the same read or write types such that bank collisions are avoided in the memory device.</p>
<p id="p-0051" num="0050">When the new command does not cause a bank conflict within the read/write bracket, the command is placed after the last entry of the command's read or write type within the read/write bracket, in operation <b>614</b>. Post process operations are performed in operation <b>618</b>. Post process operations can include, for example, moving data from a memory bank to a page holder, precharging the memory banks, and other post process operations that will be apparent to those skilled in the art after a careful reading of the present disclosure.</p>
<p id="p-0052" num="0051">In one embodiment of the present invention, additional conditions can be utilized to enhance the placement method <b>600</b> described above. For example, in one embodiment, if a read or write command is to the same DRAM page as a previously placed transaction in the queue, the new command is placed behind the command to the same DRAM page. The exact placement of the new command is based upon the general placement method <b>600</b> for all the commands that are currently behind the command with the matching DRAM page. The new command retains all the priority information when placed, allowing all subsequent commands to be placed in accordance with the placement method <b>600</b>.</p>
<p id="p-0053" num="0052">In one embodiment, all read commands from a particular source ID are always executed in the order they are received by the placement controller. In this embodiment, write commands from a particular source ID are also executed in the order they are received by the placement controller. The placement controller can place read commands ahead of write commands and vice versa as long as there is no data coherency issue. If a new read or write command has the same source ID and a greater priority as the current read or write command respectively in the queue, the new command is placed after the current command. The new command retains all the priority information when placed.</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. 7</figref> is a schematic diagram of priority chains <b>700</b>, in accordance with an embodiment of the present invention. In particular, <figref idref="DRAWINGS">FIG. 7</figref> illustrates how priority chains interact with the queue entries <b>502</b><i>a</i>-<b>502</b><i>d </i>to determine the placement of new commands. A priority chain is a series of AND gates in a chain utilized to disable lower priority queue entries by higher priority queue entries. The priority chains <b>700</b> illustrated in <figref idref="DRAWINGS">FIG. 7</figref> include a write count lock priority chain <b>702</b>, a write buffer enable priority chain <b>704</b>, a “Priority” priority chain <b>706</b>, a Priority same priority chain <b>708</b>, a read/write same priority chain <b>710</b>, and a bank split priority chain <b>712</b>.</p>
<p id="p-0055" num="0054">It should be noted that a priority chain is different than the priority assigned to a particular command. That is, the priority of a command is a value assigned to a command when the command is sent to the placement controller and is part of the total command sent. While a priority chain, as mentioned above, is a series of gates used to disable particular queue entries from accepting new commands or shifting its command towards the head of the queue.</p>
<p id="p-0056" num="0055">As shown in <figref idref="DRAWINGS">FIG. 7</figref>, each queue entry <b>502</b><i>a</i>-<b>502</b><i>d </i>has an output to, and input from, each priority chain <b>702</b>-<b>712</b>. The direction of arrows on the priority chain <b>702</b>-<b>712</b> indicate in which direction following queue entries <b>502</b><i>a</i>-<b>502</b><i>d </i>will be affected by a particular queue entry. For example, in the “Priority” priority chain <b>706</b>, the output of queue entry <b>502</b><i>d </i>affects all the other queue entries <b>502</b><i>a</i>-<b>502</b><i>c</i>, queue entry <b>502</b><i>c </i>affects queue entries <b>502</b><i>b </i>and <b>502</b><i>a</i>, queue entry <b>502</b><i>b </i>affects only queue entry <b>502</b><i>a</i>, and queue entry <b>502</b><i>a </i>does not affect any other queue entry on the “Priority” priority chain <b>706</b>. We define the “Priority” priority chain <b>706</b> as going forward or going in the direction of standard commands. On the other hand, the Bank split priority chain <b>712</b> goes in the reverse direction such that the output of queue entry <b>502</b><i>a </i>affects all other queue entries <b>502</b><i>b</i>-<b>502</b><i>d. </i></p>
<p id="p-0057" num="0056">The “Priority” priority chain <b>706</b> is controlled by the command priority of the command in each queue entry <b>502</b><i>a</i>-<b>502</b><i>d </i>and the new inbound command from the command input module. If the priority of the command in a particular queue entry <b>502</b><i>a</i>-<b>502</b><i>d </i>is higher than the priority of the new inbound command, the “Priority” priority chain <b>706</b> is disabled at that queue entry. For example, if queue entry <b>502</b><i>c </i>detects that the command in queue entry <b>502</b><i>c </i>has a higher priority than the new inbound command, queue entry <b>502</b><i>c </i>will disable queue entry <b>502</b><i>b </i>and queue entry <b>502</b><i>a </i>by disabling the “Priority” priority chain <b>706</b> at queue entry <b>502</b><i>c. </i></p>
<p id="p-0058" num="0057">To further explain this, if queue entry <b>502</b><i>c </i>detects that the new inbound command needs to be placed at this point, queue entry <b>502</b><i>c </i>disables the entries below by disabling the “Priority” priority chain <b>706</b>, which disables queue entries <b>502</b><i>b </i>and <b>502</b><i>a</i>, and accepts the new command. Queue entry <b>502</b><i>d </i>knows that it needs to load the new command in queue entry <b>502</b><i>c </i>because queue entry <b>502</b><i>d </i>is not disabled. Queue entry <b>502</b><i>b </i>and queue entry <b>502</b><i>a </i>know not to do anything because they are disabled. In this instance, queue entry <b>502</b><i>d </i>receives a “1” from the “Priority” priority chain <b>706</b>, queue entry <b>502</b><i>c </i>also receives a “1,” and queue entries <b>502</b><i>b</i>-<b>502</b><i>a </i>each receive a “0” from the “Priority” priority chain <b>706</b>. Each queue entry <b>502</b><i>a</i>-<b>502</b><i>d </i>receives a slightly different value from the “Priority” priority chain <b>706</b> depending upon the conditions of the inbound command and the particular data stored in the queue entries <b>502</b><i>a</i>-<b>502</b><i>d</i>. The remaining priority chains <b>702</b>-<b>704</b> and <b>708</b>-<b>710</b> have similar functions, the difference being the data that disables the priority chains.</p>
<p id="p-0059" num="0058">In particular, the “Priority” priority chain <b>706</b> is dependent upon the priority of a command being higher than the priority of the command stored in the queue entry <b>502</b><i>a</i>-<b>502</b><i>d</i>. The Priority same priority chain <b>708</b> is dependent upon the priority of a command being the same as the priority of the command stored in the queue entry <b>502</b><i>a</i>-<b>502</b><i>d</i>. The Read write same priority chain <b>710</b> is dependant upon both the priority of the command and the type of the command being the same as the command stored in the queue entry <b>502</b><i>a</i>-<b>502</b><i>d</i>. The Bank split priority chain <b>712</b> is dependant upon both the priority of the command and the type of the command being the same with a bank conflict between this entry and the next entry.</p>
<p id="p-0060" num="0059">The “Priority” priority chain <b>706</b> is utilized to detect new priority levels. The Priority same priority chain <b>708</b> is used to detect and append to current priority levels. The Read write same priority chain <b>710</b> is used to detect and append to read and write brackets at the same priority level. The Bank split priority chain <b>712</b> is used to detect the information to place commands between commands that would otherwise have large overhead by using the same bank with different row (page). The Write buf enable priority chain <b>702</b> is used for collision detection of write buffers for write commands, and the write count lock priority chain <b>704</b> is used to coordinate access of two commands using the same write buffer in sequence. Because of the priority chains <b>702</b>-<b>712</b>, each queue entry <b>502</b><i>a</i>-<b>502</b><i>d </i>receives all the information necessary to make a decision as to where to load data for each queue entry <b>502</b><i>a</i>-<b>502</b><i>d. </i></p>
<p id="p-0061" num="0060">As mentioned above, the command stored in the top queue entry, in <figref idref="DRAWINGS">FIG. 7</figref> queue entry <b>502</b><i>a</i>, is the next command that will be loaded into the read/write module for processing. Loading the command from the top queue entry into the read/write module is referred to as a “dequeue.” Depending on whether a dequeue occurs when a new command is received, different data movement can occur within the queue. For example, suppose a new command is received and a dequeue does not occur during that clock cycle. In addition, suppose the new command should be inserted into queue entry <b>502</b><i>b </i>and that commands are currently stored in queue entries <b>502</b><i>a</i>, <b>502</b><i>b</i>, and <b>502</b><i>c</i>. In this case the number of commands stored in the queue is increased by one. Queue entry <b>502</b><i>d </i>loads the command data stored in queue entry <b>502</b><i>c</i>, queue entry <b>502</b><i>c </i>loads the command data stored in queue entry <b>502</b><i>b</i>, queue entry <b>502</b><i>b </i>loads the new inbound command, and queue entry <b>502</b><i>a </i>does nothing, keeping its current command data.</p>
<p id="p-0062" num="0061">In another example, suppose a new command is received and a dequeue occurs during the same clock cycle. As above, suppose the new command should be inserted into queue entry <b>502</b><i>b </i>and that commands are currently stored in queue entries <b>502</b><i>a</i>, <b>502</b><i>b</i>, and <b>502</b><i>c</i>. In this case the number of commands does not change. Queue entry <b>502</b><i>d </i>and queue entry <b>502</b><i>c </i>do nothing, keeping their current command data. Queue entry <b>502</b><i>a </i>loads the command data stored in queue entry <b>502</b><i>b</i>, and queue entry <b>502</b><i>b </i>loads the new inbound command.</p>
<p id="p-0063" num="0062">Although the foregoing invention has been described in some detail for purposes of clarity of understanding, it will be apparent that certain changes and modifications may be practiced within the scope of the appended claims. Accordingly, the present embodiments are to be considered as illustrative and not restrictive, and the invention is not to be limited to the details given herein, but may be modified within the scope and equivalents of the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A reactive placement controller for interfacing with a banked memory storage, comprising:
<claim-text>a read/write module coupled to a command control module for a banked memory device;</claim-text>
<claim-text>a command queue including a plurality of queue entries coupled in series, the plurality of queue entries including a top queue entry coupled to the read/write module, each queue entry capable of storing a memory command; and</claim-text>
<claim-text>priority chains including a plurality of AND gates in a chain, the priority chains capable of allowing higher priority queue entries to disable lower priority queue entries,</claim-text>
<claim-text>wherein each queue entry includes queue control logic that functions to control storage of new memory commands into the command queue to reduce latency of commands in the command queue.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. A reactive placement controller as recited in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the queue control logic for each queue entry groups new inbound commands into brackets, wherein each bracket is a soft division of the command queue based on command data.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. A reactive placement controller as recited in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the queue control logic for each queue entry groups new inbound commands into priority brackets based on a priority value of the command.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A reactive placement controller as recited in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the queue control logic for each queue entry groups new inbound commands into read/write brackets based on a priority value of the command and a type of the command.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A reactive placement controller as recited in <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein read commands are grouped with read commands and write commands are grouped with write commands.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A reactive placement controller as recited in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the queue control logic for each queue entry groups new inbound commands into bank split brackets based on a priority value of the command, a type of the command, and bank collision proximity to other commands in the command queue.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A reactive placement controller for interfacing with a banked memory storage, comprising:
<claim-text>a read/write module coupled to a command control module for a banked memory device; and</claim-text>
<claim-text>a command queue including a plurality of queue entries coupled in series, the plurality of queue entries including a top queue entry coupled to the read/write module, each queue entry capable of storing a memory command,</claim-text>
<claim-text>wherein each queue entry is coupled to a plurality of priority chains, each priority chain including a plurality of AND gates in a chain, the priority chains capable of allowing higher priority queue entries to disable lower priority queue entries.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A reactive placement controller as recited in <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the plurality of priority chains includes a “Priority” priority chain that is controlled by a command priority value of commands, and wherein the “Priority” priority chain is capable of disabling queue entries storing commands having a higher priority than a new inbound command.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. A reactive placement controller as recited in <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the plurality of priority chains includes a Priority same priority chain that is controlled by a command priority value of commands, and wherein the Priority same priority chain is capable of disabling queue entries storing commands having a different priority than a new inbound command.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A reactive placement controller as recited in <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the plurality of priority chains includes a read write same priority chain that is controlled by a command type value of commands, and wherein the read write same priority chain is capable of disabling queue entries storing commands having a different command type than a new inbound command.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A reactive placement controller as recited in <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the plurality of priority chains includes a bank split priority chain that is controlled by a address value of commands, and wherein the bank split priority chain is capable of disabling queue entries storing commands causing a bank conflict between adjacent queue entries.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. A reactive placement controller as recited in <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the plurality of priority chains includes a write buf enable priority chain that is capable of collision detection of write buffers for write commands.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. A reactive placement controller as recited in <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the plurality of priority chains includes a write count lock priority chain that is capable of coordinating access of two commands using a same write buffer in sequence.</claim-text>
</claim>
</claims>
</us-patent-grant>
