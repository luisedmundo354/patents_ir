<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07299420-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07299420</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10458579</doc-number>
<date>20030609</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>878</us-term-extension>
<disclaimer>
<text>This patent is subject to a terminal disclaimer.</text>
</disclaimer>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>3</main-group>
<subgroup>048</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>715764</main-classification>
<further-classification>715781</further-classification>
<further-classification>715840</further-classification>
<further-classification>715856</further-classification>
<further-classification>715823</further-classification>
<further-classification>345582</further-classification>
<further-classification>345586</further-classification>
<further-classification>345619</further-classification>
<further-classification>345620</further-classification>
<further-classification>345622</further-classification>
</classification-national>
<invention-title id="d0e55">Graphical user interface for <i>in-vivo </i>imaging</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4948975</doc-number>
<kind>A</kind>
<name>Erwin et al.</name>
<date>19900800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>250361</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5202091</doc-number>
<kind>A</kind>
<name>Lisenbee</name>
<date>19930400</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>422 52</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5319209</doc-number>
<kind>A</kind>
<name>Miyakawa et al.</name>
<date>19940600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5414258</doc-number>
<kind>A</kind>
<name>Liang</name>
<date>19950500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5625377</doc-number>
<kind>A</kind>
<name>Jensen</name>
<date>19970400</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>345146</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>5636299</doc-number>
<kind>A</kind>
<name>Bueno et al.</name>
<date>19970600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>5637874</doc-number>
<kind>A</kind>
<name>Honzawa et al.</name>
<date>19970600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>5650135</doc-number>
<kind>A</kind>
<name>Contag et al.</name>
<date>19970700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>424  91</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>5672881</doc-number>
<kind>A</kind>
<name>Striepeke et al.</name>
<date>19970900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>5705807</doc-number>
<kind>A</kind>
<name>Throngnumchai</name>
<date>19980100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>5738101</doc-number>
<kind>A</kind>
<name>Sappey</name>
<date>19980400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>5740267</doc-number>
<kind>A</kind>
<name>Echerer et al.</name>
<date>19980400</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382132</main-classification></classification-national>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>5840572</doc-number>
<kind>A</kind>
<name>Copeland</name>
<date>19981100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>5867250</doc-number>
<kind>A</kind>
<name>Baron</name>
<date>19990200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>5970164</doc-number>
<kind>A</kind>
<name>Bamberger et al.</name>
<date>19991000</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382128</main-classification></classification-national>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>6217847</doc-number>
<kind>B1</kind>
<name>Contag et al.</name>
<date>20010400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>6242743</doc-number>
<kind>B1</kind>
<name>DeVito et al.</name>
<date>20010600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>6321111</doc-number>
<kind>B1</kind>
<name>Perelman et al.</name>
<date>20011100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>6332038</doc-number>
<kind>B1</kind>
<name>Funayama et al.</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382190</main-classification></classification-national>
</citation>
<citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>6333752</doc-number>
<kind>B1</kind>
<name>Hasegawa et al.</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>345764</main-classification></classification-national>
</citation>
<citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>6364829</doc-number>
<kind>B1</kind>
<name>Fulghum</name>
<date>20020400</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>6615063</doc-number>
<kind>B1</kind>
<name>Ntziachristos</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>6775567</doc-number>
<kind>B2</kind>
<name>Cable</name>
<date>20040800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00024">
<document-id>
<country>WO</country>
<doc-number>WO94/13095</doc-number>
<date>19940600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00025">
<document-id>
<country>WO</country>
<doc-number>WO00/17643</doc-number>
<date>20000300</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00026">
<document-id>
<country>WO</country>
<doc-number>WO0050872</doc-number>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00027">
<othercit>Mahmood et al., “Near-Infrared Optical Imaging of Protease Activity for Tumor Detection”, Radiology, Dec. 1999, p. 866-870.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00028">
<othercit>Weissleder et al., “Shedding Light onto Live Molecular Targets”, Nature Medicine, vol. 9, No. 1, Jan. 2003, p. 123-1218.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00029">
<othercit>Hamamatsu Corporation, USA, website, http://usa.hamamatusu.com/ pp. 1-4, Apr. 27, 2001, printed on Apr. 27, 2001.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00030">
<othercit>Hamamatsu, Imaging Box Instruction Manual, 55310-224-1, Nov. 2000.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00031">
<othercit>VetEquip Incorporated website, http://vetequip.com/1806.htm Table Top Laboratory Animal Anesthesia System, Apr. 27, 2001, printed on Apr. 27, 2001.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00032">
<othercit>VetEquip Incorporated website, http://www.vetequip.com/impac.htm IMPAC<sub>6 </sub>An anesthesia system designed for high volume, assembly-line type procedures, Apr. 27, 2001, printed on Apr. 27, 2001.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00033">
<othercit>VetEquip incorporated website, http://www.vetequip.com/1807.htm Mobile Laboratory Animal Anesthesia System, Apr. 27, 2001, printed on Apr. 27, 2001.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00034">
<othercit>The FDA's final rule on electronic signatures and electronic records means to designers and users of automation systems—http://www.che.chalmers.se/acs-lv-97/cinf-59.html (Downloaded Nov. 15, 1999).</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00035">
<othercit>Collaborative Electronic Notebook Systems Association http://www.censa.org/, Downloaded Nov. 15, 1999).</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00036">
<othercit>Electronic Notebooks http://labautomation.org/la/la2000/Courses/LA2000eln.htm (discussion of electronic notebooks available prior to Nov. 15, 1999).</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00037">
<othercit>E.C. Di Mauro, et al. “Check” A generic and specific industrial inspection tool, IEE Proceedings: Vision, Image and Signal Processing, Institution of Electrical Engineers, GB, vol. 143, No. 4, Aug. 1, 1996, pp. 241-249, XP000627046, ISSN: 1350-245X.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>41</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>715700</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715764</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715781</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715840</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715856</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715823</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345582</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345586</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345619</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345620</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345622</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>10</number-of-drawing-sheets>
<number-of-figures>11</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>09439381</doc-number>
<kind>00</kind>
<date>19991115</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>6614452</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>10458579</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20030193517</doc-number>
<kind>A1</kind>
<date>20031016</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Cable</last-name>
<first-name>Michael D.</first-name>
<address>
<city>Danville</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Beyer Weaver LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Xenogen Corporation</orgname>
<role>02</role>
<address>
<city>Alameda</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Kincaid</last-name>
<first-name>Kristine</first-name>
<department>2174</department>
</primary-examiner>
<assistant-examiner>
<last-name>Ke</last-name>
<first-name>Peng</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A graphical user interface is provided which allows the user to perform numerous operations suitable for analysis of in-vivo images within a single display screen or a single window. Using the the-vivo GUI, the user may create and manipulate analysis tools such as rectangle and ellipse tools to define regions of interest and perform various measurements on an in-vivo image. In addition, the GUI allows the user to store measurement results in a dated electronic notebook, display testing information, manipulate image presentation and print while maintaining view of the image.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="194.23mm" wi="172.64mm" file="US07299420-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="153.50mm" wi="167.47mm" file="US07299420-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="234.78mm" wi="115.82mm" file="US07299420-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="213.95mm" wi="173.82mm" file="US07299420-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="251.54mm" wi="177.88mm" file="US07299420-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="251.97mm" wi="171.87mm" orientation="landscape" file="US07299420-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="248.07mm" wi="165.61mm" orientation="landscape" file="US07299420-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="242.74mm" wi="171.45mm" orientation="landscape" file="US07299420-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="207.94mm" wi="173.06mm" file="US07299420-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="173.82mm" wi="141.48mm" orientation="landscape" file="US07299420-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="253.58mm" wi="187.11mm" file="US07299420-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This is a continuation application of prior-filed non-provisional U.S. patent application Ser. No. 09/439,381, entitled “GRAPHICAL USER INTERFACE FOR IN-VIVO IMAGING”, filed on Nov. 15, 1999 now U.S. Pat. No. 6,614,453, from which priority is claimed and which is hereby incorporated by reference.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The present invention relates generally to user interface software running on computers or computer systems. More specifically, the invention relates to user interface systems and methods used in examining and analyzing images.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">In a computer application, there are numerous ways to present user information. Graphical user interfaces (GUIs) on computer systems allow easy use of windows, control icons, etc. to display information to the user. The data displayed in a window may be of different types. Some may be graphical, such as icons or pictures, or textual, such as a word processing document, or a combination of both.</p>
<p id="p-0005" num="0004">When a computer interface is used for data management in a scientific application, the interface may include various data-specific tools and functions. To handle images, for example, an application might desirably present one or more windows for viewing the image, a tool for changing the image's appearance (e.g., sharpness), and a tool to measure features of one or more images.</p>
<p id="p-0006" num="0005">Unfortunately, the unique combination of functionality required for many imaging applications is not provided in a simple and easy to use computer interface. Specifically, available user interfaces, even those developed to handle imaging applications, do not provide a suite of particular image presentation and analysis tools that allow users to manipulate and measure image features with minimal navigation through the user interface.</p>
<p id="p-0007" num="0006">Interfaces for available applications typically require that the user first select or open various windows, menus, buttons, and/or tiles and then and then manipulate the resulting tool to implement a single operation pertinent to image analysis. Because the user may be required to perform numerous operations for a single image, or handle numerous images simultaneously, the available user interfaces are generally very awkward or unwieldy. Obviously this compromises user efficiency and effectiveness in evaluating images.</p>
<p id="p-0008" num="0007">Specialized in-vivo imaging applications can present particular challenges to the design of an appropriate user interface. In one example, the image may include one or more representations of emissions from internal portions of a specimen superimposed on a photographic representation of the specimen. The photographic representation provides the user with a pictorial reference of the specimen. The luminescence representation indicates portions of the specimen where an activity of interest may be taking place. For example, the in-vivo data may include light emissions from specific regions of the specimen used in tracking the progression of tumor or a pathogen within the specimen.</p>
<p id="p-0009" num="0008">In view of the foregoing, an improved user interface for imaging applications would be highly beneficial.</p>
<heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0010" num="0009">The present invention addresses this need by providing a computer user interface having a window or other feature that provides tools allowing the user to quickly define a perimeter around a “region of interest” on the image and then measure a property of the image within the region of interest. The region of interest may be bounded by an ellipse, rectangle, or other shape selected and sized by the user. Preferably, both the image and the tool for generating the region of interest reside on the same window or other interface feature. Thus, a region of interest can be generated with one or two user interface actions (e.g., clicking on a button and then dragging a perimeter to an appropriate location on the image to specify the region of interest). The property measured within the region of interest may be an average or total pixel value within the region of interest.</p>
<p id="p-0011" num="0010">In accordance with one embodiment of the present invention, a computer system is provided with an image measurement window, which allows the user to perform certain operations that are particularly useful for presenting and analyzing an image. In addition to having conventional computer hardware such as a processor, memory, and a display, the computer system includes a graphical user interface having a measurement window that provides both the image itself and one or more tools for defining a region of interest on the image. When a user uses one of the tools to define a region of interest, the computer system can calculate information about a portion of the image within the defined region of interest. By providing various frequently used features in a single window, interfaces of this invention remove the need to flip between alternate windows to take advantage of these features.</p>
<p id="p-0012" num="0011">Among the other features that may be provided with the image measurement window is a measurement tool. When this tool is selected, the computer system automatically calculates the information about the portion of the image when the user uses one of the tools to define the region of interest on the image. The measurement window may also include display controls for controlling at least one the following features of the displayed image: threshold, brightness, contrast, and sharpness.</p>
<p id="p-0013" num="0012">In a preferred embodiment, the one or more tools for defining the region of interest allows the user to graphically create a rectangle on the image, an ellipse on the image, and/or a grid on the image. At least one of these tools may be provided as a button which, when selected, causes a region of interest to appear on the displayed image. After the region of interest is created on the image, the user can move and/or reshape the region of interest by the action of the pointer.</p>
<p id="p-0014" num="0013">In addition, the present invention may provide a date stamped electronic notebook in conjunction with the image measurement window. The electronic notebook may display image analysis data (typically text pertaining to the image) such as measurement results, experimental parameters, user notes, and the like. The computer system may automatically display and date stamp image measurement results obtained via the user interface.</p>
<p id="p-0015" num="0014">In another aspect of the present invention provides a user interface for presenting and analyzing an image including a photographic representation of an object and a luminescence representation of the object. The luminescence representation presents the location and magnitude of radiation emitted from the object. The user interface may be characterized by the following features: (1) a first display control permitting a user to manipulate the visual presentation of at least one of the luminescence representation and the photographic representation; (2) a second display control permitting the user to create at least one region of interest on the luminescence representation; and (3) a third display control permitting the user to make a measurement of a portion of the luminescence representation bounded by the at least one region of interest. Other display controls of the user interface may include a fourth display control that permits the user to select which of the photographic representation and the luminescence representation is to be displayed. An optional fifth display control allows the user to print some portion or all of the image.</p>
<p id="p-0016" num="0015">Yet another aspect of the present invention relates to a method implemented on a computer system. The method includes analyzing a region of interest on an image presented on a display associated with the computer system. This includes defining a region of interest on the image when the user has selected a region of interest tool from a user interface presented on the display. Note that the region of interest tool and the image are concurrently displayed on the display. The method further includes calculating a property of the image within the region of interest.</p>
<p id="p-0017" num="0016">Embodiments of the present invention further relate to a computer readable medium including instructions for applying the above mentioned interfaces and methods. These and other features of the present invention will be described in more detail below in the detailed description of the invention and in conjunction with the following figures.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0018" num="0017">The present invention is illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings and in which like reference numerals refer to similar elements and in which:</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an imaging apparatus suitable for capturing photographic and luminescence images in accordance with one embodiment of the present invention.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 2</figref> is a flowchart illustrating a method of capturing photographic and luminescence images using the imaging apparatus of <figref idref="DRAWINGS">FIG. 1</figref>, for example, in accordance with one embodiment of the present invention.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 3A</figref> is an illustration showing a graphical user interface having an overlay of a photographic representation and a luminescence representation of a specimen as well as various image manipulation, analysis and measurement tools.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 3B</figref> illustrates an electronic notebook page suitable for storing raw data and non-analysis information in accordance with one embodiment of the present invention.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIGS. 3C-E</figref> illustrate the automatic storage of analysis data and measurement results into an electronic notebook page in accordance with another embodiment of the present invention.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart illustrating a method of making measurements using the GUI of <figref idref="DRAWINGS">FIG. 3</figref> in accordance with one embodiment of the present invention.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 5</figref> illustrates an image capture graphical user interface suitable for controlling the imaging apparatus of <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIGS. 6A and 6B</figref> illustrate a computer system suitable for implementing embodiments of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0027" num="0026">In the following detailed description of the present invention, numerous specific embodiments are set forth in order to provide a thorough understanding of the invention. However, as will be apparent to those skilled in the art, the present invention may be practiced without these specific details or by using alternate elements or processes. In other instances well known processes, procedures, components, and circuits have not been described in detail so as not to unnecessarily obscure aspects of the present invention.</p>
<p id="p-0028" num="0027">In accordance with one embodiment of the present invention, a graphical user interface (GUI) is provided which allows the user to perform numerous operations suitable for image analysis within a single window. This removes the need to navigate between alternate windows in order to perform a specific image analysis function. Using the GUI of this invention, the user may create and manipulate analysis tools and perform a wide variety of measurements on complex images (such as in-vivo images) conveniently and efficiently. In addition, the present invention may allow the user to store measurement results in a dated electronic notebook, display testing information, manipulate the image presentation and print while maintaining view of the image.</p>
<p id="p-0029" num="0028">One preferred embodiment of this invention pertains to graphical user interfaces for presenting and analyzing “overlay” or “composite” images including a photographic image on which is overlaid an “emissions” image. The photographic and luminescence images are taken of the same object. In one application, the object is a biological specimen. The luminescence image is taken without using light sources other than the object itself. Luminescence from the object is recorded as a function of position to produce the luminescence image. One approach to generating such composite photographic/luminescence images is described in U.S. Pat. No. 5,650,135 issued to Contag et al. on Jul. 22, 1997. The entire disclosure of that patent is incorporated herein by reference.</p>
<p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. 1</figref> illustrates an imaging apparatus <b>100</b> suitable for capturing photographic and luminescence images in accordance with one embodiment of the present invention. The imaging apparatus <b>100</b> includes a camera <b>102</b> such as a digital camera mounted at the top of a light-tight specimen box <b>104</b>. The camera <b>102</b> is capable capturing photographic images (i.e., reflection based images) of a specimen <b>106</b>. In addition, the camera <b>102</b> is sensitive enough to capture luminescence images of the specimen <b>106</b>. Camera <b>102</b> may employ a charge coupled device (CCD), a photodiode array, a photogate array, or similar image capture device. To facilitate capturing photographic images, the imaging apparatus <b>100</b> includes lights <b>108</b>. The lights <b>108</b> may be turned on or flashed while capturing photographic images of the specimen <b>106</b> and turned off while capturing luminescence images. The specimen box <b>104</b> may include a movable specimen platform <b>107</b> and other alignment instruments, which facilitates image capture of the specimen <b>106</b>.</p>
<p id="p-0031" num="0030">The camera <b>102</b> is in electrical communication with a processing apparatus <b>110</b>. The processing apparatus <b>110</b> includes imaging hardware and other suitable processing hardware to permit processing of information obtained by the camera <b>102</b>. By way of example, the processing apparatus <b>110</b> may include an I/O card, image processing logic, and control logic for controlling operation of camera <b>102</b> during image capture. The logic in apparatus <b>110</b> may take the form of software, hardware or some combination thereof. The processing apparatus <b>110</b> also communicates with a display <b>112</b>. The display <b>112</b> presents the imaging information to the user. By way of example, the display <b>112</b> may be a monitor, which presents a image measurement GUI as outlined below.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 2</figref> is a flowchart illustrating a method of capturing photographic and luminescence images using the imaging apparatus of <figref idref="DRAWINGS">FIG. 1</figref>, for example, in accordance with one embodiment of the present invention. A process flow <b>200</b> begins with placing the specimen <b>106</b> to be imaged in the imaging device (<b>202</b>). The imaging apparatus <b>100</b> is then prepared for photographic capture of the specimen <b>106</b> (<b>204</b>). The preparation may include turning on the lights <b>108</b>, focusing the CCD camera <b>102</b>, positioning the specimen <b>106</b>, etc. After preparation, the photographic image is captured (<b>206</b>). In one imaging system suitable for use with the present invention, a ‘live mode’ is used in photographic capture of the specimen <b>106</b>. The live mode includes a sequence of photographic images taken frequently enough to simulate live video. Upon completion of photographic capture, the photographic image data is transferred to processing apparatus <b>108</b> (<b>208</b>). The processing apparatus may manipulate and store the photographic image data as well as present it on the display <b>112</b>.</p>
<p id="p-0033" num="0032">Subsequently, the imaging apparatus <b>100</b> is prepared for capturing a luminescence image (<b>210</b>). The preparation may include turning off the lights <b>108</b>, for example. When ready, the CCD camera <b>102</b> captures the luminescence image. The luminescence image data is transferred to the processing apparatus <b>108</b> (<b>212</b>). The processing apparatus may store and manipulate the luminescence image data as well as present it on the display <b>112</b> (<b>214</b>). The manipulation may also include overlaying the luminescence image with the photographic image and illustrating the two images together. This overlay image may then be the basis for user analysis (<b>216</b>).</p>
<p id="p-0034" num="0033">At this point, the user now has the components of a digital overlay image stored in the processing apparatus <b>110</b> including the luminescence image and the photographic image. The information contained in the digital overlay image may be analyzed and manipulated as desired. As explained, the photographic and luminescence representations provided by the imaging apparatus <b>100</b> and imaging interface of the present invention have a wide variety of applications.</p>
<p id="p-0035" num="0034">In one particular embodiment, the luminescence representation indicates the number of times each detector pixel has received a photon over a defined length of time. In other words, the luminescence representation may display magnitude values representing the photon counts at the individual detector pixels. Regions of the object emitting radiation (e.g., photons) will appear in the luminescence representation. The luminescence images may indicate the presence of a biocompatible entity, for example. The entity can be a molecule, macromoloecule, cell, microorganism, a particle or the like. Thus, an in-vivo analysis may include detecting localization of a biocompatible entity in a mammalian subject. Alternatively, the information in the live mode may be used to track the localization of the entity over time. For more examples of analysis applications for a digital overlay image suitable for use with the present invention, the reader is referred to in U.S. Pat. No. 5,650,135, which was previously incorporated by reference.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. 3A</figref> illustrates one example of an image control/measurement window <b>300</b> in accordance with this invention. The image control window <b>300</b> includes an image measurement window <b>301</b>. Within the image measurement window <b>301</b>, an overlay image <b>302</b> is displayed. The overlay image <b>302</b> includes a visual superposition of a photographic representation of the specimen <b>106</b> and a luminescence representation of the specimen <b>106</b>. In this example, the specimen comprises three mice. The image control window <b>300</b> is well suited for manipulating the display of the overlay image <b>302</b> as well as making measurements and analyzing the luminescence representation.</p>
<p id="p-0037" num="0036">The photographic representation provides the user with a visual frame of reference of the image. The luminescence representation provides photon emission data derived from the object. As mentioned, the photon emission data may represent the specific pixels on the CCD camera <b>102</b> that detect photons over the duration of the live mode image capture period. Because the imaging apparatus <b>100</b> is typically used to measure the entire specimen <b>106</b>, the data in the luminescence representation typically has one or more distinct luminescent portions of interest. For example, the luminescence representation includes luminescent portions <b>308</b> and <b>310</b>.</p>
<p id="p-0038" num="0037">Although the image control window <b>300</b> displays an overlay image <b>302</b> comprised of two separate representations, most data manipulation and analysis of interest is performed on the luminescence representation. In particular, an analysis may include a summation of the illumination magnitudes over the pixels within a portion of the luminescence representation. Note that although the discussion will focus on a single luminescence representation for the overlay image <b>302</b>, the image control window <b>300</b> may include multiple luminescence representations taken at different times.</p>
<p id="p-0039" num="0038">In the illustrated embodiment, image control/measurement window <b>300</b> includes a control panel <b>312</b>. The control panel <b>312</b> includes a plurality of user interface control components for facilitating manipulation and analysis of information in the image measurement window <b>301</b>. To facilitate discussion, the user interface control components may be grouped into functional sections within the control panel <b>312</b>. As illustrated, the control panel <b>312</b> includes a display function section <b>314</b>, a create function section <b>316</b> and a measurement function section <b>318</b>. Other arrangements, with or without a “control panel” are contemplated. The display function section <b>314</b> includes controls for allowing the user to manipulate the presentation of the photographic representation and the luminescence representation. To manipulate the presentation of the photographic representation, the display function section <b>314</b> includes a brightness setting <b>320</b>. The brightness setting <b>320</b> is used for improving the user's visual perception of the photographic representation by allowing adjustment of the photograph's brightness. In alternative embodiments, other controls on a photographic image such as contrast, sharpness, and the like may be provided.</p>
<p id="p-0040" num="0039">To manipulate the presentation of the luminescence representation, the display function section <b>314</b> includes an upper luminescence limit <b>322</b> and a lower luminescence limit <b>324</b>. The upper luminescence limit <b>322</b> allows the user to designate the maximum data value displayed in the luminescence representation. Any pixels within the luminescence representation having a data value (e.g., a photon count) at or over this upper luminescence limit <b>322</b> will be displayed with a color corresponding to the upper luminescence limit <b>322</b>. Similarly, the lower luminescence limit <b>324</b> allows the user to designate the minimum data value displayed in the luminescence representation. Any pixels within the luminescence representation having a data value below this lower luminescence limit <b>324</b> will not be displayed. Those pixels having a data value at the lower luminescence limit will be displayed with a color corresponding to the lower luminescence limit. Thus, the upper and lower luminescence limits specify the range of pixel illumination values over which the full range of display colors will be vary. The upper luminescence limit <b>322</b> and the lower luminescence limit <b>324</b> may be useful when the user wants to selectively clear the image of outlying data for a particular analysis. Alternatively, the lower luminescence limit <b>324</b> may be useful when the user wants to clear the image of noise.</p>
<p id="p-0041" num="0040">The display function section also includes a global setting <b>326</b>. The global setting <b>326</b> provides a default option for the presentation of the luminescence representation. Specifically, the global setting sets the upper luminescence limit <b>322</b> and lower luminescence limit <b>324</b> to specified values. In a preferred embodiment, the upper luminescence limit <b>322</b> and lower luminescence limit <b>324</b> are set to the ‘full range’ of values for the luminescence representation. In other words, the upper limit is set to the value of the maximum intensity measured for any pixel in the luminescence representation and the lower limit is set to the value of the minimum intensity measured for any pixel in the luminescence representation. Alternatively, another preset option may set the upper luminescence limit <b>322</b> and lower luminescence limit <b>324</b> to a standardized range of values for the luminescence representation. For example, the standardized range may set the upper luminescence limit <b>322</b> at 95% of the maximum photon count for the luminescence representation and the lower luminescence limit <b>324</b> at 5% of the maximum photon count. Alternatively, another standardized range may be based on a statistical analysis, such as the standard deviation, of the range of data values for the luminescence representation.</p>
<p id="p-0042" num="0041">Often, it is desirable to calibrate the photographic representation and the luminescence representation to a blank view of the light-tight specimen box <b>104</b> without the specimen <b>106</b>. The image for an blank view of the light-tight specimen box <b>104</b> without the specimen <b>106</b> is often referred to as a ‘dark image’. The dark image may indicate inherent defects in a solid state camera, which defects should be subtracted from images taken with the camera. For example, the dark image may show contain bright spots corresponding to camera pixels having a high leakage current. To allow correction for such defective pixels, the display function section <b>314</b> may include a background compensation tool <b>325</b>. When a user selects the background compensation tool <b>325</b>, the computer system alters the photographic representation and the luminescence representation to compensate for any information associated with the dark image.</p>
<p id="p-0043" num="0042">The create function section <b>316</b> includes controls for allowing the user to create and manipulate tools which enable simple and flexible analysis of the data within the image measurement window <b>301</b>. In the specific embodiment depicted, the create function section <b>316</b> includes a create button <b>326</b>. The create button <b>326</b> allows the user to create a region of interest (ROI) with one action on the interface. For example, the user simply clicks on button <b>326</b> with a pointer and a new ROI appears in the image measurement window. The ROI may be any geometric shape or tool for measuring and analyzing data in a portion or portions of the luminescence representation. To facilitate generation of ROIs, the create function section <b>316</b> includes a pop-up menu <b>327</b>. The pop-up menu <b>327</b> includes a number of ROIs commonly used for image analysis. For example, the create button <b>326</b> and pop-up menu <b>327</b> may allow the user to create an ellipse (circle) <b>328</b>, a rectangle (square) <b>330</b> or a grid <b>332</b>. Upon creating an ROI, a label may be attached to the geometric outline of the ROI for user clarity. In <figref idref="DRAWINGS">FIG. 3A</figref>, for example, a label <b>334</b> is attached to circle <b>328</b>.</p>
<p id="p-0044" num="0043">To manage multiple ROIs, the create function section <b>316</b> includes a designation pop-up menu <b>335</b>. The designation pop-up menu <b>335</b> lists and numbers the ROIs as they are created. In addition, the designation pop-up menu <b>335</b> allows the user to re-access previously created ROIs that were previously numbered and stored. Typically, the ROI currently being accessed by the user is indicated to the user via highlights <b>336</b>. The create function section <b>316</b> also includes a remove tool <b>337</b>. The remove tool <b>337</b> allows the user to delete any or all of the ROIs stored in the designation pop-up menu <b>336</b>. The remove tool <b>337</b> may also include a pop-up menu <b>338</b> for convenience in deleting the ROIs.</p>
<p id="p-0045" num="0044">The image control window <b>300</b> also allows the user to manipulate the ROIs. Thus, after the circle <b>328</b> is dragged to its desired position, the size, shape, position and orientation of the circle <b>328</b> may be altered. For example, the orthogonal axis of the circle <b>328</b> may be altered to form an ellipse. The ellipse may then characterized by a major axis and a minor axis. Similarly, the dimensions of the square <b>330</b> may be altered to form a rectangle. The manipulation of the ROIs may further include rotations, expansions, etc. In one embodiment, the dragging of an ROI is done by clicking a pointer <b>344</b> on a portion of the circle <b>328</b>. Alternatively, the reshaping of an ROI may be performed by clicking the pointer <b>344</b> on one of the highlights <b>346</b> and dragging. In another embodiment, the manipulation and alterations of the ROIs may include keyboard input.</p>
<p id="p-0046" num="0045">While the image control window <b>300</b> only shows three ROI options, there are a large number of alternative ROI configurations which may be implemented. By way of example, the ROI options may be include a free-hand drawing option, polygons of five or more sides, curve drawing options, and the like. In the free-hand drawing option, the user marks a series of points, which then form a perimeter of a closed ROI. Using the created ROIs, the user may then proceed to use one or more of the ROIs to measure and analyze data.</p>
<p id="p-0047" num="0046">The measurement function section <b>318</b> includes GUI controls for allowing the user to measure and analyze data within the image measurement window <b>301</b>. The illustrated measurement function section <b>318</b> includes a measure button <b>348</b>. The measure command allows one or more functions for analysis of the data in the luminescence representation. By way of example, one function may be summation of all the pixel magnitudes within the perimeter of one or more of the ROIs. Another function may include an average of the magnitudes over the area within an ROI. Yet another function may also be a statistical analysis of the data within one or more of the ROIs.</p>
<p id="p-0048" num="0047">To increase measurement flexibility, the measurement function section <b>318</b> includes a measurement designation pop-up menu <b>350</b>. The measurement designation pop-up menu <b>350</b> enables the user to specify which of the created ROIs stored in the designation pop-up menu <b>335</b> are to be included in a measurement. Correspondingly, the user may specify any or all of the previously created ROIs for a particular measurement.</p>
<p id="p-0049" num="0048">The measurement function section <b>318</b> also includes a record option <b>352</b>. The record option <b>352</b> allows the user to store the data produced from the measure command <b>348</b>. In one embodiment, the data is stored in an electronic notebook. The electronic notebook is an on-line tool which allows testing results and information to be stored automatically and will be described further with respect to <figref idref="DRAWINGS">FIG. 3B</figref>.</p>
<p id="p-0050" num="0049">The image control window <b>300</b> also includes numerous other user interface tools. For example, a global display tool <b>354</b> is included to allow the user to control which representations are displayed in the measurement window <b>301</b>. More specifically, the user may select the overlay image <b>302</b> including the visual superposition of the photographic representation and the luminescence representation. Alternatively, using the global display tool <b>354</b>, the user may select just one of the photographic representation and the luminescence representation. The global display tool <b>354</b> may also allow the user to select between numerous luminescence representations stored for the photographic representation. The global display tool <b>354</b> typically has a default setting when a data file is accessed. For the image control window <b>300</b>, the default setting is the overlay image <b>302</b> comprising the photographic representation and one luminescence representation.</p>
<p id="p-0051" num="0050">On the right side of the image control window <b>300</b> is a luminescence image display section <b>358</b>. The luminescence image display section <b>358</b> includes a number of components to assist in viewing and comprehension of the luminescence representation. The luminescence image display section <b>358</b> includes an image maximum <b>360</b> and an image minimum <b>362</b>. The image maximum <b>360</b> indicates the magnitude of the highest data value (photon count) for any pixel in the luminescence representation. The image minimum <b>362</b> indicates the magnitude of the lowest data value (photon count) for any pixel in the luminescence representation. The difference between the image maximum <b>360</b> and the image minimum <b>362</b> corresponds to the full range of pixel magnitudes for the luminescence representation.</p>
<p id="p-0052" num="0051">The luminescence image display section <b>358</b> also includes a legend maximum <b>364</b> and legend minimum <b>366</b>. The legend maximum <b>364</b> indicates the magnitude of the maximum data value (photon count) for the image measurement window <b>301</b>. In other words, the legend maximum <b>364</b> corresponds to the upper luminescence limit <b>322</b>. The legend minimum <b>366</b> indicates the magnitude of the minimum data value for the image measurement window <b>301</b>, similarly corresponding to the lower luminescence limit <b>324</b>. Thus, if the full range is selected in the global setting <b>326</b>, the legend maximum <b>364</b> and the legend minimum <b>366</b> may correspond to the image maximum <b>360</b> and the image minimum <b>362</b>. The legend maximum <b>364</b> indicates the magnitude of the highest data value (photon count) in the luminescence representation that will be displayed with the highest intensity color (e.g., red). Any pixels having an intensity magnitude of greater than or equal to the highest data value will be given the highest intensity color. The legend minimum <b>366</b> indicates the magnitude of the lowest data value (photon count) in the luminescence representation that will be displayed with the lowest intensity color (e.g., blue).</p>
<p id="p-0053" num="0052">Included in the image display section <b>358</b> is a scale <b>364</b>. The scale <b>364</b> provides a visual mapping between a range of colors for the luminescence representation and the magnitude range specified at <b>322</b> and <b>324</b>. For the image control window <b>300</b>, the scale may be represented by a gray scale and thus individual magnitudes correspond to shades of gray or by color and thus the magnitude indicator correspond to different colors.</p>
<p id="p-0054" num="0053">The image control window <b>300</b> also includes a user information section <b>370</b>. The user information section <b>370</b> provides testing information for the overlay <b>302</b>, which may be helpful to the user. The testing information may include, for example, a user ID <b>371</b>, a test classification <b>372</b>, a testing reference number <b>373</b>, a date <b>374</b>, a label <b>375</b> and a comments field <b>376</b>.</p>
<p id="p-0055" num="0054">A print button <b>356</b> is also included and allows the user to conveniently print portions of the image control window <b>300</b>. Typically, the print button <b>356</b> employs a default setting corresponding to preferred use. For the image control window <b>300</b>, the default setting automatically prints the image measurement window <b>301</b>, the luminescence image display section <b>358</b> and the user information section <b>370</b>. Alternatively, the print command <b>356</b> may introduce a settings window to set the default print options.</p>
<p id="p-0056" num="0055">Although the present invention has been discussed primarily in the context of manipulating simple two-dimensional images, the analysis tools and methods of the present invention are also suitable for more complicated applications. By way of example, to compensate for different sized specimens or images at varying depths, the imaging apparatus <b>100</b> may take alternate luminescence images of the specimen <b>106</b>. More specifically, to overcome dependency on the depth of the image, different wavelengths may be used in capturing the luminescence image.</p>
<p id="p-0057" num="0056">As mentioned previously, the present invention may implement an electronic notebook. The electronic notebook allows the user to automatically store analysis data, ROI settings, measurement results and conveniently perform other useful note taking functions. <figref idref="DRAWINGS">FIG. 3B</figref> illustrates an electronic notebook page <b>380</b> in accordance with one embodiment of the present invention. In this case, the notebook page <b>380</b> appears as a separate window to the side of the image control window <b>300</b>.</p>
<p id="p-0058" num="0057">The electronic notebook page <b>380</b> may automatically store information corresponding to the overlay image <b>302</b> upon instantiation. By way of example, the electronic notebook page <b>380</b> may be instantiated when the user initially loads an image. In this case, image capture information will be entered first. Alternatively, the electronic notebook page <b>380</b> may be instantiated when the user creates an ROI for the first time or inputs any information, which is relevant to an analysis of the luminescence representation. In addition, if the overlay image <b>302</b> is accessed from memory, the electronic notebook page <b>380</b> may be instantiated as last saved.</p>
<p id="p-0059" num="0058">In one embodiment, the electronic notebook page <b>380</b> solely contains reference information corresponding to the overlay image <b>302</b> and does not include analysis information and results. In this case, the electronic notebook page <b>380</b> is referred to as a ‘raw data’ page. The electronic notebook page <b>380</b> may include a header <b>382</b>. The header contains classification information for the overlay image <b>302</b> such as the testing reference number <b>373</b>. The electronic notebook page <b>380</b> may also include a user input section <b>384</b>. The user input section <b>384</b> may include, for example, the user ID <b>371</b>, test classification <b>372</b>, the label <b>375</b> and comments field <b>376</b> corresponding to the user information section <b>370</b> of the image control window <b>300</b>. Alternatively, the user may enter information into the notebook page <b>380</b> as desired.</p>
<p id="p-0060" num="0059">The electronic notebook page <b>380</b> may also include other information used in characterizing data or an image. For example, a photographic image section <b>386</b> includes information relevant to the settings used for photographic image capture using the imaging apparatus <b>100</b>. In addition, an luminescence image section <b>388</b> includes information relevant to the settings used for luminescence image capture using the imaging apparatus <b>100</b>.</p>
<p id="p-0061" num="0060">For user convenience, the electronic notebook page <b>380</b> may be saved in a database which stores all the raw data files and corresponding image files in a common directory. In one embodiment, this database for raw data files is referred to as a ‘raw data set’. More specifically, the database may be arranged such that a text file is associated with each image file in the data set. The text file may contain information about the image captured. By way of example, the image information may include the time the image was taken, the camera settings (i.e. the exposure length), image identification numbers, labeling information entered by the user when the image was taken. In addition, each photographic representation and luminescence representation may have its own file in the raw data set.</p>
<p id="p-0062" num="0061">Preferably, the file formats used in the raw data set are generic to increase application flexibility. By way of example, the photographic representation and luminescence representation may be saved in a TIFF format to allow access from a wide variety of software packages. Similarly, each text file may be saved as an ASCII text file to allow flexible access. Thus, a raw data database may be established which is generic and easily accessible.</p>
<p id="p-0063" num="0062">In another embodiment, an electronic notebook page may contain information that includes analysis settings and measurement results. <figref idref="DRAWINGS">FIGS. 3C-E</figref> illustrate the automatic storage of analysis data and measurement results into an electronic notebook page <b>390</b> in accordance with another embodiment of the present invention. In this case, the electronic notebook page <b>390</b> is referred to as a ‘analyzed data’ page. In a preferred embodiment, the electronic notebook automatically stores the analysis data <b>382</b> obtained from the measure command <b>348</b> when the record option <b>352</b> is selected. Storing the analysis data provides the user a convenient mechanism to access the analysis data at a subsequent time. The analysis data may include the characteristic geometric information of the ROIs as well as the results of any measurements using the ROIs.</p>
<p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. 3C</figref> illustrates the electronic notebook page <b>390</b> before analysis information is entered. In this case, the header <b>391</b> includes a testing reference <b>398</b> and file references <b>392</b>. The testing reference <b>398</b> includes the analysis date in the first six numerical digits, the user name and may also include other testing information. In one embodiment, the electronic notebook page <b>390</b> automatically records an automatic date stamp in which an analysis was performed in the testing reference <b>398</b>. The automatic date stamp may be advantageous in the future for verifying the date of analysis and testing. In one embodiment, the automatic date stamp is subsequently unalterable to further strengthen subsequent validation. The file references <b>392</b> refer to data files which includes the loading information of the photographic representation and the luminescence representation. The file references <b>392</b> may also include the information relevant to the settings used for photographic and luminescence image capture using the imaging apparatus <b>100</b>.</p>
<p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. 3D</figref> illustrates the electronic notebook page <b>390</b> after an analysis using three ROIs <b>393</b>. For each ROI, its characteristic geometric information <b>394</b> regarding the perimeter of the ROI is automatically stored in the electronic notebook page <b>390</b>. In addition, results <b>395</b> for the measurement within each ROI <b>393</b> are automatically stored. Further, total measurement results <b>396</b> for all three ROIs are automatically stored. <figref idref="DRAWINGS">FIG. 3E</figref> illustrates the electronic notebook page <b>390</b> prior to exiting the image control window <b>300</b>.</p>
<p id="p-0066" num="0065">At this point, filing information <b>397</b> may be stored prior to closing of the electronic notebook page <b>390</b> (<figref idref="DRAWINGS">FIG. 3E</figref>). In addition, the electronic notebook page <b>390</b> allows the user to make notes and input additional analysis information at any time. Preferably this is accomplished by simply placing the cursor/pointer at the desired location within the electronic notebook and typing in the notes of interest. By way of example, statistical information for the luminescence representation such as a number of pixels <b>398</b> in the ROIs, area sums <b>399</b> and standard deviation, etc. may be stored if they are not included in the automatic transfer of information from the image control window <b>300</b>. Alternatively, luminescence representation information such as the image maximum <b>360</b>, image minimum <b>362</b> and average data value per pixel may be stored in the electronic notebook page <b>390</b>. Broadly speaking, the electronic notebook page <b>390</b> may store any information relevant to re-creating a measurement or analysis.</p>
<p id="p-0067" num="0066">In addition to the raw data set, a directory may be maintained for the electronic notebook page <b>390</b> and similar other analyzed data files. In one embodiment, this analyzed file directory is referred to as an ‘analyzed data set’. Thus, two databases may be maintained: the first containing raw data and the second containing analyzed data. In one embodiment, the files stored in the analyzed data set will contain information about the photographic representation, the luminescence representation and the text file corresponding to the analyzed data all in one file. The file may be any such format which allows these pictorial and text components. By way of example, the file may be a Living Image file suitable for use with the Living Image Software.</p>
<p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart representative of an exemplary data analysis using the image control window <b>300</b>. A process flow <b>400</b> typically begins with accessing a data file (<b>402</b>). Accessing the data file may include opening a data file previously stored in memory. Alternatively, the data file may be accessed from an image recently captured by the imaging apparatus <b>100</b>, without opening a stored file.</p>
<p id="p-0069" num="0068">After the image measurement window <b>301</b> for the data file is displayed (<b>404</b>), the user may alter the photographic representation and the luminescence representation using any of the tools in the display function section <b>314</b> (<b>406</b>). By way of example, the user may alter the upper luminescence limit <b>322</b> and lower luminescence limit <b>324</b> to facilitate viewing clarity and comprehension of the image. For an initial use of an image, the user may also enter details in the user information section <b>370</b>. In addition, the user may proceed to further alter the image display (<b>408</b>). By way of example, the user may alter the luminescence limit <b>322</b> and lower luminescence limit <b>324</b> to facilitate viewing clarity of a particular portion of the luminescence representation to be analyzed.</p>
<p id="p-0070" num="0069">Upon determining which portion or portions of the luminescence representation are to be analyzed, the user may then create one or more ROIs (<b>410</b>). After the corresponding ROIs are generated, the user may alter the generic ROIs for a particular analysis (<b>412</b>). More specifically, the user may manipulate the position, shape and angle of rotation of one or more created RIOs. Upon completion of ROI manipulation, the user may then perform a measurement within one or more of the ROIs (<b>414</b>). In a preferred embodiment, the measurement involves taking a summation of the photon counts for each of the pixels within the perimeter of one or more ROIs. The results of the measurement may then be transferred to the electronic notebook page <b>390</b> (<b>416</b>).</p>
<p id="p-0071" num="0070">The user may then continue (<b>418</b>) to make measurements on the same or different portions oft he luminescence representation using the image control window <b>300</b>. Correspondingly, the user may return to alter the image display for another measurement (<b>408</b>), create more ROIs (<b>410</b>) or manipulate the existing ROIs (<b>414</b>). If the user is finished with analysis on the current image, then the user may save the work and exit (<b>420</b>). It should be noted that the flowchart <b>400</b> is one method of using the image control window <b>300</b> for analysis of the overlay image <b>302</b>. Obviously, many of the elements of the flowchart <b>400</b> may be repeated or performed outside of the order illustrated. By way of example, at any point the user may alter the image display to improve viewing (<b>408</b>), print the image control window <b>300</b> or make notes in the electronic notebook page <b>390</b> (<b>418</b>).</p>
<p id="p-0072" num="0071">The present invention may also include other user interface components outside of the image control/measurement window <b>300</b>. By way of example, <figref idref="DRAWINGS">FIG. 5</figref> illustrates an image capture GUI <b>500</b> suitable for controlling the imaging apparatus <b>100</b>. The image capture GUI <b>500</b> includes an imaging mode control section <b>502</b>. The imaging mode control section <b>502</b> allows the user to designate one or multiple images to be taken. The camera GUI interface <b>500</b> also provides the user with interfaces to control platform selection <b>504</b>, lights on/off <b>505</b>, set light strength <b>506</b> and set the exposure duration <b>508</b>. The camera GUI interface <b>500</b> may also include other functionality and tools useful in obtaining an image with the imaging apparatus <b>100</b> not shown in <figref idref="DRAWINGS">FIG. 5</figref>. By way of example, the camera GUI interface <b>500</b> may also include control for manipulating the photon threshold for registering a pixel in the luminescence representation. Correspondingly, the photon threshold may be used to reduce electronic noise when capturing the luminescence representation.</p>
<p id="p-0073" num="0072"><figref idref="DRAWINGS">FIGS. 6A and 6B</figref> illustrate a computer system <b>600</b> suitable for implementing embodiments of the present invention. <figref idref="DRAWINGS">FIG. 6A</figref> shows one possible physical form of the computer system. Of course, the computer system may have many physical forms ranging from an integrated circuit, a printed circuit board and a small handheld device up to a huge super computer. Computer system <b>600</b> includes a monitor <b>602</b>, a display <b>604</b>, a housing <b>606</b>, a disk drive <b>608</b>, a keyboard <b>610</b> and a mouse <b>612</b>. Disk <b>614</b> is a computer-readable medium used to transfer data to and from computer system <b>600</b>.</p>
<p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. 6B</figref> is an example of a block diagram for computer system <b>600</b>. Attached to system bus <b>620</b> are a wide variety of subsystems. Processor(s) <b>622</b> (also referred to as central processing units, or CPUs) are coupled to storage devices including memory <b>624</b>. Memory <b>624</b> includes random access memory (RAM) and read-only memory (ROM). As is well known in the art, ROM acts to transfer data and instructions uni-directionally to the CPU and RAM is used typically to transfer data and instructions in a bi-directional manner. Both of these types of memories may include any suitable of the computer-readable media described below. A fixed disk <b>626</b> is also coupled bi-directionally to CPU <b>622</b>; it provides additional data storage capacity and may also include any of the computer-readable media described below. Fixed disk <b>626</b> may be used to store programs, data and the like and is typically a secondary storage medium (such as a hard disk) that is slower than primary storage. It will be appreciated that the information retained within fixed disk <b>626</b>, may, in appropriate cases, be incorporated in standard fashion as virtual memory in memory <b>624</b>. Removable disk <b>614</b> may take the form of any of the computer-readable media described below.</p>
<p id="p-0075" num="0074">CPU <b>622</b> is also coupled to a variety of input/output devices such as display <b>604</b>, keyboard <b>610</b>, mouse <b>612</b> and speakers <b>630</b>. In general, an input/output device may be any of: video displays, track balls, mice, keyboards, microphones, touch-sensitive displays, transducer card readers, magnetic or paper tape readers, tablets, styluses, voice or handwriting recognizers, biometrics readers, or other computers. CPU <b>622</b> optionally may be coupled to another computer or telecommunications network using network interface <b>640</b>. With such a network interface, it is contemplated that the CPU might receive information from the network, or might output information to the network in the course of performing the above-described method steps. Furthermore, method embodiments of the present invention may execute solely upon CPU <b>622</b> or may execute over a network such as the Internet in conjunction with a remote CPU that shares a portion of the processing.</p>
<p id="p-0076" num="0075">In addition, embodiments of the present invention further relate to computer storage products with a computer-readable medium that have computer code thereon for performing various computer-implemented operations. The media and computer code may be those specially designed and constructed for the purposes of the present invention, or they may be of the kind well known and available to those having skill in the computer software arts. Examples of computer-readable media include, but are not limited to: magnetic media such as hard disks, floppy disks, and magnetic tape; optical media such as CD-ROMs and holographic devices; magneto-optical media such as floptical disks; and hardware devices that are specially configured to store and execute program code, such as application-specific integrated circuits (ASICs), programmable logic devices (PLDs) and ROM and RAM devices. Examples of computer code include machine code, such as produced by a compiler, and files containing higher level code that are executed by a computer using an interpreter.</p>
<p id="p-0077" num="0076">Although the present invention has been discussed primarily in the context of making measurements for the summation of photon counts within the image measurement window <b>301</b>, the present invention is suitable for other imaging applications and may be tailored correspondingly. By way of example, the present invention may be adapted for analysis of high detail in-vivo applications and thus may include zoom tools in the display function section <b>314</b>. Other applications may implement global image processing procedures well known in the image processing arts. For example, binning may be implemented to account for insufficient information per pixel. More specifically, the number of pixels in each direction of the luminescence representation may be halved to produce a new pixel array comprising the magnitude of four previous pixels in a single new pixel to improve statistical analysis. Although various details have been omitted for brevity's sake, obvious design alternatives may be implemented. Therefore, the present examples are to be considered as illustrative and not restrictive, and the invention is not to be limited to the details given herein, but may be modified within the scope of the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A computer system capable of displaying and analyzing an image, the computer system comprising:
<claim-text>one or more processors;</claim-text>
<claim-text>one or more user input devices;</claim-text>
<claim-text>a display capable of displaying the image and associated information in particular ways responsive to input signals from one or more of the input devices and signals from one or more of the processors, wherein the image comprises a photographic representation of an object superimposed with a light emitting representation of the object, the light emitting representation corresponding to the location and magnitude of electro-magnetic radiation emitted from the object; and</claim-text>
<claim-text>a graphical user interface running on one or more of the processors and providing, on a single display window, the image and one or more tools for defining a region of interest on the image, wherein when a user uses one of the tools to define a region of interest, the computer system can calculate information about a portion of the image within the defined region of interest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the display window includes a measurement tool which when selected causes the computer system to automatically calculate the information about the portion of the image when the user uses one of the tools to define the region of interest on the image.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the graphical user interface further provides on the single display window display controls for controlling at least one the following features of the displayed image: threshold, brightness, contrast, and sharpness.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more tools for defining the region of interest allow the user to graphically create at least one of a rectangle on the image, an ellipse on the image, and a grid on the image.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least one of the one or more tools is a button which, when selected, causes a region of interest to appear on the displayed image.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the graphical user interface further includes a pointer displayed on the display, and wherein the region of interest can be moved and reshaped by action of the pointer.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the light emitting representation includes in-vivo light emitting data from at least one mammalian specimen.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The computer system of <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein the display window includes a visual manipulation tool which permits the user to adjust threshold magnitudes of the light emitting data which will be displayed in the light emitting representation of the image.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The computer system of <claim-ref idref="CLM-00008">claim 8</claim-ref> wherein the visual manipulation tool permits the user to set an upper threshold magnitude and an lower threshold magnitude on the display of light emitting representation.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein each image pixel of the light emitting representation corresponds to photon counts emitted from a corresponding location of the object.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the light emitting representation includes data obtained from using a live mode.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the display window includes an electronic notebook space displaying text information pertaining to the image.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The computer system of <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein the electronic notebook page automatically stores information corresponding to the photographic representation and the light emitting representation.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. A method implemented on a computer system, the method analyzing a region of interest on an image presented on a display associated with the computer system, the method comprising:
<claim-text>defining a region of interest on the image by selecting a region of interest tool from a user interface presented on the display such that the region of interest tool and the image are concurrently displayed on the display, wherein the image comprises a photographic representation of an object superimposed with a light emitting representation of the object, the light emitting representation corresponding to the location and magnitude of electro-magnetic radiation emitted from the object; and</claim-text>
<claim-text>calculating a property of the image within the region of interest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein defining a region of interest comprises at least one of positioning and reshaping, in response to a user input, the region of interest on the image to define boundaries within which the property is calculated.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the region of interest is provided as at least one of a polygon, an ellipse, and a grid.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising adjusting, in response to a user input, at least one of the brightness, sharpness, and contrast of the image.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising displaying an electronic notebook on the display concurrently with the region of interest tool and the image, wherein the calculated property of the image within the region of interest is displayed in the electronic notebook.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, further comprising displaying in said electronic notebook details about an experiment or imaged object.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, further comprising date stamping information appearing in the electronic notebook when said information is added to the electronic notebook.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, further comprising displaying in said electronic notebook user notes about an experiment or imaged object.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein the light emitting representation includes in-vivo light emitting data from at least one mammalian specimen.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein each image pixel of the light emitting representation corresponds to photon counts emitted from a corresponding location of the object.</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. A computer program product stored on a computer readable storage media and comprising program instructions provided via the computer readable storage media, the program instructions comprising instructions for analyzing a region of interest on an image presented on a display associated with the computer system, the instructions specifying:
<claim-text>defining a region of interest on the image by selecting a region of interest tool from a user interface presented on the display such that the region of interest tool and the image are concurrently displayed on the display, wherein the image comprises a photographic representation of an object superimposed with a light emitting representation of the object, the light emitting representation corresponding to the location and magnitude of electro-magnetic radiation emitted from the object; and</claim-text>
<claim-text>calculating a property of the image within the region of interest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The computer program product of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein instructions for defining a region of interest comprises instructions for at least one of positioning and reshaping, in response to a user input, the region of interest on the image to define boundaries within which the property is calculated.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The computer program product of <claim-ref idref="CLM-00024">claim 24</claim-ref>, further comprising instructions for displaying an electronic notebook on the display concurrently with the region of interest tool and the image, wherein the calculated property of the image within the region of interest is displayed in the electronic notebook.</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the light emitting representation includes luminescent light emitting data.</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein the light emitting representation includes luminescent light emitting data.</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. A computer system capable of displaying and analyzing an image, the computer system comprising:
<claim-text>one or more processors;</claim-text>
<claim-text>one or more user input devices;</claim-text>
<claim-text>a display capable of displaying the image and associated information in particular ways responsive to input signals from one or more of the input devices and signals from one or more of the processors, wherein the image comprises a pictorial representation of an object superimposed with an internal light representation of the object, the internal light representation corresponding to the location and magnitude of electro-magnetic radiation emitted from the object; and</claim-text>
<claim-text>a graphical user interface running on one or more of the processors and providing, on a single display window, the image and one or more tools for defining a region of interest on the image, wherein when a user uses one of the tools to define a region of interest, the computer system can calculate information about a portion of the image within the defined region of interest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. The computer system of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the one or more tools for defining the region of interest allow the user to graphically create at least one of a rectangle on the image, an ellipse on the image, and a grid on the image.</claim-text>
</claim>
<claim id="CLM-00031" num="00031">
<claim-text>31. The computer system of <claim-ref idref="CLM-00029">claim 29</claim-ref> wherein the internal light representation includes a light emitting representation.</claim-text>
</claim>
<claim id="CLM-00032" num="00032">
<claim-text>32. The computer system of <claim-ref idref="CLM-00031">claim 31</claim-ref> wherein the light emitting representation includes luminescent data.</claim-text>
</claim>
<claim id="CLM-00033" num="00033">
<claim-text>33. The computer system of <claim-ref idref="CLM-00029">claim 29</claim-ref> wherein the pictorial representation includes a photographic representation.</claim-text>
</claim>
<claim id="CLM-00034" num="00034">
<claim-text>34. The computer system of <claim-ref idref="CLM-00029">claim 29</claim-ref> wherein the internal light representation includes in-vivo light emitting data from at least one mammalian specimen.</claim-text>
</claim>
<claim id="CLM-00035" num="00035">
<claim-text>35. The computer system of <claim-ref idref="CLM-00034">claim 34</claim-ref> wherein the internal light representation indicates where an activity of interest may be taking place in a mammalian specimen.</claim-text>
</claim>
<claim id="CLM-00036" num="00036">
<claim-text>36. A method implemented on a computer system, the method analyzing a region of interest on an image presented on a display associated with the computer system, the method comprising:
<claim-text>defining a region of interest on the image by selecting a region of interest tool from a user interface presented on the display such that the region of interest tool and the image are concurrently displayed on the display, wherein the image comprises a pictorial representation of an object superimposed with an internal light representation of the object, the internal light representation corresponding to the location and magnitude of electro-magnetic radiation emitted from the object; and</claim-text>
<claim-text>calculating a property of the image within the region of interest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00037" num="00037">
<claim-text>37. The method of <claim-ref idref="CLM-00036">claim 36</claim-ref> wherein defining a region of interest comprises at least one of positioning and reshaping, in response to a user input, the region of interest on the image to define boundaries within which the property is calculated.</claim-text>
</claim>
<claim id="CLM-00038" num="00038">
<claim-text>38. The method of <claim-ref idref="CLM-00036">claim 36</claim-ref> wherein the internal light representation includes a light emitting representation.</claim-text>
</claim>
<claim id="CLM-00039" num="00039">
<claim-text>39. The method of <claim-ref idref="CLM-00038">claim 38</claim-ref> wherein the light emitting representation includes luminescent light emitting data.</claim-text>
</claim>
<claim id="CLM-00040" num="00040">
<claim-text>40. The method of <claim-ref idref="CLM-00036">claim 36</claim-ref> wherein the pictorial representation includes a photographic representation.</claim-text>
</claim>
<claim id="CLM-00041" num="00041">
<claim-text>41. The method of <claim-ref idref="CLM-00036">claim 36</claim-ref> wherein the internal light representation indicates where an activity of interest may be taking place in a mammalian specimen.</claim-text>
</claim>
</claims>
</us-patent-grant>
