<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07299350-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07299350</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10051668</doc-number>
<date>20020117</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>691</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>L</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>713151</main-classification>
<further-classification>713153</further-classification>
<further-classification>713189</further-classification>
<further-classification>713160</further-classification>
<further-classification>710260</further-classification>
</classification-national>
<invention-title id="d0e53">Internet protocol security decryption with secondary use speculative interrupts</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5412782</doc-number>
<kind>A</kind>
<name>Hausman et al.</name>
<date>19950500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709250</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5802153</doc-number>
<kind>A</kind>
<name>Sridhar et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>375220</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5905874</doc-number>
<kind>A</kind>
<name>Johnson</name>
<date>19990500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709250</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6016513</doc-number>
<kind>A</kind>
<name>Lowe</name>
<date>20000100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709250</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6112252</doc-number>
<kind>A</kind>
<name>Hausman et al.</name>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709250</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6148082</doc-number>
<kind>A</kind>
<name>Slattery et al.</name>
<date>20001100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>380212</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6243787</doc-number>
<kind>B1</kind>
<name>Kagan et al.</name>
<date>20010600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710263</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6304911</doc-number>
<kind>B1</kind>
<name>Brcich et al.</name>
<date>20011000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709237</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6385727</doc-number>
<kind>B1</kind>
<name>Cassagnol et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>713193</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6715005</doc-number>
<kind>B1</kind>
<name>Rodriguez et al.</name>
<date>20040300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710 41</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6718413</doc-number>
<kind>B1</kind>
<name>Wilson et al.</name>
<date>20040400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710260</main-classification></classification-national>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>6754755</doc-number>
<kind>B1</kind>
<name>Johnson et al.</name>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>710262</main-classification></classification-national>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>WO</country>
<doc-number>WO 01/05086</doc-number>
<kind>A2</kind>
<date>20000700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
</citation>
</references-cited>
<number-of-claims>13</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>713150-154</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713200</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713162</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713189</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>713160</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>710260-264</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>710 22</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>710 25</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709230</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709250</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709224</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709220</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>709227</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>370469</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>712220</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>712221</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726 11</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726 12</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726 14</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726  2</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>726  3</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>380255</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>380260</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>380 37</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>380 42</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>4</number-of-drawing-sheets>
<number-of-figures>4</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20030135757</doc-number>
<kind>A1</kind>
<date>20030717</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Connor</last-name>
<first-name>Patrick L</first-name>
<address>
<city>Portland</city>
<state>OR</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Minnick</last-name>
<first-name>Linden</first-name>
<address>
<city>Hillsboro</city>
<state>OR</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Pillsbury Winthrop Shaw Pittman LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Intel Corporation</orgname>
<role>02</role>
<address>
<city>Santa Clara</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Vu</last-name>
<first-name>Kim</first-name>
<department>2135</department>
</primary-examiner>
<assistant-examiner>
<last-name>Patel</last-name>
<first-name>Nirav</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A system for improved decryption performance includes a computer in electronic communication with an encrypted network. A controller performs a decryption operation on an encrypted packet received from the network, and the computer asserts an interrupt prior to the system completing transfer of the decrypted packet back to host memory to reduce the additional latency a packet suffers during Secondary Use. An additional interrupt may be asserted after the Secondary Use operation is complete, to ensure that the Secondary Use packet is processed. A method for improving decryption performance similarly includes asserting an interrupt prior to the complete transfer of a decrypted packet from a controller back to host memory during Secondary Use. The method may further include asserting an additional interrupt after the Secondary Use operation is complete, to ensure that the Secondary Use packet is processed.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="157.65mm" wi="140.72mm" file="US07299350-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="180.17mm" wi="143.34mm" file="US07299350-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="188.13mm" wi="146.22mm" file="US07299350-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="213.61mm" wi="147.49mm" file="US07299350-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="186.94mm" wi="152.57mm" file="US07299350-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">1. Field of the Invention</p>
<p id="p-0003" num="0002">The present invention generally relates to encrypted networks. More particularly, the present invention relates to a system and method for improving the performance of an encrypted network by asserting interrupts to reduce latency that packets suffer during Secondary Use.</p>
<p id="p-0004" num="0003">2. Discussion of the Related Art</p>
<p id="p-0005" num="0004">Internet Protocol Security (“IPSec”) is employed to protect both the confidentiality and integrity of data that is transferred on a network. Because IPSec provides a way to encrypt and decrypt data below the transport layer (e.g., Transmission Control Protocol, “TCP” or User Datagram Protocol, “UDP”), the protection is transparent to applications that transfer data. Thus, no alterations are required at the application level in order to utilize IPSec. However, when implemented in software, the algorithms used for encryption, decryption, and authentication of the data for IPSec require execution of numerous CPU cycles. Because many CPU cycles must be delegated to such cryptography operations, there are correspondingly fewer CPU cycles available to applications and other parts of the protocol stack. This configuration adds latency to received data reaching the application, thereby decreasing the throughput of the system.</p>
<p id="p-0006" num="0005">One current solution to this problem is to offload the cryptography operations to an external piece of hardware, such as a Network Interface Card (“NIC”). Generally, the most efficient way to offload such operations is to encrypt the data immediately before transmitting a packet, and to decrypt the data directly off the network before the packet is direct memory access (“DMA”) transferred to host memory. This process of decrypting and authenticating ingress data before it is transferred to host memory is known as “Inline Receive.”</p>
<p id="p-0007" num="0006">An alternative to Inline Receive is the “Secondary Use” model. In this latter model, received packets are DMA transferred into host memory. The network driver then parses each packet to match it with its corresponding Security Association (“SA”), which is a data structure that contains all information necessary to encrypt, decrypt and/or authenticate a packet. Where a cryptography accelerator is included, the driver instructs the NIC to transfer the packet across the bus to the controller, perform the cryptography operation on the packet, and then transfer the packet back to host memory. The packet is thus transferred across the bus three times: (1) upon receipt from the network through the NIC across the bus and into host memory; (2) upon transfer from the host memory across the bus to the controller; and (3) upon transfer from the controller across the bus back to host memory.</p>
<p id="p-0008" num="0007">An extra interrupt is often required to perform these transfers across the bus. However, such interrupts increase CPU utilization. Furthermore, the extra latency introduced can degrade throughput of protocols that are sensitive to the round trip time of packets, such as TCP.</p>
<p id="p-0009" num="0008">From a performance perspective (both CPU utilization and throughput), Inline Receive is generally considered a better solution than Secondary Use. However, Inline Receive is more expensive to implement because the keys and matching information for cryptography operations must be stored on the network interface in an SA cache. Due to such limitations, the INTEL PRO/100 S Server Adapter, for example, supports only a limited number of connections that can use Inline Receive. Other connections use the Secondary Use model to offload secure traffic, though Secondary Use adds latency to packets at several steps. The primary source of the increased latency for Secondary Use is the delay related to the final interrupt of the Secondary Use operation.</p>
<p id="p-0010" num="0009">Early ingress interrupts have been used on low speed buses where the transfer operation was expensive. The device typically transfers the header portion of the packet to host memory and then assert an interrupt. The header portion is used to determine if there was interest in transferring the rest of the packet to host memory. If not, the rest of the packet would be discarded. This scheme avoided burdening the bus with unnecessary data.</p>
<p id="p-0011" num="0010">With the advent of busmasters in peripheral component interconnect (“PCI”), this use of early interrupts for any traffic has become scarce. In fact, to accommodate the high packet rates of high-speed networks such as Gigabit Ethernet, most input/output (“I/O”) controller devices offer interrupt coalescing features that delay interrupt assertions to allow several interrupt events to be processed in one occurrence of the interrupt handler. When Secondary Use is utilized extensively, sending packets across the PCI bus three times reduces the bus bandwidth available. This utilization, in turn, reduces the packet rate that can be processed, further reducing or eliminating the utility of the interrupt coalescing algorithms.</p>
<p id="p-0012" num="0011">Accordingly, there is a need for a system and method of improving the performance of an encrypted network by asserting interrupts to reduce latency that packets suffer during Secondary Use.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0002" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a block diagram of an encrypted network system in accordance with an embodiment of the present invention;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 2</figref> illustrates critical path events in accordance with an embodiment of the present invention;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 3</figref> illustrates critical path events in accordance with prior art, conventional Secondary Use decryption; and</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 4</figref> illustrates a flow chart corresponding to an implementation of the logic according to an embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0003" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0017" num="0016">The present invention provides systems and methods for reducing the latency of the final interrupt of a Secondary Use process. This scheme is preferably accomplished by signaling the “Secondary Use complete” interrupt before the Secondary Use operation is fully complete, thereby allowing the associated Interrupt Handler Latency to overlap with the completion of the Secondary Use operation itself</p>
<p id="p-0018" num="0017">As depicted in <figref idref="DRAWINGS">FIG. 1</figref>, a preferred encrypted network system of the present invention may include a computing system <b>100</b> with a network driver <b>130</b>, a controller <b>120</b>, a network interface <b>160</b> with a cryptography accelerator, a bus <b>150</b>, and host memory <b>110</b> with at least one SA stored thereupon, and may further be connected to an encrypted network <b>140</b>. The network interface <b>160</b> is preferably a NIC, a component on the motherboard, or in the chip set itself. The computing system <b>100</b> is preferably a computer, and may receive an encrypted packet from the encrypted network <b>140</b>. Upon receipt of this packet, the computing system <b>100</b> may DMA transfer the packet through the network interface <b>160</b> and across the bus <b>150</b> to host memory <b>110</b>. The network driver <b>130</b> may then parse the packet, match the packet with a corresponding SA, and instruct the network interface <b>160</b> to transfer the packet and corresponding SA across the bus <b>150</b> to the controller <b>120</b> for decryption. The controller <b>120</b> may then decrypt and authenticate the packet, whereupon the decrypted packet is transferred back across the bus <b>150</b> to host memory <b>110</b>. The packet is thus transferred across the bus <b>150</b> three times.</p>
<p id="p-0019" num="0018">This configuration is further illustrated in <figref idref="DRAWINGS">FIG. 2</figref>, which indicates the critical path events of the aforementioned system. In a preferred embodiment of the present invention, an encrypted packet is received <b>201</b> and DMA transferred <b>202</b> to host memory. The driver may then parse the packet, match the packet with a corresponding SA, and instruct the network interface to transfer the packet and corresponding SA to the controller for Secondary Use decryption <b>203</b>. The packet may then be decrypted by the controller <b>204</b> and authenticated <b>205</b>. Notably, to this point the Secondary Use operation of the present invention may be similar to a conventional Secondary Use operation, as depicted in <figref idref="DRAWINGS">FIG. 3</figref> (i.e., critical path events <b>201</b>-<b>205</b> of the present invention may be similar to conventional critical path events <b>301</b>-<b>305</b>).</p>
<p id="p-0020" num="0019">As depicted in <figref idref="DRAWINGS">FIG. 3</figref>, however, conventional Secondary Use operations include an Interrupt Handler Latency <b>308</b>, because the Secondary Use interrupt is asserted <b>307</b> only after the decrypted packet is transferred back to host memory <b>306</b>. However, as depicted in <figref idref="DRAWINGS">FIG. 2</figref>, Interrupt Handler Latency is either eliminated or substantially reduced in embodiments of the present invention because the interrupt is most preferably asserted prior to completing the transfer of the decrypted packet to host memory <b>206</b>. Thus, in the present invention, the Interrupt Handler Latency most preferably occurs in parallel with the transfer of the packet <b>206</b>. Both conventional Secondary Use operations and the Secondary Use operations of the present invention may then terminate with indicating the decrypted packet to a protocol stack (<b>309</b> and <b>207</b>, respectively).</p>
<p id="p-0021" num="0020">The present invention further provides a method for improving the performance of a computing system in communication with an encrypted network. The method may include receiving an encrypted packet from a network and DMA transferring the packet to host memory. The packet may then be parsed, matched with a corresponding SA, and transferred along with the corresponding SA to a controller for decryption. The packet may next be decrypted, authenticated, and transferred back to host memory. An interrupt is preferably asserted prior to transfer of the decrypted packet back to host memory being complete.</p>
<p id="p-0022" num="0021">Another method of the present invention reduces interrupt handler latency. As depicted in <figref idref="DRAWINGS">FIG. 4</figref>, the method may be a Secondary Use operation that includes first issuing a Secondary Use decryption command to a controller <b>401</b>, such that the controller determines the appropriate time for issuance of a “Secondary Use complete” interrupt in response <b>402</b>. An appropriate time is preferably any time between issuance of the Secondary Use decryption command and completion of transfer of the decrypted packet to host memory. The method may further include transferring a packet with corresponding SA to the controller <b>403</b>. The controller may decrypt and authenticate the packet <b>404</b>. The packet may then be transferred back to host memory <b>405</b>, and the Secondary Use operation may then be complete <b>406</b>. As indicated in <figref idref="DRAWINGS">FIG. 4</figref>, most preferably, the Secondary Use complete interrupt is issued at any point during operation <b>403</b>-<b>406</b>, depending on the determination made by the controller <b>402</b>.</p>
<p id="p-0023" num="0022">To underscore the benefits of the present invention, Table 1 illustrates the latencies associated with various decryption methodologies.</p>
<p id="p-0024" num="0023">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0" pgwide="1">
<tgroup align="left" colsep="0" rowsep="0" cols="1">
<colspec colname="1" colwidth="287pt" align="center"/>
<thead>
<row>
<entry namest="1" nameend="1" rowsep="1">TABLE 1</entry>
</row>
</thead>
<tbody valign="top">
<row>
<entry namest="1" nameend="1" align="center" rowsep="1"/>
</row>
<row>
<entry>Total Latencies of Various Decryption Methodologies</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="5">
<colspec colname="offset" colwidth="63pt" align="left"/>
<colspec colname="1" colwidth="56pt" align="center"/>
<colspec colname="2" colwidth="63pt" align="center"/>
<colspec colname="3" colwidth="49pt" align="center"/>
<colspec colname="4" colwidth="56pt" align="center"/>
<tbody valign="top">
<row>
<entry/>
<entry>Clear Traffic Path</entry>
<entry/>
<entry>Conventional</entry>
<entry>Secondary Use of</entry>
</row>
<row>
<entry/>
<entry>(no encryption)</entry>
<entry>Inline Receive Path</entry>
<entry>Secondary Use</entry>
<entry>Present Invention</entry>
</row>
<row>
<entry/>
<entry>Time (μsec)</entry>
<entry>Time (μsec)</entry>
<entry>Time (μsec)</entry>
<entry>Time (μsec)</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="4" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="5">
<colspec colname="1" colwidth="63pt" align="left"/>
<colspec colname="2" colwidth="56pt" align="char" char="."/>
<colspec colname="3" colwidth="63pt" align="char" char="."/>
<colspec colname="4" colwidth="49pt" align="char" char="."/>
<colspec colname="5" colwidth="56pt" align="char" char="."/>
<tbody valign="top">
<row>
<entry>Receive Packet</entry>
<entry>13</entry>
<entry>13</entry>
<entry>13</entry>
<entry>13</entry>
</row>
<row>
<entry>Transfer to Host</entry>
<entry>8</entry>
<entry>—</entry>
<entry>8</entry>
<entry>8</entry>
</row>
<row>
<entry>Interrupt and</entry>
<entry>40</entry>
<entry>—</entry>
<entry>40</entry>
<entry>40</entry>
</row>
<row>
<entry>Handler Latency</entry>
</row>
<row>
<entry>Parse Packet and</entry>
<entry>—</entry>
<entry>—</entry>
<entry>1</entry>
<entry>1</entry>
</row>
<row>
<entry>Issue Secondary Use</entry>
</row>
<row>
<entry>Command</entry>
</row>
<row>
<entry>Transfer Packet and</entry>
<entry>—</entry>
<entry>—</entry>
<entry>8</entry>
<entry>8</entry>
</row>
<row>
<entry>SA to Controller</entry>
</row>
<row>
<entry>Decrypt Packet</entry>
<entry>—</entry>
<entry>19</entry>
<entry>19</entry>
<entry>19</entry>
</row>
<row>
<entry>Transfer Packet to</entry>
<entry>—</entry>
<entry>8</entry>
<entry>8</entry>
<entry>8</entry>
</row>
<row>
<entry>Host</entry>
</row>
<row>
<entry>Interrupt Handler</entry>
<entry>—</entry>
<entry>40</entry>
<entry>40</entry>
<entry>—</entry>
</row>
<row>
<entry>Latency</entry>
</row>
<row>
<entry>Indication</entry>
<entry>4</entry>
<entry>4</entry>
<entry>4</entry>
<entry>4</entry>
</row>
<row>
<entry>Total Latency</entry>
<entry>65</entry>
<entry>84</entry>
<entry>141</entry>
<entry>101</entry>
</row>
<row>
<entry namest="1" nameend="5" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
</p>
<p id="p-0025" num="0024">Average Interrupt Handler Latency may be determined by the controller through the common “float and jump” adaptive algorithm, or other appropriate methodologies known in the art, as described in Example 1, below. Once calculated, this value may be used in embodiments of the present invention to determine when a Secondary Use complete interrupt should be asserted (i.e., how long before completing transfer of a decrypted packet back to host memory). In preferred embodiments of the present invention, the network driver specifies the Average Interrupt Handler Latency value as part of the Secondary Use decryption command. In this manner, the network driver is free to utilize any algorithm desired to best determine this value. For example, the Secondary Use command could indicate that the interrupt should be asserted after 1,000 bytes have been transferred to the controller (during step <b>403</b>); after 600 bytes have been decrypted (during step <b>404</b>); or after 200 bytes have been transferred back to host memory (during step <b>405</b>). Referring again to <figref idref="DRAWINGS">FIG. 2</figref> and <figref idref="DRAWINGS">FIG. 4</figref>, the Secondary Use complete interrupt is most preferably asserted during the intervals <b>203</b>-<b>206</b> and <b>403</b>-<b>406</b>, respectively. In embodiments of the present invention where the Interrupt Handler Latency is relatively high and a relatively small amount of data is being decrypted, the completion interrupt may even be asserted before the data to be decrypted is completely on-chip and before the decryption operation begins.</p>
<p id="p-0026" num="0025">Several of the stages in the preferred Secondary Use operations of the present invention do not have fixed time values. For example, the time that it takes to transfer a packet across a bus depends upon determinate values, such as the particular bus clock speed and width. It also depends upon bus availability, which can change depending on other devices in the system and their individual bus activity level. The Interrupt Handler Latency value itself is not fixed, however.</p>
<p id="p-0027" num="0026">Given that there are multiple indeterminable factors, a race condition may be created in some embodiments of the present invention. Accordingly, in some instances, the interrupt handler operation could begin when the Secondary Use operation has not yet completed, such that the interrupt handler has no tasks to process. Therefore, in most preferred embodiments of the present invention, an additional interrupt is asserted after the Secondary Use operation is complete. This scheme ensures that the Secondary Use packet will be processed. If the Interrupt Handler is operating when this additional interrupt is asserted by the device, then this additional interrupt will not generate a system interrupt because the device interrupts are preferably disabled while the Interrupt Handler is operating. This means that in most instances, an additional interrupt will be masked and not increase the interrupt load on the system.</p>
<heading id="h-0004" level="1">EXAMPLE 1</heading>
<heading id="h-0005" level="1">Determination of Average Interrupt Handler Latency</heading>
<p id="p-0028" num="0027">Decryption engines process data at a rate of approximately 600 Megabits per second (“Mbit/sec”). The latency from the device Interrupt Request line (“IRQ”) to interrupt processing is based on measurements on INTEL PENTIUM III Processor and INTEL PENTIUM 4 Processor systems using a MICROSOFT WINDOWS 2000 Operating System. Notably, the value of this latency does not change significantly with processor speed.</p>
<p id="p-0029" num="0028">The latency effect on TCP peak throughput is based on the bandwidth-delay product. Thus, maximum TCP throughput is the quotient of the receiver's window size divided by round trip time. The round trip time for a connection can be estimated from the latency values in Table 1; the latency values being doubled to account for the return of an acknowledgement. Assuming few or no infrastructure delays, and a 64K byte receiver's window (largest currently allowed without window scaling), the maximum throughput is estimated.</p>
<p id="p-0030" num="0029">A single clear TCP connection generates about 500 Mbit of traffic at most. However, as more connections are added, the latencies suffered by each connection are increased. Correspondingly, throughput of an individual connection decreases while overall server throughput increases. It generally takes at least eight TCP connections to generate a gigabit of throughput.</p>
<p id="p-0031" num="0030">Referring to the decryption methodologies outlined in Table 1, a single TCP connection using Inline Receive generates approximately 400 Mbit/sec; a conventional Secondary Use connection generates approximately 230 Mbit/sec; and the Secondary Use of the present invention generates approximately 320 Mbit/sec.</p>
<p id="p-0032" num="0031">Thus, Inline Receive is generally a preferred method of decryption, since it allows the greatest throughput, but this decryption methodology cannot always be used due either to design choices or limited SA cache. However, the Secondary Use operation of the present invention performs significantly better than conventional Secondary Use methods.</p>
<p id="p-0033" num="0032">While the description above refers to particular embodiments of the present invention, it will be understood that many modifications may be made without departing from the spirit thereof The accompanying claims are intended to cover such modifications as would fall within the true scope and spirit of the present invention. The presently disclosed embodiments are therefore to be considered in all respects as illustrative and not restrictive, the scope of the invention being indicated by the appended claims, rather than the foregoing description, and all changes that come within the meaning and range of equivalency of the claims are therefore intended to be embraced therein.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A computing system for performing a decryption operation on an encrypted packet, comprising:
<claim-text>a network driver to regulate said decryption operation and to transmit a decryption command;</claim-text>
<claim-text>a host memory to store the encrypted packet;</claim-text>
<claim-text>a controller to receive the encrypted packet and to perform said decryption operation after receiving said decryption command from the network driver;</claim-text>
<claim-text>a network interface to specify an interrupt handler latency value to the controller, said interrupt handler latency value being based on a specific number of bytes being decrypted in the controller;</claim-text>
<claim-text>a bus providing electronic communication among said network driver, said host memory and said controller, said controller asserting an interrupt and after the specific number of bytes have been decrypted in the controller and before the decrypted packet is transferred back from the controller to the host memory.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. A method of decrypting an encrypted packet received by a computing system, comprising:
<claim-text>receiving said encrypted packet from a network and transferring said encrypted packet to a host memory;</claim-text>
<claim-text>issuing a decryption command to a controller;</claim-text>
<claim-text>specifying an interrupt handler latency value to the controller, the interrupt handler latency value being based on a specific number of bytes being decrypted in the controller;</claim-text>
<claim-text>transferring said encrypted packet to said controller;</claim-text>
<claim-text>converting said encrypted packet to a decrypted packet; and</claim-text>
<claim-text>transferring said decrypted packet to the host memory, wherein an interrupt is asserted after the specific number of bytes have been decrypted in the controller and before the decrypted packet has been transferred from the controller to the host memory.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the encrypted packet is transferred to the host memory via direct memory access (DMA).</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further including a network driver to parse the encrypted packet at the network interface, match the encrypted packet with a corresponding security association, and to instruct that the corresponding security association is transferred to the controller with the encrypted packet.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A program code storage device, comprising:
<claim-text>a machine-readable storage medium; and</claim-text>
<claim-text>machine-readable program code, stored on the machine-readable storage medium, the machine-readable program code having instructions that when executed cause a computer system to;</claim-text>
<claim-text>receive an encrypted packet from a network and transfer said encrypted packet to a host memory;</claim-text>
<claim-text>issue a decryption command to a controller;</claim-text>
<claim-text>specify an interrupt handler latency value to the controller, the interrupt handler latency value being based on a specific number of bytes being decrypted in the controller;</claim-text>
<claim-text>transfer said encrypted packet to said controller;</claim-text>
<claim-text>convert said encrypted packet to a decrypted packet; and</claim-text>
<claim-text>transfer said decrypted packet to the host memory, wherein an interrupt is asserted after the specific number of bytes have been decrypted in the controller and before the decrypted packet has been transferred from the controller to the host memory.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The device of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the encrypted packet is transferred to the host memory via direct memory access (DMA).</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The device of <claim-ref idref="CLM-00005">claim 5</claim-ref>, further including a network driver to parse the encrypted packet at the network interface, match the encrypted packet with a corresponding security association, and to instruct that the corresponding security association is transferred to the controller with the encrypted packet.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A method of decrypting an encrypted packet received by a network interface in a computing system, comprising:
<claim-text>receiving said encrypted packet from a network and transferring said encrypted packet to a host memory;</claim-text>
<claim-text>issuing a decryption command to a controller;</claim-text>
<claim-text>specifying an interrupt handler latency value to the controller, the interrupt handler latency value being based on a specific number of bytes being decrypted in the controller; and</claim-text>
<claim-text>transferring said encrypted packet to said controller which converts the encrypted packet to a decrypted packet and transfers the decrypted packet to the host memory, wherein an interrupt is asserted after a specific number of bytes have been decrypted in the controller and before the decrypted packets have been transferred from the controller to the host memory.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the encrypted packet is transferred to the host memory via direct memory access (DMA).</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further including a network driver to parse the encrypted packet at the network interface, match the encrypted packet with a corresponding security association, and to instruct that the corresponding security association is transferred to the controller with the encrypted packet.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. A program code storage device, comprising:
<claim-text>a machine-readable storage medium; and</claim-text>
<claim-text>machine-readable program code, stored on the machine-readable storage medium, the machine-readable program code having instructions that when executed cause a network interface to:</claim-text>
<claim-text>receive an encrypted packet from a network and transfer said encrypted packet to a host memory;</claim-text>
<claim-text>issue a decryption command to a controller;</claim-text>
<claim-text>specify an interrupt handler latency value to the controller, the interrupt handler latency value being based on a specific number of bytes being decrypted in the controller; and</claim-text>
<claim-text>transfer said encrypted packet to said controller which converts the encrypted packet to a decrypted packet and transfers the decrypted packet to the host memory, wherein an interrupt is asserted after a specific number of bytes have been decrypted in the controller and before the decrypted packets have been transferred from the controller to the host memory.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The device of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the encrypted packet is transferred to the host memory via direct memory access (DMA).</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The device of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further including a network driver to parse the encrypted packet at the network interface, match the encrypted packet with a corresponding security association, and to instruct that the corresponding security association is transferred to the controller with the encrypted packet.</claim-text>
</claim>
</claims>
</us-patent-grant>
