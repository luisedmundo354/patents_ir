<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07299110-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07299110</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10752880</doc-number>
<date>20040106</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>69</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>05</class>
<subclass>B</subclass>
<main-group>19</main-group>
<subgroup>04</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>700246</main-classification>
<further-classification>700 18</further-classification>
<further-classification>700 83</further-classification>
<further-classification>700 86</further-classification>
<further-classification>700 87</further-classification>
<further-classification>704  1</further-classification>
<further-classification>704 10</further-classification>
<further-classification>704257</further-classification>
<further-classification>706 45</further-classification>
<further-classification>707102</further-classification>
</classification-national>
<invention-title id="d0e53">Systems and methods for using statistical techniques to reason with noisy data</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4839853</doc-number>
<kind>A</kind>
<name>Deerwester et al.</name>
<date>19890600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5442792</doc-number>
<kind>A</kind>
<name>Chun</name>
<date>19950800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6088731</doc-number>
<kind>A</kind>
<name>Kiraly et al.</name>
<date>20000700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>709229</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6292771</doc-number>
<kind>B1</kind>
<name>Haug et al.</name>
<date>20010900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6466695</doc-number>
<kind>B1</kind>
<name>Potzsch et al.</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6625315</doc-number>
<kind>B2</kind>
<name>Laumeyer et al.</name>
<date>20030900</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6757646</doc-number>
<kind>B2</kind>
<name>Marchisio</name>
<date>20040600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704  8</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6850252</doc-number>
<kind>B1</kind>
<name>Hoffberg</name>
<date>20050200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>715716</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>7089226</doc-number>
<kind>B1</kind>
<name>Dumais et al.</name>
<date>20060800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  3</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>2002/0077726</doc-number>
<kind>A1</kind>
<name>Thorisson</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>700246</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>2003/0004915</doc-number>
<kind>A1</kind>
<name>Lin et al.</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2003/0217052</doc-number>
<kind>A1</kind>
<name>Rubenczyk et al.</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>2005/0021517</doc-number>
<kind>A1</kind>
<name>Marchisio</name>
<date>20050100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>707  4</main-classification></classification-national>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>EP</country>
<doc-number>1 284 461</doc-number>
<kind>A1</kind>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>EP</country>
<doc-number>1 363 200</doc-number>
<kind>A2</kind>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00016">
<othercit>Thrum et al., Probabilistic algorithms and the interactive museum tour-guide robot Minerva, 2000, Internet, p. 35.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00017">
<othercit>Snyder et al., Intelligen simulation environments, 1988, Internet, p. 357-363.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00018">
<othercit>Itoh, Research and development on knowledge base systems at ICOT, 1986, Internet, p. 437-445.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00019">
<othercit>Rumshisky, Why your word processing software doesn't fing spelling and grammar errors very well . . . And never will, 2001, Internet, p. 1-5.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00020">
<othercit>Jarzabek et al., A hybrid program knowledge base for static program analyzers, 1994, IEEE, p. 400-409.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00021">
<othercit>Darbari, Computer assisted translation system—An indian prespective, 1999, Internet, p. 80-85.</othercit>
</nplcit>
<category>cited by examiner</category>
</citation>
<citation>
<nplcit num="00022">
<othercit>Benferhat, Salem, et al., “How to Infer From Inconsistent Beliefs Without Revising?”, Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), Montreal, Canada, Aug. 20-25, 1995, pp. 1449-1455.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00023">
<othercit>Verma, Deepak, et al., “A Comparison of Spectral Clustering Algorithms”, University of Washington Computer Science &amp; Engineering, Technical Report, pp. 1-18, Mar. 5, 2001.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00024">
<othercit>Dalal, Mukesh, “Investigations Into a Theory of Knowledge Base Revision: Preliminary Report” Proceedings of the Seventh National Conference on Artificial Intelligence (AAAI), Aug. 1988, St. Paul, Minnesota, pp. 475-479.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00025">
<othercit>Del Val, Alvaro, “Research in Automated Reasoning”, Universidad Autonoma de Madrid, First Technical Workshop of the Computer Engineering Dept., Mar. 31, 2000.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00026">
<othercit>Haddawy, Peter, “An Overview of Some Recent Developments in Bayesian Problem Solving Techniques”, AI Magazine, Introduction to special issue on Uncertainty in AI, Spring 1999.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00027">
<othercit>Nebel, Bernhard, “How Hard is it to Revise a Belief Base?”, Technical Report No. 83, Institut fur Informatik, Albert-Ludwigs-Universitat Freiburg, Aug. 1996, Published in the Handbook of Defeasible Reasoning and Uncertainty Management Systems, vol. 3: Belief Change.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00028">
<othercit>Manning, Chris, et al., “Foundations of Statistical Natural Language Processing”, MIT Press, Cambridge, MA, May 1999, pp. 554-566.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00029">
<othercit>Kochenderfer, Mykel J., et al., “Common Sense Data Acquisition for Indoor Mobile Robots”, Workshop on Distributed and Collaborative Knowledge Capture, Second International Conference on Knowledge Capture (K-CAP), Florida, USA, Oct. 23-26, 2003.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00030">
<othercit>Landauer, Thomas K., et al., “An Introduction to Latent Semantic Analysis”, Discourse Processes 25, 1998, pp. 259-284.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00031">
<othercit>Deerwester, Scott, et al., “Indexing by Latent Semantic Analysis”, Journal of the American Society for Information Science (JASIS), 41:6, Sep. 1990, pp. 391-407.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00032">
<othercit>Cadoli, Marco, et al., “A Survey on Knowledge Compilation”, AI Communications, 10:137-150, 1997.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00033">
<othercit>Baeza-Yates, Ricardo et al., <i>Modem Information Retrieval</i>, 1999, pp. 163-190, ACM Press, New York.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00034">
<othercit>Bratman, Michael, <i>Intention, Plans, and Practical Reason</i>, 1987, pp. 1-27, Harvard University Press, Cambridge, Massachusetts.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00035">
<othercit>Mueller, Erik T., <i>Natural Language Processing With ThoughtTreasure</i>, 1998, Signiform, New York, [online] [retrieved on Oct. 20, 2004] Retrieved from the internet &lt;URL: http://www.signiform.com/tt/book/index.html&gt;.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00036">
<othercit>Gupta, R. et al., “Common Sense Data Acquisition for Indoor Mobile Robots,” Proceedings of the Nineteenth National Conference on Artificial Intelligence (AAAI), Jul. 25-29, 2004, pp. 605-610.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00037">
<othercit>Eagle, N., et al., “Common Sense Conversations: Understanding Casual Conversation Using A Common Sense Database,” 18<sup>th </sup>International Joint Conference on Artificial Intelligence (IJCAI), Workshop on Artificial Intelligence, Information Access, and Mobile Computing, Aug. 11, 2003.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00038">
<othercit>Guha, R. et al., “Cyc: A Midterm Report”, AI Magazine, Fall 1990, pp. 32-59.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00039">
<othercit>Liu, H. et al., “A Model of Textual Affect Sensing Using Real-World Knowledge,” In Proceedings of the Seventh International Conference on Intelligent User Interfaces (IUI), Jan. 12-15, 2003, pp. 125-132.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00040">
<othercit>Luhn, H. P., “The Automatic Derivation of Information Retrieval Encodements from Machine-Readable Texts,” Information Retrieval and Machine Translation 3(2), 1961, pp. 1021-1028.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00041">
<othercit>Nilsson, N. J., “Teleo-Reactive Programs for Agent Control,” Journal of Artificial Intelligence Research 1, 1994, pp. 139-158.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00042">
<othercit>Rao, A.S. et al., “BDI Agents: From Theory to Practice,” In Proceedings of the First International Conference on Multi-Agent Systems, Jun. 1995.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00043">
<othercit>Scott, S. et al., “Feature Engineering for Text Classification,” Proceedings of the 16<sup>th </sup>International Conference on Machine Learning (ICML), Jun. 27-30, 1999, Slovenia: Morgan Kaufmann Publishers, San Francisco, USA, pp. 379-388.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00044">
<othercit>Stork, D.G., et al., “The Open Mind Initiative,” IEEE Intelligent Systems and Their Applications 14(3), May/Jun. 1999, pp. 19-20.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00045">
<othercit>Stork, D.G., “Open Data Collection for Training Intelligent Software in the Open Mind Initiative,” Proceedings of the Engineering Intelligent Systems Symposium (EIS), Jun. 2000.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00046">
<othercit>Voorhees, E.M., “Query Expansion Using Lexical-Semantic Relations” Proceedings of the 17<sup>th </sup>International Conference on Research and Development in Information Retrieval (SIGIR), 1994; pp. 61-69.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00047">
<othercit>Wooldridge, M., “Intelligent Agents”, In Weiss, G., ed., Multiagent Systems: A Modern Approach to Distributed Artificial Intelligence. The MIT Press, Cambridge, MA, 1999, pp. 27-77.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00048">
<othercit>PCT International Search Report and Written Opinion; PCT/US05/00299, Nov. 3, 2005.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00049">
<othercit>Fagin, R. et al., “On the Semantics of Updates in Databases”, Principles of Database Systems: Proceedings of the Second ACM SIGACT-SIGMOD Symposium, Atlanta, GA, Ed. Jeffrey Ullman, 1983, pp. 352-365.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00050">
<othercit>Gardenfors, P., “Knowledge in Flux—Modeling the Dynamic of Epistemic States” (table of contents), 1988, MIT Press, Cambridge, MA.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00051">
<othercit>Jolliffe, I.T., “Principle Component Analysis” (table of contents), 1986, Springer-Verlag, New York, NY.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00052">
<othercit>Kannan, R. et al., “On Clusterings—Good, Bad and Spectral”, 41<sup>st </sup>Annual Symposium on Foundations of Computer Science, Nov. 12-14, 2000, Redondo Beach, CA.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00053">
<othercit>Manning, C.D. et al., “Chapter 15: Topics in Information Retrieval: Latent Semantic Indexing”, Foundations of Statistical Natural Language Processing, 1999, pp. 554-566, MIT Press, Cambridge, MA.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00054">
<othercit>Myers, K. et al., “Reasoning with Analogical Representations”, Principles of Knowledge Representation and Reasoning: Proceedings of the Third International Conference (KR '92), Ed. B. Nebel et al., 1992, pp. 189-200, Morgan Kaufmann Publishers, San Mateo, CA.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00055">
<othercit>Bellegarda, J. R., “Exploiting Latent Semantic Information in Statistical Language Modeling,” Proceedings of the IEEE, Aug. 2000, vol. 88, No. 8, pp. 1279-1296.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00056">
<othercit>Harabagiu, S. M., et al., “PARIS: A Parallel Inference System,” IEEE, Nov. 16, 1996, pp. 216-223.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00057">
<othercit>Pan, X., et al., “Providing Context for Free Text Interpretation,” Proceedings: International Conference on Natural Language Processing and Knowledge Engineering, Oct. 26-29, 2003, Piscataway, NJ, pp. 704-709.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00058">
<othercit>Tsuji, T., et al., “The Construction of Knowledge Bases with Morphological Semantics,” IEEE International Conference on Systems, Man and Cybernetics, Beijing, China, Oct. 14-17, 1996, pp. 31-36, vol. 1.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>33</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>700246</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>5</number-of-drawing-sheets>
<number-of-figures>5</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20050149230</doc-number>
<kind>A1</kind>
<date>20050707</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Gupta</last-name>
<first-name>Rakesh</first-name>
<address>
<city>Cupertino</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Kochenderfer</last-name>
<first-name>Mykel J.</first-name>
<address>
<city>Edinburgh</city>
<country>GB</country>
</address>
</addressbook>
<nationality>
<country>GB</country>
</nationality>
<residence>
<country>GB</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Duell</last-name>
<first-name>Mark E.</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
<agent sequence="02" rep-type="attorney">
<addressbook>
<orgname>Fenwick &amp; West LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Honda Motor Co., Ltd.</orgname>
<role>03</role>
<address>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Black</last-name>
<first-name>Thomas</first-name>
<department>3661</department>
</primary-examiner>
<assistant-examiner>
<last-name>Marc</last-name>
<first-name>McDieunel</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Systems and methods are presented that enable logical reasoning even in the presence of noisy (inconsistent) data. The knowledge base is processed in order to make it consistent and is also compiled. This processing includes checking and correcting spelling, removing stopwords, performing, grouping words of similar and related meaning, and compacting the knowledge base. A robot can use the processed knowledge base to perform many different types of tasks, such as answering a query, determining a course of action that is designed to achieve a particular goal, and determining its own location.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="156.97mm" wi="232.33mm" file="US07299110-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="232.83mm" wi="158.24mm" orientation="landscape" file="US07299110-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="204.47mm" wi="174.67mm" orientation="landscape" file="US07299110-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="208.87mm" wi="51.99mm" file="US07299110-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="226.91mm" wi="100.67mm" file="US07299110-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="209.55mm" wi="51.48mm" file="US07299110-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">1. Field of the Invention</p>
<p id="p-0003" num="0002">The present invention relates to automated reasoning. More particularly, the present invention relates to using statistical techniques in order to enable automated reasoning with noisy data.</p>
<p id="p-0004" num="0003">2. Description of Background Art</p>
<p id="p-0005" num="0004">Robots will soon be expected to accomplish tasks within their environments and to satisfy the perceived requests and desires of their users. Determining these desires and reasoning about how they can be accomplished requires common sense. One of the main challenges in the field of robotics is making robots more intelligent by endowing them with common sense. In order for robots to have common sense, they need some amount of general knowledge to use as a basis. They can then reason from this basis to accomplish their tasks and interact with their world intelligently.</p>
<p id="p-0006" num="0005">Automated reasoning, a topic within the field of artificial intelligence, is concerned with using computers to perform logical reasoning. Logical reasoning, such as deduction, consists of drawing conclusions from facts. Conclusions are formed by applying rules (e.g., implications) to facts. This is also known as inferencing. Logical reasoning systems comprise implications, a basis of facts, and control mechanisms for applying implications to these facts. In automated reasoning systems, facts and implications are stored in a “knowledge base.” Facts are established by, for example, user input (e.g., by typing in “The stove is hot”) or sensor input (e.g., by placing a heat sensor near the stove). Implications are established by, for example, user input (e.g., by typing in “An item in a refrigerator is cold”) or machine learning.</p>
<p id="p-0007" num="0006">For logical reasoning to be sound, an implication must require that its conclusion follow inevitably from the fact from which it is drawn. Depending on the facts and implications that a system starts with, many different conclusions can be reached. In addition, implications can be applied to both facts (originally input into the system) and conclusions (generated by implications). Because of the interactions between facts, implications, and conclusions, it is important that the initially-input facts and implications be correct. If the facts or implications are false or inconsistent with one another, the resulting conclusions may be invalid.</p>
<p id="p-0008" num="0007">Thus, automated reasoning systems must have self-consistent knowledge bases. Any sound and complete consistency check will require an exponential amount of time based on the number of items in the database. Consistency checks need to be performed each time something is added the knowledge base. The result is that automated reasoning systems are very brittle. Their knowledge bases are frequently handcrafted, and differences in vocabulary are usually not tolerated.</p>
<p id="p-0009" num="0008">One way to reason with inconsistent knowledge is to revise the knowledge base before performing the reasoning. Any revision process requires, either explicitly or implicitly, the ordering of rules based on priority. This has been proved by “On the semantics of updates in database” by R. Fagin, J. D. Ullman, M. Y. Vardi, in Principles of Database Systems: Proceedings of the Second ACM SIGACT-SIGMOD Symposium, pp. 352-365, Atlanta, 1983; and “Knowledge in Flux—Modeling the Dynamic of Epistemic States” by P. Gardenfors, Cambridge, Mass., 1988. Alternatively, one can reason with inconsistent knowledge without first revising the knowledge base, as discussed in “How to infer from inconsistent beliefs without revising?” by S. Benferhat, D. Dubois, and H. Prade, Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, Montreal, Canada, Aug. 20-25, 1995. In general, prior work in this area has been based on logical artificial intelligence techniques rather than on statistical techniques.</p>
<p id="p-0010" num="0009">Before inferencing from a knowledge base, it is also useful to “compile” the knowledge base. Compilation of a knowledge base can comprise cleaning, generalizing, and compacting the data in the knowledge base. Compilation can decrease the amount of resources (time, memory, etc.) required by the reasoning process.</p>
<p id="p-0011" num="0010">What is needed is a way to enable automated reasoning systems to use noisy data, that is, knowledge bases that are not self-consistent. In addition, automated reasoning systems should be able to handle tasks that contain words that are not in the knowledge base.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0012" num="0011">One of the main challenges in the field of robotics is making robots more intelligent by endowing them with common sense. This common sense can then be used to perform logical reasoning. Common sense is stored in a knowledge base as a set of statements and implications. It is important that the statements and implications be consistent with one another; if they are not, the resulting conclusions may be invalid.</p>
<p id="p-0013" num="0012">Systems and methods are presented that enable logical reasoning even in the presence of noisy (inconsistent) data. The knowledge base is processed in order to make it consistent and also compiled. This processing includes checking and correcting spelling, removing stopwords, performing stemming, grouping words of similar and related meaning, and compacting the knowledge base.</p>
<p id="p-0014" num="0013">A robot can use the processed knowledge base to perform many different types of tasks in many different environments. In one embodiment, the robot is a mobile robot used in a home or office environment. Possible tasks include, for example, answering a query, determining a course of action that is designed to achieve a particular goal, and determining its own location.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0015" num="0014">The invention is illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings in which like reference numerals refer to similar elements.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a block diagram of a preferred embodiment of an apparatus for reasoning when noisy data is present.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 2</figref> illustrates a more detailed block diagram of the contents of the memory unit in <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 3</figref> illustrates a method for reasoning when noisy data is present.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 4</figref> illustrates a method for processing a knowledge base.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 5</figref> illustrates a method for determining a location using Bayesian inferencing.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0021" num="0020">In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the invention. It will be apparent, however, to one skilled in the art that the invention can be practiced without these specific details. In other instances, structures and devices are shown in block diagram form in order to avoid obscuring the invention.</p>
<p id="p-0022" num="0021">Reference in the specification to “one embodiment” or “an embodiment” means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the invention. The appearances of the phrase “in one embodiment” in various places in the specification are not necessarily all referring to the same embodiment.</p>
<p id="p-0023" num="0022">Some portions of the detailed descriptions that follow are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here, and generally, conceived to be a self-consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually, though not necessarily, these quantities take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared, and otherwise manipulated. It has proven convenient at times, principally for reasons of common usage, to refer to these signals as bits, values, elements, symbols, characters, terms, numbers, or the like.</p>
<p id="p-0024" num="0023">It should be borne in mind, however, that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise, as apparent from the following discussion, it is appreciated that throughout the description, discussions utilizing terms such as “processing” or “computing” or “calculating” or “determining” or “displaying” or the like, refer to the action and processes of a computer system, or similar electronic computing device, that manipulates and transforms data represented as physical (electronic) quantities within the computer system's registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission, or display devices.</p>
<p id="p-0025" num="0024">The present invention also relates to an apparatus for performing the operations herein. This apparatus is specially constructed for the required purposes, or it comprises a general-purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program is stored in a computer readable storage medium, such as, but not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, and magnetic-optical disks, read-only memories (ROMs), random access memories (RAMs), EPROMs, EEPROMs, magnetic or optical cards, or any type of media suitable for storing electronic instructions, and each coupled to a computer system bus.</p>
<p id="p-0026" num="0025">The algorithms and displays presented herein are not inherently related to any particular computer or other apparatus. Various general-purpose systems are used with programs in accordance with the teachings herein, or more specialized apparatus are constructed to perform the required method steps. The required structure for a variety of these systems will appear from the description below. In addition, the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein.</p>
<p id="h-0005" num="0000">1. Architecture of Reasoning Apparatus</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a block diagram of a preferred embodiment of an apparatus for reasoning when noisy data is present. Reasoning apparatus <b>100</b> preferably includes a processor <b>110</b>, a main memory <b>120</b>, a data storage device <b>130</b>, and an input/output controller <b>180</b>, all of which are communicatively coupled to a system bus <b>140</b>. Reasoning apparatus <b>100</b> can be, for example, a computer or a robot.</p>
<p id="p-0028" num="0027">Reasoning apparatus <b>100</b> uses statistical reasoning to enable it to reason when noisy data is present. Statistical reasoning, unlike logical reasoning, includes the notion of uncertainty. This uncertainty is expressed through the use of statistics, such as latent semantic analysis, and probability theory, such as Bayesian networks. Statistical reasoning has traditionally been used to work with large text documents in the fields of data retrieval and data mining.</p>
<p id="p-0029" num="0028">By processing a knowledge base using statistical methods, reasoning apparatus <b>100</b> makes the knowledge base unambiguously reflect consensus knowledge. Reasoning apparatus <b>100</b> can then reason from the knowledge base without creating invalid results. Statistical reasoning techniques have not been used in this area in the past. One possible reason for this is that in the past, the available data has not been dense enough to leverage statistical techniques.</p>
<p id="p-0030" num="0029">Reasoning apparatus <b>100</b> also uses statistical methods to process queries and commands. This results in reasoning apparatus <b>100</b> being able to handle tasks that contain words that are not in the knowledge base.</p>
<p id="p-0031" num="0030">Processor <b>110</b> processes data signals and comprises various computing architectures including a complex instruction set computer (CISC) architecture, a reduced instruction set computer (RISC) architecture, or an architecture implementing a combination of instruction sets. Although only a single processor is shown in <figref idref="DRAWINGS">FIG. 1</figref>, multiple processors may be included.</p>
<p id="p-0032" num="0031">Main memory <b>120</b> stores instructions and/or data that are executed by processor <b>110</b>. The instructions and/or data comprise code for performing any and/or all of the techniques described herein. Main memory <b>120</b> is preferably a dynamic random access memory (DRAM) device, a static random access memory (SRAM) device, or some other memory device known in the art.</p>
<p id="p-0033" num="0032">Data storage device <b>130</b> stores data and instructions for processor <b>110</b> and comprises one or more devices including a hard disk drive, a floppy disk drive, a CD-ROM device, a DVD-ROM device, a DVD-RAM device, a DVD-RW device, a flash memory device, or some other mass storage device known in the art.</p>
<p id="p-0034" num="0033">Network controller <b>180</b> links reasoning apparatus <b>100</b> to other devices so that reasoning apparatus <b>100</b> can communicate with these devices.</p>
<p id="p-0035" num="0034">System bus <b>140</b> represents a shared bus for communicating information and data throughout reasoning apparatus <b>100</b>. System bus <b>140</b> represents one or more buses including an industry standard architecture (ISA) bus, a peripheral component interconnect (PCI) bus, a universal serial bus (USB), or some other bus known in the art to provide similar functionality.</p>
<p id="p-0036" num="0035">Additional components that may be coupled to reasoning apparatus <b>100</b> through system bus <b>140</b> include a display device <b>150</b>, a keyboard <b>160</b>, and a cursor control device <b>170</b>. Display device <b>150</b> represents any device equipped to display electronic images and data to a local user or maintainer. Display device <b>150</b> is a cathode ray tube (CRT), a liquid crystal display (LCD), or any other similarly equipped display device, screen, or monitor. Keyboard <b>160</b> represents an alphanumeric input device coupled to reasoning apparatus <b>100</b> to communicate information and command selections to processor <b>110</b>. Cursor control device <b>170</b> represents a user input device equipped to communicate positional data as well as command selections to processor <b>110</b>. Cursor control device <b>170</b> includes a mouse, a trackball, a stylus, a pen, cursor direction keys, or other mechanisms to cause movement of a cursor.</p>
<p id="p-0037" num="0036">It should be apparent to one skilled in the art that reasoning apparatus <b>100</b> includes more or fewer components than those shown in <figref idref="DRAWINGS">FIG. 1</figref> without departing from the spirit and scope of the present invention. For example, reasoning apparatus <b>100</b> may include additional memory, such as, for example, a first or second level cache or one or more application specific integrated circuits (ASICs). As noted above, reasoning apparatus <b>100</b> may be comprised solely of ASICs. In addition, components may be coupled to reasoning apparatus <b>100</b> including, for example, image scanning devices, digital still or video cameras, or other devices that may or may not be equipped to capture and/or download electronic data to/from reasoning apparatus <b>100</b>.</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. 2</figref> illustrates a more detailed block diagram of the contents of the memory unit in <figref idref="DRAWINGS">FIG. 1</figref>. Generally, memory unit <b>120</b> comprises several code modules for reasoning when noisy data is present. Specifically, the code modules in memory unit <b>120</b> include a main program <b>200</b>, knowledge base processing program <b>205</b>, inferencing program <b>210</b>, spell check module <b>215</b>, stopword module <b>220</b>, stemming module <b>225</b>, latent semantic analysis module <b>230</b>, WordNet module <b>235</b>, statistics generation module <b>240</b>, and knowledge base <b>245</b>.</p>
<p id="p-0039" num="0038">All code modules <b>205</b>, <b>210</b>, <b>215</b>, <b>220</b>, <b>225</b>, <b>230</b>, <b>235</b>, <b>240</b>, <b>245</b> are communicatively coupled to main program <b>200</b>. Main program <b>200</b> centrally controls the operation and process flow of reasoning apparatus <b>100</b>, transmitting instructions and data to as well as receiving data from each code module <b>205</b>, <b>210</b>, <b>215</b>, <b>220</b>, <b>225</b>, <b>230</b>, <b>235</b>, <b>240</b>, <b>245</b>. Details of its operation will be discussed below with reference to <figref idref="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0040" num="0039">Knowledge base processing program <b>205</b> processes a knowledge base in order to make it self-consistent and also compiles a knowledge base. Knowledge base processing program <b>205</b> accomplishes this by using spell check module <b>215</b>, stopword module <b>220</b>, stemming module <b>225</b>, and latent semantic analysis module <b>230</b>.</p>
<p id="p-0041" num="0040">Knowledge base <b>245</b> stores a knowledge base comprising facts and implications. As implications are applied to facts, the resulting conclusions are also stored in knowledge base <b>245</b>.</p>
<p id="p-0042" num="0041">Spell check module <b>215</b> checks and corrects the spelling of words. Stopword module <b>220</b> removes particular words from a collection of words. Stemming module <b>225</b> maps word variants to the same word. For example, “cooking”, “cooked”, and “cooks” would be mapped to “cook”. Latent semantic analysis module <b>230</b> performs latent semantic analysis on a collection of implications to find the most relevant implications. WordNet module <b>235</b> compacts data. WordNet module <b>235</b> also enables reasoning about words that do not exist in a knowledge base. Inferencing program <b>210</b> uses facts and implications stored in a knowledge base and generates conclusions through inferencing. Statistics generation module <b>240</b> generates statistics based on data in a knowledge base. Code modules <b>200</b>-<b>245</b> will be further discussed below with reference to <figref idref="DRAWINGS">FIGS. 3 and 4</figref>.</p>
<p id="h-0006" num="0000">2. Usage of Reasoning Apparatus</p>
<p id="p-0043" num="0042">As noted above, reasoning apparatus <b>100</b> can be used in many different contexts to perform many different tasks. <figref idref="DRAWINGS">FIG. 3</figref> illustrates a method for reasoning when noisy data is present. In one embodiment, this reasoning is based on common sense knowledge.</p>
<p id="p-0044" num="0043">In the first step, main program <b>200</b> begins <b>300</b>. Main program <b>200</b> then loads <b>305</b> data into the knowledge base <b>245</b>. The data consists of statements and implications. In one embodiment, the knowledge base <b>245</b> is designed to enable reasoning from common sense knowledge. In this embodiment, a statement is a relation based on a real-world object. A relation is a pair
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>φ=(<i>o,p</i>)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where o is the object and p is a property of the object (an adjective or attribute). For example, one statement is (coffee, heated). A statement can describe the current state of an object (“the coffee is heated”) or it can describe the desired state of an object (“the coffee should be heated”). A statement can also represent an action (“do something to make the coffee heated”).
</p>
<p id="p-0045" num="0044">Common sense knowledge itself is represented by implications. Implications apply to a first statement (the antecedent) and create a second statement (the consequent). In this embodiment, a “causes implication” encodes the knowledge that one statement implies (or causes) another statement. For example, (coffee, refrigerated) implies (coffee, cold). This is represented symbolically as
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>φ<sub>1</sub>→φ<sub>2 </sub>where φ<sub>1</sub>=(coffee, refrigerated) and φ<sub>2</sub>=(coffee, cold)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
Causes implications can be used to predict the results of actions. The variable F denotes the set of all causes implications in the knowledge base <b>245</b>.
</p>
<p id="p-0046" num="0045">A “desires implication” encodes the knowledge that one statement indicates a desire that another statement be true. For example, (stomach, growling) indicates (human, fed). This is represented symbolically as
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>φ<sub>1</sub>→<sub>d</sub>φ<sub>2 </sub>where φ<sub>1</sub>=(stomach, growling) and φ<sub>2</sub>=(human, fed)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
Desires implications can be used to anticipate human desires. The variable I denotes the set of all desires implications in the knowledge base <b>245</b>.
</p>
<p id="p-0047" num="0046">The variable S denotes the set of all statements that are true in the current state of the world. The variable S* (the closure of S) is given by the recursive definition
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>S*=S∪{φ:φ′→φεF</i><img id="CUSTOM-CHARACTER-00001" he="1.78mm" wi="1.78mm" file="US07299110-20071120-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/><i>φ′εS*}</i><?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
S* is a function of time because the states of objects can change and new knowledge can be inserted into the knowledge base <b>245</b>.
</p>
<p id="p-0048" num="0047">In one embodiment, the data is loaded into a MySQL™ database from MySQL AB. The following table contains relations that might be used in the database.</p>
<p id="p-0049" num="0048">
<tables id="TABLE-US-00001" num="00001">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="3">
<colspec colname="offset" colwidth="28pt" align="left"/>
<colspec colname="1" colwidth="77pt" align="left"/>
<colspec colname="2" colwidth="112pt" align="left"/>
<thead>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
<row>
<entry/>
<entry>Type of Relation</entry>
<entry>Fields</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry/>
<entry>Statements</entry>
<entry>id, obj, prop, desire</entry>
</row>
<row>
<entry/>
<entry>Causes</entry>
<entry>id, obj1, prop1, obj2, prop2</entry>
</row>
<row>
<entry/>
<entry>Desires</entry>
<entry>id, obj1, prop1, obj2, prop2</entry>
</row>
<row>
<entry/>
<entry>Objects</entry>
<entry>id, name</entry>
</row>
<row>
<entry/>
<entry>Uses</entry>
<entry>id, obj, vp</entry>
</row>
<row>
<entry/>
<entry>Rooms</entry>
<entry>id, name</entry>
</row>
<row>
<entry/>
<entry>Proximity</entry>
<entry>id, obj1, obj2</entry>
</row>
<row>
<entry/>
<entry>Locations</entry>
<entry>id, obj, room</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="2" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
<br/>
The Statements, Causes, and Desires relations enable inferencing. The Objects, Uses, Rooms, Proximity, and Locations relations are used to accomplish specific tasks. These tasks include goal achievement and parameter determination and will be further discussed below.
</p>
<p id="p-0050" num="0049">The data might have been communicated to reasoning apparatus <b>100</b> through the input/output controller <b>180</b>. Alternatively, the data might have been present in data storage device <b>130</b>.</p>
<p id="p-0051" num="0050">Once main program <b>200</b> has loaded <b>305</b> the data into the knowledge base <b>245</b>, main program <b>200</b> processes <b>310</b> the knowledge base <b>245</b> using statistical methods. One purpose for this processing is to make the knowledge base self-consistent. One way to ensure that a knowledge base is self-consistent is to handcraft it, making sure that each piece of information is valid and checking that it does not conflict with other information in the knowledge base. Since a knowledge base needs to contain a lot of information in order to be useful, handcrafting one can take a lot of time. It would be preferable if the knowledge base could be made self-consistent without requiring a person to review each piece of information manually. Another purpose for this processing is to compile the knowledge base, generalizing and compacting it so that it requires less storage space and reasoning can be performed on it more quickly.</p>
<p id="p-0052" num="0051">Step <b>310</b> is detailed in <figref idref="DRAWINGS">FIG. 4</figref>. <figref idref="DRAWINGS">FIG. 4</figref> illustrates a method for processing a knowledge base. In the first step, knowledge base processing program <b>205</b> begins <b>400</b>. Knowledge base processing program <b>205</b> then checks <b>405</b> and corrects the spelling of the words in the knowledge base <b>245</b> by using spell check module <b>215</b>. Then, knowledge base processing program <b>205</b> removes <b>410</b> common words from the knowledge base <b>245</b>, such as “a”, “an”, and “the”, by using stopword module <b>220</b>. After this, knowledge base processing program <b>205</b> performs stemming <b>415</b> on the words in the knowledge base <b>245</b>. Steps <b>405</b>, <b>410</b>, and <b>415</b> are optional. They increase the value of the knowledge base by standardizing the data within it.</p>
<p id="p-0053" num="0052">In step <b>420</b>, knowledge base processing program <b>205</b> groups <b>420</b> words of similar and related meanings together into notional families. Notional families serve to cluster data and reduce data dimensionality in order to find the most relevant implications. In other words, notional families identify a consensus in the knowledge base, and this consensus serves as the reasoning apparatus' common sense. Notional families were first proposed in “The automatic derivation of information retrieval encodement from machine readable text” by H. P. Luhn, Information Retrieval and Machine Translation, 3(2), pp. 1021-1028, 1961, which is hereby incorporated by reference.</p>
<p id="p-0054" num="0053">One way to cluster data and reduce data dimensionality in order to find the most relevant implications is to perform latent semantic analysis on the implications in the knowledge base. Latent semantic analysis is a statistical method that indexes phrases or documents to reflect topic similarity. Topic similarity is based on word co-occurrence, a valid indicator of topic relatedness. In latent semantic space, phrases can have high similarity even if they do not share any terms, so long as their terms are semantically similar according to the co-occurrence analysis. In other words, latent semantic analysis addresses the synonymy problem of people using different words to refer to the same concept. Latent semantic analysis results in a unique consequent statement for each antecedent statement and vice versa.</p>
<p id="p-0055" num="0054">Here, latent semantic analysis indexes implications leading to each consequent and then applies these indices via singular value decomposition to find the most relevant implications. The time needed to perform singular value decomposition is exponential based on the rank of the statement by implication matrix and the number of singular values that are computed. Latent semantic analysis is described further in “Indexing by Latent Semantic Analysis” by S. C. Deerwester, S. T. Dumais, T. K. Landauer, G. W. Fumas, and R. A. Harshman, Journal of the American Society of Information Science, 41(6), pp. 391-407, 1990; and “Foundations of Statistical Natural Language Processing” by C. D. Manning and H. Schuetze, Chapter: Topics in Information Retrieval: Latent Semantic Indexing, 2001; both of which are hereby incorporated by reference.</p>
<p id="p-0056" num="0055">Other techniques to cluster data and reduce data dimensionality in order to find the most relevant implications include the statistical methods of spectral clustering and principal component analysis. Spectral clustering methods cluster points using eigenvectors of matrices derived from that data. The basic idea of principal component analysis is to determine the components s<sub>1</sub>, s<sub>2</sub>, . . . , s<sub>n </sub>that explain the maximum amount of variance possible by n linearly transformed components. Spectral clustering is described further in “A Comparison of Spectral Clustering Algorithms” by D. Verma and M. Meila, University of Washington (UW) Computer Science and Engineering (CSE) Technical Report, Mar. 5, 2001; and “On Clusterings—Good, Bad, and Spectral” by R. Kannan, S. Vempala, and A. Veta, 41<sup>st </sup>Annual Symposium on Foundations of Computer Science, Nov. 12-14, 2000, Redondo Beach, Calif.; both of which are hereby incorporated by reference. Principal component analysis is described further in Principal Component Analysis by I. T. Jolliffe, Springer-Verlag, 1986, which is hereby incorporated by reference.</p>
<p id="p-0057" num="0056">In step <b>425</b>, knowledge base processing program <b>205</b> compiles <b>425</b> the knowledge base using WordNet module <b>235</b>. WordNet®, from Princeton University, is a lexical database for the English language. Nouns, verbs, adjectives, and adverbs are organized into synonym sets. Each set represents one underlying lexical concept (the “root word”), and different relations link the sets.</p>
<p id="p-0058" num="0057">Each root word is a hypernym of the related synonyms. Hypernymy is a linguistic term for an is-a relationship. For example, since a fork is silverware, “silverware” is a hypernym of “fork.” One example of WordNet synonym sets involves the root word “can” (as a noun). A first hypernym would be “tin can,” a second hypernym would be “toilet,” and a third hypernym would be “bathroom.” Synonyms in the “tin can” group would include “milk can” and “oil can,” while synonyms in the “bathroom” group would include “restroom” and “washroom.”</p>
<p id="p-0059" num="0058">WordNet module <b>235</b> generalizes knowledge in the knowledge base <b>245</b> by replacing synonyms with their hypernyms. WordNet module <b>235</b> then compacts the knowledge base by associating implications with hypernyms rather than with synonyms. Then, when a synonym is encountered, the hypernym can be determined and the hypernym's implications can be used. For example, if the knowledge base does not have any implications about “fork,” it can use implications about “silverware.” Without the WordNet synonym sets, a “fork” antecedent would not match any implications, and no consequent would be determined. The WordNet synonym sets also save memory by storing each implication once (at the hypernym level), rather than storing each implication multiple times (at the synonym level). Also, better reasoning results can be obtained by first pruning irrelevant hypernyms from the WordNet synonym sets based on the real-world context.</p>
<p id="p-0060" num="0059">If the synonyms co-occurred in the knowledge base, then they would have already been clustered together by latent semantic analysis or a similar technique. WordNet has the added benefit of clustering synonyms together even if they do not occur in the knowledge base. An alternative is to assemble a list of synonyms for a term and then use the synonyms as part of the feature vector for latent semantic analysis. Step <b>425</b> is optional, but compiling the knowledge base enables more implications to be used, saves storage space, and increases the speed of the reasoning process.</p>
<p id="p-0061" num="0060">After knowledge base processing program <b>205</b> has compiled <b>425</b> the knowledge base <b>245</b> using WordNet module <b>235</b>, knowledge base processing program <b>205</b> ends <b>430</b>. This also ends the processing of the knowledge base <b>245</b> (step <b>310</b> in <figref idref="DRAWINGS">FIG. 3</figref>).</p>
<p id="p-0062" num="0061">At this point, the knowledge base is self-consistent. It is preferably completely self-consistent, but in one embodiment, it is substantially self-consistent. In addition, there is a unique implication leading to each consequent, which means that there is a unique antecedent for each consequent. The next step is to actually use the reasoning apparatus <b>100</b>. A person submits a command to the reasoning apparatus <b>100</b>, and main program <b>200</b> receives <b>315</b> the command.</p>
<p id="p-0063" num="0062">Reasoning apparatus <b>100</b> can process a command even if the command contains a word that is not in the knowledge base. For example, one query is “Where might I find a carafe?” The knowledge base has the following two pieces of information: 1) Bottles and refrigerators are found together; and 2) Refrigerators are found in the kitchen. First, main program <b>200</b> uses WordNet module <b>235</b> to prune out irrelevant senses of “bottle” in the context of an indoor environment. From the remaining senses, main program <b>200</b> determines that “bottle” is a hypernym for “carafe.” Since “bottle” is a hypernym for “carafe,” knowledge about bottles also applies to carafes. Thus, carafes and refrigerators are found together. Since refrigerators are found in the kitchen, so are carafes.</p>
<p id="p-0064" num="0063">After main program <b>200</b> has received <b>315</b> the command, it performs <b>320</b> the task specified by the command. After main program <b>200</b> has performed <b>320</b> the task, it ends <b>325</b>.</p>
<p id="p-0065" num="0064">Reasoning apparatus <b>100</b> can be used in many different contexts. The discussion below focuses on using reasoning apparatus <b>100</b> in conjunction with a mobile robot in an indoor home or office environment. However, reasoning apparatus <b>100</b> could also be used without a robot and in environments other than a home or office. Reasoning apparatus <b>100</b> can also be used to perform many different types of tasks. One task is to answer a query. In one situation, reasoning apparatus <b>100</b> may be able to answer the query using information already in the knowledge base. In another situation, answering a query may also require inferencing based on that information.</p>
<p id="h-0007" num="0000">2.1 Sample Task: Goal Achievement</p>
<p id="p-0066" num="0065">Another task is to determine a course of action that is designed to achieve a particular goal. This goal can be directly input by a user, or its desirability can be deduced by the reasoning apparatus <b>100</b> based on the knowledge base and inferencing. Once the goal is known, reasoning apparatus <b>100</b> can determine a course of action to perform in order to achieve the goal. The course of action would be determined by backward chaining implications starting at the goal situation.</p>
<p id="p-0067" num="0066">In this embodiment, the variable D denotes the set of all statements that are explicitly desired. The variable D* denotes the set of all statements that are desired, either explicitly or by implication. D* is given by the recursive definition
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>D*=D∪{φ:φ′→</i><sub>d</sub><i>φεI</i><img id="CUSTOM-CHARACTER-00002" he="1.78mm" wi="1.78mm" file="US07299110-20071120-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/><i>φ′εS*}</i><?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
D* is a function of time because the states of objects can change and new knowledge can be inserted into the knowledge base <b>245</b>. The variable C denotes the set of all statements that are capable of being directly accomplished by the robot. The variable C* denotes the set of all statements that are capable of being accomplished by the robot, either directly or indirectly (i.e., by implication). C* is given by the recursive definition
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>C*=C∪{φ:φ′→φεF</i><img id="CUSTOM-CHARACTER-00003" he="1.78mm" wi="1.78mm" file="US07299110-20071120-P00001.TIF" alt="custom character" img-content="character" img-format="tif"/><i>φ′εC*}</i><?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
C* is a function of time because the states of objects can change and new knowledge can be inserted into the knowledge base <b>245</b>.
</p>
<p id="p-0068" num="0067">For example, assume that reasoning apparatus <b>100</b> is used in conjunction with a robot. The first step is for reasoning apparatus <b>100</b> to determine a goal. The robot touches a soda can and senses that it is warm. Main program <b>200</b> then performs inferencing over “(soda-can, warm)” using inferencing program <b>210</b>. Inferencing program <b>210</b> checks whether “(soda-can, warm)” is the antecedent of any desires implications. If there is more than one matching desires implication, inferencing program <b>210</b> chooses the implication with the closest meaning (based on latent semantic analysis or a similar technique). Eventually, inferencing program <b>210</b> chooses the implication
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>φ<sub>1</sub>→<sub>d</sub>φ<sub>2 </sub>where φ<sub>1</sub>=(soda-can, warm) and φ<sub>2</sub>=(soda-can, chilled)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
Since this is a desires implication, the consequent is the goal. Thus, inferencing program <b>210</b> has just determined the goal “(soda-can, chilled)” without any user input.
</p>
<p id="p-0069" num="0068">The next step is for reasoning apparatus <b>100</b> to determine a course of action to perform in order to achieve the goal. Main program <b>200</b> performs inferencing over the goal using inferencing program <b>210</b>. This time, however, inferencing program <b>210</b> checks whether “(soda-can, chilled)” is the consequent of any causes implications.</p>
<p id="p-0070" num="0069">In one embodiment, inferencing program <b>210</b> uses the following action-selection algorithm. The algorithm uses state knowledge and common sense to determine a list of actions to take. Given the implications (I and F), the current state (S and D) and the capabilities of the robot (C), the following algorithm computes the actions that the robot should take:</p>
<p id="p-0071" num="0070">
<tables id="TABLE-US-00002" num="00002">
<table frame="none" colsep="0" rowsep="0">
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="21pt" align="left"/>
<colspec colname="1" colwidth="196pt" align="left"/>
<thead>
<row>
<entry/>
<entry namest="offset" nameend="1" align="center" rowsep="1"/>
</row>
</thead>
<tbody valign="top">
<row>
<entry/>
<entry>GETACTIONS(I, F, S, D, C)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="35pt" align="left"/>
<colspec colname="1" colwidth="182pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>A ← 0</entry>
</row>
<row>
<entry/>
<entry>Q ← S</entry>
</row>
<row>
<entry/>
<entry>R ← D</entry>
</row>
<row>
<entry/>
<entry>while Q ≠ &lt;&gt;</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="49pt" align="left"/>
<colspec colname="1" colwidth="168pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>do φ ← Q.pop_front</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="63pt" align="left"/>
<colspec colname="1" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>R ← R ∪ {φ′ : φ →<sub>d </sub>φ′ ∈ I}</entry>
</row>
<row>
<entry/>
<entry>Q.push_back(&lt;φ′ : φ → φ′ ∈ F&gt;)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="35pt" align="left"/>
<colspec colname="1" colwidth="182pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>for each φ<sub>d </sub>in R</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="49pt" align="left"/>
<colspec colname="1" colwidth="168pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>do Q ← &lt;φ : φ → φ<sub>d </sub>∈ F&gt;</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="63pt" align="left"/>
<colspec colname="1" colwidth="154pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>while Q ≠ &lt;&gt;</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="77pt" align="left"/>
<colspec colname="1" colwidth="140pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>do φ ← Q.pop_front</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="91pt" align="left"/>
<colspec colname="1" colwidth="126pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>if φ ∈ C</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="105pt" align="left"/>
<colspec colname="1" colwidth="112pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>then A ← A ∪ {φ}</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="91pt" align="left"/>
<colspec colname="1" colwidth="126pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>Q.push_back(&lt;φ′ : φ′ → φ ∈ F&gt;)</entry>
</row>
</tbody>
</tgroup>
<tgroup align="left" colsep="0" rowsep="0" cols="2">
<colspec colname="offset" colwidth="35pt" align="left"/>
<colspec colname="1" colwidth="182pt" align="left"/>
<tbody valign="top">
<row>
<entry/>
<entry>return A</entry>
</row>
<row>
<entry/>
<entry namest="offset" nameend="1" align="center" rowsep="1"/>
</row>
</tbody>
</tgroup>
</table>
</tables>
<br/>
Note that this exact algorithm is not required. The same inferencing can be performed using, for example, a theorem prover or general purpose inferencing engine like SNARK™ (SRI's New Automated Reasoning Kit) from SRI International.
</p>
<p id="p-0072" num="0071">Eventually, inferencing program <b>210</b> finds the implication
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>φ<sub>1</sub>→φ<sub>2 </sub>where φ<sub>1</sub>=(soda-can, refrigerated) and φ<sub>2</sub>=(soda-can, chilled)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
Since this is a causes implication, the course of action to achieve the goal is the antecedent. Thus, inferencing program <b>210</b> has just determined the necessary course of action. Note that the inferencing necessary to determine the goal and the inferencing necessary to determine the course of action required only one step. Inferencing program <b>210</b> can also determine goals and courses of action where more than one inferencing step is necessary.
</p>
<p id="p-0073" num="0072">Once the course of action has been determined, the reasoning apparatus <b>100</b> can proceed to carry out those actions in order to achieve the goal (e.g., if the reasoning apparatus <b>100</b> were used in conjunction with a robot). Reasoning apparatus <b>100</b> directs the robot to perform these actions, the actions are performed, and the goal is achieved. In this embodiment, the knowledge base <b>245</b> would also contain information about objects themselves (the Objects relation) and how various objects are used (the Uses relation). The robot would use this information to determine how to accomplish various tasks. The knowledge base <b>245</b> might also contain information about in what types of rooms particular objects are usually found (the Locations relation) and which objects are usually found together (the Proximity relation). The robot would use this information to determine where to find a particular object that it needs to perform a task. Each of these relations was discussed above with reference to a possible database implementation.</p>
<p id="h-0008" num="0000">2.2 Sample Task: Location Determination</p>
<p id="p-0074" num="0073">Reasoning apparatus <b>100</b> can also use its observations of the environment and its common sense knowledge about objects and locations to determine its own location. Location determination is helpful when, for example, reasoning apparatus <b>100</b> is used in conjunction with a mobile robot. A related task is to label rooms and open areas in a home or office given 1) a two-dimensional map, 2) location knowledge, and 3) simulated objects and room labels. In order for the robot and people to have natural interactions, it is helpful for the robot to possess knowledge of the surrounding space, such as a layout of rooms. Map structure can be generated using common sense constraints such as 1) an office is owned by an individual; 2) a gallery and a walkway are not owned by an individual; and 3) a reception area is located at an entrance to an office.</p>
<p id="p-0075" num="0074">Map layout information, such as labels of objects and rooms, can then be incorporated into sentences and modified map layouts to reflect sentential information. This is further discussed in “Reasoning with Analogical Representations” by K. Myers and K. Konolige, in Principles of Knowledge Representation and Reasoning: Proceedings of the Third International Conference (KR92) (B. Nebel, C. Rich, and W. Swartout, eds.), San Mateo, Calif., 1992, which is hereby incorporated by reference. Note that a map does not have to be human-generated; it can also be generated by laser data. Laser data can also be extracted from cameras to build a sparse map of the unknown environment.</p>
<p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. 5</figref> illustrates a method for determining a location using Bayesian inferencing. For example, a robot is located in one room (a)) of a set of rooms (ω): ωεΩ. Reasoning apparatus <b>100</b> determines the type of the room based on 1) which objects are probably present in the room, 2) which of these objects is usually found in each type of room, and 3) how common these objects are in general. When these probabilities are used with Bayes' theorem, the type of room with the highest probability can be calculated.</p>
<p id="p-0077" num="0076">After the method begins <b>500</b>, reasoning apparatus <b>100</b> determines <b>505</b> which objects are in the room. The robot collects knowledge (D) about objects in the room using one or more methods. These methods include, for example, direct user input (e.g., by typing in “This room contains a bed”) or speech recognition (e.g., by hearing a person say “This room contains a bed” and then processing the speech). Ideally, a mobile robot should be able to associate human terms with sensory data by receiving a running description of its immediate surroundings as it explores a new home or office. These human-provided labels could be room types (e.g., “This is a kitchen”) or objects (“This is a chair”). Another possibility is for reasoning apparatus <b>100</b> to use object recognition (e.g., by taking a picture of the room and then processing the picture).</p>
<p id="p-0078" num="0077">Based on this knowledge, the robot determines whether certain objects (x) are present in the room. If the robot's knowledge were perfect, then it would know with 100% certainty which objects were present. However, each of the methods discussed above has a different inherent confidence value (level of certainty). While direct user input might have close to 100% certainty, speech recognition probably has less certainty, perhaps only 91%. This means that if speech recognition determines that there is a bed in the room, the probability that there is actually a bed in the room might be 91%. Since the level of certainty differs based on the method used, the probability that particular objects have been observed is the conditional probability distribution P(x<sub>i</sub>|D) over the objects x<sub>i</sub>∈X.</p>
<p id="p-0079" num="0078">Next, reasoning apparatus <b>100</b> determines <b>510</b> which of these objects is usually found in each type of room. This is represented symbolically as P(x<sub>i</sub>|ω). One way to calculate this value is to count the number of entries in the knowledge base wherein a particular object x<sub>i </sub>is mentioned as being in a particular room ω and then divide by the number of entries of wherein any object x is mentioned as being in that particular room ω. This can be represented symbolically as
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>P</i>(<i>x</i><sub>i</sub>|ω)=<i>C</i>(<i>x</i><sub>i</sub>,ω)/<i>C</i>(ω), where x<sub>i </sub>is a particular object and ω is a particular room<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0080" num="0079">Reasoning apparatus <b>100</b> then determines <b>515</b> how common these objects are in general. This is represented symbolically as P(x<sub>i</sub>). One way to calculate this value is to count the number of entries in the knowledge base wherein a particular object x<sub>i </sub>is mentioned and then divide by the total number of entries in the knowledge base.</p>
<p id="p-0081" num="0080">Lastly, reasoning apparatus <b>100</b> determines <b>520</b> the location of the robot. The room in which the robot is located is given by</p>
<p id="p-0082" num="0081">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <msup>
          <mi>ω</mi>
          <mi>′</mi>
        </msup>
        <mo>=</mo>
        <mi/>
        <mo>⁢</mo>
        <mrow>
          <mi>arg</mi>
          <mo>⁢</mo>
          <mrow>
            <munder>
              <mi>max</mi>
              <mi>ωeΩ</mi>
            </munder>
            <mo>⁢</mo>
            <mrow>
              <mi>P</mi>
              <mo>⁢</mo>
              <mstyle>
                <mspace width="0.6em" height="0.6ex"/>
              </mstyle>
              <mo>⁢</mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mi>ω</mi>
                  <mo>❘</mo>
                  <mi>D</mi>
                </mrow>
                <mo>)</mo>
              </mrow>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mo>=</mo>
        <mi/>
        <mo>⁢</mo>
        <mrow>
          <mi>arg</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mrow>
            <munder>
              <mi>max</mi>
              <mi>ωeΩ</mi>
            </munder>
            <mo>⁢</mo>
            <mrow>
              <munderover>
                <mo>∑</mo>
                <mi>x</mi>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
              </munderover>
              <mo>⁢</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>⁢</mo>
              <mrow>
                <mi>P</mi>
                <mo>⁡</mo>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <mi>ω</mi>
                    <mo>,</mo>
                    <mrow>
                      <mi>x</mi>
                      <mo>❘</mo>
                      <mi>D</mi>
                    </mrow>
                  </mrow>
                  <mo>)</mo>
                </mrow>
              </mrow>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mo>=</mo>
        <mi/>
        <mo>⁢</mo>
        <mrow>
          <mi>arg</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mrow>
            <munder>
              <mi>max</mi>
              <mi>ωeΩ</mi>
            </munder>
            <mo>⁢</mo>
            <mrow>
              <munderover>
                <mo>∑</mo>
                <mi>x</mi>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
              </munderover>
              <mo>⁢</mo>
              <mfrac>
                <mrow>
                  <mrow>
                    <mi>P</mi>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mi>ω</mi>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>⁢</mo>
                  <mrow>
                    <mi>P</mi>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>x</mi>
                        <mo>❘</mo>
                        <mi>ω</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>⁢</mo>
                  <mrow>
                    <mi>P</mi>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>x</mi>
                        <mo>❘</mo>
                        <mi>D</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                </mrow>
                <mrow>
                  <mi>P</mi>
                  <mo>⁡</mo>
                  <mrow>
                    <mo>(</mo>
                    <mi>x</mi>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mfrac>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mo>=</mo>
        <mi/>
        <mo>⁢</mo>
        <mrow>
          <mi>arg</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.3em" height="0.3ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mrow>
            <munder>
              <mi>max</mi>
              <mi>ωeΩ</mi>
            </munder>
            <mo>⁢</mo>
            <mrow>
              <mrow>
                <mi>P</mi>
                <mo>⁡</mo>
                <mrow>
                  <mo>(</mo>
                  <mi>ω</mi>
                  <mo>)</mo>
                </mrow>
              </mrow>
              <mo>⁢</mo>
              <munderover>
                <mrow>
                  <mo>∑</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                </mrow>
                <msub>
                  <mi>x</mi>
                  <mn>1</mn>
                </msub>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
              </munderover>
              <mo>⁢</mo>
              <mfrac>
                <mrow>
                  <mrow>
                    <mi>P</mi>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <msub>
                          <mi>x</mi>
                          <mn>1</mn>
                        </msub>
                        <mo>❘</mo>
                        <mi>ω</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>⁢</mo>
                  <mrow>
                    <mi>P</mi>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <msub>
                          <mi>x</mi>
                          <mn>1</mn>
                        </msub>
                        <mo>❘</mo>
                        <mi>D</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                </mrow>
                <mrow>
                  <mi>P</mi>
                  <mo>⁡</mo>
                  <mrow>
                    <mo>(</mo>
                    <msub>
                      <mi>x</mi>
                      <mn>1</mn>
                    </msub>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mfrac>
              <mo>⁢</mo>
              <mi>…</mi>
              <mo>⁢</mo>
              <munderover>
                <mrow>
                  <mo>∑</mo>
                  <mfrac>
                    <mrow>
                      <mrow>
                        <mi>P</mi>
                        <mo>⁡</mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <msub>
                              <mi>x</mi>
                              <mi>n</mi>
                            </msub>
                            <mo>❘</mo>
                            <mi>ω</mi>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                      <mo>⁢</mo>
                      <mrow>
                        <mi>P</mi>
                        <mo>⁡</mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <msub>
                              <mi>x</mi>
                              <mi>n</mi>
                            </msub>
                            <mo>❘</mo>
                            <mi>D</mi>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                    </mrow>
                    <mrow>
                      <mi>P</mi>
                      <mo>⁡</mo>
                      <mrow>
                        <mo>(</mo>
                        <msub>
                          <mi>x</mi>
                          <mi>n</mi>
                        </msub>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                  </mfrac>
                </mrow>
                <msub>
                  <mi>x</mi>
                  <mi>n</mi>
                </msub>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
              </munderover>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mo>=</mo>
        <mi/>
        <mo>⁢</mo>
        <mrow>
          <mrow>
            <mi>arg</mi>
            <mo>⁢</mo>
            <mrow>
              <munder>
                <mi>max</mi>
                <mi>ωeΩ</mi>
              </munder>
              <mo>⁢</mo>
              <mrow>
                <mi>ln</mi>
                <mo>⁢</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
                <mo>⁢</mo>
                <mrow>
                  <mi>P</mi>
                  <mo>⁡</mo>
                  <mrow>
                    <mo>(</mo>
                    <mi>ω</mi>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mrow>
            </mrow>
          </mrow>
          <mo>+</mo>
          <mrow>
            <munderover>
              <mrow>
                <mo>∑</mo>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
              </mrow>
              <mrow>
                <mi>i</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
              <mi>n</mi>
            </munderover>
            <mo>⁢</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
            <mo>⁢</mo>
            <mi>ln</mi>
            <mo>⁢</mo>
            <mrow>
              <munderover>
                <mo>∑</mo>
                <msub>
                  <mi>x</mi>
                  <mi>i</mi>
                </msub>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
              </munderover>
              <mo>⁢</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"/>
              </mstyle>
              <mo>⁢</mo>
              <mfrac>
                <mrow>
                  <mrow>
                    <mi>P</mi>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <msub>
                          <mi>x</mi>
                          <mi>i</mi>
                        </msub>
                        <mo>❘</mo>
                        <mi>ω</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>⁢</mo>
                  <mrow>
                    <mi>P</mi>
                    <mo>⁡</mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <msub>
                          <mi>x</mi>
                          <mi>i</mi>
                        </msub>
                        <mo>❘</mo>
                        <mi>D</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                </mrow>
                <mrow>
                  <mi>P</mi>
                  <mo>⁡</mo>
                  <mrow>
                    <mo>(</mo>
                    <msub>
                      <mi>x</mi>
                      <mi>i</mi>
                    </msub>
                    <mo>)</mo>
                  </mrow>
                </mrow>
              </mfrac>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
<br/>
Vector x indicates the presence or absence of the objects. Each object x<sub>i </sub>is associated with an index i. If the value of x at index i is 1, then object x<sub>i </sub>is present; if the value is 0, then object x<sub>i </sub>is not present. Since x contains only binary values, the computational complexity is linear in the number of possible objects. In order to calculate the above value, we assume a generative Bayesian model where ω influences x and x influences D and calculate the joint distribution
</p>
<p id="p-0083" num="0082">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>P</mi>
          <mo>⁡</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mi>ω</mi>
              <mo>,</mo>
              <mi>x</mi>
              <mo>,</mo>
              <mi>D</mi>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mi/>
        <mo>⁢</mo>
        <mrow>
          <mrow>
            <mi>P</mi>
            <mo>⁡</mo>
            <mrow>
              <mo>(</mo>
              <mi>ω</mi>
              <mo>)</mo>
            </mrow>
          </mrow>
          <mo>⁢</mo>
          <mrow>
            <mi>P</mi>
            <mo>⁡</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>x</mi>
                <mo>❘</mo>
                <mi>ω</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
          <mo>⁢</mo>
          <mrow>
            <mi>P</mi>
            <mo>⁡</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>D</mi>
                <mo>❘</mo>
                <mi>x</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mo>=</mo>
        <mi/>
        <mo>⁢</mo>
        <mfrac>
          <mrow>
            <mrow>
              <mi>P</mi>
              <mo>⁡</mo>
              <mrow>
                <mo>(</mo>
                <mi>ω</mi>
                <mo>)</mo>
              </mrow>
            </mrow>
            <mo>⁢</mo>
            <mrow>
              <mi>P</mi>
              <mo>⁡</mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mi>x</mi>
                  <mo>❘</mo>
                  <mi>ω</mi>
                </mrow>
                <mo>)</mo>
              </mrow>
            </mrow>
            <mo>⁢</mo>
            <mrow>
              <mi>P</mi>
              <mo>⁡</mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mi>x</mi>
                  <mo>❘</mo>
                  <mi>D</mi>
                </mrow>
                <mo>)</mo>
              </mrow>
            </mrow>
            <mo>⁢</mo>
            <mrow>
              <mi>P</mi>
              <mo>⁡</mo>
              <mrow>
                <mo>(</mo>
                <mi>D</mi>
                <mo>)</mo>
              </mrow>
            </mrow>
          </mrow>
          <mrow>
            <mi>P</mi>
            <mo>⁡</mo>
            <mrow>
              <mo>(</mo>
              <mi>x</mi>
              <mo>)</mo>
            </mrow>
          </mrow>
        </mfrac>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0084" num="0083">Although the invention has been described in considerable detail with reference to certain embodiments thereof, other embodiments are possible as will be understood to those skilled in the art.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US07299110-20071120-M00001.NB">
<img id="EMI-M00001" he="41.23mm" wi="76.20mm" file="US07299110-20071120-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US07299110-20071120-M00002.NB">
<img id="EMI-M00002" he="10.92mm" wi="76.20mm" file="US07299110-20071120-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for processing a knowledge base, the knowledge base comprising a plurality of statements and a plurality of rules, a rule linking two statements, the method comprising:
<claim-text>grouping words of related meanings comprise one of latent semantic analysis, spectral clustering, and principal component analysis; and</claim-text>
<claim-text>determining a set of relevant rules.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step of:
<claim-text>generalizing the knowledge base by replacing a statement associated with a first object with a statement associated with a second object, the second object being a hypernym of the first object.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step of:
<claim-text>inferencing using the knowledge base.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref> wherein inferencing using the knowledge base comprises the step of:
<claim-text>inferencing using an object not present in the knowledge base.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref> wherein the object not present in the knowledge base is one of a hypernym and a synonym of an object that is present in the knowledge base.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, further comprising the step of one of answering a query, determining how to perform a task, and determining how to fulfill a desire.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, further comprising the step of one of determining consensus knowledge and determining common sense knowledge.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, further comprising the step of determining a location of a robot.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step of:
<claim-text>correcting a spelling of a word in the knowledge base, responsive to a determination that the spelling is incorrect.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step of:
<claim-text>removing a word, responsive to a determination that the word is on a list of stopwords.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step of:
<claim-text>replacing a word with a root form of the word, responsive to a determination that the word is not in root form.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. An apparatus for processing a knowledge base, the knowledge base comprising a plurality of statements and a plurality of rules, a rule linking two statements, the apparatus comprising:
<claim-text>a grouping module, configured to group words of related meanings comprise one of latent semantic analysis, spectral clustering, and principal component analysis; and</claim-text>
<claim-text>a relevancy module, configured to determine a set of relevant rules.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising:
<claim-text>a generalization module, configured to generalize the knowledge base by replacing a statement associated with a first object with a statement associated with a second object, the second object being a hypernym of the first object.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising:
<claim-text>an inference module, configured to inference using the knowledge base.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The apparatus of <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein inferencing using the knowledge base comprises:
<claim-text>inferencing using an object not present in the knowledge base.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the object not present in the knowledge base is one of a hypernym and a synonym of an object that is present in the knowledge base.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The apparatus of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising one of answering a query, determining how to perform a task, and determining how to fulfill a desire.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The apparatus of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising one of determining consensus knowledge and determining common sense knowledge.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The apparatus of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising determining a location of a robot.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising:
<claim-text>correcting a spelling of a word in the knowledge base, responsive to a determination that the spelling is incorrect.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising:
<claim-text>removing a word, responsive to a determination that the word is on a list of stopwords.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising:
<claim-text>replacing a word with a root form of the word, responsive to a determination that the word is not in root form.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. An apparatus for processing a knowledge base, the knowledge base comprising a plurality of statements and a plurality of rules, a rule linking two statements, the apparatus comprising:
<claim-text>means for grouping words of related meanings comprise one of latent semantic analysis, spectral clustering, and principal component analysis; and</claim-text>
<claim-text>means for determining a set of relevant rules.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The apparatus of <claim-ref idref="CLM-00023">claim 23</claim-ref>, further comprising:
<claim-text>means for generalizing the knowledge base by replacing a statement associated with a first object with a statement associated with a second object, the second object being a hypernym of the first object.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The apparatus of <claim-ref idref="CLM-00023">claim 23</claim-ref>, further comprising: means for inferencing using the knowledge base.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. The apparatus of <claim-ref idref="CLM-00025">claim 25</claim-ref> wherein inferencing using the knowledge base comprises:
<claim-text>inferencing using an object not present in the knowledge base.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The apparatus of <claim-ref idref="CLM-00026">claim 26</claim-ref> wherein the object not present in the knowledge base is one of a hypernym and a synonym of an object that is present in the knowledge base.</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The apparatus of <claim-ref idref="CLM-00025">claim 25</claim-ref>, further comprising one of means for answering a query, means for determining how to perform a task, and means for determining how to fulfill a desire.</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. The apparatus of <claim-ref idref="CLM-00025">claim 25</claim-ref>, further comprising one of means for determining consensus knowledge and means for determining common sense knowledge.</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. The apparatus of <claim-ref idref="CLM-00025">claim 25</claim-ref>, further comprising means for determining a location of a robot.</claim-text>
</claim>
<claim id="CLM-00031" num="00031">
<claim-text>31. The apparatus of <claim-ref idref="CLM-00023">claim 23</claim-ref>, further comprising:
<claim-text>means for correcting a spelling of a word in the knowledge base, responsive to a determination that the spelling is incorrect.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00032" num="00032">
<claim-text>32. The apparatus of <claim-ref idref="CLM-00023">claim 23</claim-ref>, further comprising:
<claim-text>means for removing a word, responsive to a determination that the word is on a list of stopwords.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00033" num="00033">
<claim-text>33. The apparatus of <claim-ref idref="CLM-00023">claim 23</claim-ref>, further comprising:
<claim-text>means for replacing a word with a root form of the word, responsive to a determination that the word is not in root form.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
