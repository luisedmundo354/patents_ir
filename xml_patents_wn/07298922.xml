<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298922-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298922</doc-number>
<kind>B1</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10886999</doc-number>
<date>20040707</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>687</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>32</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382294</main-classification>
<further-classification>382164</further-classification>
<further-classification>382284</further-classification>
<further-classification>382291</further-classification>
<further-classification>358518</further-classification>
<further-classification>358520</further-classification>
<further-classification>342 25 A</further-classification>
<further-classification>342409</further-classification>
</classification-national>
<invention-title id="d0e53">Synthetic panchromatic imagery method and system</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5812705</doc-number>
<kind>A</kind>
<name>Wang et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382294</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>6097835</doc-number>
<kind>A</kind>
<name>Lindgren</name>
<date>20000800</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6874420</doc-number>
<kind>B2</kind>
<name>Lewis et al.</name>
<date>20050400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>101485</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6990249</doc-number>
<kind>B2</kind>
<name>Nomura</name>
<date>20060100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382254</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>7075427</doc-number>
<kind>B1</kind>
<name>Pace et al.</name>
<date>20060700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>34053922</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7133083</doc-number>
<kind>B2</kind>
<name>Jaynes et al.</name>
<date>20061100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348745</main-classification></classification-national>
</citation>
<citation>
<nplcit num="00007">
<othercit>William K. Pratt, “Digital Image Processing”, Second Edition, Wiley-Interscience, pp. 651-673, 1991.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>25</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382164</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382167</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382284</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382294</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358  12</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358518</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>358520</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>342 25 A</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>342409</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>21</number-of-drawing-sheets>
<number-of-figures>21</number-of-figures>
</figures>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Lindgren</last-name>
<first-name>John Elmer</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Christie</last-name>
<first-name>David Nicholas</first-name>
<address>
<city>Brentwood</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>McDermott Will &amp; Emery LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Lockheed Martin Corporation</orgname>
<role>02</role>
<address>
<city>Bethesda</city>
<state>MD</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Mehta</last-name>
<first-name>Bhavesh M.</first-name>
<department>2624</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">Method and system for generating synthetic panchromatic imagery. A method for making a multi-spectral image includes capturing a panchromatic image of an imaging target. Additionally, the method includes capturing at least a first spectral image of the imaging target in a first spectral bandwidth, and capturing at least a second spectral image of the imaging target in a second spectral bandwidth. Also, the method includes determining at least a first spectral weight and a second spectral weight for the first spectral image and the second spectral image respectively. Additionally, the method includes generating a synthetic panchromatic image, determining a registration offset between the synthetic panchromatic image and the captured panchromatic image, warping the first spectral image and the second spectral image, and generating a multi-spectral image.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="146.39mm" wi="165.95mm" file="US07298922-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="167.89mm" wi="167.64mm" orientation="landscape" file="US07298922-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="204.89mm" wi="122.00mm" orientation="landscape" file="US07298922-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="169.33mm" wi="117.60mm" orientation="landscape" file="US07298922-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="139.45mm" wi="148.25mm" orientation="landscape" file="US07298922-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="132.16mm" wi="150.79mm" orientation="landscape" file="US07298922-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="136.57mm" wi="146.81mm" orientation="landscape" file="US07298922-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="121.16mm" wi="147.66mm" orientation="landscape" file="US07298922-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="187.03mm" wi="125.14mm" orientation="landscape" file="US07298922-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="187.62mm" wi="138.85mm" orientation="landscape" file="US07298922-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="188.13mm" wi="104.06mm" orientation="landscape" file="US07298922-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="187.54mm" wi="133.18mm" orientation="landscape" file="US07298922-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="188.38mm" wi="136.57mm" orientation="landscape" file="US07298922-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="136.06mm" wi="151.38mm" orientation="landscape" file="US07298922-20071120-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="132.00mm" wi="153.42mm" orientation="landscape" file="US07298922-20071120-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="134.87mm" wi="149.10mm" orientation="landscape" file="US07298922-20071120-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="134.87mm" wi="159.68mm" orientation="landscape" file="US07298922-20071120-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00017" num="00017">
<img id="EMI-D00017" he="110.32mm" wi="147.07mm" orientation="landscape" file="US07298922-20071120-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00018" num="00018">
<img id="EMI-D00018" he="133.60mm" wi="166.96mm" orientation="landscape" file="US07298922-20071120-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00019" num="00019">
<img id="EMI-D00019" he="134.03mm" wi="152.82mm" orientation="landscape" file="US07298922-20071120-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00020" num="00020">
<img id="EMI-D00020" he="125.73mm" wi="159.09mm" orientation="landscape" file="US07298922-20071120-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00021" num="00021">
<img id="EMI-D00021" he="131.40mm" wi="159.60mm" orientation="landscape" file="US07298922-20071120-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCES TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">NOT APPLICABLE</p>
<heading id="h-0002" level="1">STATEMENT AS TO RIGHTS TO INVENTIONS MADE UNDER FEDERALLY SPONSORED RESEARCH OR DEVELOPMENT</heading>
<p id="p-0003" num="0002">NOT APPLICABLE</p>
<heading id="h-0003" level="1">REFERENCE TO A “SEQUENCE LISTING,” A TABLE, OR A COMPUTER PROGRAM LISTING APPENDIX SUBMITTED ON A COMPACT DISK</heading>
<p id="p-0004" num="0003">NOT APPLICABLE</p>
<heading id="h-0004" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0005" num="0004">The present invention relates generally to imaging techniques. More particularly, the invention provides a method and system for generating synthetic panchromatic images. Merely by way of example, the invention has been applied to generating high resolution pan-sharpened multi-spectral images. The method and system for generating high resolution images can be used to generate satellite imagery products. Additionally, it would be recognized that the invention has a much broader range of applicability.</p>
<p id="p-0006" num="0005">Optical systems have been widely used for detecting color images of various targets. Such optical systems often employ a panchromatic detector and a multi-spectral detector. The panchromatic detector generates panchromatic gray-scale images, while the multi-spectral detector detects spectral images in various bands of wavelengths, such as red, green, blue and near infrared (“NIR”) bands. The panchromatic detector typically possesses a spatial resolution higher than that of the multi-spectral detector. Using the multi-spectral detector with relatively low resolution reduces costs of optical systems and associated transmission bandwidth requirements. Further, the high resolution panchromatic images and the low spatial resolution multi-spectral images can be mathematically combined to form high resolution multi-spectral images in a process called pan-sharpening. A system acquiring and synthesizing the multi-spectral images and the panchromatic images is described below.</p>
<p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. 1</figref> is a simplified diagram for a conventional optical system with panchromatic detector and multi-spectral detector. Optical system <b>110</b> is an imaging system positioned in a spacecraft that generates images of targets on the earth surface. Optical system <b>110</b> includes at least multi-spectral image detector <b>120</b> and panchromatic image detector <b>130</b>. Multi-spectral detector <b>120</b> generates multiple images in different bands of wavelengths. As discussed above, the bands of wavelength may include red, green, blue and NIR bands. Within optical system <b>110</b>, multi-spectral detector <b>120</b> and panchromatic detector <b>130</b> are placed in different locations. For each imaging object, optical system <b>110</b> generates multiple images, such as panchromatic, red, green, blue and NIR images. The specific processes for image acquisition is described below.</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. 2</figref> illustrates a simplified conventional process for optical system <b>110</b> to capture multiple images of an imaging target on the earth surface. Optical system <b>110</b> moves with respect to earth surface <b>210</b>. For example, at time t<sub>1</sub>, panchromatic detector <b>130</b> of optical system <b>110</b> captures a panchromatic image of imaging area <b>220</b>. Subsequently, at time t<sub>2</sub>, multi-spectral detector <b>120</b> of optical system <b>110</b> captures several spectral images of imaging area <b>220</b>. In another example, at time t<sub>1</sub>, multi-spectral detector <b>120</b> of optical system <b>110</b> captures several spectral images of imaging area <b>220</b>. Subsequently, at time t<sub>2</sub>, panchromatic detector <b>130</b> of optical system <b>110</b> captures a black-and-white image of imaging area <b>220</b>. The interval between time t<sub>1 </sub>and time t<sub>2 </sub>is usually small. For example, the interval may be only 0.5 second. Nonetheless, during this short interval, imaging surface <b>220</b> may have changed. Additionally, imaging angle α<sub>1 </sub>at time t<sub>1 </sub>and imaging angle α<sub>2 </sub>at time t<sub>2 </sub>are usually different. The imaging angle is the angle between the imaging direction and the reference direction vertical to imaging area <b>220</b>. Consequently, the panchromatic image may not match the multi-spectral images, and this mismatch creates difficulties in producing high resolution color images.</p>
<p id="p-0009" num="0008">Hence it is desirable to improve technique for creating high resolution color images.</p>
<heading id="h-0005" level="1">BRIEF SUMMARY OF THE INVENTION</heading>
<p id="p-0010" num="0009">The present invention relates generally to imaging techniques. More particularly, the invention provides a method and system for generating synthetic panchromatic images. Merely by way of example, the invention has been applied to generating high resolution pan-sharpened multi-spectral images. The method and system for generating high resolution images can be used to generate satellite imagery products. Additionally, it would be recognized that the invention has a much broader range of applicability.</p>
<p id="p-0011" num="0010">According to the present invention, a number of embodiments for generating and using synthetic panchromatic images are provided. Merely by way of an example, a method for making a multi-spectral image includes capturing a panchromatic image of an imaging target. The captured panchromatic image is associated with a captured panchromatic resolution. Additionally, the method includes capturing at least a first spectral image of the imaging target in a first spectral bandwidth. The first spectral image is associated with a first spectral resolution. Moreover, the method includes capturing at least a second spectral image of the imaging target in a second spectral bandwidth. The second spectral image is associated with a second spectral resolution. Also, the method includes determining at least a first spectral weight and a second spectral weight for the first spectral image and the second spectral image respectively based on at least information associated with the captured panchromatic image, the first spectral image and the second spectral image. Additionally, the method includes generating a synthetic panchromatic image based on at least information associated with the first spectral image, the second spectral image, the first spectral weight, and the second spectral weight. The synthetic panchromatic image is associated with a synthetic panchromatic resolution. Moreover, the method includes determining a registration offset between the synthetic panchromatic image and the captured panchromatic image by matching a first pixel on the synthetic panchromatic image and a second pixel on the captured panchromatic image. The first pixel and the second pixel correspond to a same portion of the imaging target. Also, the method includes warping the first spectral image and the second spectral image based on at least information associated with the registration offset, and generating a multi-spectral image based on at least information associated with the first spectral image, the second spectral image, the first spectral weight, the second spectral weight, the captured panchromatic image, and the registration offset. The generated multi-spectral image is associated with a third resolution.</p>
<p id="p-0012" num="0011">According to another embodiment of the present invention, a method for making a multi-spectral image includes capturing a panchromatic image of an imaging target. The captured panchromatic image is associated with a captured panchromatic spatial resolution. Additionally, the method includes capturing at least a first spectral image of the imaging target in a first spectral bandwidth. The first spectral image is associated with a first spectral spatial resolution, and the first spectral spatial resolution is lower than the captured panchromatic spatial resolution. Moreover, the method includes capturing at least a second spectral image of the imaging target in a second spectral bandwidth. The second spectral image is associated with a second spectral spatial resolution, and the second spectral spatial resolution is lower than the captured panchromatic spatial resolution. Also, the method includes generating a synthetic panchromatic image based on at least information associated with the first spectral image and the second spectral image. The synthetic panchromatic image is associated with a synthetic panchromatic spatial resolution. Additionally, the method includes processing at least information associated with the synthetic panchromatic image and the captured panchromatic image, and determining a registration offset between the synthetic panchromatic image and the captured panchromatic image by matching a first pixel on the synthetic panchromatic image and a second pixel on the captured panchromatic image. The first pixel and the second pixel correspond to a same portion of the imaging target. Moreover, the method includes warping the first spectral image and the second spectral image based on at least information associated with the registration offset, and generating a multi-spectral image based on at least information associate with the first spectral image, the second spectral image, the first spectral weight, the second spectral weight, the captured panchromatic image, and the registration offset. The multi-spectral image is associated with a third spatial resolution, and the third spatial resolution is substantially equal to the captured panchromatic spatial resolution.</p>
<p id="p-0013" num="0012">According to yet another embodiment of the present invention, a method for making a color image includes capturing a panchromatic image of an imaging target. The captured panchromatic image is associated with a captured panchromatic resolution. Additionally, the method includes capturing at least a first spectral image of the imaging target in a first spectral bandwidth. The first spectral image is associated with a first spectral resolution. Moreover, the method includes capturing at least a second spectral image of the imaging target in a second spectral bandwidth. The second spectral image is associated with a second spectral resolution. Also, the method includes determining at least a first spectral weight and a second spectral weight for the first spectral image and the second spectral image respectively based on at least information associated with the captured panchromatic image, the first spectral image and the second spectral image, and generating a synthetic panchromatic image based on at least information associated with the first spectral image, the second spectral image, the first spectral weight, and the second spectral weight. The synthetic panchromatic image is associated with a synthetic panchromatic resolution. Additionally, the method includes determining a registration offset between the synthetic panchromatic image and the captured panchromatic image by matching a first pixel on the synthetic panchromatic image and a second pixel on the captured panchromatic image. The first pixel and the second pixel correspond to a same portion of the imaging target. Moreover, the method includes warping the first spectral image and the second spectral image based on at least information associated with the registration offset, and generating a color image based on at least information associated with the first spectral image, the second spectral image, the first spectral weight, the second spectral weight, the captured panchromatic image, and the registration offset. The generated multi-spectral image is associated with a third resolution. The color image is free from image distortion, smeared color, and saturated color.</p>
<p id="p-0014" num="0013">Many benefits may be achieved by way of the present invention over conventional techniques. For example, certain embodiments of the present invention improve the quality of panchromatic sharpening processes and subsequently derived high quality multi-spectral image products. In some embodiments of the present invention, the synthetic panchromatic image can provide high correlation with the captured panchromatic image. This high correlation leads to accurate panchromatic to multi-spectral registration offset generation and thus improves effectiveness of subsequent panchromatic sharpening. Certain embodiments of the present invention allow panchromatic sensor and/or spectral imaging sensors to be designed with less strict requirements in order to maintain the same image registration accuracy. Use of synthetic panchromatic image allows effective post-processing to remove image misregistration artifacts caused by sensors. Some embodiments of the present invention can be implemented very efficiently using existing hardware and software technology.</p>
<p id="p-0015" num="0014">Depending upon the embodiment under consideration, one or more of these benefits may be achieved. These benefits and various additional objects, features and advantages of the present invention can be fully appreciated with reference to the detailed description and accompanying drawings that follow.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 1</figref> is a simplified diagram for a conventional optical system with panchromatic detector and multi-spectral detector.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 2</figref> illustrates a simplified conventional process for optical system to capture multiple images of an imaging target on the earth surface.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 3</figref> illustrates a simplified misalignment between a panchromatic image and a spectral image according to one embodiment of the present invention.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 4</figref> shows certain geometrical degradations and distortions in pan-sharpened multi-spectral imagery.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 5</figref> shows certain smeared colors in pan-sharpened multi-spectral imagery.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 6</figref> shows certain saturated colors in pan-sharpened multi-spectral imagery.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 7</figref> is a simplified block diagram for a method using a synthetic panchromatic image to synthesize a multi-spectral image according to one embodiment of the present invention.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIGS. 8 and 9</figref> are simplified diagrams showing different resolutions for captured panchromatic image and synthetic panchromatic image.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 10</figref> is a simplified block diagram for registering images according to one embodiment of the present invention.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 11</figref> shows a simplified diagram for maximizing correlation according to one embodiment of the present invention.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 12</figref> shows a simplified diagram for maximizing correlation according to another embodiment of the present invention.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIGS. 13(A)</figref>, (B), and (C) are simplified diagrams showing superior image quality according to one embodiment of the present invention.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIGS. 14(A)</figref>, (B), and (C) are simplified diagrams showing superior image quality according to another embodiment of the present invention.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIGS. 15(A)</figref>, (B), and (C) are simplified diagrams showing superior image quality according to yet another embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0007" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0030" num="0029">The present invention relates generally to imaging techniques. More particularly, the invention provides a method and system for generating synthetic panchromatic images. Merely by way of example, the invention has been applied to generating high resolution pan-sharpened multi-spectral images. The method and system for generating high resolution images can be used to generate satellite imagery products. Additionally, it would be recognized that the invention has a much broader range of applicability.</p>
<p id="p-0031" num="0030">As shown in <figref idref="DRAWINGS">FIG. 2</figref>, multi-spectral detector <b>120</b> and panchromatic detector <b>130</b> usually capture images at different times. During the interval, imaging area may have changed. Additionally, imaging angle α<sub>1 </sub>at time t<sub>1 </sub>and imaging angle α<sub>2 </sub>at time t<sub>2 </sub>are usually different. Consequently, the spectral images captured by multi-spectral detector <b>120</b> are not aligned with the panchromatic image captured by panchromatic detector <b>130</b>.</p>
<p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. 3</figref> illustrates a simplified misalignment between a panchromatic image and a spectral image according to one embodiment of the present invention. This diagram is merely an example, which should not unduly limit the scope of the claims. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. Panchromatic image <b>310</b> and spectral image <b>320</b> are captured for the same imaging target. Thus a certain area of the imaging target corresponds to a pixel on panchromatic image <b>310</b> and a larger area of the imaging target corresponds to a pixel on spectral image <b>320</b>. The pixel has a position in panchromatic image <b>310</b> that is different from the pixel in spectral image <b>320</b>. For example, the pixel on spectral image <b>320</b> represents an area of the imaging target that is further to the right than the area associated with the pixel on panchromatic image <b>310</b>. In some applications, panchromatic image <b>310</b> usually has a higher resolution than spectral image <b>320</b>. Several spectral images are pan-sharpened with a panchromatic image to create a high resolution multi-spectral image. The misregistration between panchromatic image <b>310</b> and spectral image <b>320</b> usually reduces the quality of pan-sharpened multi-spectral imagery. The pan-sharpened multi-spectral image becomes less radiometrically accurate and less visually crisp.</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIGS. 4</figref>, <b>5</b>, and <b>6</b> illustrate various types of image defects. These diagrams are merely examples, which should not unduly limit the scope of the claims. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. <figref idref="DRAWINGS">FIG. 4</figref> shows certain geometrical degradations and distortions in pan-sharpened multi-spectral imagery, <figref idref="DRAWINGS">FIG. 5</figref> shows certain smeared colors in pan-sharpened multi-spectral imagery, and <figref idref="DRAWINGS">FIG. 6</figref> shows certain saturated colors in pan-sharpened multi-spectral imagery.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. 7</figref> is a simplified block diagram for a method using a synthetic panchromatic image to synthesize a multi-spectral image according to one embodiment of the present invention. This diagram is merely an example, which should not unduly limit the scope of the claims. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. The method includes process <b>710</b> for capturing images, process <b>720</b> for determining spectral weights, process <b>730</b> for generating synthetic panchromatic image, process <b>740</b> for registering images, process <b>750</b> for warping spectral images, and process <b>760</b> for synthesizing an image. Although the above has been shown using a selected sequence of processes, there can be many alternatives, modifications, and variations. For example, some of the processes may be expanded and/or combined. Other processes may be inserted to those noted above. Depending upon the embodiment, the specific sequence of processes may be interchanged with other replacements. Further details of these processes are found throughout the present specification and more particularly below.</p>
<p id="p-0035" num="0034">At process <b>710</b> for capturing images, a panchromatic image and at least two spectral images are captured for an imaging target. The panchromatic image usually covers a wide range of the spectrum, while each spectral image is usually in a specific band of wavelength, such as red band, green band, blue band, or NIR band. In certain embodiment of the present invention, at process <b>710</b>, five images are captured for an imaging target, and these images are panchromatic, red, green, blue, and NIR. Additionally, in some embodiments of the present invention, the panchromatic image and the at least two spectral images are captured at different times. Additionally, in certain embodiments of the present invention, the captured spectral images have a resolution lower than that of the captured panchromatic image.</p>
<p id="p-0036" num="0035">At process <b>720</b> for determining spectral weights, relative weights of the spectral images are estimated. The relative weights usually vary from 0% to 100%, and the sum of all relative weights usually does not exceed 100%. Each spectral image is multiplied by its corresponding relative weight and the sum of weighted spectral images should approximate intensities of a panchromatic image at various pixels.</p>
<p id="p-0037" num="0036">According to one embodiment of the present invention, process <b>720</b> uses a linear spectral model. See U.S. Pat. No. 6,097,835. U.S. Pat. No. 6,097,835 is hereby incorporated by reference for all purposes. The linear spectral model assumes that the panchromatic image covers a spectrum that is nearly identical to the combined spectrum of various spectral images. For example, the panchromatic spectrum is nearly identical to the combined spectrum of red, green, blue, and NIR bands of wavelengths. Additionally, the liner spectral model assumes pixels that are in the same location in panchromatic image and spectral images correspond to the same part of the imaging target with only limited misregistration. Moreover, the linear spectral model also assumes a linear relationship between intensities of the panchromatic image and spectral images, as shown below.</p>
<p id="p-0038" num="0037">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mi>p</mi>
        <mo>=</mo>
        <mrow>
          <mi>b</mi>
          <mo>+</mo>
          <mrow>
            <munderover>
              <mo>∑</mo>
              <mrow>
                <mi>i</mi>
                <mo>=</mo>
                <mn>0</mn>
              </mrow>
              <mrow>
                <mi>n</mi>
                <mo>-</mo>
                <mn>1</mn>
              </mrow>
            </munderover>
            <mo>⁢</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
            <mo>⁢</mo>
            <mrow>
              <msub>
                <mi>w</mi>
                <mi>i</mi>
              </msub>
              <mo>⁢</mo>
              <msub>
                <mi>m</mi>
                <mi>i</mi>
              </msub>
            </mrow>
          </mrow>
          <mo>+</mo>
          <mi>ɛ</mi>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>1</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0039" num="0038">where p is the intensity for a pixel in panchromatic image, w<sub>i </sub>is the spectral weight for i<sup>th </sup>spectral image, m<sub>i </sub>is the intensity for a pixel in i<sup>th </sup>spectral image, n is the total number of spectral images for an imaging target, b is a constant additive bias in panchromatic intensity values, and ε is an error term. Alternatively, Equation 1 can be rewritten into vector format, as shown below.
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>p=b+{right arrow over (w)}</i><sup>T</sup><i>{right arrow over (m)}+ε</i>  (Equation 2)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0040" num="0039">where {right arrow over (m)} is a column vector of pixel intensities on various spectral images, and {right arrow over (w)} is a column vector of spectral weights for various spectral images. More specifically,</p>
<p id="p-0041" num="0040">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mover>
            <mi>m</mi>
            <mo>-&gt;</mo>
          </mover>
          <mo>=</mo>
          <mrow>
            <mo>[</mo>
            <mtable>
              <mtr>
                <mtd>
                  <msub>
                    <mi>m</mi>
                    <mn>0</mn>
                  </msub>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mi>⋮</mi>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <msub>
                    <mi>m</mi>
                    <mrow>
                      <mi>n</mi>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                  </msub>
                </mtd>
              </mtr>
            </mtable>
            <mo>]</mo>
          </mrow>
        </mrow>
        <mo>⁢</mo>
        <mstyle>
          <mtext>
</mtext>
        </mstyle>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>2</mn>
          <mo>⁢</mo>
          <mi>A</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mover>
          <mi>w</mi>
          <mo>-&gt;</mo>
        </mover>
        <mo>=</mo>
        <mrow>
          <mo>[</mo>
          <mtable>
            <mtr>
              <mtd>
                <msub>
                  <mi>w</mi>
                  <mn>0</mn>
                </msub>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mi>⋮</mi>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>w</mi>
                  <mrow>
                    <mi>n</mi>
                    <mo>-</mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
              </mtd>
            </mtr>
          </mtable>
          <mo>]</mo>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>2</mn>
          <mo>⁢</mo>
          <mi>B</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0042" num="0041">Both Equations 1 and 2 assume that intensity values of the panchromatic image and the spectral images have been processed to correspond to a common spatial resolution. For example, the captured panchromatic image may have a resolution sixteen times better than that of the captured spectral images. For each pixel in the spectral image, the intensities of sixteen pixels on the panchromatic image can be averaged. Alternatively, other methods can be used to match the spatial resolution of the spectral images and the panchromatic image.</p>
<p id="p-0043" num="0042">According to certain embodiments of the present invention, relative sensitivities of spectral images in various bands of wavelength are known, so the weight vector {right arrow over (w)} and panchromatic bias b can be calculated directly from radiometry measurements. In other embodiments, the model is unknown but linear, so the standard least square method can be used to determine {right arrow over (w)} and b. For example, {right arrow over (w)} and b can be determined using the “pseudo-inverse” method. See, e.g., W. Press, B. Fannery, S. Teukolsky, W. Vetterling, Numerical Recipes, Chapter 2, Cambridge University Press, 1988.</p>
<p id="p-0044" num="0043">Process <b>720</b> may use pixel intensities only in a sample area of panchromatic image and spectral images or use pixel intensities in the entire panchromatic image and spectral images. The number of pixels used for estimating spectral weights can be represented by s. Accordingly, Equations 1 and 2 can be can be written in matrix form as shown below.</p>
<p id="p-0045" num="0044">
<maths id="MATH-US-00003" num="00003">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mo>[</mo>
          <mtable>
            <mtr>
              <mtd>
                <msub>
                  <mi>p</mi>
                  <mn>0</mn>
                </msub>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mi>⋮</mi>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>p</mi>
                  <mrow>
                    <mi>s</mi>
                    <mo>-</mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
              </mtd>
            </mtr>
          </mtable>
          <mo>]</mo>
        </mrow>
        <mo>=</mo>
        <mrow>
          <mrow>
            <mrow>
              <mo>[</mo>
              <mtable>
                <mtr>
                  <mtd>
                    <msub>
                      <mi>m</mi>
                      <mrow>
                        <mn>0</mn>
                        <mo>,</mo>
                        <mn>0</mn>
                      </mrow>
                    </msub>
                  </mtd>
                  <mtd>
                    <mi>…</mi>
                  </mtd>
                  <mtd>
                    <msub>
                      <mi>m</mi>
                      <mrow>
                        <mn>0</mn>
                        <mo>,</mo>
                        <mrow>
                          <mi>n</mi>
                          <mo>-</mo>
                          <mn>1</mn>
                        </mrow>
                      </mrow>
                    </msub>
                  </mtd>
                  <mtd>
                    <mn>1</mn>
                  </mtd>
                </mtr>
                <mtr>
                  <mtd>
                    <mi>⋮</mi>
                  </mtd>
                  <mtd>
                    <mstyle>
                      <mspace width="0.3em" height="0.3ex"/>
                    </mstyle>
                  </mtd>
                  <mtd>
                    <mi>⋮</mi>
                  </mtd>
                  <mtd>
                    <mi>⋮</mi>
                  </mtd>
                </mtr>
                <mtr>
                  <mtd>
                    <msub>
                      <mi>m</mi>
                      <mrow>
                        <mrow>
                          <mi>s</mi>
                          <mo>-</mo>
                          <mn>1</mn>
                        </mrow>
                        <mo>,</mo>
                        <mn>0</mn>
                      </mrow>
                    </msub>
                  </mtd>
                  <mtd>
                    <mstyle>
                      <mspace width="0.3em" height="0.3ex"/>
                    </mstyle>
                  </mtd>
                  <mtd>
                    <msub>
                      <mi>m</mi>
                      <mrow>
                        <mrow>
                          <mi>s</mi>
                          <mo>-</mo>
                          <mn>1</mn>
                        </mrow>
                        <mo>,</mo>
                        <mrow>
                          <mi>n</mi>
                          <mo>-</mo>
                          <mn>1</mn>
                        </mrow>
                      </mrow>
                    </msub>
                  </mtd>
                  <mtd>
                    <mn>1</mn>
                  </mtd>
                </mtr>
              </mtable>
              <mo>]</mo>
            </mrow>
            <mo>⁡</mo>
            <mrow>
              <mo>[</mo>
              <mtable>
                <mtr>
                  <mtd>
                    <msub>
                      <mi>w</mi>
                      <mn>0</mn>
                    </msub>
                  </mtd>
                </mtr>
                <mtr>
                  <mtd>
                    <mi>⋮</mi>
                  </mtd>
                </mtr>
                <mtr>
                  <mtd>
                    <msub>
                      <mi>w</mi>
                      <mrow>
                        <mi>n</mi>
                        <mo>-</mo>
                        <mn>1</mn>
                      </mrow>
                    </msub>
                  </mtd>
                </mtr>
                <mtr>
                  <mtd>
                    <mi>b</mi>
                  </mtd>
                </mtr>
              </mtable>
              <mo>]</mo>
            </mrow>
          </mrow>
          <mo>+</mo>
          <mrow>
            <mo>[</mo>
            <mtable>
              <mtr>
                <mtd>
                  <msub>
                    <mi>ɛ</mi>
                    <mn>0</mn>
                  </msub>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mi>⋮</mi>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <msub>
                    <mi>ɛ</mi>
                    <mrow>
                      <mi>s</mi>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                  </msub>
                </mtd>
              </mtr>
            </mtable>
            <mo>]</mo>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>3</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0046" num="0045">where {right arrow over (p)} is the intensity vector for panchromatic image, {right arrow over (M)} is the intensity matrix for spectral images, {right arrow over (ε)} is the error vector. In more detail,</p>
<p id="p-0047" num="0046">
<maths id="MATH-US-00004" num="00004">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mover>
            <mi>p</mi>
            <mo>-&gt;</mo>
          </mover>
          <mo>=</mo>
          <mrow>
            <mo>[</mo>
            <mtable>
              <mtr>
                <mtd>
                  <msub>
                    <mi>p</mi>
                    <mn>0</mn>
                  </msub>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mi>⋮</mi>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <msub>
                    <mi>p</mi>
                    <mrow>
                      <mi>s</mi>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                  </msub>
                </mtd>
              </mtr>
            </mtable>
            <mo>]</mo>
          </mrow>
        </mrow>
        <mo>⁢</mo>
        <mstyle>
          <mtext>
</mtext>
        </mstyle>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>3</mn>
          <mo>⁢</mo>
          <mi>A</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mover>
          <mi>M</mi>
          <mo>-&gt;</mo>
        </mover>
        <mo>=</mo>
        <mrow>
          <mo>[</mo>
          <mtable>
            <mtr>
              <mtd>
                <msub>
                  <mi>m</mi>
                  <mrow>
                    <mn>0</mn>
                    <mo>,</mo>
                    <mn>0</mn>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi>…</mi>
              </mtd>
              <mtd>
                <msub>
                  <mi>m</mi>
                  <mrow>
                    <mn>0</mn>
                    <mo>,</mo>
                    <mrow>
                      <mi>n</mi>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                  </mrow>
                </msub>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mi>⋮</mi>
              </mtd>
              <mtd>
                <mstyle>
                  <mspace width="0.3em" height="0.3ex"/>
                </mstyle>
              </mtd>
              <mtd>
                <mstyle>
                  <mspace width="1.1em" height="1.1ex"/>
                </mstyle>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>m</mi>
                  <mrow>
                    <mrow>
                      <mi>s</mi>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                    <mo>,</mo>
                    <mn>0</mn>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mrow>
                  <mi>…</mi>
                  <mo>⁢</mo>
                  <mstyle>
                    <mspace width="0.3em" height="0.3ex"/>
                  </mstyle>
                </mrow>
              </mtd>
              <mtd>
                <msub>
                  <mi>m</mi>
                  <mrow>
                    <mrow>
                      <mi>s</mi>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                    <mo>,</mo>
                    <mrow>
                      <mi>n</mi>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                  </mrow>
                </msub>
              </mtd>
            </mtr>
          </mtable>
          <mo>]</mo>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>3</mn>
          <mo>⁢</mo>
          <mi>B</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mover>
          <mi>ɛ</mi>
          <mo>-&gt;</mo>
        </mover>
        <mo>=</mo>
        <mrow>
          <mo>[</mo>
          <mtable>
            <mtr>
              <mtd>
                <msub>
                  <mi>ɛ</mi>
                  <mn>0</mn>
                </msub>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mi>⋮</mi>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>ɛ</mi>
                  <mrow>
                    <mi>s</mi>
                    <mo>-</mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
              </mtd>
            </mtr>
          </mtable>
          <mo>]</mo>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>3</mn>
          <mo>⁢</mo>
          <mi>C</mi>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0048" num="0047">The objective of the least square method is to minimize the magnitude of error term {right arrow over (ε)}. The magnitude of {right arrow over (ε)} can be calculated as below.</p>
<p id="p-0049" num="0048">
<maths id="MATH-US-00005" num="00005">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mi>J</mi>
        <mo>=</mo>
        <mrow>
          <mrow>
            <msup>
              <mi>ɛ</mi>
              <mi>T</mi>
            </msup>
            <mo>⁢</mo>
            <mi>ɛ</mi>
          </mrow>
          <mo>=</mo>
          <mrow>
            <munderover>
              <mo>∑</mo>
              <mrow>
                <mi>i</mi>
                <mo>=</mo>
                <mn>0</mn>
              </mrow>
              <mrow>
                <mi>s</mi>
                <mo>-</mo>
                <mn>1</mn>
              </mrow>
            </munderover>
            <mo>⁢</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
            <mo>⁢</mo>
            <msubsup>
              <mi>ɛ</mi>
              <mi>i</mi>
              <mn>2</mn>
            </msubsup>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>4</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0050" num="0049">where J is the magnitude of the error term. The minimum value for J is usually reached when</p>
<p id="p-0051" num="0050">
<maths id="MATH-US-00006" num="00006">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mo>[</mo>
          <mtable>
            <mtr>
              <mtd>
                <mover>
                  <mi>w</mi>
                  <mo>-&gt;</mo>
                </mover>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mi>b</mi>
              </mtd>
            </mtr>
          </mtable>
          <mo>]</mo>
        </mrow>
        <mo>=</mo>
        <mrow>
          <msup>
            <mrow>
              <mo>(</mo>
              <mrow>
                <msup>
                  <mover>
                    <mi>M</mi>
                    <mo>-&gt;</mo>
                  </mover>
                  <mi>T</mi>
                </msup>
                <mo>⁢</mo>
                <mi>M</mi>
              </mrow>
              <mo>)</mo>
            </mrow>
            <mrow>
              <mo>-</mo>
              <mn>1</mn>
            </mrow>
          </msup>
          <mo>⁢</mo>
          <msup>
            <mover>
              <mi>M</mi>
              <mo>-&gt;</mo>
            </mover>
            <mi>T</mi>
          </msup>
          <mo>⁢</mo>
          <mover>
            <mi>p</mi>
            <mo>-&gt;</mo>
          </mover>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>5</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0052" num="0051">The least square method as discussed above usually works for well-behaved input data. Alternatively, other methods such as the singular value decomposition (SVD) algorithm can be utilized to estimate the weight vector {right arrow over (w)} and panchromatic bias b. See, e.g., W. Press, B. Fannery, S. Teukolsky, W. Vetterling, Numerical Recipes, Chapter 2, Cambridge University Press, 1988.</p>
<p id="p-0053" num="0052">At process <b>730</b> for generating synthetic panchromatic image, a synthetic panchromatic image is created based on spectral images. The process <b>730</b> usually does not use the captured panchromatic image. For example, the captured spectral images usually have a resolution lower than that of the captured panchromatic image, so the synthetic panchromatic image also has a resolution lower than that of the captured panchromatic image. The synthetic panchromatic image can be created with various methods. According to one embodiment of the present invention, the synthetic panchromatic image is generated as follows.</p>
<p id="p-0054" num="0053">
<maths id="MATH-US-00007" num="00007">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mi>p</mi>
        <mo>=</mo>
        <mrow>
          <mi>b</mi>
          <mo>+</mo>
          <mrow>
            <munderover>
              <mo>∑</mo>
              <mrow>
                <mi>i</mi>
                <mo>=</mo>
                <mn>0</mn>
              </mrow>
              <mrow>
                <mi>n</mi>
                <mo>-</mo>
                <mn>1</mn>
              </mrow>
            </munderover>
            <mo>⁢</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
            <mo>⁢</mo>
            <mrow>
              <msub>
                <mi>w</mi>
                <mi>i</mi>
              </msub>
              <mo>⁢</mo>
              <msub>
                <mi>m</mi>
                <mi>i</mi>
              </msub>
            </mrow>
          </mrow>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>6</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0055" num="0054">where p is the intensity for a pixel in the synthetic panchromatic image, w<sub>i </sub>is the spectral weight for i<sup>th </sup>captured spectral image, m<sub>i </sub>is the intensity for a pixel in i<sup>th </sup>captured spectral image, n is the total number of spectral images for an imaging target, b is a constant additive bias in panchromatic intensity values. The weight vector {right arrow over (w)} and panchromatic bias b have been determined in process <b>720</b>.</p>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIGS. 8 and 9</figref> are simplified diagrams showing different resolutions for captured panchromatic image and synthetic panchromatic image. These diagrams are merely examples, which should not unduly limit the scope of the claims. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. <figref idref="DRAWINGS">FIG. 810</figref> shows captured panchromatic image <b>810</b>, and in contrast <figref idref="DRAWINGS">FIG. 9</figref> shows synthetic panchromatic image <b>910</b>. The synthetic panchromatic image <b>910</b> is created with captured spectral images. The captured spectral images have a linear resolution only one quarter of the linear resolution of captured panchromatic image <b>810</b>. Consequently, synthetic panchromatic image <b>910</b> also has a linear resolution only one quarter of that of captured panchromatic image <b>810</b>.</p>
<p id="p-0057" num="0056">At process <b>740</b> for registering images, the captured panchromatic image and the synthetic panchromatic image are aligned by computing registration offsets. The alignment can match pixels on the captured panchromatic image and the synthetic panchromatic image that correspond to the same imaging area. The registration offsets represent the size of relative movement between the captured and the synthetic panchromatic images.</p>
<p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. 10</figref> is a simplified block diagram for registering images according to one embodiment of the present invention. This diagram is merely an example, which should not unduly limit the scope of the claims. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. Process <b>740</b> for registering images includes process <b>742</b> for matching resolutions and process <b>744</b> for maximizing correlation. Although the above has been shown using a selected sequence of processes, there can be many alternatives, modifications, and variations. For example, some of the processes may be expanded and/or combined. Other processes may be inserted to those noted above. Depending upon the embodiment, the specific sequence of processes may be interchanged with other replaced. Process <b>742</b> may be skipped if the synthetic panchromatic image has substantially the same resolution as the captured panchromatic image. Further details of these processes are found throughout the present specification and more particularly below.</p>
<p id="p-0059" num="0058">At process <b>742</b> for matching resolutions, pixel intensities of the panchromatic image and the spectral images are processed to correspond to a common spatial resolution. For example, as shown in <figref idref="DRAWINGS">FIGS. 8 and 9</figref>, the captured panchromatic image may have a linear resolution four times higher than that of the captured spectral images. Hence each pixel in the synthetic panchromatic image corresponds to sixteen pixels in the captured panchromatic image. The intensities of sixteen pixels on the captured panchromatic image should be averaged. Alternatively, the intensities of four pixels on the captured panchromatic image are averaged, and the intensity of each pixel in the synthetic panchromatic image is repeated four times. In other words, each synthetic pixel is divided into four pixels. Other methods such as oversampling the spectral images by a factor of two and down-sampling the panchromatic image by a factor of 2 can also be used to match the spatial resolutions of the synthetic panchromatic resolution and the captured panchromatic image.</p>
<p id="p-0060" num="0059">At process <b>744</b> for maximizing correlation, pixels of the captured panchromatic image are matched with pixels of the synthetic panchromatic image so that corresponding pixels in the captured panchromatic image and the synthetic panchromatic image describe the same part of the imaging target. Matching all pixels in the captured panchromatic image with all pixels in the synthetic panchromatic image may be difficult, but process <b>744</b> maximizes the correlation between the captured and synthetic panchromatic images.</p>
<p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. 11</figref> shows a simplified diagram for maximizing correlation according to one embodiment of the present invention. This diagram is merely an example, which should not unduly limit the scope of the claims. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. Captured panchromatic image <b>1110</b> and synthetic panchromatic image <b>1120</b> have been processed so that they have the same spatial resolution. At process <b>744</b>, captured and synthetic panchromatic images <b>1110</b> and <b>1120</b> moves with respect to each other in one or several of directions <b>1130</b>, <b>1140</b>, <b>1150</b> and <b>1160</b>. The overlapping pixels in captured and synthetic panchromatic images <b>1110</b> and <b>1120</b> should correspond to substantially the same imaging area. At least, process <b>740</b> tries to match as many pixels as possible. As discussed above, <figref idref="DRAWINGS">FIG. 11</figref> is merely an illustration. The movement between captured panchromatic image <b>1110</b> and synthetic panchromatic image <b>1120</b> may involve a movement in any direction, a rotation around any axis, or other form of movement.</p>
<p id="p-0062" num="0061">According to one embodiment of the present invention, process <b>744</b> maximizes a normalized cross correlation as follows.</p>
<p id="p-0063" num="0062">
<maths id="MATH-US-00008" num="00008">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mi>ρ</mi>
        <mo>=</mo>
        <mfrac>
          <mrow>
            <msup>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mi>v</mi>
                  <mo>-</mo>
                  <mover>
                    <mi>v</mi>
                    <mi>_</mi>
                  </mover>
                </mrow>
                <mo>)</mo>
              </mrow>
              <mi>T</mi>
            </msup>
            <mo>⁢</mo>
            <mrow>
              <mo>(</mo>
              <mrow>
                <mi>w</mi>
                <mo>-</mo>
                <mover>
                  <mi>w</mi>
                  <mi>_</mi>
                </mover>
              </mrow>
              <mo>)</mo>
            </mrow>
          </mrow>
          <mrow>
            <mrow>
              <mo></mo>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mi>v</mi>
                  <mo>-</mo>
                  <mover>
                    <mi>v</mi>
                    <mi>_</mi>
                  </mover>
                </mrow>
                <mo>)</mo>
              </mrow>
              <mo></mo>
            </mrow>
            <mo>⁢</mo>
            <mrow>
              <mo></mo>
              <mrow>
                <mi>w</mi>
                <mo>-</mo>
                <mover>
                  <mi>w</mi>
                  <mi>_</mi>
                </mover>
              </mrow>
              <mo></mo>
            </mrow>
          </mrow>
        </mfrac>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>7</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0064" num="0063">where</p>
<p id="p-0065" num="0064">
<maths id="MATH-US-00009" num="00009">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mi>v</mi>
        <mo>=</mo>
        <mrow>
          <mo>[</mo>
          <mtable>
            <mtr>
              <mtd>
                <msub>
                  <mi>v</mi>
                  <mn>1</mn>
                </msub>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mi>⋮</mi>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>v</mi>
                  <mi>Q</mi>
                </msub>
              </mtd>
            </mtr>
          </mtable>
          <mo>]</mo>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>8</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mover>
          <mi>v</mi>
          <mi>_</mi>
        </mover>
        <mo>=</mo>
        <mfrac>
          <mrow>
            <munderover>
              <mo>∑</mo>
              <mrow>
                <mi>i</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
              <mi>Q</mi>
            </munderover>
            <mo>⁢</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
            <mo>⁢</mo>
            <msub>
              <mi>v</mi>
              <mi>i</mi>
            </msub>
          </mrow>
          <mi>Q</mi>
        </mfrac>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>9</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mi>w</mi>
        <mo>=</mo>
        <mrow>
          <mo>[</mo>
          <mtable>
            <mtr>
              <mtd>
                <msub>
                  <mi>w</mi>
                  <mn>1</mn>
                </msub>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mi>⋮</mi>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>w</mi>
                  <mi>Q</mi>
                </msub>
              </mtd>
            </mtr>
          </mtable>
          <mo>]</mo>
        </mrow>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>10</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
  <mtr>
    <mtd>
      <mrow>
        <mover>
          <mi>w</mi>
          <mi>_</mi>
        </mover>
        <mo>=</mo>
        <mfrac>
          <mrow>
            <munderover>
              <mo>∑</mo>
              <mrow>
                <mi>i</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
              <mi>Q</mi>
            </munderover>
            <mo>⁢</mo>
            <mstyle>
              <mspace width="0.3em" height="0.3ex"/>
            </mstyle>
            <mo>⁢</mo>
            <msub>
              <mi>w</mi>
              <mi>i</mi>
            </msub>
          </mrow>
          <mi>Q</mi>
        </mfrac>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>11</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0066" num="0065">Q is the total number of pixels in the synthetic panchromatic image and the total number of pixels in the captured panchromatic image. v<sub>1</sub>, . . . , v<sub>Q </sub>are intensities for pixel <b>1</b>, . . . , pixel Q respectively in the synthetic panchromatic image. w<sub>1</sub>, . . . , w<sub>Q </sub>are intensities for pixel <b>1</b>, . . . , pixel Q respectively in the captured panchromatic image. ρ varies from minus 1 to positive one, and positive one usually represents perfect correlation between the synthetic and captured panchromatic images. Process <b>744</b> maximizes ρ and thereby improves the correlation between the synthetic and captured panchromatic images.</p>
<p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. 12</figref> shows a simplified diagram for maximizing correlation according to another embodiment of the present invention. This diagram is merely an example, which should not unduly limit the scope of the claims. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. As discussed above, captured and synthetic panchromatic images can be moved with respect to each other in order to maximize their correlation. This correlation usually involves translation of images by at least one pixel, but the maximum correlation sometimes requires image translation of a fraction of a pixel. Such sub-pixel translation can be accomplished by fitting a polynomial to the correlation as a function of registration offset, where the registration offset is the number of pixels by which the two images are translated with respect to each other.</p>
<p id="p-0068" num="0067">For example, as shown in <figref idref="DRAWINGS">FIG. 12</figref>, correlation values between captured and synthetic panchromatic images are measured with registration offset equal to one, two, and three pixels. At offset equal to one pixel, correlation has value A. At offset equal to two pixels, correlation has value B. At offset equal to three pixels, correlation has value C. Using these data points, the relationship between correlation and offset can be fitted with a quadratic function. As shown in <figref idref="DRAWINGS">FIG. 12</figref>, the quadratic function is represented by Curve D. Curve D provides maximum correlation value E at registration offset equal to about 1.5 pixels. Maximum correlation value D is larger than any of measured values A, B, and C. Hence by function fitting or curve fitting, the maximum correlation can be achieved with limited number of correlation measurements. As discussed above and further emphasized here, <figref idref="DRAWINGS">FIG. 12</figref> is merely an example. The number of measured correlations is not limited to three, and it may take any value. Depending on the number of measured correlations, the fitting function is not limited to quadratic function, and it may take any form.</p>
<p id="p-0069" num="0068">At process <b>750</b> for warping spectral images, the spectral images are warped so that they align with the captured panchromatic image. This warping utilizes registration offsets (tie points) generated in process <b>740</b>. A number of warping methods can be used, including but not limited to the polynomial warp.</p>
<p id="p-0070" num="0069">At process <b>760</b> for synthesizing an image, a multi-spectral image is synthesized through a pan-sharpening process that uses the captured spectral images and captured panchromatic image. A multi-spectral image usually refers an image containing information from at least two bands of wavelengths. For example, a multi-spectral image could be a color image containing information from red band, green band, blue band, and NIR band. In certain embodiments of the present invention, the captured panchromatic image has a higher spatial resolution than the captured spectral images. Hence the captured panchromatic image can be used to sharpen the captured spectral images.</p>
<p id="p-0071" num="0070">One alternative for panchromatic sharpening is to simply resample spectral images to panchromatic resolution using standard processes such as nearest neighbor, bilinear, or bicubic interpolation. See W. K. Pratt, Digital Image Processing, Second Edition, Chapter 14.5, John Wiley and Sons, New York, 1991. This method usually cannot produce a crisp multi-spectral image. Indeed the degree of blurriness of the synthesized image usually depends on the interpolation scheme used and the scene content.</p>
<p id="p-0072" num="0071">Alternatively, panchromatic sharpening can improve on the above method. See U.S. Pat. No. 6,097,835. U.S. Pat. No. 6,097,835 is hereby incorporated by reference for all purposes. The re-sampled spectral images may be adjusted to the closest “model” intensity contained in the hyperplane determined by p−b and {right arrow over (w)}. Each panchromatic intensity, p, determines a different but parallel hyperplane. Based on the re-sampled intensity vector {right arrow over (m)} for spectral images, weight vector {right arrow over (w)}, and unbiased panchromatic value p−b, {right arrow over (m)}′ can be projected to a point, m, on the plane defined in Equation 1 along the direction of {right arrow over (w)}.</p>
<p id="p-0073" num="0072">Solving the equations for this projection is straightforward. The closest point on a hyperplane to a given exterior point can be found by starting at the exterior point and projecting to the hyperplane in the direction normal to the hyperplane. {right arrow over (w)} is a vector normal to the hyperplane in Equation 1. If t denotes a scalar for projecting from {right arrow over (m)}′ in the direction of {right arrow over (w)}, the vector point {right arrow over (m)}′+t{right arrow over (w)} intersects the hyperplane in Equation 1 precisely when
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>p−b={right arrow over (w)}</i><sup>T</sup>(<i>{right arrow over (m)}′+t{right arrow over (w)}</i>)  (Equation 12)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0074" num="0073">
<maths id="MATH-US-00010" num="00010">
<math overflow="scroll">
<mtable>
  <mtr>
    <mtd>
      <mrow>
        <mrow>
          <mi>Then</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mi>t</mi>
        </mrow>
        <mo>=</mo>
        <mfrac>
          <mrow>
            <mi>p</mi>
            <mo>-</mo>
            <mi>b</mi>
            <mo>-</mo>
            <mrow>
              <msup>
                <mover>
                  <mi>w</mi>
                  <mo>-&gt;</mo>
                </mover>
                <mi>T</mi>
              </msup>
              <mo>⁢</mo>
              <msup>
                <mover>
                  <mi>m</mi>
                  <mo>-&gt;</mo>
                </mover>
                <mi>t</mi>
              </msup>
            </mrow>
          </mrow>
          <mrow>
            <msup>
              <mover>
                <mi>m</mi>
                <mo>-&gt;</mo>
              </mover>
              <mi>T</mi>
            </msup>
            <mo>⁢</mo>
            <mover>
              <mi>w</mi>
              <mo>-&gt;</mo>
            </mover>
          </mrow>
        </mfrac>
      </mrow>
    </mtd>
    <mtd>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>Equation</mi>
          <mo>⁢</mo>
          <mstyle>
            <mspace width="0.8em" height="0.8ex"/>
          </mstyle>
          <mo>⁢</mo>
          <mn>13</mn>
        </mrow>
        <mo>)</mo>
      </mrow>
    </mtd>
  </mtr>
</mtable>
</math>
</maths>
</p>
<p id="p-0075" num="0074">Consequently, the equation for an output pixel intensity of spectral images is given by
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>m</i><sub>i</sub>=CLAMP(<i>m</i><sub>i</sub><i>+tw</i><sub>i</sub>)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0076" num="0075">where the CLAMP operator prevents pixel under or over flow on each output band. For a scalar, x, the CLAMP operator can be defined as follows:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?>CLAMP(<i>x</i>)=Max(MinIntensity,Min(<i>x</i>,MaxIntensity))  (Equation 13)<?in-line-formulae description="In-line Formulae" end="tail"?>
</p>
<p id="p-0077" num="0076">where MinIntensity and MaxIntensity represent respectively the minimum and maximum intensities desired in the resulting image.</p>
<p id="p-0078" num="0077"><figref idref="DRAWINGS">FIGS. 13(A)</figref>, (B), and (C) are simplified diagrams showing superior image quality according to one embodiment of the present invention. These diagrams are merely examples, which should not unduly limit the scope of the claims. <figref idref="DRAWINGS">FIG. 13(A)</figref> shows a multi-spectral image without any panchromatic sharpening. The multi-spectral image usually has a lower resolution, hence when displayed as a color image produces only a blurry image. <figref idref="DRAWINGS">FIG. 13(B)</figref> shows a pan-sharpened multi-spectral image based on captured spectral images and a captured panchromatic image. The captured spectral images and the captured panchromatic image are unregistered. Hence the pan-sharpened multi-spectral image contains distortions even though the image shows some improvements over the image in <figref idref="DRAWINGS">FIG. 13(A)</figref>. <figref idref="DRAWINGS">FIG. 13(C)</figref> shows a pan-sharpened multi-spectral image according to one embodiment of the present invention. The panchromatic sharpening process utilizes a synthetic panchromatic image in order to improve the registration between the captured spectral images and captured panchromatic image. As shown in <figref idref="DRAWINGS">FIG. 13(C)</figref>, the image provides a view of the scene with few distortions.</p>
<p id="p-0079" num="0078"><figref idref="DRAWINGS">FIGS. 14(A)</figref>, (B), and (C) are simplified diagrams showing superior image quality according to another embodiment of the present invention. These diagrams are merely examples, which should not unduly limit the scope of the claims. <figref idref="DRAWINGS">FIG. 14(A)</figref> shows a multi-spectral image without any panchromatic sharpening. The multi-spectral image usually has a lower resolution, hence when displayed as a color image produces only a blurry image. <figref idref="DRAWINGS">FIG. 14(B)</figref> shows a pan-sharpened multi-spectral image based on captured spectral images and a captured panchromatic image. The captured spectral images and the captured panchromatic image are unregistered. Hence the pan-sharpened multi-spectral image contains distortions even though the image shows some improvements over the image in <figref idref="DRAWINGS">FIG. 14(A)</figref>. <figref idref="DRAWINGS">FIG. 14(C)</figref> shows a pan-sharpened multi-spectral image according to another embodiment of the present invention. The panchromatic sharpening process utilizes a synthetic panchromatic image in order to improve the registration between captured spectral images and captured panchromatic image. As shown in <figref idref="DRAWINGS">FIG. 14(C)</figref>, the image provides a view of the scene with few smeared colors.</p>
<p id="p-0080" num="0079"><figref idref="DRAWINGS">FIGS. 15(A)</figref>, (B), and (C) are simplified diagrams showing superior image quality according to yet another embodiment of the present invention. These diagrams are merely examples, which should not unduly limit the scope of the claims. <figref idref="DRAWINGS">FIG. 15(A)</figref> shows a multi-spectral image without any panchromatic sharpening. The multi-spectral image usually has a lower resolution, hence when displayed as a color image produces only a blurry image. <figref idref="DRAWINGS">FIG. 15(B)</figref> shows a pan-sharpened multi-spectral image based on captured spectral images and a captured panchromatic image. The captured spectral images and the captured panchromatic image are unregistered. Hence the pan-sharpened multi-spectral image contains distortions even though the image shows some improvements over the image in <figref idref="DRAWINGS">FIG. 15(A)</figref>. <figref idref="DRAWINGS">FIG. 15(C)</figref> shows a pan-sharpened multi-spectral image according to yet another embodiment of the present invention. The panchromatic sharpening process utilizes a synthetic panchromatic image in order to improve the registration between captured spectral images and captured panchromatic image. As shown in <figref idref="DRAWINGS">FIG. 15(C)</figref>, the image provides a view of the scene with few saturated colors.</p>
<p id="p-0081" num="0080">The present invention has various advantages. Certain embodiments of the present invention improve the quality of panchromatic sharpening processes and subsequently derived high quality multi-spectral image products. In some embodiments of the present invention, the synthetic panchromatic image can provide high correlation with the captured panchromatic image. This high correlation leads to accurate panchromatic to multi-spectral registration offset generation and thus improves effectiveness of subsequent panchromatic sharpening. Certain embodiments of the present invention allow panchromatic sensor and/or spectral imaging sensors to be designed with less strict requirements in order to maintain the same image registration accuracy. Use of synthetic panchromatic image allows effective post-processing to remove image misregistration artifacts caused by sensors. Some embodiments of the present invention can be implemented very efficiently using existing hardware and software technology.</p>
<p id="p-0082" num="0081">It is understood the examples and embodiments described herein are for illustrative purposes only. Certain embodiments of the present invention may be implemented by a computer program. Various modifications or changes in light thereof will be suggested to persons skilled in the art and are to be included within the spirit and purview of this application and scope of the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-math idrefs="MATH-US-00001" nb-file="US07298922-20071120-M00001.NB">
<img id="EMI-M00001" he="8.81mm" wi="76.20mm" file="US07298922-20071120-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00002" nb-file="US07298922-20071120-M00002.NB">
<img id="EMI-M00002" he="29.63mm" wi="76.20mm" file="US07298922-20071120-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00003" nb-file="US07298922-20071120-M00003.NB">
<img id="EMI-M00003" he="15.49mm" wi="76.20mm" file="US07298922-20071120-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00004" nb-file="US07298922-20071120-M00004.NB">
<img id="EMI-M00004" he="42.67mm" wi="76.20mm" file="US07298922-20071120-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00005" nb-file="US07298922-20071120-M00005.NB">
<img id="EMI-M00005" he="8.81mm" wi="76.20mm" file="US07298922-20071120-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00006" nb-file="US07298922-20071120-M00006.NB">
<img id="EMI-M00006" he="8.81mm" wi="76.20mm" file="US07298922-20071120-M00006.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00007" nb-file="US07298922-20071120-M00007.NB">
<img id="EMI-M00007" he="8.81mm" wi="76.20mm" file="US07298922-20071120-M00007.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00008" nb-file="US07298922-20071120-M00008.NB">
<img id="EMI-M00008" he="7.45mm" wi="76.20mm" file="US07298922-20071120-M00008.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00009" nb-file="US07298922-20071120-M00009.NB">
<img id="EMI-M00009" he="52.92mm" wi="76.20mm" file="US07298922-20071120-M00009.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-math idrefs="MATH-US-00010" nb-file="US07298922-20071120-M00010.NB">
<img id="EMI-M00010" he="9.14mm" wi="76.20mm" file="US07298922-20071120-M00010.TIF" alt="embedded image " img-content="math" img-format="tif"/>
</us-math>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for making a multi-spectral image, the method comprising:
<claim-text>capturing a panchromatic image of an imaging target, the captured panchromatic image being associated with a captured panchromatic resolution;</claim-text>
<claim-text>capturing at least a first spectral image of the imaging target in a first spectral bandwidth, the first spectral image being associated with a first spectral resolution;</claim-text>
<claim-text>capturing at least a second spectral image of the imaging target in a second spectral bandwidth, the second spectral image being associated with a second spectral resolution;</claim-text>
<claim-text>determining at least a first spectral weight and a second spectral weight for the first spectral image and the second spectral image respectively based on at least information associated with the captured panchromatic image, the first spectral image and the second spectral image;</claim-text>
<claim-text>generating a synthetic panchromatic image based on at least information associated with the first spectral image, the second spectral image, the first spectral weight, and the second spectral weight, the synthetic panchromatic image being associated with a synthetic panchromatic resolution;</claim-text>
<claim-text>determining a registration offset between the synthetic panchromatic image and the captured panchromatic image by matching a first pixel on the synthetic panchromatic image and a second pixel on the captured panchromatic image, the first pixel and the second pixel corresponding to a same portion of the imaging target;</claim-text>
<claim-text>warping the first spectral image and the second spectral image based on at least information associated with the registration offset;</claim-text>
<claim-text>generating a multi-spectral image based on at least information associated with the first spectral image, the second spectral image, the first spectral weight, the second spectral weight, the captured panchromatic image, and the registration offset, the generated multi-spectral image being associated with a third resolution.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the generating a synthetic panchromatic image is free from using information associated with the captured panchromatic image.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the third resolution is higher than the first spectral resolution and the second spectral resolution.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the captured panchromatic resolution is higher than the first spectral resolution and the second spectral resolution.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref> wherein the captured panchromatic resolution is higher than the synthetic panchromatic resolution.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref> wherein the synthetic panchromatic resolution is equal to the first spectral resolution and the second spectral resolution.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the first spectral weight ranges from 0% to 100%.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein a sum of the first spectral weight and the second spectral weight is smaller than or equal to 100%.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref> wherein the determining at least a first spectral weight and a second spectral weight uses at least a linear spectral model.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref> wherein the determining at least a first spectral weight and a second spectral weight uses at least intensities of pixels located in a first portion of the captured panchromatic image, a second portion of the first spectral image, and a third portion of the second spectral image.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the determining a registration offset comprises maximizing a correlation between the synthetic panchromatic image and the captured panchromatic image.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref> wherein the determining a registration offset further comprises:
<claim-text>processing at least information associated with the synthetic panchromatic image and the captured panchromatic image;</claim-text>
<claim-text>modifying at least one of the synthetic panchromatic resolution and the captured panchromatic resolution based on at least information associated with the synthetic panchromatic image and the captured panchromatic image;</claim-text>
<claim-text>wherein in response to the modifying at least one of the synthetic panchromatic resolution and the captured panchromatic resolution, the synthetic panchromatic resolution equals the captured panchromatic resolution.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein the maximizing a correlation between the synthetic panchromatic image and the captured panchromatic image comprises:
<claim-text>translating the synthetic panchromatic image and the captured panchromatic image with respect to each other by a first offset value;</claim-text>
<claim-text>determining a first correlation value corresponding to the first offset value;</claim-text>
<claim-text>translating the synthetic panchromatic image and the captured panchromatic image with respect to each other by a second offset value;</claim-text>
<claim-text>determining a second correlation value corresponding to the second offset value;</claim-text>
<claim-text>processing at least information associated with the first correlation value, the first offset value, the second correlation value, and the second offset value;</claim-text>
<claim-text>fitting the correlation as a function of the registration offset based on at least information associated with the first correlation value, the first offset value, the second correlation value, and the second offset value;</claim-text>
<claim-text>determining a maximum correlation and the registration offset corresponding to the maximum correlation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the generating a multi-spectral image comprises:
<claim-text>re-sampling at least the first spectral image and the second spectral image based on information associated with the captured panchromatic resolution;</claim-text>
<claim-text>synthesizing the multi-spectral image based on at least information associated with the re-sampled first spectral image, the re-sampled second spectral image, and the captured panchromatic image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. A method for making a multi-spectral image, the method comprising:
<claim-text>capturing a panchromatic image of an imaging target, the captured panchromatic image being associated with a captured panchromatic spatial resolution;</claim-text>
<claim-text>capturing at least a first spectral image of the imaging target in a first spectral bandwidth, the first spectral image being associated with a first spectral spatial resolution, the first spectral spatial resolution being lower than the captured panchromatic spatial resolution;</claim-text>
<claim-text>capturing at least a second spectral image of the imaging target in a second spectral bandwidth, the second spectral image being associated with a second spectral spatial resolution, the second spectral spatial resolution being lower than the captured panchromatic spatial resolution;</claim-text>
<claim-text>generating a synthetic panchromatic image based on at least information associated with the first spectral image and the second spectral image, the synthetic panchromatic image being associated with a synthetic panchromatic spatial resolution;</claim-text>
<claim-text>processing at least information associated with the synthetic panchromatic image and the captured panchromatic image;</claim-text>
<claim-text>determining a registration offset between the synthetic panchromatic image and the captured panchromatic image by matching a first pixel on the synthetic panchromatic image and a second pixel on the captured panchromatic image, the first pixel and the second pixel corresponding to a same portion of the imaging target;</claim-text>
<claim-text>warping the first spectral image and the second spectral image based on at least information associated with the registration offset;</claim-text>
<claim-text>generating a multi-spectral image based on at least information associate with the first spectral image, the second spectral image, the first spectral weight, the second spectral weight, the captured panchromatic image, and the registration offset, the multi-spectral image being associated with a third spatial resolution, the third spatial resolution being substantially equal to the captured panchromatic spatial resolution.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the third spatial resolution is higher than the synthetic panchromatic spatial resolution.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the multi-spectral image is free from image distortion, smeared color, and saturated color.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the generating a synthetic panchromatic image is free from using information associated with the captured panchromatic image.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the first spectral spatial resolution equals the second spectral spatial resolution.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref> wherein the synthetic panchromatic spatial resolution equals the first spectral spatial resolution.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the determining a registration offset comprises maximizing a correlation between the synthetic panchromatic image and the captured panchromatic image.</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref> wherein the determining a registration offset further comprises:
<claim-text>processing at least information associated with the synthetic panchromatic image and the captured panchromatic image;</claim-text>
<claim-text>modifying at least one of the synthetic panchromatic spatial resolution and the captured panchromatic spatial resolution based on at least information associated with the synthetic panchromatic image and the captured panchromatic image;</claim-text>
<claim-text>wherein in response to the modifying at least one of the synthetic panchromatic spatial resolution and the captured panchromatic spatial resolution, the synthetic panchromatic spatial resolution equals the captured panchromatic spatial resolution.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref> wherein the maximizing a correlation between the synthetic panchromatic image and the captured panchromatic image comprises:
<claim-text>translating the synthetic panchromatic image and the captured panchromatic image with respect to each other by a first offset value;</claim-text>
<claim-text>determining a first correlation value corresponding to the first offset value;</claim-text>
<claim-text>translating the synthetic panchromatic image and the captured panchromatic with respect to each other by a second offset value;</claim-text>
<claim-text>determining a second correlation value corresponding to the second offset value;</claim-text>
<claim-text>processing at least information associated with the first correlation value, the first offset value, the second correlation value, and the second offset value;</claim-text>
<claim-text>fitting the correlation as a function of the registration offset based on at least information associated with the first correlation value, the first offset value, the second correlation value, and the second offset value;</claim-text>
<claim-text>determining a maximum correlation and the registration offset corresponding to the maximum correlation.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the generating a multi-spectral image comprises:
<claim-text>re-sampling the first spectral image and the second spectral image based on at least information associated with the captured panchromatic spatial resolution;</claim-text>
<claim-text>synthesizing the multi-spectral image based on at least information associated with the re-sampled the re-sampled, and the captured panchromatic image.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. A method for making a color image, the method comprising:
<claim-text>capturing a panchromatic image of an imaging target, the captured panchromatic image being associated with a captured panchromatic resolution;</claim-text>
<claim-text>capturing at least a first spectral image of the imaging target in a first spectral bandwidth, the first spectral image being associated with a first spectral resolution;</claim-text>
<claim-text>capturing at least a second spectral image of the imaging target in a second spectral bandwidth, the second spectral image being associated with a second spectral resolution;</claim-text>
<claim-text>determining at least a first spectral weight and a second spectral weight for the first spectral image and the second spectral image respectively based on at least information associated with the captured panchromatic image, the first spectral image and the second spectral image;</claim-text>
<claim-text>generating a synthetic panchromatic image based on at least information associated with the first spectral image, the second spectral image, the first spectral weight, and the second spectral weight, the synthetic panchromatic image being associated with a synthetic panchromatic resolution;</claim-text>
<claim-text>determining a registration offset between the synthetic panchromatic image and the captured panchromatic image by matching a first pixel on the synthetic panchromatic image and a second pixel on the captured panchromatic image, the first pixel and the second pixel corresponding to a same portion of the imaging target;</claim-text>
<claim-text>warping the first spectral image and the second spectral image based on at least information associated with the registration offset;</claim-text>
<claim-text>generating a color image based on at least information associated with the first spectral image, the second spectral image, the first spectral weight, the second spectral weight, the captured panchromatic image, and the registration offset, the generated multi-spectral image being associated with a third resolution;</claim-text>
<claim-text>wherein the color image is free from image distortion, smeared color, and saturated color.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
