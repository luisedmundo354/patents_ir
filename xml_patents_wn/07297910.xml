<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07297910-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07297910</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11320676</doc-number>
<date>20051230</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>02</class>
<subclass>B</subclass>
<main-group>7</main-group>
<subgroup>04</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>02</class>
<subclass>B</subclass>
<main-group>27</main-group>
<subgroup>40</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>03</class>
<subclass>B</subclass>
<main-group>13</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>2502012</main-classification>
<further-classification>2502014</further-classification>
<further-classification>348345</further-classification>
</classification-national>
<invention-title id="d0e43">System and method for utilizing an autofocus feature in an automated microscope</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5561498</doc-number>
<kind>A</kind>
<name>Sekine et al.</name>
<date>19961000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>396 53</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5774444</doc-number>
<kind>A</kind>
<name>Shimano et al.</name>
<date>19980600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>36911002</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6677565</doc-number>
<kind>B1</kind>
<name>Wahl et al.</name>
<date>20040100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6792203</doc-number>
<kind>B1</kind>
<name>Ide et al.</name>
<date>20040900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>396 65</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6819639</doc-number>
<kind>B1</kind>
<name>Gelbart</name>
<date>20041100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>369 4438</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>7030927</doc-number>
<kind>B2</kind>
<name>Sasaki</name>
<date>20060400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348345</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>7232980</doc-number>
<kind>B2</kind>
<name>Oshiro et al.</name>
<date>20070600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>2502013</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>2002/0050518</doc-number>
<kind>A1</kind>
<name>Roustaei</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>235454</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>2004/0125230</doc-number>
<kind>A1</kind>
<name>Suda</name>
<date>20040700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348345</main-classification></classification-national>
</citation>
</references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>10</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>2502011-2014</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>348345</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>7</number-of-drawing-sheets>
<number-of-figures>7</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20070152130</doc-number>
<kind>A1</kind>
<date>20070705</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Fomitchov</last-name>
<first-name>Pavel A.</first-name>
<address>
<city>New York</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<last-name>Bentley</last-name>
<first-name>Dwayne</first-name>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>General Electric Company</orgname>
<role>02</role>
<address>
<city>Schenectady</city>
<state>NY</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Luu</last-name>
<first-name>Thanh X.</first-name>
<department>2878</department>
</primary-examiner>
<assistant-examiner>
<last-name>Livedalen</last-name>
<first-name>Brian J</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">The invention relates to a method for adjusting focus in an automated microscope. The method may comprise the steps of: providing an optical detector for image acquisition, wherein the optical detector comprises an array of sensor pixels; designating a region of interest in the array of sensor pixels to emulate a confocal aperture; directing a light beam to illuminate an object according to a predefined pattern, thereby forming an image of the illuminated pattern at the optical detector, wherein the image of the illuminated pattern substantially overlaps the designated region of interest; detecting a light intensity from sensor pixels located within the designated region of interest; and adjusting a relative focal position of an objective lens based on the detected light intensity.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="134.03mm" wi="231.39mm" file="US07297910-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="179.92mm" wi="174.75mm" orientation="landscape" file="US07297910-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="176.19mm" wi="168.32mm" orientation="landscape" file="US07297910-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="172.80mm" wi="154.86mm" orientation="landscape" file="US07297910-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="177.12mm" wi="173.91mm" orientation="landscape" file="US07297910-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="236.05mm" wi="146.47mm" orientation="landscape" file="US07297910-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="187.11mm" wi="139.45mm" orientation="landscape" file="US07297910-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="235.03mm" wi="147.74mm" orientation="landscape" file="US07297910-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0002" num="0001">Automated microscopes such as confocal laser scanning microscopes and wide-field fluorescence microscopes are powerful imaging tools that are especially valuable for inspection of biological samples. One important component in a typical automated microscope is an autofocusing system. Ideally, the autofocusing system should be able to adjust focus for the microscope's optical system to obtain high-contrast images and should do so in a fast, accurate and reliable manner. However, very few existing autofocusing systems, if any, can meet such requirements in a cost-efficient way. Most known autofocusing systems fall into two categories: image-based or confocal-based, both of which have notable shortcomings.</p>
<p id="p-0003" num="0002">An image-based autofocusing system may rely on an image-processing algorithm to find a best focus for a microscope. Such an image-based autofocusing system may cause a main optical detector in the microscope to acquire a number of images while an objective lens is moved within its focus range, so that each image corresponds to a different focal position. The contrast of each image is then analyzed and evaluated by applying the image-processing algorithm to the image data. The best focal position is identified as one that corresponds to the strongest contrast in the acquired images. Although such a image-based autofocusing system is usually simple, reliable and inexpensive, it is relatively slow since multiple images have to be acquired and then processed with the complex contrast-evaluation algorithm. In addition, this type of image-based autofocusing cannot be performed during image acquisition (i.e., operate in a “tracking mode”) because the main optical detector would not be available for autofocusing operations.</p>
<p id="p-0004" num="0003">An image-based autofocusing system may also rely on a separate set of hardware (e.g., a separate optical detector and separate optical components) that operates somewhat independently from the microscope's main image acquisition system. This type of autofocusing system is also referred to as a hardware-based system.</p>
<p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. 1</figref> shows a prior art microscope <b>100</b> equipped with a hardware-based autofocusing system <b>120</b>. A main image acquisition system in the microscope <b>100</b> comprises a main charge coupled device (CCD) detector <b>102</b>, a main optical path <b>104</b> that comprises an objective lens <b>110</b> and other optical elements, a main illumination light source <b>106</b>, and an object stage <b>108</b>. The main illumination light source <b>106</b> generates a light beam <b>10</b> (typically a laser) that is directed, via the main optical path <b>104</b>, to the object stage <b>108</b> to illuminate a sample thereon. An image of the sample is then detected by the main CCD detector <b>102</b>.</p>
<p id="p-0006" num="0005">In addition to and independent from the main image acquisition system, the hardware-based autofocusing system <b>120</b> provides a secondary image acquisition system that includes a secondary CCD detector <b>122</b>, a secondary optical path <b>124</b> and an autofocus light source <b>126</b>. The autofocus light source <b>126</b> typically generates an autofocus light beam <b>20</b> having a different wavelength from the light beam <b>10</b> generated by the main illumination light source <b>106</b>. The autofocus light beam <b>20</b> is coupled into the main optical path <b>104</b> to illuminate the object stage <b>108</b>. A resulting image is then detected by the secondary CCD detector <b>122</b>. A microcontroller (or microprocessor) <b>128</b> is available to analyze the autofocus images acquired by the secondary CCD detector <b>122</b>. The microcontroller <b>128</b> is also coupled to a motion control unit <b>112</b> that adjusts a relative position of the object stage <b>108</b> with respect to the objective lens <b>110</b>. By coordinating the movement of the object stage <b>108</b> and the acquisition and analysis of autofocus images, the microcontroller <b>128</b> may quickly identify an optimal focal position that produces the strongest contrast in the autofocus image. It should be noted that a hardware-based autofocusing system, such as the system <b>120</b>, may also be adapted for confocal-based autofocusing, wherein a physical confocal aperture (not shown) is used and, instead of analyzing entire images, light intensity through the confocal aperture may be analyzed for focus adjustments.</p>
<p id="p-0007" num="0006">With a secondary image acquisition system dedicated to autofocusing, a hardware-based autofocusing system can zero in on the best focus fairly fast and may also be able to perform focus adjustment when the microscope's main image acquisition system is busy acquiring sample images. However, the dedicated autofocusing hardware also substantially increases the overall complexity and cost of the microscope. Furthermore, a hardware-based autofocusing system is typically incapable of flexible adaptation to different imaging modes the microscope operates in.</p>
<p id="p-0008" num="0007">Apart from confocal-based autofocusing, there is another type of non-image-based autofocusing approach known as position-sensitive autofocusing. Position-sensitive autofocusing can be used for tracking-mode focus adjustments, and is widely used in optical drives such as compact disk (CD) drives and digital versatile disk (DVD) drives. However, it is very difficult to implement position-sensitive autofocusing in an imaging system with multiple objective lenses.</p>
<heading id="h-0002" level="1">BRIEF SUMMARY OF THE INVENTION</heading>
<p id="p-0009" num="0008">The present invention is directed to an autofocusing system and method that overcomes these and other drawbacks of known systems and methods.</p>
<p id="p-0010" num="0009">According to one embodiment, the invention relates to a method for adjusting focus in an automated microscope. The method may comprise the steps of: providing an optical detector for image acquisition, wherein the optical detector comprises an array of sensor pixels; designating a region of interest in the array of sensor pixels to emulate a confocal aperture; directing a light beam to illuminate an object according to a predefined pattern, thereby forming an image of the illuminated pattern at the optical detector, wherein the image of the illuminated pattern substantially overlaps the designated region of interest; detecting a light intensity from sensor pixels located within the designated region of interest; and adjusting a relative focal position of an objective lens based on the detected light intensity.</p>
<p id="p-0011" num="0010">According to another embodiment, the invention relates to an automated microscope. The automated microscope may comprise: at least one light source that generates a light beam; an optical path and an optical detector for image acquisition, wherein the optical path has an objective lens therein, and wherein the optical detector comprises an array of sensor pixels; a motion mechanism capable of moving the objective lens within a focus adjustment range; and a processor module coupled to the optical detector and the motion mechanism. The processor module may designate a region of interest in the array of sensor pixels to emulate a confocal aperture. The optical path may direct the light beam to illuminate the object according to a predefined pattern, thereby forming an image of the illuminated pattern at the optical detector, wherein the image of the illuminated pattern substantially overlaps the designated region of interest. The processor module may determine a desired relative focal position of the objective lens by coordinating the movement of the objective lens and detection of light intensity from sensor pixels located within the designated region of interest.</p>
<p id="p-0012" num="0011">According to yet another embodiment, the invention relates to a method for adjusting focus in an automated microscope. The method may comprise the steps of: providing an optical detector for image acquisition, wherein the optical detector comprises an array of sensor pixels; directing a light beam to illuminate an object according to a line pattern, thereby forming a line-shaped image at the optical detector; designating a region of interest in the array of sensor pixels, wherein the designated region of interest crosses the line-shaped image; determining, based on detection data collected from sensor pixels located within the designated region of interest, a width of the line-shaped image and a light intensity associated with the line-shaped image; and adjusting a relative focal position of an objective lens based on the width and the light intensity.</p>
<p id="p-0013" num="0012">It is a technical advantage of the present invention that an autofocus method and system for an automated microscope is disclosed. It is another technical advantage of the present invention that a pixel-based optical detector is used to emulate a confocal aperture and/or to improve the speed and accuracy of microscope focus adjustments. It is a further technical advantage of the present invention that the autofocus technique may be useful for confocal or wide-field microscopes.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0014" num="0013">In order to facilitate a fuller understanding of the present invention, reference is now made to the appended drawings. These drawings should not be construed as limiting the present invention, but are intended to be exemplary only.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 1</figref> shows a prior art microscope equipped with a hardware-based autofocusing system.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram illustrating a prior art method for confocal autofocusing.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram illustrating an exemplary autofocusing method according to an embodiment of the present invention.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram illustrating an exemplary microscope with an autofocusing function according to an embodiment of the present invention.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 5</figref> is a close-up view of a pixel-based optical detector according to an embodiment of the present invention.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 6</figref> is a flow chart illustrating an exemplary autofocusing method according to an embodiment of the present invention.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 7</figref> illustrates another exemplary autofocusing method according to an embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0022" num="0021">Embodiments of the present invention introduce a new autofocusing technique that not only provides faster and more accurate focus adjustment than existing image-based autofocusing approaches, but does not require a separate detection system as in existing hardware-based autofocusing systems. These advantages are achieved by using a pixel-based optical detector that serves both as a microscope's main detector for image acquisition and as the detector for autofocus purpose. The pixel-based optical detector may comprise a two-dimensional (2-D) array of sensor pixels whose detection data may be selectively accessed. That is, detection data associated with each sensor pixel in the 2-D array is capable of an independent readout and/or reset. One example of a suitable optical detector may be a complementary metal oxide semiconductor (CMOS) detector having a random access feature. Another example of a suitable optical detector may be a charge-coupled device (CCD) detector. The pixel-based optical detector may be positioned in place of a physical confocal aperture and may be programmed to emulate a virtual confocal aperture. Light intensity detected from sensor pixels located within the virtual confocal aperture may be used as a basis for focus adjustments.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 2</figref> is a diagram illustrating a prior art method for confocal autofocusing. In a simplified autofocusing system <b>200</b> (main imaging acquisition system for the microscope not shown), a light source <b>202</b> may generate a light beam <b>22</b>. The light beam <b>22</b> may be focused by an objective lens <b>204</b> onto an object <b>24</b> and illuminate a point <b>26</b> on an object <b>24</b>. An image of the point <b>26</b> may be formed on a confocal aperture <b>208</b>. If the focal plane of the objective lens <b>204</b> coincides with the object plane <b>206</b>, then light beams originating from the point <b>26</b> are in focus on the confocal aperture <b>208</b>. These light beams may produce the highest light intensity and may be detected by an optical detector <b>210</b> located behind the confocal aperture <b>208</b>. Other out-of-focus light beams are blocked by the confocal aperture <b>210</b>. Focus adjustment for the optical system <b>200</b> may involve changing a relative position of the objective lens <b>204</b> to find the focal position that produces one of the peaks in the light intensity at the confocal aperture <b>208</b>.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 3</figref> is a diagram illustrating an exemplary autofocusing method according to an embodiment of the present invention. The exemplary method may be implemented with an autofocusing system <b>300</b>. A light beam <b>32</b>, generated by a light source <b>302</b>, may pass through a beam-shaping element <b>303</b> that converts the light beam <b>32</b> into a light beam <b>33</b> that, after passing through an objective lens <b>304</b>, forms a predefined illumination pattern (e.g., a point, a line, or a rectangular shape) on a object <b>34</b>. In the autofocusing system <b>300</b>, a main difference from the prior art autofocusing system <b>200</b> (shown in <figref idref="DRAWINGS">FIG. 2</figref>) is that the confocal aperture <b>208</b> may be emulated by a pixel-based optical detector <b>310</b> having a 2-D array of sensor pixels. The optical detector <b>310</b> may be positioned where the physical confocal aperture <b>208</b> used to be, wherein detection data associated with the sensor pixels may be selectively accessed. The illuminated pattern on the object <b>34</b> may form an image directly on the 2-D array of sensor pixels.</p>
<p id="p-0025" num="0024">The random access capability of the optical detector <b>310</b> may allow selective detection of incident light on the 2-D pixel array. As such, a “virtual confocal aperture” may be flexibly emulated by designating a region of interest (ROI) in the array of sensor pixels. With the emulated confocal aperture, detection signals from those sensor pixels located outside the ROI may be reset to reject out-of-focus light. The shape of the virtual confocal aperture (or ROI) may be the same as or similar to the predefined pattern, and may be determined based on the operation mode of a microscope in which this exemplary method is implemented. For example, if the microscope operates in a point-confocal mode, the illuminated pattern and the ROI may be configured to have a point-like shape. If the microscope operates in a line-confocal mode, the illuminated pattern and the ROI may be shaped into a line. Both the illuminated pattern and the ROI are typically centered in a field of view of the microscope. The size of the ROI may be the same as or smaller than the image of the illuminated pattern. A search for a desired focus may involve detection of light intensity from those sensor pixels located within the ROI together with a synchronized movement of the objective lens <b>304</b>. An optimal focal position of the objective lens <b>304</b> may be identified as one that produces one of the peaks in the light intensity inside the virtual confocal aperture.</p>
<p id="p-0026" num="0025">Focus adjustment according to the exemplary method illustrated in <figref idref="DRAWINGS">FIG. 3</figref> may be faster than traditional image-based autofocusing systems for a number of reasons. For example, the detection data may be read out fairly fast because, instead of collecting data from the entire sensor pixel array, only data from those sensor pixels within the ROI are read out. In addition, no extensive image processing is required. Compared to hardware-based autofocusing systems, the exemplary method in <figref idref="DRAWINGS">FIG. 3</figref> does not require a separate optical detector or optical system to be dedicated to autofocusing. Instead, the autofocusing function may be implemented with the microscope's main image acquisition system. The autofocusing system <b>300</b> shown in <figref idref="DRAWINGS">FIG. 3</figref> may actually be a microscope's main image acquisition system as well. For example, the optical detector <b>310</b> may be the main optical detector that also serves the autofocusing purposes.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 4</figref> is a block diagram illustrating an exemplary microscope <b>400</b> with an autofocusing function according to an embodiment of the present invention. The microscope <b>400</b> may comprise one or more light sources <b>402</b> that are capable of generating one or more light beams either for image acquisition (e.g., fluorescence excitation) or for autofocusing. A light beam <b>40</b> may be selected from the one or more light sources <b>402</b> with, for example, an optical switch (not shown). The light beam <b>40</b> may pass through a beam-shaping module, which, in this example, is a line-forming module <b>404</b> that converts the light beam <b>40</b> into a light beam <b>42</b> diverging in the horizontal direction only. The light beam <b>42</b> may be directed by an optical element <b>406</b> (e.g., a dichroic mirror or a beam splitter) and then focused by an objective lens <b>408</b> to illuminate a line pattern <b>44</b> on an object <b>410</b>. The line pattern <b>44</b> may be centered in the field of view of the microscope <b>400</b>. Light reflecting off the object <b>410</b> may pass through the objective lens <b>408</b>, the beam splitter <b>406</b> and a tube lens <b>412</b> before forming an image of the line pattern <b>44</b> on a pixel-based optical detector <b>414</b>.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 5</figref> is a close-up view of the pixel-based optical detector <b>414</b> according to an embodiment of the present invention. The optical detector <b>414</b> may comprise a 2-D array of sensor pixels <b>502</b>. Each sensor pixel may detect an optical signal incident thereon and have the resulting detection data read out or reset independently from the other sensor pixels. The illuminated line patter <b>44</b> may form an image covering a rectangular area <b>46</b> in the center of the optical detector <b>414</b>. The size of the rectangular area <b>46</b> depends on overall magnification of the imaging system, and may vary depending on how focused the image is. The more focused the image is, the smaller the rectangular area <b>46</b> becomes. During calibration, the size of the sharpest image of the line pattern <b>44</b> may be estimated and used as an upper limit to designate a region of interest (ROI) in the center of the optical detector <b>414</b>. For example, if the area <b>46</b> shown in <figref idref="DRAWINGS">FIG. 5</figref> represents approximately the smallest size observed for the image of the line pattern <b>44</b>, then an array of sensor pixels of the same or smaller size than the area <b>46</b> may be designated as the ROI. For example, either the rectangular area <b>46</b> or a slightly smaller rectangular area <b>48</b> may be selected to serve as a virtual confocal slit. Light intensity from those pixels located within the virtual confocal slit may be detected and analyzed, while detector data from pixels outside the virtual confocal slit may be either reset or ignored to reject out-of-focus light.</p>
<p id="p-0029" num="0028">Referring back to <figref idref="DRAWINGS">FIG. 4</figref>, the microscope <b>400</b> may further comprise a processor unit <b>416</b> which may be a microprocessor, microcontroller, a personal computer (PC), or similar electronic device. Coupled to the optical detector <b>414</b> and the objective lens <b>408</b>, the processor unit <b>416</b> may coordinate the movement of the objective lens <b>408</b> with the detection of light intensity from the ROI in order to find a best focal position that corresponds to one of the highest light intensities detected. Instead of moving the objective lens <b>408</b>, the object <b>410</b> may be moved with respect to the objective lens <b>408</b>.</p>
<p id="p-0030" num="0029">It should be noted that <figref idref="DRAWINGS">FIGS. 4 and 5</figref> only show the major components in the microscope <b>400</b>. In practice, more components may be desirable for more satisfactory operations of image acquisition and autofocusing. A preferred embodiment of an optical system for use in the microscope <b>400</b> may be found in a related U.S. patent application Ser. No. 11/184,444, filed on Jul. 19, 2005, which is incorporated herein in its entirety.</p>
<p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. 6</figref> is a flow chart illustrating an exemplary autofocusing method according to an embodiment of the present invention.</p>
<p id="p-0032" num="0031">In step <b>602</b>, an autofocus light beam may be coupled into the main optical path of an automated microscope. The automated microscope may have one or more main light sources for image acquisition. The autofocus light beam may be generated from a light source dedicated to autofocusing and may have a wavelength that is substantially different from the main light sources. Alternatively, the autofocus light beam may be generated from one of the main light sources. Before being coupled into the main optical path, the autofocus light beam may be shaped according to a predefined pattern. According to a preferred embodiment, the light beam may be expanded to form a horizontal line pattern.</p>
<p id="p-0033" num="0032">In step <b>604</b>, the autofocus light beam may be focused by an objective lens and may illuminate an object according to the predefined pattern. For example, the autofocus light beam may be focused onto a horizontal line in the center of the microscope's field of view.</p>
<p id="p-0034" num="0033">In step <b>606</b>, the illuminated pattern on the object may form an image at a main optical detector of the microscope. The image of an illuminated line pattern is also shaped like a line. The line may be sharp or blurred depending on whether the illuminated line pattern is in focus or out of focus. If perfectly in focus, that is, the object plane coincides with the focal plane of the objective lens, the line may be the narrowest and the brightest. If out of focus to some extent, the line may be thicker and less bright.</p>
<p id="p-0035" num="0034">The main optical detector may have an array of sensor pixels that are amenable to selective or random data access. During calibration, in step <b>608</b>, a region of interest (ROI) may be designated in the array of sensor pixels to emulate a confocal aperture. The ROI may be defined in such a way that it overlaps but is no larger than the sharpest image of the illuminated pattern. Therefore, for the illuminated line pattern centered in the field of view, the ROI may be chosen as a narrow and horizontally extending rectangular area centered in the array of sensor pixels.</p>
<p id="p-0036" num="0035">In step <b>610</b>, during autofocusing, light intensity may be detected from sensor pixels located within the ROI, while those sensor pixels outside the ROI may be reset. In synchronization with step <b>610</b>, the relative position of the objective lens may be changed, in step <b>612</b>, with respect to the object. The relative movement of the objective lens with respect to the object may involve moving the objective lens while keeping the object stationary, moving the object while keeping the objective lens stationary, or moving both the objective lens and the object. The steps <b>610</b> and <b>612</b> may be repeated such that, for each incremental position within a focus range, the corresponding light intensity in the ROI may be detected.</p>
<p id="p-0037" num="0036">In step <b>614</b>, a desired focal position of the objective lens may be selected for the microscope's image acquisition purposes. From the data collected in steps <b>610</b> and <b>612</b>, a relationship of the changes in light intensity with respect to the relative position of the objective lens may be used as a basis for the search of a desired focal position. There may be one or more local maximums in the light intensity detected in the ROI. One of the local maximums may correspond to the best focal position of the objective lens. Other local maximums may be caused by strong reflections at, for example, an air-to-glass or glass-to-fluid interface. Thus, these local maximums may be used to identify the focal positions where the focal plane of the objective lens meets an interface in the object. One of the interfaces may be used as a reference for the focal position of the objective lens. For example, during image acquisition of the microscope, a predetermined offset may be applied to the movement of the objective lens or an object stage in order to bring a sample of interest to the focal plane of the objective lens.</p>
<p id="p-0038" num="0037">According to embodiments of the present invention, various autofocus illumination patterns may be flexibly combined with various types of ROI's in the optical detector's sensor pixel array, either to serve different operation modes of a microscope or to improve the speed and accuracy in finding a best focus. <figref idref="DRAWINGS">FIG. 7</figref> illustrates another exemplary autofocusing method according to an embodiment of the present invention. In <figref idref="DRAWINGS">FIG. 7</figref>, there is shown the same optical detector <b>414</b> as used in the microscope <b>400</b> shown in <figref idref="DRAWINGS">FIG. 4</figref>. The horizontally extending line pattern <b>44</b> may form a line-shaped image <b>74</b> on the optical detector <b>414</b>. The ROI in this case may be designated as a vertically extending rectangular area <b>72</b>. As the focal position of the objective lens <b>408</b> is adjusted, the width and light intensity of the line-shaped image <b>74</b> may change. Both changes may be captured by the detection data collected from sensor pixels located within the rectangular area <b>72</b>. The detection data may provide a light intensity distribution along the ROI. As the line-shaped image <b>74</b> becomes more in focus, the light intensity becomes more concentrated in the center. Compared with the above-described autofocusing method which is based on light intensity detection in an emulated confocal aperture, the exemplary method illustrated in <figref idref="DRAWINGS">FIG. 7</figref> may provide more information associated with the focal position of the objective lens <b>408</b>. For example, based on the width of the line-shaped image <b>74</b> and/or how fast the width changes, it may be predicted as to how far away the objective lens <b>408</b> is from its optimal focal position. Accordingly, the movement of the objective lens <b>408</b> may be sped up or slowed down. As a result, the search for the best focus may become faster and more accurate.</p>
<p id="p-0039" num="0038">It should be noted at this point that, despite the foregoing specific examples, the autofocusing technique in accordance with embodiments of the present invention may be adapted for a wide variety of microscopes. For example, those skilled in the art may appreciate that the autofocusing technique disclosed herein may be applicable to both wide-field microscopes and confocal microscopes, and the microscopes may operate in either a fluorescence mode or a non-fluorescence mode.</p>
<p id="p-0040" num="0039">While the foregoing description includes many details, it is to be understood that these have been included for purposes of explanation only, and are not to be interpreted as limitations of the present invention. It will be apparent to those skilled in the art that other modifications to the embodiments described above can be made without departing from the spirit and scope of the invention. Accordingly, such modifications are considered within the scope of the invention as intended to be encompassed by the following claims and their legal equivalents.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for adjusting focus in an automated microscope, the method comprising:
<claim-text>providing an optical detector for image acquisition, wherein the optical detector comprises an array of sensor pixels;</claim-text>
<claim-text>designating a region of interest in the array of sensor pixels to emulate a virtual confocal aperture;</claim-text>
<claim-text>directing a light beam to focus and illuminate an object according to a diffraction limited point configured to reject out of focus light thereby forming an image of the illuminated diffraction limited point at the optical detector, wherein the image of the illuminated diffraction limited point substantially overlaps the designated region of interest;</claim-text>
<claim-text>detecting a light intensity from sensor pixels located within the designated region of interest based on the optical detector being configured to have random access capability for selective detection of the light intensity; and</claim-text>
<claim-text>adjusting a relative focal position of an objective lens based on the detected light intensity.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>selecting, for image acquisition, the relative focal position that corresponds to a peak in the light intensity detected.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of designating the region of interest further comprises:
<claim-text>calibrating the emulated virtual confocal aperture such that a sharpest image of the illuminated pattern, formed at the optical detector, is no smaller than the designated region of interest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>resetting or ignoring sensor pixels that are located outside the designated region of interest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>the automated microscope operates in a line-confocal mode; and</claim-text>
<claim-text>the predefined pattern has a shape of a straight line and is centered in a field of view.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the optical detector is selected from a group consisting of:
<claim-text>a CMOS optical detector; and</claim-text>
<claim-text>a CCD camera.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the light beam is dedicated to autofocusing and has a wavelength that is different from a light source employed by the automated microscope for image acquisition.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>identifying one or more interfaces on or near the object by detecting changes in the light intensity while adjusting the relative focal position of the objective lens.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the diffraction limited point is a diffraction limited line.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. An automated microscope comprising:
<claim-text>at least one light source that generates a light beam;</claim-text>
<claim-text>an optical path and an optical detector for image acquisition, wherein the optical path has an objective lens therein, and wherein the optical detector comprises an array of sensor pixels;</claim-text>
<claim-text>a motion mechanism capable of moving the objective lens within a focus adjustment range; and</claim-text>
<claim-text>a processor module coupled to the optical detector and the motion mechanism;</claim-text>
<claim-text>wherein:
<claim-text>the processor module designates a region of interest in the array of sensor pixels to emulate a virtual confocal aperture,</claim-text>
<claim-text>the optical path directs the light beam to focus and illuminate an object according to a diffraction limited point configured to reject out of focus light thereby forming an image of the illuminated diffraction limited point at the optical detector, wherein the image of the illuminated diffraction limited point substantially overlaps the designated region of interest, and</claim-text>
<claim-text>the processor module determines a desired relative focal position of the objective lens by coordinating the movement of the objective lens and detection of light intensity from sensor pixels located within the designated region of interest based on the optical detector being configured to have random access capability for selective detection of the light intensity.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The automated microscope according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the processor module selects, for image acquisition, the relative focal position that corresponds to a peak in the light intensity detected.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The automated microscope according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the processor module calibrates the emulated virtual confocal aperture such that a sharpest image of the illuminated pattern, formed at the optical detector, is no smaller than the designated region of interest.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The automated microscope according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the processor module resets or ignores sensor pixels that are located outside the designated region of interest.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The automated microscope according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein:
<claim-text>the automated microscope operates in a line-confocal mode; and</claim-text>
<claim-text>the predefined pattern has a shape of a straight line.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The automated microscope according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein:
<claim-text>the automated microscope operates in a point-confocal mode; and</claim-text>
<claim-text>the predefined pattern has a point-like shape.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The automated microscope according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein:
<claim-text>the automated microscope operates in a wide-field mode; and</claim-text>
<claim-text>the predefined pattern has a point-like shape.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The automated microscope according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the optical detector is selected from a group consisting of:
<claim-text>a CMOS optical detector; and</claim-text>
<claim-text>a CCD camera.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The automated microscope according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the light beam is generated by an autofocus light source and has a wavelength that is different from a light source employed by the automated microscope for image acquisition.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The automated microscope according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the processor module identifies one or more interfaces on or near the object by detecting changes in the light intensity while adjusting the relative focal position of the objective lens.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the diffraction limited point is a diffraction limited line.</claim-text>
</claim>
</claims>
</us-patent-grant>
