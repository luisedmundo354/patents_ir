<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298891-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298891</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10891950</doc-number>
<date>20040715</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>735</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>T</subclass>
<main-group>15</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>08</class>
<subclass>B</subclass>
<main-group>23</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>01</class>
<subclass>V</subclass>
<main-group>3</main-group>
<subgroup>38</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382154</main-classification>
<further-classification>382109</further-classification>
<further-classification>345419</further-classification>
<further-classification>345420</further-classification>
<further-classification>340970</further-classification>
<further-classification>702  5</further-classification>
</classification-national>
<invention-title id="d0e53">Bare earth digital elevation model extraction for three-dimensional registration from topographical points</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5644386</doc-number>
<kind>A</kind>
<name>Jenkins et al.</name>
<date>19970700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>356  401</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5844614</doc-number>
<kind>A</kind>
<name>Chong</name>
<date>19981200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5875108</doc-number>
<kind>A</kind>
<name>Hoffberg</name>
<date>19990200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5901246</doc-number>
<kind>A</kind>
<name>Hoffberg</name>
<date>19990500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>5988862</doc-number>
<kind>A</kind>
<name>Kacyra</name>
<date>19991100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6081750</doc-number>
<kind>A</kind>
<name>Hoffberg</name>
<date>20000600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6246468</doc-number>
<kind>B1</kind>
<name>Dimsdale</name>
<date>20010600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6330523</doc-number>
<kind>B1</kind>
<name>Kacyra</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6400996</doc-number>
<kind>B1</kind>
<name>Hoffberg</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>6405132</doc-number>
<kind>B1</kind>
<name>Breed</name>
<date>20020600</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>6418424</doc-number>
<kind>B1</kind>
<name>Hoffberg</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>6420698</doc-number>
<kind>B1</kind>
<name>Dimsdale</name>
<date>20020700</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00013">
<document-id>
<country>US</country>
<doc-number>6473079</doc-number>
<kind>B1</kind>
<name>Kacyra</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00014">
<document-id>
<country>US</country>
<doc-number>6512518</doc-number>
<kind>B2</kind>
<name>Dimsdale</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00015">
<document-id>
<country>US</country>
<doc-number>6512993</doc-number>
<kind>B2</kind>
<name>Kacyra</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00016">
<document-id>
<country>US</country>
<doc-number>6526352</doc-number>
<kind>B1</kind>
<name>Breed</name>
<date>20030200</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00017">
<document-id>
<country>US</country>
<doc-number>6654690</doc-number>
<kind>B2</kind>
<name>Rahmes et al.</name>
<date>20031100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>702  5</main-classification></classification-national>
</citation>
<citation>
<patcit num="00018">
<document-id>
<country>US</country>
<doc-number>6741341</doc-number>
<kind>B2</kind>
<name>DeFlumere</name>
<date>20040500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>3561411</main-classification></classification-national>
</citation>
<citation>
<patcit num="00019">
<document-id>
<country>US</country>
<doc-number>6864828</doc-number>
<kind>B1</kind>
<name>Golubiewski et al.</name>
<date>20050300</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>342 25 C</main-classification></classification-national>
</citation>
<citation>
<patcit num="00020">
<document-id>
<country>US</country>
<doc-number>7046841</doc-number>
<kind>B1</kind>
<name>Dow et al.</name>
<date>20060500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382154</main-classification></classification-national>
</citation>
<citation>
<patcit num="00021">
<document-id>
<country>US</country>
<doc-number>7242460</doc-number>
<kind>B2</kind>
<name>Hsu et al.</name>
<date>20070700</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>356  401</main-classification></classification-national>
</citation>
<citation>
<patcit num="00022">
<document-id>
<country>US</country>
<doc-number>2002/0059042</doc-number>
<kind>A1</kind>
<name>Kacyra</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00023">
<document-id>
<country>US</country>
<doc-number>2002/0145607</doc-number>
<kind>A1</kind>
<name>Dimsdale</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00024">
<document-id>
<country>US</country>
<doc-number>2002/0149585</doc-number>
<kind>A1</kind>
<name>Kacyra</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00025">
<document-id>
<country>US</country>
<doc-number>2002/0158870</doc-number>
<kind>A1</kind>
<name>Brunkhart</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<patcit num="00026">
<document-id>
<country>US</country>
<doc-number>2003/0001835</doc-number>
<kind>A1</kind>
<name>Dimsdale</name>
<date>20030100</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00027">
<othercit>J.A. Williams and M. Bennamoun, “Simultaneous Registration of Multiple Point Sets Using Orthonormal Matrices” Proc. IEEE ICASSP, Jun. 2000.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00028">
<othercit>Created by John Pike, maintained by Steven Aftergood, “Interferometric Synthetic Aperture Radar (IFSAR) Shuttle Radar Topography Mission (SRTM)”  Intelligence Resource Program, Feb. 25, 2000.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
<citation>
<nplcit num="00029">
<othercit>Dr. James E. Arnold, Lidar Tutorial, NASA, Aug. 2, 1999.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>19</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382109</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382154</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382216</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382241</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382260</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382266</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382272</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382275</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382294</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382295</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382296</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382305</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>702  5</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>702  6</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>702 59</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>703  6</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701  1</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701  4</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>701301</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345419</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345420</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345421</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>345427</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>356 12</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>356  501</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>324543</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>324522</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>324523</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>324713</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>324525</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>324 67</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>341 26</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>341 22</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>451  5</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>451228</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>451 49</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>340970</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>715964</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>3</number-of-drawing-sheets>
<number-of-figures>3</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20060013442</doc-number>
<kind>A1</kind>
<date>20060119</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>McDowall</last-name>
<first-name>Tom</first-name>
<address>
<city>Melbourne</city>
<state>FL</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Auxier</last-name>
<first-name>Jake</first-name>
<address>
<city>West Melbourne</city>
<state>FL</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Rahmes</last-name>
<first-name>Mark</first-name>
<address>
<city>Melbourne</city>
<state>FL</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="004" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Fermo</last-name>
<first-name>Ray</first-name>
<address>
<city>Melbourne</city>
<state>FL</state>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Allen, Dyer, Doppelt, Milbrath &amp; Gilchrist, P.A.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Harris Corporation</orgname>
<role>02</role>
<address>
<city>Melbourne</city>
<state>FL</state>
<country>US</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Chawan</last-name>
<first-name>Sheela</first-name>
<department>2624</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A method (<b>300</b>) for extracting a digital elevation model from a plurality of raw topographical points representing a plurality of frames representing a plurality of perspectives of a multi-dimensional object comprising a surface and above-surface obstructions, comprises steps or acts of: finding the surface (<b>304</b>) by filtering out data points produced by the above-surface obstructions to provide a plurality of surface data points representing the surface; and filtering the surface data points (<b>306</b>) with a competitive filter to provide a multi-dimensional surface shell of digital elevation model data points. The above-described method can also be carried out by a specialized or programmable information processing system (<b>200</b>) or as a set of instructions in a computer-readable medium such as a CD ROM or DVD or the like.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="143.43mm" wi="172.04mm" file="US07298891-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="142.41mm" wi="180.00mm" file="US07298891-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="143.76mm" wi="173.06mm" file="US07298891-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="206.08mm" wi="152.65mm" file="US07298891-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application relates to technology similar to that discussed in concurrently filed U.S. patent applications Ser. No. 10/892,047 entitled “METHOD AND SYSTEM FOR SIMULTANEOUSLY REGISTERING MULTI-DIMENSIONAL TOPOGRAPHICAL POINTS”, Ser. No. 10/892,055 entitled “SYSTEM AND METHOD FOR IMPROVING SIGNAL TO NOISE RATIO IN 3-D POINT DATA SCENES UNDER HEAVY OBSCURATION”, and Ser. No. 10/892,063 entitled “METHOD AND SYSTEM FOR EFFICIENT VISUALIZATION METHOD FOR COMPARISON OF LADAR POINT DATA TO DETAILED CAD MODELS OF TARGETS” which are assigned to the same assignee as the present application and are incorporated by reference herein in their entirety.</p>
<heading id="h-0002" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0003" num="0002">The invention disclosed broadly relates to the field of a digital signal processing of topographical data and more particularly relates to a system and method for extraction of digital elevation (DEM) models from a set of topographical points.</p>
<heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0004" num="0003">Systems for processing digital representations of images are commonly used to process data representing surfaces such as DEMs. A DEM is digital map of the elevation of an area on the earth. The data is collected by any well-known means such as LADAR (imaging Laser RADAR), or by IFSAR (Interferometric Synthetic Aperture Radar) or the like. In operation, the LADAR instrument transmits light to a target. The transmitted light interacts with and is changed by the target. Some of this light is reflected or scattered back to the sensor of the instrument where it is detected, stored, and analyzed. The change in the properties of the light enables some property of the target to be determined. The time required for light to travel to the target and back to the LADAR instrument is used to determine the range to the target. IFSAR is used to ingest and process high-resolution elevation data produced through a technique called radar interferometry. As in the case of LADAR, IFSAR produces data useful for extracting DEMs.</p>
<p id="p-0005" num="0004">Digital elevation models may be represented as a height map through gray scale images wherein the pixel values are actually terrain elevation values. The pixels are also correlated to world space (longitude and latitude), and each pixel represents some variable volume of that space depending on the purpose of the model and land area depicted.</p>
<p id="p-0006" num="0005">Referring to <figref idref="DRAWINGS">FIG. 1</figref> there is shown an example of an airborne LADAR system <b>100</b>. The system comprises a LADAR instrument <b>102</b> mounted on the bottom of an aircraft <b>104</b>. Below the aircraft is an area comprising the ground and a canopy formed by trees and other foliage obstructing the view of the ground (earth) from an aerial view. The LADAR instrument <b>102</b> emits a plurality of laser light pulses which are directed toward the ground. The LADAR instrument <b>102</b> comprises a sensor <b>103</b> that detects the reflections/scattering of the pulses. The LADAR instrument <b>102</b> provides data including elevation versus position information from a single image. It should be noted however, that multiple frames of portions of the area from different perspectives are used to generate the image. The tree canopy overlying the terrain results in significant obscuration of targets (e.g. tank <b>106</b>) under that tree canopy. The points received by the sensor of instrument <b>102</b> from the ground and the target <b>106</b> are thus sparse. Hence, a robust system for processing the points is required. Moreover, to be of the most tactical and strategic value, an image of the ground wherein the target <b>106</b> can be perceived easily must be available quickly.</p>
<p id="p-0007" num="0006">Extraction of data points generated by LADAR to produce a DEM is known. However, such methods are computationally intensive, and where a large number of data points are processed, run-time applications can be difficult or slow. Therefore, there is a need for more efficient methods and systems for production of DEMs using topological data points.</p>
<heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0008" num="0007">The above-discussed and other shortcomings of the prior art are addressed and overcome by the present invention which provides a method for extracting a digital elevation model from a plurality of raw topographical points representing a plurality of perspectives of a multi-dimensional object. The method comprises steps or acts of: finding a surface of the object by filtering out data points produced by above-surface obstructions to provide a plurality of surface data points representing the surface; and filtering the surface data points with a competitive filter to provide a multi-dimensional surface shell of digital elevation model data points. The above-described method can also be carried out by a specialized or programmable information processing system or as a set of instructions in a computer-readable medium such as a CD ROM or DVD or the like.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. 1</figref> is a depiction of an airborne LADAR instrument for processing images of a tree-covered terrain concealing a target.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. 2</figref> is a high level block diagram showing an information processing system according to an embodiment of the invention.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. 3</figref> is flowchart of a method for extracting a bare earth digital elevation model according to another embodiment of the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0006" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0012" num="0011">Referring to <figref idref="DRAWINGS">FIG. 2</figref>, there is shown high level block diagram showing an information processing system <b>200</b> using an embodiment of the invention. The system <b>200</b> comprises a source <b>202</b> of topographical data points. These points are preferably a plurality of three-dimensional (3D) topographical point values provided by a LADAR instrument <b>102</b> as discussed with respect to <figref idref="DRAWINGS">FIG. 1</figref>.</p>
<p id="p-0013" num="0012">Referring again to <figref idref="DRAWINGS">FIG. 2</figref>, the data source <b>202</b> creates, in a conventional manner, a plurality of frames (or volumes) comprising points representing a complex multidimensional object such as the terrain shown in <figref idref="DRAWINGS">FIG. 1</figref>. In this embodiment, the object comprises a base surface (e.g., the ground or earth) and a plurality of obstructions (e.g., tree tops) above the surface. Each frame comprises the points collected by the sensor <b>103</b> over a given period of time (an exposure) as the aircraft <b>104</b> moves over the terrain. In the preferred embodiment, this time period is one-third of a second and, with current instruments, that exposure results in collection of hundreds of thousands of points by the LADAR sensor <b>103</b>. Each point is defined by a set of three-dimensional coordinates (x, y, z).</p>
<p id="p-0014" num="0013">One way that the present system <b>200</b> improves on the performance of the prior art is, at least in part, by using only data points representing the ground surface and a target <b>106</b> (if present) and not the obstructions at a height greater than a predetermined threshold above the ground. Using only the ground points greatly reduces the number of points that are to be down-linked and processed and thus reduces the time required to produce a model of the terrain.</p>
<p id="p-0015" num="0014">The data provided by the LADAR instrument <b>102</b> may comprise an effect known as ringing (or corona effect). Ringing is caused by scattering of the light produced by a target area that sometimes causes a false image to appear. A ringing removal filter (circuitry or program logic) <b>204</b> is used for filtering the received 3D topographical points to remove the ringing. Not all topographical data includes ringing. Therefore, the filer <b>204</b> is not always required. The ringing is removed by ignoring all data beyond a selected azimuth setting (for example), thus eliminating any false images. The selection of the azimuth setting is governed by statistical data or determined heuristically. In cases where the input comprises ringing, the use of the ringing removal filter <b>204</b> in system <b>200</b> increases the signal to noise ratio at the output of the filter <b>204</b>.</p>
<p id="p-0016" num="0015">The output provided by the ringing noise removal filter <b>204</b> is received at a ground finder <b>206</b>. The ground finder <b>206</b> is used for finding a ground surface using the plurality of raw topographical points (e.g., from the LADAR instrument <b>102</b>) and their coordinates and providing a plurality of ground points representing a plurality of frames, in turn representing patches of the ground surface and the target <b>106</b>. The ground finder <b>206</b> finds the ground by extracting ground points from its input and filtering out points representing the obstructions such as those from the top of the trees. As expected, the number of LADAR pulses that reach the ground through the trees and other foliage is much smaller than those emitted by the LADAR source (or emitter). Therefore, the points of light representing the ground (ground points) detected at the LADAR sensor <b>103</b> is commensurately smaller than the total number received from the totality of the terrain below the aircraft <b>104</b>.</p>
<p id="p-0017" num="0016">The ground finder <b>206</b> thus extracts a ground surface shell (a set of points defining a three-dimensional surface) from the topographical data provided at the output of the ringing removal filter <b>204</b>. The output of the ground finder <b>206</b> comprises a set of data representing the ground surface that includes the target <b>106</b>.</p>
<p id="p-0018" num="0017">The ground finder <b>206</b> also operates to make sure that the ground is continuous so that there are no large changes in the topography. This is accomplished by creating a two-dimensional (2D) grid for the ground surface and determining the height of the ground at each grid component. Each grid component preferably represents a square part of the ground that is one meter on each side. Once this data is collected for the entire grid, the ground finder <b>206</b> eliminates points that appear to be out of place or which are based on insufficient data. The decision on which points to eliminate is based on artifacts programmed into the ground finder <b>206</b>. The ground finder <b>206</b> is further programmed to ignore any points higher than a predetermined height (e.g., the height of a person, such as six feet) when calculating the contour of the ground surface. The predetermined height is determined by rule-based statistics. That is done to eliminate any structures that are not likely to be part of the ground. Thus, the output of the ground finder <b>206</b> provides a more faithful representation of the actual ground surface than systems also using the treetop data.</p>
<p id="p-0019" num="0018">The output of the ground finder <b>206</b> is provided to a competitive filter <b>208</b>. The competitive filter <b>208</b> is used to work on the ground surface data (ground points) provided by the ground finder <b>206</b>. The ground points are filtered using the competitive filter <b>208</b> to obtain a 3D shell of DEM points. The competitive filter <b>208</b> filters ground surface data not tied to geospatial coordinates such as the data collected by the LADAR instrument <b>202</b>. The filter <b>208</b> works by performing a polynomial fit of predetermined order for each frame of data points. This is done by determining which polynomial best represents the set of points in the frame. One example is a first order polynomial (a tilted plane) and the other is a numeric average (zero order). In the preferred embodiment, the average and the tilted plane (respectively, zero and first order polynomials) compete for the best fit in any given frame or volume of points. Other embodiments may utilize higher order polynomials. A method for fitting polynomials in frames is discussed in U.S. patent application Ser. No. 09/827,305, the disclosure of which is hereby incorporated by reference in its entirety.</p>
<p id="p-0020" num="0019">Thus, for every frame of points the filter <b>208</b> determines a tilted plane that fits the points in that frame. Each frame is a micro frame that covers a patch of ground constituting a small portion of the total area being processed. The output of the competitive filter <b>208</b> is a contour comprising a plurality of (e.g., thirty) planes, one for each frame acquired. An optimal estimate of the ground surface allows for obscuration by the trees and foliage to produce an image of a partially obscured target. Once each frame is processed by the filter <b>208</b> the output is an unregistered DEM surface. In this embodiment the surface is a ground surface, however it should be appreciated that the method and system of the invention can be used on any surface of a target object.</p>
<p id="p-0021" num="0020">The data produced by the competitive filter <b>208</b> DEM is not suitable for rendering an image that is useful to a user of the system <b>200</b>. To produce a viewable image we must first complete a registration process. In the preferred embodiment the registration is performed by an iterative process performed by blocks <b>210</b> (a registration engine) and <b>212</b> (a rigid transform engine). In this embodiment, to obtain a 3D representation of the ground surface, several sets of data (frames) are automatically pieced together to create an image of an entire target area or surface. Each set of data (or frame) is taken from a different perspective providing a different view of the surface features. Registration determines the relative positions of each of the points representing the surface as the sensor <b>103</b> moves over that surface. Thus different views of the surface area are aligned with each other by performing a translation and rotation of each frame to fit an adjacent frame or frames.</p>
<p id="p-0022" num="0021">The first part of the registration process is to find in a second frame the closest point for each of a plurality of points in a first (adjacent) frame. Once the closest point is found, the points are aligned such that the frames make a good fit representing the registered model or image. This is known as a pair wise process. Each iteration of the process produces a better fit and the process continues until an optimum alignment is realized. This is accomplished by determining a computation cost associate with each rotation and translation of each frame to fit other frames. Using the information (matches between adjacent frames) collected in each iteration, subsequent iterations correct the alignment until an abort criterion is reached. This criterion can be the completion of a number of iterations or the accomplishment of a predetermined goal. In this embodiment, we perform the closest point search for each point in a first frame to locate closest points in at least one other frame by entering observations from each iteration into a matrix and then solving the matrix at once so that all transformations are performed substantially simultaneously (i.e., an n-wise process). An example of a matrix is found in J. A. Williams and M. Bennamoun, “Simultaneous Registration of Multiple Point Sets Using Orthonormal Matrices” Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP June 2000) at pp. 2199-2202.</p>
<p id="p-0023" num="0022">In the preferred embodiment the iterative process is repeated several (e.g., five) times to determine an optimum rotation and translation for the frames. We preferably use the algorithm presented in J. A. Williams and M. Bennamoun, “Simultaneous Registration of Multiple Point Sets Using Orthonormal Matrices” Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP June 2000) at pp. 2199-2202, the disclosure of which is hereby incorporated by reference.</p>
<p id="p-0024" num="0023">The iterated transformations discussed above are performed at block <b>212</b>. Each transformation is a rigid transformation. A transform is said to be rigid if it preserves the distances between corresponding points.</p>
<p id="p-0025" num="0024">The frame integrator block <b>214</b> performs an integration (or union) of the registered volumes produced by block <b>212</b> and the result is cropped to a size and shape suitable for presentation and then it is visually exploited at block <b>216</b> to show the structure of the target. The result is a 3D model that is displayed quickly. In the embodiment discussed herein a target such as the tank <b>106</b> hidden under the treetops as shown in <figref idref="DRAWINGS">FIG. 1</figref> is depicted without the obscuring effect of the canopy of trees over the tank <b>106</b>.</p>
<p id="p-0026" num="0025">As discussed above, the speed of the registration process is critical in many applications such a locating a hidden target such as a tank <b>106</b> in a combat environment. One way to speed up the process is to improve the speed of the search for corresponding points from frame to frame. This can be accomplished by using any of several well-known k-D tree algorithms. Thus, the data points from each frame are mapped into a tree structure such that the entire set of points in an adjacent frame do not have to be searched to find the closest point for a given point in a first frame. An example of a k-D tree algorithm is found at the web site located at http://www.rolemaker.dk/nonRoleMaker/uni/algogem/kdtree.htm.</p>
<p id="p-0027" num="0026">Referring to <figref idref="DRAWINGS">FIG. 3</figref>, there is shown a flow chart illustrating a simplified method <b>300</b> for extraction of bare earth digital elevation model according to an embodiment of the invention. The method is performed using a system such as the one described with respect to <figref idref="DRAWINGS">FIG. 2</figref>. In step <b>302</b> the system receives a plurality of multi-dimensional points representing a frame volume. In step <b>304</b> the system finds the ground by isolating ground points from above-ground obstructions. In step <b>306</b> the system filters the ground points to obtain a multi-dimensional shell of digital elevation model points. The result of filtering is a DEM representing the ground area beneath the obstructions shown in <figref idref="DRAWINGS">FIG. 1</figref>. There are several possible applications for this output.</p>
<p id="p-0028" num="0027">Therefore, while there has been described what is presently considered to be the preferred embodiment, it is understood by those skilled in the art that other modifications can be made within the spirit of the invention.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>We claim:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A method for extracting a digital elevation model from a plurality of raw topographical points representing a plurality of frames, each frame representing a perspective of a multi-dimensional object comprising a surface and above-surface obstructions, the method comprising:
<claim-text>finding the surface by filtering out data points representing the above-surface obstructions to provide a plurality of surface data points representing the surface; and</claim-text>
<claim-text>filtering the surface data points with a competitive filter to provide a multi-dimensional surface shell of digital elevation model data points comprising a plurality of filtered frames.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the filtering with the competitive filter comprises determining a plurality of tilted planes defining the surface.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the topographical points comprise coordinates in three dimensions.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising registering the plurality of filtered frames.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising using an iterative closest point process for aligning data points in adjacent frames.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising integrating the plurality of filtered frames for display thereof.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising performing a k-D tree search for each of a plurality of points in a first frame to find a closest point in at least one adjacent frame.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A system for extracting a bare earth digital elevation model from a plurality of raw topographical points representing a multi-dimensional object comprising a surface and above-surface obstructions, the system comprising:
<claim-text>a ground finder for finding a ground surface by receiving the plurality of raw topographical Points representing a plurality of frames, each frame representing a portion of the surface and filtering ground points from above-ground obstruction points to provide a plurality of ground points representing the ground surface; and</claim-text>
<claim-text>a competitive filter for filtering the ground points to obtain a multi-dimensional shell of digital elevation model points.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising registration logic for registering the shell of digital elevation model points.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the ground finder finds the ground surface by processing ground points and clips every point above a predetermined threshold height.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the multi-dimensional points comprise coordinates in three-dimensions.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref> further comprising a ringing noise removal filter for receiving the plurality of raw topographical points to remove any ringing effect in the raw topographical points and to provide a signal with improved signal to noise ratio to the ground finder.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref> further comprising a LADAR sensor for receiving points of light reflected or scattered by a subject surface and providing the plurality of topographical points.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref> further comprising a LADAR source for emitting pulses of light to the surface.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref> further comprising an IFSAR instrument for receiving data points produced by a subject surface and providing the plurality of topographical points.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. A computer readable medium comprising program instructions for extracting a digital elevation model from a plurality of raw topographical points representing a plurality of frames representing a plurality of perspectives of a multi-dimensional object comprising a surface and above-surface obstructions, the medium comprising instructions for:
<claim-text>finding the surface by filtering out data points produced by the above-surface obstructions to provide a plurality of surface data points representing the surface; and</claim-text>
<claim-text>filtering the surface data points with a competitive filter to provide a multi-dimensional surface shell of digital elevation model data points comprising a plurality of filtered frames.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The medium of <claim-ref idref="CLM-00016">claim 16</claim-ref> further comprising an instruction for registering the shell of digital elevation model points.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The medium of <claim-ref idref="CLM-00016">claim 16</claim-ref> further comprising an instruction for using an iterative closest point algorithm.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The medium of <claim-ref idref="CLM-00016">claim 16</claim-ref> further comprising an instruction for using a fast KD Tree search on adjacent collected pairs of surface shells finding rotation and translation parameters that are optimal for the current iteration.</claim-text>
</claim>
</claims>
</us-patent-grant>
