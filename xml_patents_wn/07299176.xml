<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07299176-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07299176</doc-number>
<kind>B1</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10251702</doc-number>
<date>20020919</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>883</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>10</class>
<subclass>L</subclass>
<main-group>21</main-group>
<subgroup>00</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>704228</main-classification>
</classification-national>
<invention-title id="d0e53">Voice quality analysis of speech packets by substituting coded reference speech for the coded speech in received packets</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4476559</doc-number>
<kind>A</kind>
<name>Brolin et al.</name>
<date>19841000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370522</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5737365</doc-number>
<kind>A</kind>
<name>Gilbert et al.</name>
<date>19980400</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>375224</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>5812534</doc-number>
<kind>A</kind>
<name>Davis et al.</name>
<date>19980900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370260</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>5940479</doc-number>
<kind>A</kind>
<name>Guy et al.</name>
<date>19990800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>379 9301</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6009082</doc-number>
<kind>A</kind>
<name>Caswell et al.</name>
<date>19991200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370276</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6275797</doc-number>
<kind>B1</kind>
<name>Randic</name>
<date>20010800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704233</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6289003</doc-number>
<kind>B1</kind>
<name>Raitola et al.</name>
<date>20010900</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714748</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6330428</doc-number>
<kind>B1</kind>
<name>Lewis et al.</name>
<date>20011200</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>704230</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6910168</doc-number>
<kind>B2</kind>
<name>Baker et al.</name>
<date>20050600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>714751</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>US</country>
<doc-number>7061903</doc-number>
<kind>B2</kind>
<name>Higuchi</name>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370352</main-classification></classification-national>
</citation>
<citation>
<patcit num="00011">
<document-id>
<country>US</country>
<doc-number>7068594</doc-number>
<kind>B1</kind>
<name>Tasker</name>
<date>20060600</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370217</main-classification></classification-national>
</citation>
<citation>
<patcit num="00012">
<document-id>
<country>US</country>
<doc-number>2002/0003799</doc-number>
<kind>A1</kind>
<name>Tomita</name>
<date>20020100</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>370392</main-classification></classification-national>
</citation>
<citation>
<nplcit num="00013">
<othercit>International Telecommunication Union, ITU-T Telecommunication Standardization Sector of ITU, ITU-T Recommendation G.113, “<i>Transmission Systems and Media, General Characteristics of International Telephone Connections and International Telephone Circuits</i>”, 1 cover page, 1 page Foreword, 2 pages Contents, 1 page Summary, 31 pages of text, Feb. 1996.</othercit>
</nplcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>33</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>704230</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704231</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>704233</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>714747</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>714748</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>714749</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>714750</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>714751</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>3</number-of-drawing-sheets>
<number-of-figures>4</number-of-figures>
</figures>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Lee</last-name>
<first-name>Yueh-ju</first-name>
<address>
<street>1082 Norfolk Dr.</street>
<city>San Jose</city>
<state>CA</state>
<postcode>95129</postcode>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Chang</last-name>
<first-name>Shang-Pin</first-name>
<address>
<street>4227 Nerissa Cir.</street>
<city>Fremont</city>
<state>CA</state>
<postcode>94555</postcode>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Luong</last-name>
<first-name>Phuong</first-name>
<address>
<street>1805 Cheney Dr.</street>
<city>San Jose</city>
<state>CA</state>
<postcode>95128</postcode>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="004" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Shi</last-name>
<first-name>Hang</first-name>
<address>
<street>231 Dixon Landing Rd. Apt. 233</street>
<city>Milpitas</city>
<state>CA</state>
<postcode>95035</postcode>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="005" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Lin</last-name>
<first-name>Frank C.</first-name>
<address>
<street>12056 Jamestown Ct.</street>
<city>Saratoga</city>
<state>CA</state>
<postcode>95070</postcode>
<country>US</country>
</address>
</addressbook>
<nationality>
<country>omitted</country>
</nationality>
<residence>
<country>US</country>
</residence>
</applicant>
<applicant sequence="006" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Huang</last-name>
<first-name>Yu-Lun</first-name>
<address>
<street>6F-1, No. 86 Ta-Hsueh Road</street>
<city>Hsinchu, 300</city>
<country>TW</country>
</address>
</addressbook>
<nationality>
<country>TW</country>
</nationality>
<residence>
<country>TW</country>
</residence>
</applicant>
</applicants>
</parties>
<examiners>
<primary-examiner>
<last-name>{hacek over (S)}mits</last-name>
<first-name>Talivaldis Ivars</first-name>
<department>2626</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A system and method for voice quality analysis include the ability to receive packets in a voice stream and to generate a receipt indicator for the packets. The system and method also include the ability to substitute a reference voice sample for the voice data in the packets and to compare the voice data in the voice-substituted packets to the reference voice sample to determine voice quality.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="98.55mm" wi="167.98mm" file="US07299176-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="236.30mm" wi="171.62mm" file="US07299176-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="236.90mm" wi="135.13mm" orientation="landscape" file="US07299176-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="206.16mm" wi="128.61mm" file="US07299176-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">TECHNICAL FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">This invention relates in general to communication systems, and, more particularly, to a system and method for voice quality analysis of communication systems.</p>
<heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">One type of network that has received considerable interest over the past several years for its voice conveyance capabilities is the packet data network. In such a network, sound at an origination point may be digitized, placed into packets, and sent across the network in the packets to a destination point, which may reproduce the sound based on the data in the packets.</p>
<p id="p-0004" num="0003">Unfortunately, the packets in such a network may be sent at irregular intervals, sent by different routes, and/or discarded. This leads to voice packets arriving at irregular intervals, arriving in a different order, and/or not arriving at all relative to their generation at the origination point. Thus, voice quality may suffer.</p>
<p id="p-0005" num="0004">Typical systems for assessing voice quality in a packet data network require recording a test voice stream at a destination point and generating a reference voice stream from a reference voice sample. The recorded voice stream and the generated voice stream may then be compared to determine the voice quality of the network.</p>
<p id="p-0006" num="0005">This approach, however, requires an additional device in the network under test so that the test voice stream may be introduced. Furthermore, introducing the test voice stream requires coordination between the origination and destination points and produces extra load in the network, which corrupts the analysis. Additionally, by only being able to measure voice quality from the origination point to the destination point, isolating problems in the network is difficult.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0007" num="0006">The present invention provides a system and method that substantially reduce and/or eliminate at least some of the problems and/or disadvantages with existing systems and methods for voice quality analysis. To accomplish this, the present invention provides, at least in certain embodiments, a voice quality module that does not require a test stream to be introduced into the network.</p>
<p id="p-0008" num="0007">In particular embodiments, a system for voice quality analysis includes a voice packet capture module, a voice data substitution module, and a voice quality analysis module. The voice packet capture module is operable to receive packets in a voice stream and to generate a receipt indicator for the packets. The voice data substitution module is operable to substitute a reference voice sample for the voice data in the packets. The voice quality analysis module is operable to compare the voice data in the voice-substituted packets to the reference voice sample to determine voice quality.</p>
<p id="p-0009" num="0008">In certain embodiments, a method for voice quality analysis includes receiving packets in a voice stream and generating a receipt indicator for the packets. The method also includes substituting a reference voice sample for the voice data in the packets and comparing the voice data in the voice-substituted packets to the reference voice sample to determine voice quality.</p>
<p id="p-0010" num="0009">The present invention has several technical features. For example, because a voice quality module may be coupled between an originating endpoint and a receiving endpoint, problems introduced by the receiving endpoint may be eliminated from the voice quality analysis. Furthermore, because a voice quality module may be coupled to a communication system at a variety of locations, problems with voice quality in the communication system may be isolated and/or identified. As another example, because a reference voice sample does not have to be introduced into a communication system for a voice quality module to perform its task, the operations of the system may not be disturbed by the analysis, leading to more accurate analysis. Moreover, by still being able to use a reference voice sample, privacy concerns are assuaged. As another example, a device does not have to be provided at one of the endpoints to introduce the reference voice stream into the communication system, which simplifies the analysis process. Moreover, the test stream introduction and recording do not have to be coordinated, which also simplifies the analysis process.</p>
<p id="p-0011" num="0010">Of course, some embodiments may possess none, one, some, or all of these technical features and/or additional technical features. Other technical features will be readily apparent to those skilled in the art from the figures, detailed written description, and claims.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0012" num="0011">The figures described below provide a more complete understanding of the present invention and its technical features, especially when considered with the following detailed written description:</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a communication system in accordance with one embodiment of the present invention;</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. 2</figref> illustrates one embodiment of a voice quality module for the communication system of <figref idref="DRAWINGS">FIG. 1</figref>;</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. 3</figref> illustrates a portion of memory for the voice quality module of <figref idref="DRAWINGS">FIG. 2</figref>; and</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. 4</figref> illustrates a method for voice quality analysis in accordance with one embodiment of the present invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. 1</figref> illustrates a communication system <b>10</b> in accordance with one embodiment of the present invention. In general, communication system <b>10</b> includes endpoints <b>20</b>, a communication network <b>30</b>, and a voice quality module <b>50</b>. Endpoints <b>20</b> generate and/or store voice data and convey it through communication network <b>30</b> in packets, a succession of related packets from one of endpoints <b>20</b> forming a voice-packet stream. Voice quality module <b>50</b>, in turn, is able to analyze the effects that the conveyance has on the packets and, hence, the voice data.</p>
<p id="p-0018" num="0017">In more detail, endpoints <b>20</b> may include telephones, voice-capable personal computers, personal computers, voice-capable personal digital assistants, personal digital assistants, a voice-mail storage and delivery system, and/or any other type of device for generating voice data, storing voice data, sending it to communication network <b>30</b>, receiving it from communication network <b>30</b>, and/or converting it to audible sound. If one of endpoints <b>20</b> generates voice data based on audible sound of a user, it will typically include a microphone to convert the audible sound into electrical signals, an encoder to convert the electrical signals to voice data, and a processor executing logical instructions to group the voice data into packets and send them to communication network <b>30</b>. If one of endpoints <b>20</b> generates audible sound based on voice data, it will typically include a processor executing logical instructions to receive voice packets from communication network <b>30</b> and ungroup the voice data from the packets, a decoder to convert the voice data to electrical signals, and a speaker to convert the electrical signals to audible sound. In particular embodiments, endpoints <b>20</b> are telephones that utilize Internet protocol (IP) telephony techniques.</p>
<p id="p-0019" num="0018">Communication network <b>30</b> provides the conveyance of the voice data packets between endpoints <b>20</b>. To accomplish this, communication network <b>30</b> is coupled to endpoints <b>20</b> by links <b>31</b>. Links <b>31</b> may be wires, cables, fiber-optic cables, microwave channels, infrared channels, or any other type of wireline or wireless path for conveying data. Additionally, communication network <b>30</b> includes conveyance modules <b>32</b>. Conveyance modules <b>32</b> may be switches, routers, bridges, voice gateways, call managers, transceivers, hubs, and/or any other type of device for conveying data packets. Conveyance modules <b>32</b> are also coupled to each other by links <b>31</b>, which may have intervening conveyance modules. Communication network <b>30</b> may operate according to any appropriate type of protocol, such as, for example, Ethernet, IP, X.25, frame relay, or any other packet data protocol. Note that communication network <b>30</b> may also support the conveyance of non-voice data packets between endpoints <b>20</b> and/or other devices.</p>
<p id="p-0020" num="0019">Communication network <b>30</b> also includes a gateway <b>34</b>, which is coupled to conveyance module <b>32</b><i>o </i>by one of links <b>31</b>. Gateway <b>34</b> is operable to convert voice data packets in communication network <b>30</b> to a format suitable for a public switched telephone network (PSTN) <b>40</b> and/or to convert voice data from PSTN <b>40</b> to a format suitable for communication network <b>30</b>. Thus, endpoints <b>20</b> may operate with standard telephony devices.</p>
<p id="p-0021" num="0020">Voice quality module <b>50</b> is coupled to conveyance module <b>32</b><i>z </i>by one of links <b>31</b> in the illustrated embodiment, although it could be coupled to any of conveyance modules <b>32</b>, or even one of endpoints <b>20</b>. By being coupled to conveyance module <b>32</b><i>z</i>, voice quality module <b>50</b> is operable to receive packets from a voice-packet stream being conveyed by conveyance module <b>32</b><i>z </i>and to analyze the voice quality for the stream. To receive packets from a voice-packet stream, voice quality module <b>50</b> may, for example, tap a shared medium, such as, for example, an Ethernet connection or a wireless connection. The voice data in the packets may then be replaced by an encoded reference voice sample, and the packets analyzed using the encoded reference voice sample. Voice quality module <b>50</b> may include a communication interface, a processor, a memory, an encoder, a decoder, a voice synthesizer, a reference voice sample, a filter, an echo canceller, and/or any other components for receiving and analyzing packets for voice quality analysis. In particular embodiments, voice quality module <b>50</b> is a Linux-based PC with an Ethernet port.</p>
<p id="p-0022" num="0021">In operation, when one of endpoints <b>20</b>, endpoint <b>20</b><i>a</i>, for example, wishes to convey voice data to another of endpoints <b>20</b>, endpoint <b>20</b><i>z</i>, for example, a session is established between the endpoints. A session may be established according to the real-time transfer protocol (RTP), the H.323 protocol, the Skinny protocol, or any other appropriate protocol. Then, endpoint <b>20</b><i>a </i>may begin to send packets containing voice data, which may or may not have been generated by endpoint <b>20</b><i>a</i>, to conveyance module <b>32</b><i>a </i>of communication network <b>30</b>. Upon receiving the packets, conveyance module <b>32</b><i>a </i>routes the packets toward endpoint <b>20</b><i>z</i>. Typically, the route will be defined during establishment of the session, or conveyance module <b>32</b><i>a </i>may define the route. Sometimes, however, packets may take alternate routes. The packets are conveyed over links <b>31</b> and through conveyance modules <b>32</b> towards endpoint <b>20</b><i>z. </i></p>
<p id="p-0023" num="0022">When packets in the voice stream arrive at conveyance module <b>32</b><i>z</i>, voice quality module <b>50</b> may store the packets and their arrival characteristics in order to perform voice quality analysis. To determine which packets to analyze, voice quality module <b>50</b> may examine the destination address of the packets, the origination address of the packets, the arrival port of the packets, the type of data conveyed by the packets, and/or any other appropriate indicia. For example, using the destination address, voice conveyance module <b>50</b> may look for voice packets destined for a particular endpoint <b>30</b>, on a particular local area network (LAN), or on a particular virtual LAN (VLAN). For instance, if voice quality module <b>50</b> is coupled to a catalyst switch, it may use the switch's spanning feature to record and analyze the voice streams on a VLAN. For a service provider environment, it may be beneficial to couple voice quality module <b>50</b> to an aggregation point or other device where network congestion is likely to occur. As another example, voice quality module <b>50</b> may look for signaling messages indicating that a call is being set up. This may be done upon command, at predetermined intervals, or upon any other appropriate criterion. The packets of interest may be stored along with their arrival characteristics, such as, for example, time of arrival, order of arrival, and/or any other appropriate arrival characteristics.</p>
<p id="p-0024" num="0023">Once a sufficient number of packets of interest have been collected, perhaps indicated by the end of the voice stream from endpoint <b>20</b><i>a </i>to endpoint <b>20</b><i>z </i>or by a sufficient amount of voice data having been received, a reference voice sample may be substituted for the voice data in the collected packets. To accomplish this, the collected packets may be examined to determine the type of encoding, and possibly frame size and packetization, used for the voice data in the packets. The reference voice sample may then be encoded similarly, and the encoded reference voice sample may be substituted for the voice data in the packets, perhaps based on the size of each packet and the sequence in the voice stream. Note that if some packets are missing from the voice stream, the portion of the encoded reference voice sample associated with that packet may be discarded.</p>
<p id="p-0025" num="0024">The packets with the encoded reference voice sample may be processed as if they were the actual packets arriving from endpoint <b>20</b><i>a</i>, with the jitter, packet losses, and/or packet ordering that occurred prior to arriving at voice quality module <b>50</b>. For example, the voice data in the packets may be decoded, synthesized, and compared to the reference voice sample to obtain a voice quality analysis. The voice quality analysis may be made according to perceptual speech quality measurement (PSQM) techniques, such as, for example, those described in ITU-T P.861, or any other appropriate technique. Results of the analysis, such as, for example, signaling events (e.g., call setup and disconnect), statistics (e.g., jitter, drop, order), a voice quality score, or any other appropriate data, may be conveyed to a user by display device, acoustic device, electronic message, and/or other appropriate technique and/or stored for later retrieval. In particular embodiments, the results are conveyed if a threshold is broken, such as, for example, a high PSQM score. In certain embodiments, a representation of the reference voice sample or the voice data in the packets may also be output and/or sent to a user.</p>
<p id="p-0026" num="0025">As illustrated in <figref idref="DRAWINGS">FIG. 1</figref>, the present invention has several technical features. For example, because voice quality module <b>50</b> may be coupled between endpoints <b>20</b>, problems introduced by the receiving endpoint may be eliminated from the voice quality analysis. Furthermore, because voice quality module <b>50</b> may be coupled to communication network <b>30</b> at a variety of locations, voice quality module <b>50</b> may provide enhanced location and/or identification of problems with voice quality in communication network <b>30</b>. In particular embodiments, a number of voice quality modules like voice quality module <b>50</b> could be used in system <b>10</b> to enhance location and/or identification of problems with voice quality. As another example, because a reference voice sample does not have to be introduced into communication network <b>30</b> for voice quality module <b>50</b> to perform its task, the operations of the network may not be disturbed by the analysis, leading to more accurate results. Moreover, by still being able to use a reference voice sample, privacy concerns are assuaged. As another example, a device does not have to be provided at one of endpoints <b>20</b> to introduce the reference voice stream into communication network <b>30</b>, which simplifies the analysis process. Moreover, test stream introduction and recording do not have to be coordinated, which also simplifies the analysis process. A variety of other technical features exist.</p>
<p id="p-0027" num="0026">Although <figref idref="DRAWINGS">FIG. 1</figref> illustrates one embodiment of a communication system in accordance with the present invention, other embodiments may include fewer, more, and/or a different arrangement of components. For example, certain embodiments may not include gateway <b>40</b>. As an additional example, in some embodiments, one, some, or all of endpoints <b>20</b> and voice quality module <b>50</b> may be part of communication network <b>30</b>. As another example, voice quality module <b>50</b> may be part of one of conveyance modules <b>32</b> or of one of endpoints <b>20</b>. As an additional example, some embodiments may include other devices, such as non-voice-enabled computers, servers, or workstations, that use communication network <b>30</b> to convey data. In particular embodiments, voice quality module <b>50</b> may be coupled to a communication system at any of a variety of points, such as, for example, conveyance modules, links, endpoints, or gateways, allowing enhanced location and/or identification of problems with voice quality. Moreover, the communication system may include a variety of voice quality modules such as voice quality module <b>50</b>, which may again improve voice quality analysis. For instance, by examining the analysis from two such modules, voice quality information over a section may be determined, and, if the modules have synchronized clocks, delay measurements may be determined. A variety of other examples exist.</p>
<p id="p-0028" num="0027">Note that voice quality module <b>50</b> may suffer from several drawbacks. For example, if a tap is not perfect, voice packets may be missed, and, hence, voice quality may be undercomputed. As another example, even if the tap is perfect, routing flaps or load splitting might cause some voice packets to be conveyed by alternate routes, which may bypass the tap, leading to an effect similar to the one just mentioned. As a further example, in encoding schemes where the packet type does not reflect the encoding, the encoding of the data may have to be estimated, or the signaling messages for the session between endpoints may have to be tapped. The former is error prone, and the latter may be difficult because the signaling may go by a different path or may be encrypted. In particular embodiments, however, voice quality module <b>50</b> may run in a distributed mode in which it examines both a signaling channel and a bearer channel. As an additional example, the arrival characteristics of the voice packets may only reflect the conditions in communication system <b>10</b> upstream of the tap. Thus, conditions in communication system <b>10</b> downstream of the tap may not be reflected by the voice quality analysis. As another example, accurate emulation of an adaptive jitter algorithm may be imperfect because of sensitivity of the algorithm to initial conditions and other timing-related problems. As a further example, encrypted RTP packets may be difficult to interpret correctly since the packet type is inside the encrypted envelope; of course, time sequence and sequence number are probably in the clear, so the basic tap information is still available. Even with these potential drawbacks, however, the various embodiments of the present invention have advantages, some of which have been mentioned previously.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 2</figref> illustrates one embodiment of voice quality module <b>50</b>. As illustrated, this embodiment of voice quality module <b>50</b> includes a voice packet capture module <b>51</b>, a voice data substitution module <b>54</b>, a reference voice sample <b>55</b>, a maximum length sequence (MLS) module <b>56</b>, a decoding module <b>57</b>, a voice synthesis module <b>58</b>, and a voice quality analysis module <b>59</b>.</p>
<p id="p-0030" num="0029">Voice packet capture module <b>51</b> receives packets from communication network <b>30</b>, determines whether the packets are of interest, and, if they are of interest, stores them and their associated arrival characteristics in a memory <b>52</b>, which is a type of computer readable media. To determine whether a packet is of interest, voice packet capture module <b>51</b> may examine the destination address of the packet, the origination address of the packet, the type of data in the packet, the arrival port of the packet, and/or any other appropriate criterion that indicates the packet is part of a voice stream. If a packet is of interest, voice packet capture module <b>51</b> stores the packet and its associated arrival characteristics in a location <b>53</b> in memory <b>52</b>. Voice packet capture module <b>51</b> continues to examine packets and store those of interest in location <b>53</b> until a sufficient number of packets have been received. A sufficient number of packets may be received, for example, if there are no more packets in a voice stream or if voice data representing a predetermined period of time, such as, for example sixty seconds, has been received.</p>
<p id="p-0031" num="0030">In particular embodiments, voice packet capture module <b>51</b> may include a communication interface, such as, for example, a network interface card, a transceiver, a modem, and/or a port, and a processor operating according to logical instructions, such as, for example, a microprocessor, a field programmable gate array (FPGA), an application specific integrated circuit (ASIC), and/or any other type of device for manipulating data in a logical manner. The instructions for the processor could be stored in memory <b>52</b>. Furthermore, memory <b>52</b> may include read-only memory (ROM), random access memory (RAM), compact-disk read-only memory (CD-ROM), registers, and/or any other type of volatile or non-volatile electromagnetic or optical data storage service. In general, voice packet capture module <b>51</b> may be any type of device that can receive, examine, and store packets from communication network <b>30</b>.</p>
<p id="p-0032" num="0031">Voice data substitution module <b>54</b> replaces the voice data in the packets of interest with voice data of reference voice sample <b>55</b>, which may be a WAV file, an AU file, or any other storable representation of audible sound. To accomplish this, voice data substitution module <b>54</b> examines the packets to determine the type of encoding used for the voice data, such as, for example, G.711, G.726, or G.729. For example, if the packets are sent using RTP, they may indicate the type of encoding used in the RTP header. As another example, the payload type and payload length for the packets, which may be in another header, may be examined to determine the encoding scheme. Voice data substitution module <b>54</b> may then encode reference voice sample <b>55</b> according to a similar encoding scheme and substitute the encoded reference voice sample for the voice data in the packets of interest, perhaps by using the sequence number of the packets. In doing this, voice data substitution module <b>54</b> may have to discard some of the encoded reference voice sample because of missing voice packets. Also, voice data substitution module <b>54</b> may truncate or recycle reference voice sample <b>55</b>, depending on the length of the voice stream to be analyzed. Voice data substitution module <b>54</b> may then output the packets, which now contain the encoded reference voice sample instead of the original voice data, according to their arrival characteristics to decoding module <b>57</b>.</p>
<p id="p-0033" num="0032">In particular embodiments, voice data substitution module <b>54</b> includes a processor operating according to logical instructions encoded in a memory. In general, however, voice data substitution module <b>54</b> may be any type of device that can examine voice packets and substitute an encoded reference voice sample for the voice data in the packets.</p>
<p id="p-0034" num="0033">MLS module <b>56</b> provides a pseudo-random code that voice data substitution module <b>54</b> may use to align the encoded reference voice sample with the reference voice sample. For example, voice data substitution module <b>54</b> may place the code in the first packet(s) in the voice stream to align the encoded reference with the reference.</p>
<p id="p-0035" num="0034">Decoding module <b>57</b> decodes the voice data, which is now the encoded reference voice sample, in the packets. In accomplishing this, the decoding module <b>57</b> may determine the type of encoding used on the voice data in the packets, apply a jitter buffer to the packets, and decode the voice data. Note that decoding module <b>57</b> may discard packets if they are too far out of order. Decoding module <b>57</b> passes the decoded voice data to voice synthesis module <b>58</b>.</p>
<p id="p-0036" num="0035">In particular embodiments, decoding module <b>57</b> includes a processor operating according to logical instructions encoded in a memory and operates similarly to one of endpoints <b>30</b>. In general, however, decoding module <b>57</b> may be any type of device for decoding voice data.</p>
<p id="p-0037" num="0036">Voice synthesis module <b>58</b> is responsible for converting the decoded voice data into a voice synthesized format. For example, voice synthesis module <b>58</b> may convert the decoded voice data into a WAV or an AU file. In particular embodiments, voice synthesis module <b>58</b> may be an audio format converter. In general, voice synthesis module <b>58</b> may be any type of device for synthesizing sound.</p>
<p id="p-0038" num="0037">After conversion of the decoded voice data into a voice synthesized format, voice quality analysis module <b>59</b> may compare the synthesized voice data to the reference voice sample <b>55</b> to perform a voice quality analysis. For example, voice quality analysis module <b>59</b> may use perceptual speech quality management (PSQM) techniques to determine voice quality. The results of such an analysis may be output to a user by a display device, an acoustic device, an electronic message, and/or any other suitable communication technique.</p>
<p id="p-0039" num="0038">In particular embodiments, voice quality analysis module <b>59</b> may be a PESQ, PAMS, or SNR calculator. In general, however, voice quality analysis module <b>59</b> may be any device that can compare audible sound.</p>
<p id="p-0040" num="0039">Although <figref idref="DRAWINGS">FIG. 2</figref> illustrates one embodiment of voice quality module <b>50</b>, other embodiments may have fewer, more, and/or a different arrangement of components and/or fewer, more, and/or a different ordering of functions. For example, in certain embodiments, the reference voice sample may be apriori encoded according to the same scheme as the voice data in the packets of interest. Thus, voice data substitution module <b>54</b> may not have to encode the reference voice sample. As an additional example, in some embodiments, the encoded reference voice sample may be compared to the voice data in the packets after substitution of the encoded reference voice sample for the voice data in the packets. Thus, the voice data in the packets does not have to be decoded and synthesized. As another example, in certain embodiments, voice quality module <b>50</b> may analyze more than one voice stream at a time. As another example, certain embodiments may not include MLS module <b>56</b>. As an additional example, decoding module <b>57</b> may process the voice packets according to the receipt characteristics. Thus, the packets do not have to be output from module <b>54</b> according to the receipt characteristics. As a further example, although voice quality module <b>50</b> has been illustrated as including voice packet capture module <b>51</b>, voice data substitution module <b>54</b>, reference voice sample <b>55</b>, MLS module <b>56</b>, decoding module <b>57</b>, voice synthesis module <b>58</b>, and voice quality analysis module <b>59</b>, in other embodiments, some or all of the functions of the modules may be performed by a processor implementing a set of logical instructions. For instance, a processor implementing logical instructions, which may be encoded in an appropriate form of computer readable media, may be able to perform some or all of the functions of voice packet capture module <b>51</b>, voice data substitution module <b>54</b>, MLS module <b>56</b>, decoding module <b>57</b>, voice synthesis module <b>58</b>, and voice quality analysis module <b>59</b>. As another example, in some embodiments, instead of replacing the actual voice data with the reference voice sample, the process can be reversed such that the actual voice payload is used to generate the reference voice sample. Once the reference voice sample is generated, the voice quality analysis module may be used to analyze the particular conversation. This may be particularly useful where a user want to find out how voice quality differs with different voice samples. A variety of other examples exist.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 3</figref> illustrates one embodiment of location <b>53</b> in memory <b>52</b> of voice packet capture module <b>51</b>. As mentioned previously, location <b>53</b> stores voice packets of interest and their associated receipt characteristics. In this embodiment, location <b>53</b> includes records <b>100</b>, each of which corresponds to a received, analyzed, and stored voice packet. Furthermore, each of records <b>100</b> includes a receipt indicator section <b>110</b> and a voice packet section <b>120</b>.</p>
<p id="p-0042" num="0041">Receipt indicator section <b>110</b> includes a time stamp field <b>112</b> and a sequence number field <b>114</b>. Time stamp field <b>112</b> contains an indication of the time at which the associated voice packet arrived at voice packet capture module <b>51</b>. As illustrated, time stamp field <b>112</b> indicates the hour, minute, second, and hundredth of a second at which a packet was received. The data in field <b>112</b> may be useful, among other things, for determining the jitter of the voice packets. Sequence number field <b>114</b> contains an indication of the sequence in which the associated voice packet arrived at voice packet capture module <b>51</b>. The data in field <b>114</b> may be useful, among other things, for determining the order in which voice packets arrived at voice packet capture module <b>51</b>.</p>
<p id="p-0043" num="0042">Voice packet section <b>120</b> includes an RTP section <b>122</b>, a user datagram protocol (UDP) section <b>124</b>, and an IP packet section <b>126</b>. RTP section <b>122</b> includes a time stamp field <b>132</b>, a sequence number field <b>134</b>, and a coding type field <b>136</b>. Time stamp field <b>132</b> contains an indication of when the associated voice data was processed. Field <b>132</b> may be useful in determining jitter and/or determining whether packets are missing from the voice stream. Sequence number field <b>134</b> contains an indication of where the associated voice data belongs in the voice stream. Field <b>134</b> may be useful in determining jitter, determining whether packets are missing from the voice stream, and/or determining the proper order of voice packets. Furthermore, the data may be useful for associating the encoded reference voice sample with the appropriate voice packets. Coding type field <b>136</b> contains an indication of the type of encoding scheme used for the voice data. For example, data that represents audible sounds may be encoded using G.711, G.726, or G.729. As mentioned previously, by examining the data in field <b>136</b>, the type of encoding used for the voice data may be determined and used for encoding the reference voice sample. UDP section <b>124</b> includes a port number field <b>142</b>. Port number field <b>142</b> contains an indication of the port for which the voice packet is destined at the receiving device. Field <b>142</b> may be useful in identifying packets of interest. IP packet section <b>126</b> includes a destination address field <b>152</b>, a type of service (TOS) field <b>154</b>, and a voice data field <b>156</b>. Destination address field <b>152</b> contains an indication of the destination of the voice packet, such as, for example, an IP address. Field <b>152</b> may be useful in identifying packets of interest. TOS field <b>154</b> contains an indication of the type of data that the packet is carrying. For example, the data in field <b>154</b> may indicate that the packet is carrying general data, audio data, video data, low priority data, high priority data, or any other type of data. In some embodiments, by examining TOS field <b>154</b> and the size of the voice data, an indication of the encoding for the voice data may be obtained. Voice data field <b>156</b> contains the actual voice data that is being conveyed. Field <b>156</b> may be encoded according to G.711, G.726, G.729, or any other appropriate format.</p>
<p id="p-0044" num="0043">Although one embodiment of location <b>53</b> in memory <b>52</b> is illustrated by <figref idref="DRAWINGS">FIG. 3</figref>, other embodiments may contain more, less, and/or a different arrangement of data. For example, in particular embodiments, field <b>114</b> may be eliminated. As another example, in certain embodiments, the captured voice packet may not contain field <b>134</b>, field <b>136</b>, and/or field <b>154</b>. Moreover, parts of the packet may be encrypted. As a further example, in some embodiments, the fields may not be arranged in a tabular format, instead being related by link lists, relational databases, hierarchical databases, or any other arrangement of data. In particular embodiments, field <b>156</b> may be eliminated, especially if an indicia of the amount of voice data in the field is generated. A variety of other examples exist.</p>
<p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. 4</figref> is a flowchart <b>400</b> that illustrates a method for voice quality analysis in accordance with one embodiment of the present invention. The method begins at decision block <b>404</b> with determining whether a packet has been received. Received packets may be streaming voice packets, streaming data packets, data packets, or any other type of packets.</p>
<p id="p-0046" num="0045">Once a packet has been received, the method calls for determining whether the packet is of interest at decision block <b>408</b>. A packet may be of interest, for example, if it is carrying voice data, is destined for a particular endpoint, originates from a particular endpoint, destined for a particular port, and/or contains any other appropriate voice-stream indicia. If the packet is not of interest, the method returns to decision block <b>404</b> to check whether another packet has been received. If, however, the packet is of interest, the method calls for generating a receipt indicator for the packet at function block <b>412</b>. As discussed previously, the receipt indicator may indicate the time that the packet was received, the sequence in which the packet was received, and/or any other appropriate receipt characteristic. At function block <b>416</b>, the method calls for storing the packet and the receipt indicator. For example, the packet and receipt indicator may be stored in a location of a memory.</p>
<p id="p-0047" num="0046">After this, the method calls for determining whether a sufficient number of packets of interest have been received at decision block <b>420</b>. A sufficient number of packets of interest may have been received, for example, if a predetermined amount of a voice stream, such as, for instance, sixty seconds, is represented by the packets of interest or if there are no more packets in a voice stream. If a sufficient number of packets of interest have not been received, the method returns to decision block <b>404</b> to check whether another packet has been received.</p>
<p id="p-0048" num="0047">If, however, a sufficient number of packets of interest have been received, the method calls for substituting a reference voice sample for the voice data in the packets at function block <b>424</b>. As discussed previously, this may include: 1) determining the type of encoding used for the voice data in the packets; 2) encoding the reference voice sample using the identified encoding type; and 3) substituting the encoded reference voice sample for the voice data in the packets. The method then calls for comparing the voice data, which is now the encoded reference voice sample, in the packets to the reference voice sample at function block <b>428</b>. As discussed previously, this may include decoding the voice data in the packets, generating a voice synthesis of the decoded data, and comparing the generated voice synthesis to the reference voice sample using PSQM techniques. After this, the method is at an end.</p>
<p id="p-0049" num="0048">Returning to decision block <b>404</b>, if a packet has not been received, the method calls for determining whether a voice stream is idle at decision block <b>432</b>. A voice stream may be idle, for example, if no packets have been received from it in thirty seconds. If a voice stream is not idle, the method calls for returning to decision block <b>404</b>. If, however, a voice stream is idle, the method calls performing the voice quality analysis operations discussed previously, beginning at function block <b>424</b>.</p>
<p id="p-0050" num="0049">Although flowchart <b>400</b> illustrates one embodiment of a method for voice quality analysis, other embodiments may include fewer, more, and/or a different arrangement of operations. For example, if packets are prescreened to identify those of interest, decision block <b>408</b> may be eliminated. As another example, the receipt indicator may be generated upon receipt of a packet and stored with the packet before determining whether the packet is of interest. As an additional example, a particular voice stream may need to be identified at the beginning of the method to determine which packets are of interest. As a further example, a plurality of voice streams may be analyzed simultaneously, meaning that the packets from the different voice streams will have to be identified separately from each other. A variety of other examples exist.</p>
<p id="p-0051" num="0050">While a variety of embodiments have been discussed for the present invention, a variety of additions, deletions, modifications, and/or substitutions will be readily suggested to those skilled in the art. It is intended, therefore, that the following claims encompass such additions, deletions, modifications, and/or substitutions to the extent that they do not do violence to the spirit of the claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A system for voice quality analysis, comprising:
<claim-text>a voice packet capture module operable to receive packets in a voice stream and to generate a receipt indicator for the packets;</claim-text>
<claim-text>a voice data substitution module operable to substitute a reference voice sample for voice data in the packets, and</claim-text>
<claim-text>a voice quality analysis module operable to compare the voice data in the voice-substituted packets to the reference voice sample to determine voice quality;</claim-text>
<claim-text>wherein, to substitute a reference voice sample for the voice data in the packets, the voice data substitution module is operable to:
<claim-text>determine an encoding scheme used for the voice data in the packets;</claim-text>
<claim-text>encode the reference voice sample according to the determined encoding scheme; and</claim-text>
<claim-text>associate portions of the encoded reference voice sample with the packets.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the packets comprise Internet protocol packets.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the voice data is encoded according to G.711.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the receipt indicator comprises a time stamp and a sequence number.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the voice packet capture module is further operable to:
<claim-text>determine whether a packet is of interest; and</claim-text>
<claim-text>retain the packet if it is of interest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the voice packet capture module is operable to examine a destination address of the packet to determine whether a packet is of interest.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A system for voice quality analysis, comprising:
<claim-text>a voice packet capture module operable to receive packets in a voice stream and to generate a receipt indicator for the packets;</claim-text>
<claim-text>a voice data substitution module operable to substitute a reference voice sample for voice data in the packets, and</claim-text>
<claim-text>a voice quality analysis module operable to compare the voice data in the voice-substituted packets to the reference voice sample to determine voice quality;</claim-text>
<claim-text>a decoding module operable to receive the voice-substituted packets according to an order and timing in which they were received by the voice packet capture module and to decode the voice data in the packets; and</claim-text>
<claim-text>a voice synthesis module operable to generate a synthetic voice sample based on the decoded data;</claim-text>
<claim-text>wherein the voice quality analysis module is operable to compare the synthetic voice sample to the reference voice sample to compare the voice data in the packets to the reference voice sample.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the decoding module is further operable to compensate, at least in part, for jitter in the voice-substituted packets.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the voice quality analysis module implements perceptual speech quality measurement techniques to compare the synthetic voice sample to the reference voice sample.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A method for voice quality analysis, comprising:
<claim-text>receiving packets in a voice stream;</claim-text>
<claim-text>generating a receipt indicator for the packets;</claim-text>
<claim-text>substituting a reference voice sample for voice data in the packets; and</claim-text>
<claim-text>comparing the voice data in the voice-substituted packets to the reference voice sample to determine voice quality;</claim-text>
<claim-text>wherein substituting a reference voice sample for the voice data in the packets comprises:
<claim-text>determining an encoding scheme used for the voice data in the packets;</claim-text>
<claim-text>encoding the reference voice sample according to the determined encoding scheme; and</claim-text>
<claim-text>associating portions of the encoded reference voice sample with the packets.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the packets comprise Internet protocol packets.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the voice data is encoded according to G.711.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the receipt indicator comprises a time stamp and a sequence number.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising:
<claim-text>determining whether a packet is of interest; and</claim-text>
<claim-text>retaining the packet if it is of interest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein determining whether a packet is of interest comprises examining a destination address of the packet.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein associating portions of the encoded reference voice sample with the packets comprises:
<claim-text>determining that a packet is missing from the voice stream; and</claim-text>
<claim-text>discarding the associated portion of the encoded reference voice sample.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. A method for voice quality analysis, comprising:
<claim-text>receiving packets in a voice stream;</claim-text>
<claim-text>generating a receipt indicator for the packets;</claim-text>
<claim-text>substituting a reference voice sample for voice data in the packets; and</claim-text>
<claim-text>comparing the voice data in the voice-substituted packets to the reference voice sample to determine voice quality;</claim-text>
<claim-text>wherein comparing the voice data in the voice-substituted packets to the reference voice sample comprises:
<claim-text>generating a stream of the packets according to an order and timing in which they were received;</claim-text>
<claim-text>compensating, at least in part, for jitter in the packets;</claim-text>
<claim-text>decoding the voice data in the packets;</claim-text>
<claim-text>generating a synthetic voice sample based on the decoded data; and</claim-text>
<claim-text>comparing the synthetic voice sample to the reference voice sample.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein comparing the synthetic voice sample to the reference voice sample comprises implementing perceptual speech quality measurement techniques.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. A set of logic for voice quality analysis, the logic encoded in a computer readable medium and operable to:
<claim-text>receive packets in a voice stream;</claim-text>
<claim-text>generate a receipt indicator for the packets;</claim-text>
<claim-text>substitute a reference voice sample for voice data in the packets; and</claim-text>
<claim-text>compare the voice data in the voice-substituted packets to the reference voice sample to determine voice quality;</claim-text>
<claim-text>wherein, to substitute a reference voice sample for the voice data in the packets, the logic is operable to:
<claim-text>determine an encoding scheme used for the voice data in the packets;</claim-text>
<claim-text>encode the reference voice sample according to the determined encoding scheme; and</claim-text>
<claim-text>associate portions of the encoded reference voice sample with the packets.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The logic of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the receipt indicator comprises a time stamp and a sequence number.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text>21. The logic of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the logic is further operable to:
<claim-text>determine whether a packet is of interest; and</claim-text>
<claim-text>retain the packet if it is of interest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text>22. The logic of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the logic is operable to examine a destination address of the packet to determine whether a packet is of interest.</claim-text>
</claim>
<claim id="CLM-00023" num="00023">
<claim-text>23. The logic of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein, to associate portions of the encoded reference voice sample with the packets, the logic is operable to:
<claim-text>determine that a packet is missing from the voice stream; and</claim-text>
<claim-text>discard the associated portion of the encoded reference voice sample.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00024" num="00024">
<claim-text>24. A set of logic for voice quality analysis, the logic encoded in a computer readable medium and operable to:
<claim-text>receive packets in a voice stream;</claim-text>
<claim-text>generate a receipt indicator for the packets;</claim-text>
<claim-text>substitute a reference voice sample for voice data in the packets; and</claim-text>
<claim-text>compare the voice data in the voice-substituted packets to the reference voice sample to determine voice quality;</claim-text>
<claim-text>wherein, to compare the voice data in the voice-substituted packets to the reference voice sample, the logic is operable to:
<claim-text>generate a stream of the packets according to an order and timing in which they were received;</claim-text>
<claim-text>compensate, at least in part, for jitter in the packets;</claim-text>
<claim-text>decode the voice data in the packets;</claim-text>
<claim-text>generate a synthetic voice sample based on the decoded data; and</claim-text>
<claim-text>compare the synthetic voice sample to the reference voice sample.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00025" num="00025">
<claim-text>25. The logic of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein, to compare the synthetic voice sample to the reference voice sample, the logic is operable to implement perceptual speech quality measurement techniques.</claim-text>
</claim>
<claim id="CLM-00026" num="00026">
<claim-text>26. A system for voice quality analysis, comprising:
<claim-text>means for receiving packets in a voice stream;</claim-text>
<claim-text>means for generating a receipt indicator for the packets;</claim-text>
<claim-text>means for substituting a reference voice sample for voice data in the packets; and</claim-text>
<claim-text>means for comparing the voice data in the voice-substituted packets to the reference voice sample to determine voice quality;</claim-text>
<claim-text>wherein substituting a reference voice sample for the voice data in the packets comprises:
<claim-text>determining an encoding scheme used for the voice data in the packets;</claim-text>
<claim-text>encoding the reference voice sample according to the determined encoding scheme; and</claim-text>
<claim-text>associating portions of the encoded reference voice sample with the packets.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00027" num="00027">
<claim-text>27. The system of <claim-ref idref="CLM-00026">claim 26</claim-ref>, wherein the receipt indicator comprises a time stamp and a sequence number.</claim-text>
</claim>
<claim id="CLM-00028" num="00028">
<claim-text>28. The system of <claim-ref idref="CLM-00026">claim 26</claim-ref>, wherein the means for receiving packets in a voice stream is further operable to:
<claim-text>determine whether a packet is of interest; and</claim-text>
<claim-text>retain the packet if it is of interest.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00029" num="00029">
<claim-text>29. The system of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein determining whether a packet is of interest comprises examining a destination address of the packet.</claim-text>
</claim>
<claim id="CLM-00030" num="00030">
<claim-text>30. The system of <claim-ref idref="CLM-00026">claim 26</claim-ref>, wherein associating portions of the encoded reference voice sample with the packets comprises:
<claim-text>determining that a packet is missing from the voice stream; and</claim-text>
<claim-text>discarding the associated portion of the encoded reference voice sample.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00031" num="00031">
<claim-text>31. A system for voice quality analysis, comprising:
<claim-text>means for receiving packets in a voice stream;</claim-text>
<claim-text>means for generating a receipt indicator for the packets;</claim-text>
<claim-text>means for substituting a reference voice sample for voice data in the packets; and</claim-text>
<claim-text>means for comparing the voice data in the voice-substituted packets to the reference voice sample to determine voice quality;</claim-text>
<claim-text>wherein comparing the voice data in the voice-substituted packets to the reference voice sample comprises:
<claim-text>generating a stream of packets according to an order and timing in which they were received;</claim-text>
<claim-text>compensating, at least in part, for jitter in the packets;</claim-text>
<claim-text>decoding the voice data in the packets;</claim-text>
<claim-text>generating a synthetic voice sample based on the decoded data; and</claim-text>
<claim-text>comparing the synthetic voice sample to the reference voice sample.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00032" num="00032">
<claim-text>32. The system of <claim-ref idref="CLM-00031">claim 31</claim-ref>, wherein comparing the synthetic voice sample to the reference voice sample comprises implementing perceptual speech quality measurement techniques.</claim-text>
</claim>
<claim id="CLM-00033" num="00033">
<claim-text>33. A system for voice quality analysis, comprising:
<claim-text>a voice packet capture module operable to receive voice packets, to determine whether a packet is of interest, to retain a packet if it is of interest, and to generate a time stamp and a sequence number for a retained packet;</claim-text>
<claim-text>a voice data substitution module operable to substitute a reference voice sample for the voice data in the retained packets, wherein substituting a reference voice sample comprises determining the encoding scheme used for the voice data in the retained packets, encoding the reference voice sample according to the determined encoding scheme, and associating portions of the encoded reference voice sample with the packets;</claim-text>
<claim-text>a decoding module operable to receive the voice-substituted packets according to the order and timing in which they were received by the voice packet capture module, to remove at least part of the jitter from the packets, and to decode the voice data in the packets;</claim-text>
<claim-text>a voice synthesis module operable to generate a synthetic voice sample based on the decoded data; and</claim-text>
<claim-text>a voice quality analysis module operable to compare the synthetic voice sample to the reference voice sample using perceptual speech quality techniques to determine voice quality.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-grant>
