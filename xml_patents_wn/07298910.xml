<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298910-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298910</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>11230110</doc-number>
<date>20050919</date>
</document-id>
</application-reference>
<us-application-series-code>11</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>JP</country>
<doc-number>P11-148452</doc-number>
<date>19990527</date>
</priority-claim>
</priority-claims>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>36</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382233</main-classification>
</classification-national>
<invention-title id="d0e61">Wavelet inverse transform method and apparatus and wavelet decoding method and apparatus</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>5901249</doc-number>
<kind>A</kind>
<name>Ito</name>
<date>19990500</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382239</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5933535</doc-number>
<kind>A</kind>
<name>Lee et al.</name>
<date>19990800</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382243</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>6021224</doc-number>
<kind>A</kind>
<name>Castelli et al.</name>
<date>20000200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382232</main-classification></classification-national>
</citation>
<citation>
<patcit num="00004">
<document-id>
<country>US</country>
<doc-number>6229926</doc-number>
<kind>B1</kind>
<name>Chui et al.</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382240</main-classification></classification-national>
</citation>
<citation>
<patcit num="00005">
<document-id>
<country>US</country>
<doc-number>6233357</doc-number>
<kind>B1</kind>
<name>Li et al.</name>
<date>20010500</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382248</main-classification></classification-national>
</citation>
<citation>
<patcit num="00006">
<document-id>
<country>US</country>
<doc-number>6473528</doc-number>
<kind>B2</kind>
<name>Li et al.</name>
<date>20021000</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382233</main-classification></classification-national>
</citation>
<citation>
<patcit num="00007">
<document-id>
<country>US</country>
<doc-number>6501861</doc-number>
<kind>B1</kind>
<name>Cho et al.</name>
<date>20021200</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>282243</main-classification></classification-national>
</citation>
<citation>
<patcit num="00008">
<document-id>
<country>US</country>
<doc-number>6587588</doc-number>
<kind>B1</kind>
<name>Bottou et al.</name>
<date>20030700</date>
</document-id>
</patcit>
<category>cited by other</category>
<classification-national><country>US</country><main-classification>382240</main-classification></classification-national>
</citation>
<citation>
<patcit num="00009">
<document-id>
<country>US</country>
<doc-number>6898325</doc-number>
<kind>B2</kind>
<name>Gormish</name>
<date>20050500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382248</main-classification></classification-national>
</citation>
<citation>
<patcit num="00010">
<document-id>
<country>JP</country>
<doc-number>11-285006</doc-number>
<date>19991000</date>
</document-id>
</patcit>
<category>cited by other</category>
</citation>
</references-cited>
<number-of-claims>20</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382232-233</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382234-248</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382251-252</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>37524001-24025</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3483981</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3484031</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>3484201</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>341 50</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>35842601-42616</main-classification>
<additional-info>unstructured</additional-info>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>12</number-of-drawing-sheets>
<number-of-figures>12</number-of-figures>
</figures>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>09579803</doc-number>
<kind>00</kind>
<date>20000526</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>6968086</doc-number>
<kind>A </kind>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>11230110</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20060012495</doc-number>
<kind>A1</kind>
<date>20060119</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Fukuhara</last-name>
<first-name>Takahiro</first-name>
<address>
<city>Kanagawa</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Kimura</last-name>
<first-name>Seiji</first-name>
<address>
<city>Chiba</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Kiya</last-name>
<first-name>Hitoshi</first-name>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
<nationality>
<country>JP</country>
</nationality>
<residence>
<country>JP</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Finnegan, Henderson, Farabow, Garrett &amp; Dunner, L.L.P.</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Sony Corporation</orgname>
<role>03</role>
<address>
<city>Tokyo</city>
<country>JP</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Sherali</last-name>
<first-name>Isherali</first-name>
<department>2624</department>
</primary-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A wavelet inverse transform method includes a decoding object coefficient extracting step of extracting only coefficients necessary for decoding a specified area from wavelet transform coefficients, and a wavelet inverse transform step of inverse transforming coefficients extracted from the decoding object coefficient extracting step. The decoding object coefficient extracting step extracts transform coefficients not only inside the specified area but also those outside the specified area. This enables only an optional partial picture to be decoded without decoding the entire picture. A corresponding wavelet inverse transform device is also disclosed.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="141.73mm" wi="155.02mm" file="US07298910-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="198.29mm" wi="86.95mm" orientation="landscape" file="US07298910-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="187.45mm" wi="142.66mm" orientation="landscape" file="US07298910-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="219.63mm" wi="107.95mm" orientation="landscape" file="US07298910-20071120-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="177.80mm" wi="141.56mm" orientation="landscape" file="US07298910-20071120-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="223.94mm" wi="122.94mm" orientation="landscape" file="US07298910-20071120-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="216.83mm" wi="139.45mm" orientation="landscape" file="US07298910-20071120-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="167.39mm" wi="113.96mm" orientation="landscape" file="US07298910-20071120-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="183.81mm" wi="152.65mm" orientation="landscape" file="US07298910-20071120-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="198.29mm" wi="132.25mm" orientation="landscape" file="US07298910-20071120-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="161.37mm" wi="146.64mm" orientation="landscape" file="US07298910-20071120-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="243.33mm" wi="137.67mm" orientation="landscape" file="US07298910-20071120-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="219.79mm" wi="94.49mm" orientation="landscape" file="US07298910-20071120-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?RELAPP description="Other Patent Relations" end="lead"?>
<p id="p-0002" num="0001">This application is a Continuation of U.S. application Ser. No. 09/579,803, filed May 26, 2000, now U.S. Pat. No. 6,968,086, which is hereby incorporated by reference in its entirety herein.</p>
<?RELAPP description="Other Patent Relations" end="tail"?>
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading>
<p id="p-0003" num="0002">1. Field of the Invention</p>
<p id="p-0004" num="0003">This invention relates to a wavelet inverse transform method and apparatus used in extracting and decoding only transform coefficients of a specified partial area from wavelet transform coefficients obtained on encoding by wavelet transform. This invention also relates to a corresponding wavelet decoding method and apparatus.</p>
<p id="p-0005" num="0004">2. Description of Related Art</p>
<p id="p-0006" num="0005">Among conventional typical picture compression systems, there is a JPEG (Joint Photographic Experts Group) system, standardized by the ISO (International Organization for Standardization). This system, employing an orthogonal transform, specifically the discrete cosine transform (DCT), is known to furnish a good encoded or decoded picture when a higher number of allocated bits is used. However, if the number of encoding bits is decreased to more than a certain extent, block distortion proper to DCT becomes outstanding so that subjective deterioration is apparent. On the other hand, such a system in which an entire picture is split into plural bands by a filter, termed a filter bank, comprising the combination of a high-pass filter and a low-pass filter, and encoding is performed from one band to another, is now being researched briskly. In particular, the wavelet encoding free from the defect of block distortion, which becomes outstanding in high compression such as is presented in DCT, is thought to be promising as a technique which should take the place of the DCT.</p>
<p id="p-0007" num="0006">Nowadays, an electronic still camera or a video movie exploits the JPEG or MPEG, with the transform system being the DCT. Since a product based on the wavelet transform is predicted to be presented to the market in time to come, investigations in improving the efficiency in the encoding system are proceeding briskly in many research institutes. As a matter of fact, JPEG 2000, now being worked by ISO/IEC/JTC1_SC29/WG1, which is the same organization as the JPEG, as a format the recommendation for the standardization of which is scheduled to be issued in December 2000, is felt to be promising as the next-generation international standardization system for still pictures. With this JPEG 2000, it has almost been established to use the wavelet transform in place of the preexisting DCT of JPEG as a basic transformation system for picture compression.</p>
<p id="p-0008" num="0007">The present invention is directed to the elimination of the problem in expanding only a partial area in wavelet inverse transform. That is, the entire wavelet transform coefficients are not read out and decoded, as is done in the conventional technique. This represents a significant merit in reducing the memory capacity size. In the wavelet encoding, wavelet transform needs to be applied to the entire picture to store and hold the generated wavelet transform coefficients transiently in a memory. In wavelet decoding, the operation which is the reverse of the wavelet encoding operation is performed, thus necessitating an extremely large memory capacity for storing and holding the coefficients for the entire picture. Should the picture size be increased, the memory capacity needs to be correspondingly increased. Thus, the conventional practice is not desirable for a device having a limited memory capacity, such as an electronic still camera, camcorder or PDA.</p>
<p id="p-0009" num="0008">Recently, in e.g., the international standardization activities of JPEG 2000, such a technique is investigated in which the entire picture of an object of encoding is split into plural blocks to perform the encoding on the block basis. If the encoding by the encoder is done on the block bases from the outset, partial decoding can be achieved by reading out an encoded bitstream associated with a pre-set block. However, there lacks up to now a research into partial decoding in the absence of constraint on the encoder.</p>
<heading id="h-0002" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0010" num="0009">It is therefore an object of the present invention to provide a wavelet inverse transform method and apparatus and a wavelet decoding method and apparatus in which an encoded bitstream generated on wavelet transforming a usual entire picture is inputted to decode only an optional partial picture without decoding the entire picture.</p>
<p id="p-0011" num="0010">In one aspect, the present invention provides wavelet inverse transform device including decoding object coefficient extracting means for extracting only coefficients necessary for decoding a specified area from wavelet transform coefficients, and wavelet inverse transform means for inverse transforming coefficients extracted from the decoding object coefficient extracting means, wherein the decoding object coefficient extracting means extracts transform coefficients not only inside the specified area but also those outside the specified area.</p>
<p id="p-0012" num="0011">In another aspect, the present invention provides a wavelet inverse transform method including a decoding object coefficient extracting step of extracting only coefficients necessary for decoding a specified area from wavelet transform coefficients, and a wavelet inverse transform step of inverse transforming coefficients extracted from the decoding object coefficient extracting means, wherein the decoding object coefficient extracting step extracts transform coefficients not only inside the specified area but also those outside the specified area.</p>
<p id="p-0013" num="0012">In another aspect, the present invention provides a decoding device including entropy decoding means for entropy decoding an encoded bitstream, generated on wavelet inverse transforming a picture, decoding object coefficient extracting means for extracting, from among wavelet transform coefficients obtained by the entropy decoding means, those necessary for decoding a specified area and wavelet inverse transforming means for inverse transforming the coefficients extracted by the decoding object coefficient extracting means, wherein the decoding object coefficient extracting means extracts transform coefficients not only in the specified area but also those on an outer rim of the specified area.</p>
<p id="p-0014" num="0013">In another aspect, the present invention provides a wavelet decoding method including an entropy decoding step of entropy decoding an encoded bitstream, generated on wavelet inverse transforming a picture, a decoding object coefficient extracting step of extracting, from among wavelet transform coefficients obtained by the entropy decoding step, those necessary for decoding a specified area and a wavelet inverse transforming step of inverse transforming the coefficients extracted by the decoding object coefficient extracting step, wherein the decoding object coefficient extracting step extracts transform coefficients not only in the specified area but also those on an outer rim of the specified area.</p>
<p id="p-0015" num="0014">In the decoding object coefficient extracting means or step, wavelet transform coefficients required for decoding are extracted based on the information concerning an area determined by the decoding object area determining means or step determining the area of the decoding object. The transform coefficients, thus extracted, are inverse-transformed by the wavelet inverse transform means or step. Of the transform coefficients generated in the wavelet inverse transform means or step, those in a valid range are extracted based on overlap holding processing.</p>
<p id="p-0016" num="0015">The decoding object area determining means or step determines a decoding object area by an external input or determining means or step to send a position coordinate of apices in case of a rectangular area and the information on a center position as well as the radius in case of a circular area. The decoding object coefficient extracting means or step extracts coefficients necessary for decoding the area in question to send the extracted coefficients to the wavelet inverse transform means or step. The decoding object coefficient extraction means or step extracts coefficients necessary for decoding the area to send the extracted coefficients to the wavelet inverse transform means or step. The wavelet inverse transform means or step performs convolution by filter coefficients having pre-set tap lengths and wavelet transform coefficients to generate a decoded picture of the specified area.</p>
<p id="p-0017" num="0016">According to the present invention, an encoded bitstream, generated on wavelet inverse transforming a usual entire picture, is inputted, to decode only an optional partial picture, without decoding the entire picture.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. 1</figref> shows a specified example of a wavelet inverse transform device according to the present invention and is a block diagram showing the structure of a wavelet inverse transform device adapted for performing the processing corresponding to the wavelet inverse transform method according to the present invention.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. 2</figref> shows a decoding object area.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. 3</figref> is a block diagram showing the structure of an ordinary wavelet transform unit.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. 4</figref> shows band splitting of a two-dimensional picture.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. 5</figref> is a block diagram showing the structure of an ordinary wavelet inverse transform unit.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 6</figref> is a conceptual view showing wavelet coefficients on wavelet splitting up to two.</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 7</figref> shows an impulse response of a filter for performing wavelet transform.</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. 8</figref> shows a decoding object range and a filtering range.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 9</figref> shows partial decoding of a one-dimensional specified area employing an overlap holding method.</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. 10</figref> shows partial decoding of a two-dimensional specified area employing an overlap holding method.</p>
<p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. 11</figref> shows a specified example of a wavelet decoding device according to the present invention and is a block diagram of a wavelet decoding device operating based on the wavelet decoding method of the present invention.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 12</figref> is a block diagram showing the structure of a wavelet transform encoding device.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0004" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
<p id="p-0030" num="0029">Referring to <figref idref="DRAWINGS">FIGS. 1 to 10</figref>, a wavelet inverse transform device <b>10</b>, as a specified example of a wavelet inverse transform apparatus of the present invention, adapted for performing the processing corresponding to a wavelet inverse transform of the present invention, is explained in detail. Meanwhile, the wavelet inverse transform device <b>10</b> constitutes a main portion of a wavelet decoding device <b>60</b> which will be explained subsequently with reference to <figref idref="DRAWINGS">FIG. 11</figref>.</p>
<p id="p-0031" num="0030">Among specified examples of application, there are an electronic camera, a portable telephone, a mobile picture transmission/reception terminal (PDA), a printer, an expander for a satellite image or an image for medical use, a software module thereof, an expander for a picture used in a game or a three-dimensional CG, and a software module thereof.</p>
<p id="p-0032" num="0031">Referring to <figref idref="DRAWINGS">FIG. 1</figref>, this wavelet inverse transform device <b>10</b> includes a decoding object area decision unit <b>11</b>, a decoding object coefficient extraction unit <b>12</b> and a wavelet inverse transform unit <b>13</b>.</p>
<p id="p-0033" num="0032">The decoding object area decision unit <b>11</b> determines a decoding object area <b>11</b> by an external input or decision means provided in the decision unit <b>11</b>, to send out apex position coordinates if the decoding object area is a rectangular area, or to send out the center position and the radius information if the decoding object area is a circular area.</p>
<p id="p-0034" num="0033">The decoding object coefficient extraction unit <b>12</b> extracts coefficients required in decoding an area determined by the decoding object area decision unit <b>11</b>, from wavelet conversion coefficients <b>100</b> inputted from a coefficient input terminal <b>14</b>, to send the extracted coefficients to the wavelet inverse transform unit <b>13</b>. In particular, this decoding object coefficient extraction unit <b>12</b> extracts transform coefficients not only in a specified area but also transform coefficients lying on an outer rim of the specified area.</p>
<p id="p-0035" num="0034">The wavelet inverse transform unit <b>13</b> inverse-transforms the coefficients extracted by the decoding object coefficient extraction unit <b>12</b>.</p>
<p id="p-0036" num="0035">The operation of the above-described wavelet inverse transform device <b>10</b> is hereinafter explained. First, the decoding object area decision unit <b>11</b> determines an area in a picture to be decoded. For example, it is assumed that a partial areal picture at a center area (<b>1</b>, <b>1</b>), from nine areas obtained on vertical <b>3</b> by horizontal <b>3</b> division, as shown in <figref idref="DRAWINGS">FIG. 2</figref>, is to be decoded. For denoting the decoding object area, a number depicting the number of division in the vertical and horizontal directions and the number of a block area as counted from a given terminal side may be used. Alternatively, the upper left apex coordinate and the lower right apex coordinate of a shaded area may be used.</p>
<p id="p-0037" num="0036">The decoding object area information <b>101</b>, represented using any of the above methods by the decoding object area decision unit <b>11</b>, is entered to the decoding object coefficient extraction unit <b>12</b> where wavelet inverse transform coefficients <b>102</b> required for decoding are extracted. Such extraction of the wavelet transform coefficients will be discussed subsequently in detail.</p>
<p id="p-0038" num="0037">Here, the schematics of the wavelet transform and wavelet inverse transform, as basic techniques to which the present invention pertains, are explained.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. 3</figref> shows an ordinary structure of a wavelet transform unit. This unit performs octave splitting, as the most popular one of plural wavelet transform technique, over plural levels. In the case of <figref idref="DRAWINGS">FIG. 3</figref>, the number of levels is three. Specifically, picture signals are split into a low range and a high range, with only the low range components being split hierarchically. Although <figref idref="DRAWINGS">FIG. 3</figref> shows wavelet transform for a one-dimensional system, such as, for example, horizontal components of a picture, for the sake of convenience, it may be extended to a two-dimensional system in order to cope with the two-dimensional signals.</p>
<p id="p-0040" num="0039">First, a picture photographed by a camera, not shown, is digitized to retrieve input picture signals <b>115</b> from an input terminal <b>20</b>. These input picture signals <b>115</b> are band-split by a low-pass filter <b>21</b> and a high-pass filter <b>22</b> to produce low range components and high range components which then are decimated by downsamplers <b>23</b>, <b>23</b> in resolution to one-half The operation up to this point is the level <b>1</b> which issues two outputs, namely an L (meaning low) output <b>116</b> and an H (meaning high) output <b>117</b>. Only the low range component, obtained on decimation, are again band-split by a low-pass filter <b>24</b> and a high-pass filter <b>25</b> and decimated in resolution by downsamplers <b>26</b>, <b>26</b> to one-half. The operation up to this point is the level <b>2</b> which issues two outputs, namely an LL output <b>118</b> and an LH output <b>118</b>. Only the low range component, that is the LL component <b>118</b>, is again band-split by a low-pass filter <b>27</b> and a high-pass filter <b>28</b> and decimated in resolution to one-half by downsamplers <b>29</b>, <b>29</b>. The operation up to this point is the level <b>3</b>. By performing the above-described processing up to a pre-set level, the band components, obtained on hierarchically band-splitting the low range component, are generated sequentially. The band components, generated at the level <b>3</b>, are an LLL component <b>120</b> and an LLH component <b>121</b>. The LLL component <b>120</b>, LLH component <b>121</b>, LH component <b>119</b> and the H component <b>117</b> are outputted to outside at output terminals <b>30</b>, <b>31</b>, <b>32</b> and <b>33</b>, respectively.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. 4</figref> shows band components obtained on band splitting a two-dimensional picture up to the level <b>2</b>. It is noted that the notation of L and H in <figref idref="DRAWINGS">FIG. 4</figref> differs from that of <figref idref="DRAWINGS">FIG. 3</figref> dealing with the one-dimensional signal. That is, in <figref idref="DRAWINGS">FIG. 4</figref>, four components LL, LH, HL and HH are produced by level <b>1</b> band splitting in both the horizontal and vertical directions, where LL means that both the horizontal and vertical components are L and LH means that the horizontal component is H and the vertical component is L. The LL component is again band-split to generate LLLL, LLHL, LLLH and LLHH.</p>
<p id="p-0042" num="0041">The structure and the operation of the routine wavelet inverse transform is explained with reference to <figref idref="DRAWINGS">FIG. 5</figref>. When the band components, outputted by the wavelet transform explained in connection with <figref idref="DRAWINGS">FIG. 3</figref>, that is the LLL component <b>120</b>, LLH component <b>121</b>, LH component <b>119</b> and the H component <b>117</b>, are inputted at an input terminal <b>43</b>, the LLL component <b>120</b> and the LLH component <b>121</b> are first upsampled by a factor of two by upsamplers <b>44</b>, <b>44</b>. The low range component and the high range component are filtered in succession by a low-pass filter <b>49</b> and a high-pass filter <b>46</b>, respectively, and synthesized together by an adder <b>47</b>. This completes the inverse transform of level <b>3</b>, so that a band component LL<b>118</b> is obtained. The band component LL<b>118</b> and the LH component <b>119</b> from the input terminal <b>42</b> are upsampled to a double resolution by upsamplers <b>48</b>, <b>48</b>. The low range component and the high range component are filtered in succession by a low-pass filter <b>49</b> and a high-pass filter <b>50</b>, respectively, and synthesized together by an adder <b>51</b>. This completes the inverse transform of level <b>2</b>, so that a band component L<b>116</b> is obtained. The band component L<b>116</b> and the H component <b>117</b> from the input terminal <b>43</b> are upsampled to a double resolution by upsamplers <b>52</b>, <b>52</b>. The low range component and the high range component are filtered in succession by a low-pass filter <b>53</b> and a high-pass filter <b>54</b>, respectively, and synthesized together by an adder <b>55</b>. This completes the level <b>1</b> inverse transform so that an ultimate inverse-transformed decoded signal <b>115</b> is outputted at an output terminal <b>56</b>. The above is the basic structure and operation of the routine wavelet inverse transform.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. 6</figref> represents the wavelet transform in connection the signal length. As a result of level <b>1</b> transform of the entire signal input x(n), two sorts of coefficients L and H, having a length equal to one-half that of x(n), are generated. In addition, the level <b>2</b> transform splits the low range component L into coefficients LL and LH with one-half lengths.</p>
<p id="p-0044" num="0043">In the present embodiment, a linear phase FIR filter is assumed, with the tap length of filters used for wavelet transform and wavelet inverse transform being L, the number of impulse responses during the negative time being Head and with the number of impulse responses during the positive time excluding 0 being Tail. <figref idref="DRAWINGS">FIG. 7</figref> shows a case wherein L=7, Head=3 and Tail=3. That is, according to the present invention, the transform coefficients on the outer rim of a specified area are associated with the number of impulses of the filter used for wavelet inverse transform.</p>
<p id="p-0045" num="0044">The filtering operation at the time of wavelet inverse transform is explained with reference to <figref idref="DRAWINGS">FIG. 8</figref> showing a case wherein a filter of an odd number tap length L=7 shown in <figref idref="DRAWINGS">FIG. 7</figref> is used. It may be seen that, in filtering in both the horizontal and vertical directions, three coefficients each on the left and right sides of the current position (d and k) are affected by filtering. Therefore, if the center position of a coefficient lies on the boundary of an area being inverse transformed, as in the case of the coefficients d and k, coefficients needs to be extracted from the neighboring area. In <figref idref="DRAWINGS">FIG. 8</figref>, now explained, the coefficient area to be extracted in redundance are expressed as L_head, L_tail (low range), H_head, H_tail (high range).</p>
<p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. 9</figref> shows the distribution of band components when the wavelet transform is applied to a one-dimensional signal x(n) up to the level <b>2</b>, it may be seen that a shaded portion <b>2</b> of x(n) is reflected by a portion indicated <b>2</b> in each of bands LL, LH and H. Therefore, in order to calculate the wavelet transform coefficients of the level <b>1</b> from the level <b>2</b>, the wavelet inverse transform means is in need of P<b>2</b> partial coefficients corresponding to the area <b>2</b>, among the band components of the splitting level <b>2</b>, partial coefficients in LL, along with L_head <b>2</b> and L_tail <b>2</b>, lying forwardly and backwardly thereof, and partial coefficients in LH, along with H_head <b>2</b> and H_tail <b>2</b>, lying forwardly and backwardly thereof. <b>17</b>.</p>
<p id="p-0047" num="0046">Then, of the coefficients of the splitting level <b>1</b>, obtained on inverse transform, as described above, only (L_head <b>1</b>+<b>2</b>P<b>2</b>+L_tail) transform coefficients, necessary by the overlap holding processing as later explained, are extracted. Then, P<b>1</b> partial coefficients, lying in a portion <b>2</b> in the band H, are extracted, along with the coefficients L_head and L_tail, lying ahead and at back of the P<b>1</b> coefficients, are extracted. Then, from decoded signals, obtained on inverse transform of extracted coefficients obtained on inverse transform of the level <b>2</b> LL and LH, and from the partial coefficients from H, the partial signals x(<b>2</b>), corresponding to the target area <b>2</b>, are taken out using overlap holding processing. The above is the explanation on the operation for the one-dimensional system.</p>
<p id="p-0048" num="0047">The overlap holding processing is introduced in, for example, Nishiro Takaya, co-inventor of the present case, an assistant professor of Tokyo Metropolitan University, “Fast Fourier Transform and its Application”, published by SHOKODO, pp. 109 to 112. This technique is a method of linear convolution of an infinite input sequence and features employing overlapping data in dividing input data into blocks and also employing cyclic convolution as the block-based convolution. In the cyclic convolution, initial overlapping portions of the cyclic convolution are truncated. There is no necessity of summing the results of the cyclic convolution.</p>
<p id="p-0049" num="0048">The two-dimensional wavelet inverse transform is now explained with reference to <figref idref="DRAWINGS">FIG. 10</figref>, showing areas of wavelet transform coefficients, required from one splitting level to another, when the shaded portion in <figref idref="DRAWINGS">FIG. 2</figref> is to be decoded, such areas being shown shaded in <figref idref="DRAWINGS">FIG. 10</figref>.</p>
<p id="p-0050" num="0049">For completely decoding the target partial picture, it is necessary to extract and inverse-transform surrounding coefficients, shown by broken lines in <figref idref="DRAWINGS">FIG. 10</figref>, as discussed above. Since <figref idref="DRAWINGS">FIG. 10</figref> shows a case wherein the dividing level is three, the inverse transform is performed using partial coefficients of the extracted four areas in performing the level <b>3</b> decoding. From the next level on, decoding is performed using the three partial coefficients of the level in question and the completely decoded results of the previous level. This sequence of operations is repeated to realize the partial decoding.</p>
<p id="p-0051" num="0050">In <figref idref="DRAWINGS">FIG. 10</figref>, Pheadi and Ptaili denote the number of coefficients required to be added on the left and upper sides at level i and that required to be added on the right and lower sides at level i, respectively. These coefficients are extracted from the outer rim side of the object area, as discussed above. In the two-dimensional system, only valid coefficients at each inverse transform level are selected and extracted by the overlap holding processing. The foregoing is the explanation on the partial decoding of a two-dimensional picture.</p>
<p id="p-0052" num="0051">A wavelet decoding device <b>60</b>, as a specified example of the wavelet decoding device of the present invention, operating by the wavelet decoding method of the present invention, is now explained with reference to <figref idref="DRAWINGS">FIG. 11</figref>. This wavelet decoding device <b>60</b> represents a specified example of the wavelet inverse transform device <b>10</b> built into a decoding device.</p>
<p id="p-0053" num="0052">This wavelet decoding device <b>60</b> includes an entropy decoding unit <b>62</b>, a dequantizer <b>63</b>, a transform coefficient back-scanning unit <b>64</b> and the above-mentioned wavelet inverse transform device <b>10</b>.</p>
<p id="p-0054" num="0053">The entropy decoding unit <b>62</b> entropy-decodes an encoded bitstream generated on wavelet transform encoding a picture.</p>
<p id="p-0055" num="0054">When the wavelet transform coefficients are being quantized in the wavelet transform encoding, the dequantizer <b>63</b> dequantizes the quantization coefficients obtained at the entropy decoding unit <b>62</b> to restore the dequantized quantization coefficients to <b>26</b>.</p>
<p id="p-0056" num="0055">If the transform coefficients are being scanned to raise the encoding efficiency in the wavelet transform encoding, the transform coefficient back-scanning unit <b>64</b> back-scans the transform coefficients to restore the original coefficients. It is wavelet transform coefficients <b>107</b> from this transform coefficient back-scanning unit <b>64</b> that are routed to the decoding object coefficient extraction unit <b>12</b> of the wavelet inverse transform device <b>10</b>.</p>
<p id="p-0057" num="0056">Before proceeding to description of the wavelet decoding device <b>60</b>, reference is had to <figref idref="DRAWINGS">FIG. 12</figref> to explain an associated wavelet transform encoding device <b>70</b>.</p>
<p id="p-0058" num="0057">The wavelet transform encoding device <b>70</b> is made up of a wavelet transform unit <b>72</b>, a transform coefficient scanning unit <b>73</b>, a quantizer <b>74</b> and an entropy encoding unit <b>75</b>.</p>
<p id="p-0059" num="0058">First, a picture photographed by a camera, not shown, is digitized and input picture signals <b>110</b> are retrieved at an input terminal <b>71</b>. The wavelet transform unit <b>72</b> generates transform coefficients <b>111</b> from the input picture signals <b>110</b> to send the generated transform coefficients <b>111</b> to the transform coefficient scanning unit <b>73</b>, which then scans the transform coefficients to re-array the coefficients such as to improve the encoding efficiency. For example, it is assumed here that the wavelet transform coefficients are scanned from left to right (in the horizontal direction) and from above to below (in the vertical direction). The as-scanned coefficients <b>112</b>, obtained on re-arraying in the transform coefficient scanning unit <b>73</b>, are quantized by the quantizer <b>74</b> from which quantized coefficients <b>113</b> are outputted to the entropy encoding unit <b>75</b>.</p>
<p id="p-0060" num="0059">It suffices for the quantizer <b>74</b> to employ routinely used scalar quantization as indicated by the following equation:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>Q=x/Δ</i>  (1)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where x is a value of the wavelet transform coefficient and Δ is a quantization index value.
</p>
<p id="p-0061" num="0060">The entropy encoding unit <b>75</b> applies information source encoding to the quantized coefficients <b>113</b> by way of information compression. As the information source encoding at this entropy encoding unit <b>75</b>, the Huffman encoding or the arithmetic encoding may be used. An ultimate encoded bitstream <b>114</b> is sent out via the entropy encoding unit <b>75</b> to an output terminal <b>76</b>.</p>
<p id="p-0062" num="0061">The operation of the wavelet decoding device <b>60</b> is hereinafter explained. An encoded bitstream <b>104</b> is sent via an input terminal <b>61</b> to the entropy decoding unit <b>62</b>, which then entropy-decodes the encoded bitstream <b>104</b> to send the resulting quantized coefficients <b>105</b> to the dequantizer <b>63</b>.</p>
<p id="p-0063" num="0062">The dequantizer <b>63</b> dequantizes the quantized coefficients <b>105</b> to output the dequantized transform coefficients. Meanwhile, the entropy decoding unit <b>62</b> needs to be a counterpart device of the entropy encoding unit <b>75</b>.</p>
<p id="p-0064" num="0063">It suffices for the dequantizer <b>63</b> to employ routinely used scalar dequantization as indicated by the following equation:
<br/>
<?in-line-formulae description="In-line Formulae" end="lead"?><i>x=Qx/Δ</i>  (2)<?in-line-formulae description="In-line Formulae" end="tail"?>
<br/>
where Q is a value of the quantization coefficient and Δ is a quantization index value.
</p>
<p id="p-0065" num="0064">The transform coefficients <b>106</b> are sent to the transform coefficient back-scanning unit <b>64</b> which then applies back-scanning transform, as a reverse procedure to the operation performed by the transform coefficient scanning unit <b>73</b>, to the transform coefficients <b>106</b> to generate the original transform coefficients. The resulting transform coefficients <b>107</b> are inputted to the decoding object coefficient extraction unit <b>12</b> of the wavelet inverse transform device <b>10</b>. The ensuing operation is the same as that described above and hence is not explained for simplicity.</p>
<p id="p-0066" num="0065">In the wavelet decoding device <b>60</b>, shown in <figref idref="DRAWINGS">FIG. 11</figref>, it is possible to decode only a desired portion of a picture, without it being necessary to input an encoded bitstream produced on wavelet transform of an entire picture to decode the entire picture, as is done in the conventional practice. Of course, there is imposed no constraint on the encoding device <b>70</b> to split the picture into plural areas at the outset to performing the encoding.</p>
<p id="p-0067" num="0066">The fact that only an optional portion needs to be decoded gives three favorable results, that is the results that the processing volume of convolution in filtering may be reduced, the memory width may also be reduced and that the memory accessing frequency can be diminished.</p>
<p id="p-0068" num="0067">There is also such merit that, by exploiting overlap holding processing, the operation on the encoder side may be the reverse of that on the decoder side and vice versa so that the teaching of the present invention can be applied to lossless encoding.</p>
<p id="p-0069" num="0068">Moreover, since it suffices to read out transform coefficients of an decoding object, there is no necessity of limiting the partial area of the decoding object to a rectangular area such that an area of a circle or a more complex figure can be dealt with.</p>
<p id="p-0070" num="0069">Although the configuration of the present invention has been stated to be implemented by hardware, it may, of course, be implemented by software.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A wavelet transform device comprising:
<claim-text>decoding object coefficient extracting means for extracting, from a plurality of wavelet transform coefficients, partial coefficients necessary for decoding a specified area of a picture; and</claim-text>
<claim-text>wavelet inverse transform means for inverse transforming said extracted partial coefficients,</claim-text>
<claim-text>wherein said extracted partial coefficients are wavelet transform coefficients that include said specified area of every split level and outside said specified area,</claim-text>
<claim-text>wherein said wavelet inverse transform means transforms using the three partial coefficients of the level and the completely transformed results of the previous level when one or more levels other than a max level are transformed.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. The wavelet inverse transform device according to <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising:
<claim-text>decoding object area determining means for determining a decoding object area, said decoding object coefficient extracting means extracting coefficients necessary for decoding an area determined by said decoding object area determining means.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. The wavelet inverse transform device according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein said wavelet transform coefficients are made up of transform coefficients of a plurality of splitting levels and include transform coefficients inside of and on an outer rim side of each splitting level based specified area.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. The wavelet inverse transform device according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein transform coefficients on the outer rim side of the specified area extracted by said decoding object coefficient extracting means correspond to the number of impulse response of a filter used in said wavelet inverse transform means.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. The wavelet inverse transform device according to <claim-ref idref="CLM-00003">claim 3</claim-ref> wherein said wavelet transform coefficients are obtained on hierarchically splitting a low range component of a plurality of splitting levels.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. The wavelet inverse transform device according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein, of transform coefficients generated by said wavelet inverse transform means, those in a valid range based on overlap holding processing are extracted.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. The wavelet inverse transform device according to <claim-ref idref="CLM-00006">claim 6</claim-ref> wherein extraction of the coefficients in the valid range based on said overlap holding processing is performed from one level of the wavelet splitting to another.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A wavelet inverse transform method comprising:
<claim-text>decoding object coefficient extracting step for extracting, from a plurality of wavelet transform coefficients, partial coefficients necessary for decoding a specified area of a picture; and</claim-text>
<claim-text>wavelet inverse transform step for inverse transforming said extracted partial coefficients,</claim-text>
<claim-text>wherein said extracted partial coefficients are wavelet transform coefficients that include said specified area of every split level and outside said specified area,</claim-text>
<claim-text>said wavelet inverse transform transforms step using the three partial coefficients of the level and the completely transformed results of the previous level when one or more levels other than a max level are transformed.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text>9. The wavelet inverse transform method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein decoding object coefficient extracting step extracts transform coefficients outside said specified area that are necessary for decoding at least one of said transform coefficients inside said specified area.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text>10. A wavelet decoding device comprising:
<claim-text>entropy decoding means for entropy decoding an encoded bitstream, generated on wavelet inverse transforming a picture;</claim-text>
<claim-text>decoding object coefficient extracting means for extracting, from a plurality of wavelet transform coefficients obtained by said entropy decoding means, partial coefficients necessary for decoding a specified area of said picture; and</claim-text>
<claim-text>wavelet inverse transform means for inverse transforming said extracted partial coefficients of said specified area,</claim-text>
<claim-text>wherein said extracted partial coefficients are wavelet transform coefficients that include said specified area of every split level and outside said specified area,</claim-text>
<claim-text>said wavelet inverse transform means transforms using the three partial coefficients of the level and the completely transformed results of the previous level when one or more levels other than a max level are transformed.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text>11. The wavelet decoding device according to <claim-ref idref="CLM-00010">claim 10</claim-ref> further comprising:
<claim-text>dequantizing means to restore wavelet transform coefficients obtained by said entropy decoding means to restore wavelet transform coefficients, said decoding object coefficient extracting means for extracting coefficients necessary for decoding the specified area from among the wavelet transform coefficients obtained by said dequantizing means.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text>12. The wavelet inverse transform device according to <claim-ref idref="CLM-00010">claim 10</claim-ref> wherein decoding object area determining means for determining a decoding object area, said decoding object coefficient extracting means extracting coefficients necessary for decoding an area determined by said decoding object area determining means.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text>13. The wavelet inverse transform device according to <claim-ref idref="CLM-00010">claim 10</claim-ref> wherein said wavelet transform coefficients are made up of transform coefficients of a plurality of splitting levels and include transform coefficients inside of and on an outer rim side of each splitting level based specified area.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text>14. The wavelet inverse transform device according to <claim-ref idref="CLM-00010">claim 10</claim-ref> wherein transform coefficients on the outer rim side of the specified area extracted by said decoding object coefficient extracting means correspond to the number of impulse responses of a filter used in said wavelet inverse transform means.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text>15. The wavelet inverse transform device according to <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein said wavelet transform coefficients are obtained on hierarchically splitting a low range component of a plurality of splitting levels.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text>16. The wavelet inverse transform device according to <claim-ref idref="CLM-00010">claim 10</claim-ref> wherein, of transform coefficients generated by said wavelet inverse transform means, those in a valid range based on overlap holding processing are extracted.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text>17. The wavelet inverse transform device according to <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein extraction of the coefficients in the valid range based on said overlap holding processing is performed from one level of the wavelet splitting to another.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text>18. A wavelet decoding method comprising:
<claim-text>entropy decoding step for entropy decoding an encoded bitstream, generated on wavelet inverse transforming a picture;</claim-text>
<claim-text>decoding object coefficient extracting step for extracting, from a plurality of wavelet transform coefficients obtained by said entropy decoding step, partial coefficients necessary for decoding a specified area of said picture; and</claim-text>
<claim-text>wavelet inverse transform step for inverse transforming said extracted partial coefficients of said specified area,</claim-text>
<claim-text>wherein said extracted partial coefficients are wavelet transform coefficients that include said specified area of every split level and outside said specified area,</claim-text>
<claim-text>said wavelet inverse transform step transforms using the three partial coefficients of the level and the completely transformed results of the previous level when one or more levels other than a max level are transformed.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text>19. The wavelet decoding method according to <claim-ref idref="CLM-00018">claim 18</claim-ref> further comprising:
<claim-text>dequantizing step to restore wavelet transform coefficients obtained by said entropy decoding means to restore wavelet transform coefficients, said decoding object coefficient extracting step for extracting coefficients necessary for decoding the specified area from among the wavelet transform coefficients obtained by said dequantizing step.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text>20. The wavelet decoding method according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein decoding object coefficient extracting step extracts transform coefficients outside said specified area that are necessary for decoding at least one of said transform coefficients inside said specified area.</claim-text>
</claim>
</claims>
</us-patent-grant>
