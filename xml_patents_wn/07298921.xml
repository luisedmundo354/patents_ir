<us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="US07298921-20071120.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20071106" date-publ="20071120">
<us-bibliographic-data-grant>
<publication-reference>
<document-id>
<country>US</country>
<doc-number>07298921</doc-number>
<kind>B2</kind>
<date>20071120</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>10353508</doc-number>
<date>20030129</date>
</document-id>
</application-reference>
<us-application-series-code>10</us-application-series-code>
<us-term-of-grant>
<us-term-extension>821</us-term-extension>
</us-term-of-grant>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>32</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>64</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>K</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20071120</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classification-national>
<country>US</country>
<main-classification>382294</main-classification>
<further-classification>382278</further-classification>
<further-classification>382293</further-classification>
<further-classification>382318</further-classification>
</classification-national>
<invention-title id="d0e53">Document scanning method and document scanner</invention-title>
<references-cited>
<citation>
<patcit num="00001">
<document-id>
<country>US</country>
<doc-number>4282546</doc-number>
<kind>A</kind>
<name>Reitmeier</name>
<date>19810800</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>348580</main-classification></classification-national>
</citation>
<citation>
<patcit num="00002">
<document-id>
<country>US</country>
<doc-number>5675672</doc-number>
<kind>A</kind>
<name>Nakabayashi</name>
<date>19971000</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382318</main-classification></classification-national>
</citation>
<citation>
<patcit num="00003">
<document-id>
<country>US</country>
<doc-number>2002/0051573</doc-number>
<kind>A1</kind>
<name>Sakai et al.</name>
<date>20020500</date>
</document-id>
</patcit>
<category>cited by examiner</category>
<classification-national><country>US</country><main-classification>382194</main-classification></classification-national>
</citation>
</references-cited>
<number-of-claims>8</number-of-claims>
<us-exemplary-claim>1</us-exemplary-claim>
<us-field-of-classification-search>
<classification-national>
<country>US</country>
<main-classification>382278</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382318</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382293</main-classification>
</classification-national>
<classification-national>
<country>US</country>
<main-classification>382294</main-classification>
</classification-national>
</us-field-of-classification-search>
<figures>
<number-of-drawing-sheets>2</number-of-drawing-sheets>
<number-of-figures>4</number-of-figures>
</figures>
<us-related-documents>
<related-publication>
<document-id>
<country>US</country>
<doc-number>20040146218</doc-number>
<kind>A1</kind>
<date>20040729</date>
</document-id>
</related-publication>
</us-related-documents>
<parties>
<applicants>
<applicant sequence="001" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Tinn</last-name>
<first-name>Graham James Ohn</first-name>
<address>
<city>Offord Cluny</city>
<country>GB</country>
</address>
</addressbook>
<nationality>
<country>GB</country>
</nationality>
<residence>
<country>GB</country>
</residence>
</applicant>
<applicant sequence="002" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Cullum</last-name>
<first-name>Andrew Roy</first-name>
<address>
<city>Dry Drayton</city>
<country>GB</country>
</address>
</addressbook>
<nationality>
<country>GB</country>
</nationality>
<residence>
<country>GB</country>
</residence>
</applicant>
<applicant sequence="003" app-type="applicant-inventor" designation="us-only">
<addressbook>
<last-name>Melvin</last-name>
<first-name>Andrew John</first-name>
<address>
<city>Bedworth</city>
<country>GB</country>
</address>
</addressbook>
<nationality>
<country>GB</country>
</nationality>
<residence>
<country>GB</country>
</residence>
</applicant>
</applicants>
<agents>
<agent sequence="01" rep-type="attorney">
<addressbook>
<orgname>Barnes &amp; Thornburg LLP</orgname>
<address>
<country>unknown</country>
</address>
</addressbook>
</agent>
</agents>
</parties>
<assignees>
<assignee>
<addressbook>
<orgname>Colortrac Limited</orgname>
<role>03</role>
<address>
<city>Cambridgeshire</city>
<country>GB</country>
</address>
</addressbook>
</assignee>
</assignees>
<examiners>
<primary-examiner>
<last-name>Bella</last-name>
<first-name>Matthew C.</first-name>
<department>2624</department>
</primary-examiner>
<assistant-examiner>
<last-name>Tucker</last-name>
<first-name>Wes</first-name>
</assistant-examiner>
</examiners>
</us-bibliographic-data-grant>
<abstract id="abstract">
<p id="p-0001" num="0000">A document scanning method comprises causing relative movement between a document and first and second imaging elements, such that each of a succession of scan lines of the document is exposed in turn to the imaging elements; generating first and second image data words representative of overlapping portions of each scan line; and concatenating at least a portion of the words to generate a third word representative of the scan line, the method being characterised by the steps of cross-correlating at least a portion of each of the words to identify a portion of the second word that is included in the first word; discarding a portion of at least one of words; concatenating the first word or remainder thereof with the second word or remainder thereof to form the third word; and, if necessary, compressing or expanding the third word by linear interpolation so as to obtain a word of a predetermined length.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="95.17mm" wi="147.57mm" file="US07298921-20071120-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="201.85mm" wi="164.68mm" file="US07298921-20071120-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="225.81mm" wi="173.99mm" file="US07298921-20071120-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?BRFSUM description="Brief Summary" end="lead"?>
<heading id="h-0001" level="1">FIELD OF THE INVENTION</heading>
<p id="p-0002" num="0001">This invention relates to a document scanning method and to a document scanner that is operable to implement the document scanning method.</p>
<heading id="h-0002" level="1">BACKGROUND TO THE INVENTION</heading>
<p id="p-0003" num="0002">Large format document scanners, i.e. those for scanning documents of widths greater than approximately 11 inches, employ a plurality of imaging elements. The imaging elements are so arranged that, in use, each element generates image data representative of a portion of a scan line of a document. Each portion of the scan line has a slight overlap with one to two other portions, dependent on whether the portion is from an end or the middle of the scan line. In a known method of generating image data representative of the entire scan line from the image data from a plurality of imaging elements, an initial and/or terminal portion of the image data from each imaging element, corresponding to the slight overlap or overlaps, is discarded, and the remainders of the image data are concatenated with one another.</p>
<p id="p-0004" num="0003">The known method assumes that a distance from the document to the imaging elements is constant, and that the slight overlaps of the portions of the scan line are therefore also constant, and an initial and/or terminal portion of a predetermined length of the image data from each element is discarded. However, due to imperfections of a process by which the document is moved relative to the imaging elements or vice versa, or due to imperfections of the document itself, such as folds that cannot be completely flattened, the distance from the document to the imaging elements, and hence the slight overlaps of the portions of the scan line, are variable. If the distance from the document to the imaging elements increases, discarding a portion of the image data of the predetermined length results in duplication of data in the image data representative of the entire scan line, and hence duplication of some portions in a resulting image of the scan line. Where the distance from the document to the imaging elements decreases, discarding a portion of the image data of the predetermined length results in deletion of data from the image data representative of the entire scan line, and hence, omission of some portions in a resulting image of the scan line. <figref idref="DRAWINGS">FIG. 1</figref> of the attached drawing figures illustrates the effects of variation of distance from the document to the scanning elements when the known document scanning method is employed.</p>
<heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading>
<p id="p-0005" num="0004">According to a first aspect of the invention there is provided a document scanning method comprising the steps of causing relative movement between a document and first and second imaging elements, such that each of a succession of scan lines of the document is exposed in turn to the imaging elements; generating by means of the first and second imaging elements respective first and second image data words representative of respective first and second overlapping portions of each scan line; and concatenating at least a portion of each of the first and second words to generate a third image data word representative of the scan line, the method being characterised by the steps of cross-correlating at least a portion of each of the first and second words to identify a portion of the second word that is included in the first word; discarding a portion of at least one of the first and second words; concatenating the first word or remainder thereof with the second word or remainder thereof to form the third image data word; and, if necessary, compressing or expanding the third word by linear interpolation so as to obtain an image data word of a predetermined length.</p>
<p id="p-0006" num="0005">It should be noted that, as used herein, the term “word” is not intended to apply solely to 4 bits of data (which is one specific meaning of the term to those skilled in the art) but instead encompasses a packet of data of any size.</p>
<p id="p-0007" num="0006">The invention therefore provides a document scanning method that compensates for variations in a distance from a document to the image elements.</p>
<p id="p-0008" num="0007">The term “document” as used herein, refers to anything bearing text and/or images on a medium. The medium may comprise any suitable material, such as paper, canvas, card, or metal. It will be apparent that a “document” is not limited to things on which text and/or images are applied by printing: text and/or images could be formed by any suitable process (e.g. etching, stamping, embossing, painting etc.).</p>
<p id="p-0009" num="0008">The step of cross-correlating at least a portion of each of the first and second words may advantageously consist of cross-correlating a terminal portion of the first word with an initial portion of the second word, said terminal portion of the first word and initial portion of the second word including image data representative of an overlap of the first and second overlapping portions of a scan line.</p>
<p id="p-0010" num="0009">In this way the cross-correlation is simplified and can therefore be accomplished more quickly and with a reduced likelihood of spurious correlation.</p>
<p id="p-0011" num="0010">Preferably the steps of discarding a portion of at least one of the first and second words and concatenating the first word or remainder thereof with the second word or remainder thereof to form the third image data word consist of discarding a terminal portion of the first word and an initial portion of the second word, said terminal portion of the first word being substantially representative of a first half of the overlap of the first and second overlapping portions of the scan line, and said initial portion of the second word being substantially representative of a second half of the overlap of the first and second overlapping portions of the scan line, and concatenating the remainder of the first word with the remainder of the second word to form the third image data word.</p>
<p id="p-0012" num="0011">The terminal portion of the first word and the initial portion of the second word include image data obtained from the extremities of the fields of view of the imaging elements, and are more likely to contain errors than data obtained from nearer to the centres of the fields of view of the imaging elements. By discarding these portions, the likelihood of introducing errors into the third image data word is reduced.</p>
<p id="p-0013" num="0012">Preferably the method further comprises the step, after identifying the portion of the second word that is included in the first word, of determining whether the length of said portion exceeds a predetermined value, which indicates that a spurious correlation has occurred, and if so, discarding a portion of at least one of the first and second words of a default length.</p>
<p id="p-0014" num="0013">In a preferred embodiment of the invention, the method further comprises the steps, after identifying the portion of the second word that is included in the first word and determining that the length of said portion does not exceed the predetermined value, of subtracting the length of said portion from said default length to generate an offset value, determining a running average of the offset value and the offset values of any preceding scan lines, rounding the running average to the nearest integer, if necessary, and discarding a terminal portion of the first word and an initial portion of the second word of a length equal to one half of the sum of the rounded running average and default length.</p>
<p id="p-0015" num="0014">It is to be understood that where it is determined that the length of the portion of the second word that is included in the first word exceeds the predetermined value, the offset value for that scan line is zero, since a spurious correlation must have occurred.</p>
<p id="p-0016" num="0015">The step of discarding the terminal portion of the first word and initial portion of the second word of a length equal to one half of the sum of the rounded running average and the default length makes scan lines in which a spurious correlation has occurred less conspicuous in a resulting image of the document.</p>
<p id="p-0017" num="0016">According to a second aspect of the invention there is provided a document scanner having first and second imaging elements, a scanning mechanism and a microprocessor, the microprocessor being operable to control the scanning mechanism and process image data from the first and second imaging elements to perform a document scanning method according to the first aspect of the invention.</p>
<p id="p-0018" num="0017">The first and second imaging elements are typically linear-array contact image sensors or charge coupled device—(CCD) based cameras.</p>
<p id="p-0019" num="0018">The scanning mechanism may be either an arrangement of rollers by means of which a document may be moved relative to the imaging elements (a so-called sheet-feed arrangement) or an arrangement by means of which the imaging elements are moved relative to a document (a so-called flatbed arrangement).</p>
<p id="p-0020" num="0019">The microprocessor may advantageously be contained in the document scanner.</p>
<p id="p-0021" num="0020">In a preferred embodiment of the invention, however, the microprocessor forms part of a programmed computer and the document scanner is operable to transmit the first and second words from the imaging elements to the computer and to receive the third image data words and control data from the computer.</p>
<?BRFSUM description="Brief Summary" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0004" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading>
<p id="p-0022" num="0021">The invention will now be described in more detail and by way of illustrative example with reference to the attached drawing figures, in which:</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. 1</figref> is a schematic diagram showing the effects of variation of distance from a document to the imaging elements of a document scanner when the known document scanning method is employed;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. 2</figref> is a schematic diagram showing the effects of variation of distance from the document to the imaging elements when a method in accordance with the first aspect of the invention is employed; and</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIGS. 3 and 4</figref> are front and side sectional views, respectively, of a document scanner in accordance with the second aspect of the invention.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?DETDESC description="Detailed Description" end="lead"?>
<heading id="h-0005" level="1">DETAILED DESCRIPTION OF AN EMBODIMENT</heading>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. 1</figref> shows first and second linear-array CCD-based cameras <b>10</b> and <b>12</b> respectively. The first camera <b>10</b> generates a first image data word representative of a first portion of a scan line of a document and the second camera <b>12</b> generates a second image data word representative of a second, overlapping portion of the scan line. In the known method it is assumed that the document is always at a position <b>14</b>, and a terminal portion of the first word and an initial portion of the second word are discarded, the discarded portions of the words corresponding to the overlap of the first and second portions of the scan line, and the remainders of the first and second words are concatenated to generate an image data word representative of two contiguous portions of the scan line. This is illustrated by the intersection <b>16</b> of the respective effective fields of view, <b>18</b> and <b>20</b>, of the first and second cameras.</p>
<p id="p-0027" num="0026">If, however, the document is in fact at a position <b>22</b>, which is closer to the cameras than the assumed position <b>14</b>, and the same terminal portion of the first word and initial portion of the second word are discarded, the discarded portions will correspond to a portion of the scan line longer than the overlap of the first and second portions of the scan line. The image data word resulting from the concatenating the remainders of the first and second words will be representative of two discontinuous portions of the scan line. These discontinuous portions are denoted in <figref idref="DRAWINGS">FIG. 1</figref> by reference numerals <b>24</b> and <b>26</b>. A portion of the scan line between the two discontinuous portions, denoted in <figref idref="DRAWINGS">FIG. 1</figref> by reference numeral <b>28</b>, will fall outside the effective fields of view <b>18</b> and <b>20</b> of the cameras, and will be omitted from the image data word.</p>
<p id="p-0028" num="0027">If, on the other hand, the document is in fact at a position <b>30</b>, which is further from the cameras than the assumed position <b>14</b>, and the same terminal portion of the first word and initial portion of the second- word are discarded, the discarded portions will correspond to a portion of the scan line shorter than the overlap of the first and second portions of the scan line. The image data word resulting from concatenating the remainders of the first and second words will include data representative of two slightly overlapping portions of the scan line. These overlapping portions are denoted in <figref idref="DRAWINGS">FIG. 1</figref> by reference numerals <b>32</b> and <b>34</b>, with their overlap denoted by reference numeral <b>36</b>, which falls within the effective fields of view <b>18</b> and <b>20</b> of both cameras, and will be duplicated in the image data word.</p>
<p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. 2</figref> shows first and second linear-array CCD-based cameras <b>38</b> and <b>40</b>, which have respective actual fields of view <b>42</b> and <b>44</b>. A document can take any position from a far position <b>46</b> from the cameras to a near position <b>48</b> to the cameras. Whether in the far position <b>46</b> or the near position <b>48</b>, or anywhere between, in the method of the invention there is always an overlap of the actual fields of view of the cameras. The overlaps of the actual fields of view of the cameras with respect to the far and near positions <b>46</b> and <b>48</b> of the document are denoted in <figref idref="DRAWINGS">FIG. 2</figref> by reference numerals <b>50</b> and <b>52</b> respectively.</p>
<p id="p-0030" num="0029">The method of the invention is as follows:</p>
<p id="p-0031" num="0030">For each scan line of the document, a microprocessor, which, in the preferred embodiment of the second aspect of the invention, forms part of a programmed computer to which the document scanner is connected, receives first and second image data words A and B from respective first and second CCD-based cameras of a document scanner.</p>
<p id="p-0032" num="0031">Each image data word consists of a large number of data units, each of which corresponds to a pixel of the scan line. The microprocessor selects a data unit A_END from data word A and a data unit B_START from data word B. A_END and B_START correspond to the last and first data units of the remainders of data words A and B respectively, if predetermined portions of data words A and B were to be discarded in accordance with the known document scanning method, i.e. assuming that the distance from the document to the imaging elements is constant.</p>
<p id="p-0033" num="0032">The microprocessor cross-correlates a portion of data word A from unit A−25 to unit A+25 with a portion of data word B from unit B−25+p to B+25+p for values of p from −15 to +15, using the sum of the squares of the differences of the portions from data words A and B.</p>
<p id="p-0034" num="0033">The value of p that gives the smallest sum of the squares of the differences is stored by the microprocessor for each scan line. A negative value of p represents the number of pixels that would have been omitted from the scan line if the known document scanning method had been used, while a positive value of p represents the number of pixels that would have been duplicated in the scan line if the known document scanning method had been used.</p>
<p id="p-0035" num="0034">The microprocessor calculates a running average of the value of p for the scan line and for any preceding scan lines, then rounds the running average for the scan line to the nearest integer, p_real. The use of the running average p_real rather than p itself makes the effects of any spurious correlations on the image resulting from the image data less conspicuous.</p>
<p id="p-0036" num="0035">If p_real is zero, then the terminal portion of data word A from A_END+1 onwards is discarded, and the initial portion of data word B up to B_START−1 is discarded, and the remainders of words A and B are concatenated, such that B_START follows A_END. No further processing is necessary for the scan line.</p>
<p id="p-0037" num="0036">If p_real is negative, then the terminal portion of data word A from A_END+1 onwards is discarded, and the initial portion of data word B up to B_START−1+p_real is discarded. Data compression is used to compress the portion of the remainder of data word B from B_START+p_real to B_START+25 to 26 data units. The remainder of data word A and the compressed remainder of data word B are concatenated, such that B_START+p_real follows A_END.</p>
<p id="p-0038" num="0037">If p_real is positive, then the terminal portion of data word A from A_END+1 onwards is discarded, and the initial portion of data word B up to B_START−1+p_real is discarded.</p>
<p id="p-0039" num="0038">Linear interpolation is used to expand the portion of the remainder of data word B from B_START+p_real to B_START+25 to 26 data units. The remainder of data word A and the expanded remainder of data word B are concatenated, such that B_START follows A_END.</p>
<p id="p-0040" num="0039">The foregoing description relates to a document scanning method that uses only two imaging elements. The method can, however, be extended to use three or more imaging elements. In that case, the microprocessor would receive a third or subsequent data word C, select a data unit B_END in data word B and a data unit C_START in data word C, and apply the method as set out above in respect of data words A and B.</p>
<p id="p-0041" num="0040">The cross-correlation of the terminal and initial portions of data words B and C would not be affected by any compression or expansion of data word B, because the compression or expansion affects only the initial portion of data word B.</p>
<p id="p-0042" num="0041">Turning to <figref idref="DRAWINGS">FIGS. 3 and 4</figref>, a sheet-feed document scanner in accordance with the second aspect of the invention comprises a body <b>56</b> and lid <b>58</b>. The body <b>56</b> contains three CCD-based cameras <b>60</b>, <b>62</b> and <b>64</b>, lower pinch rollers, of which one is denoted by reference numeral <b>66</b>, motor <b>68</b> operable to drive the lower pinch rollers, and two fluorescent tubes <b>70</b> for illuminating a document as it is scanned.</p>
<p id="p-0043" num="0042">The lid contains upper pinch rollers, one of which is denoted by reference numeral <b>72</b>, which engage with the lower pinch rollers or a document as it is scanned. A direction of feed of a document as it is scanned is indicated by the arrow <b>74</b> of <figref idref="DRAWINGS">FIG. 4</figref>.</p>
<p id="p-0044" num="0043">In <figref idref="DRAWINGS">FIG. 3</figref> the document scanner is shown connected to a programmed computer <b>76</b> containing a microprocessor operable to process image data from the cameras <b>60</b>, <b>62</b> and <b>64</b> in accordance with the method of the first aspect of the invention.</p>
<p id="p-0045" num="0044">While the invention has been described with reference to one preferred embodiment, it is to be clearly understood by those skilled in the art that the invention is not limited thereto.</p>
<p id="p-0046" num="0045">Rather, the scope of the invention is to be interpreted only in conjunction with the appended claims.</p>
<?DETDESC description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>The invention claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text>1. A document scanning method for producing image data from a document from which data an image of the document can be produced, the method comprising the steps of causing relative movement between a document and both of first and second imaging elements at the same time, such that each of a succession of scan lines of the document is exposed in turn to the imaging elements; generating by means of the first and second imaging elements respective first and second image data words representative of respective first and second overlapping portions of each scan line, the first and second image data words being one-dimensional strings of pixel values; and concatenating at least a portion of each of the first and second words to generate a third image data word representative of the scan line, the third image data word being a one-dimensional string of pixel values, the method further including the steps of cross-correlating at least a portion of each of the first and second words to identify a portion of the second word that is included in the first word; discarding a portion of at least one of the first and second words; concatenating the first word or remainder thereof with the second word or remainder thereof to form the third image data word; and, if necessary, compressing or expanding the third word by linear interpolation so as to obtain an image data word of a predetermined length.</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text>2. A method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of cross-correlating at least a portion of each of the first and second words consists of cross-correlating a terminal portion of the first word with an initial portion of the second word, said terminal portion of the first word and initial portion of the second word including image data representative of an overlap of the first and second overlapping portions of a scan line.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text>3. A method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the steps of discarding a portion of at least one of the first and second words and concatenating the first word or remainder thereof with the second word or remainder thereof to form the third image data word consist of discarding a terminal portion of the first word and an initial portion of the second word, said terminal portion of the first word being substantially representative of a first half of the overlap of the first and second overlapping portions of the scan line, and said initial portion of the second word being substantially representative of a second half of the overlap of the first and second overlapping portions of the scan line, and concatenating the remainder of the first word with the remainder of the second word to form the third image data word.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text>4. A method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step, after identifying the portion of the second word that is included in the first word, of determining whether the length of said portion exceeds a predetermined value, which indicates that a spurious correlation has occurred, and if so, discarding a portion of at least one of the first and second words of a default length.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text>5. A method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising the steps, after identifying the portion of the second word that is included in the first word and determining that the length of said portion does not exceed the predetermined value, of subtracting the length of said portion from said default length to generate an offset value, determining a running average of the offset value and the offset values of any preceding scan lines, rounding the running average to the nearest integer, if necessary, and discarding a terminal portion of the first word and an initial portion of the second word of a length equal to one half of the sum of the rounded running average and default length.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text>6. A document scanner having first and second imaging elements, a scanning mechanism and a microprocessor, the microprocessor being operable to control the scanning mechanism and process image data from the first and second imaging elements to perform a document scanning method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text>7. A document scanner according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the microprocessor is contained in the document scanner.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text>8. A document scanner according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the microprocessor forms part of a programmed computer and the document scanner is operable to transmit the first and second words from the imaging elements to the computer and to receive the third image data words and control data from the computer.</claim-text>
</claim>
</claims>
</us-patent-grant>
